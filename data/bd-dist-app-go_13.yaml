- en: 'Chapter 10: Capturing Gin Application Metrics'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 10 章：捕获 Gin 应用指标
- en: In this final chapter, you will learn how to debug, troubleshoot, and monitor
    the RESTful API in near-real time. You will also learn how to collect Gin application
    metrics to measure the of the Gin application and to profile for abnormal behavior.
    Besides that, you will also explore how to stream Gin debug logs to a centralized
    logging platform using the ELK stack.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的最后一部分，你将学习如何在接近实时的情况下调试、故障排除和监控 RESTful API。你还将学习如何收集 Gin 应用指标来衡量 Gin 应用的性能，并对其异常行为进行剖析。除此之外，你还将探索如何使用
    ELK 堆栈将 Gin 调试日志流式传输到集中式日志平台。
- en: 'As such, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将涵盖以下主题：
- en: Exposing Gin application metrics with Prometheus
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Prometheus 暴露 Gin 应用指标
- en: Monitoring server-side metrics
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控服务器端指标
- en: Streaming Gin logs to the ELK platform
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 Gin 日志流式传输到 ELK 平台
- en: By the end of this chapter, you will be able to instrument and monitor a Dockerized
    Gin web application running in production and debug its logs with ease.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够仪表化和监控在生产中运行的 Docker 化 Gin 网络应用，并轻松调试其日志。
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To follow the content in this chapter, you will need the following:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 要跟随本章的内容，你需要以下条件：
- en: A complete understanding of the previous chapter. This chapter is a follow-up
    to the previous one as it will use the same source code. Hence, some snippets
    won't be explained to avoid repetition.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对前一章内容的完整理解。本章是前一章的后续，因为它将使用相同的源代码。因此，为了避免重复，一些代码片段将不会进行解释。
- en: It is assumed that you already have knowledge of Docker and containerization.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假设你已经具备 Docker 和容器化的知识。
- en: The code bundle for this chapter is hosted on GitHub at [https://github.com/PacktPublishing/Building-Distributed-Applications-in-Gin/tree/main/chapter10](https://github.com/PacktPublishing/Building-Distributed-Applications-in-Gin/tree/main/chapter10).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码包托管在 GitHub 上，网址为 [https://github.com/PacktPublishing/Building-Distributed-Applications-in-Gin/tree/main/chapter10](https://github.com/PacktPublishing/Building-Distributed-Applications-in-Gin/tree/main/chapter10)。
- en: Exposing Gin metrics with Prometheus
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Prometheus 暴露 Gin 指标
- en: In the previous chapter, you learned how to automate the deployment process
    for a Gin application. However, no app is immune from downtime or external attacks
    (**DDoS**). That's why you need to set up the right tools to constantly monitor
    the performance of your application. **Prometheus** ([https://prometheus.io](https://prometheus.io))
    is a common open source tool for monitoring applications.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一章中，你学习了如何自动化 Gin 应用的部署过程。然而，没有任何应用能够免疫停机或外部攻击（**DDoS**）。这就是为什么你需要设置正确的工具来持续监控你应用的性能。**Prometheus**
    ([https://prometheus.io](https://prometheus.io)) 是一种常见的开源监控工具。
- en: 'You can install the Go client by running the following command from your terminal
    session:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过在终端会话中运行以下命令来安装 Go 客户端：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, update the `main.go` file so that it exposes an HTTP route on the `/prometheus`
    path. The route handler will call the Prometheus HTTP handler, which will return
    a list of runtime and application metrics:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，更新 `main.go` 文件，使其在 `/prometheus` 路径上暴露一个 HTTP 路由。路由处理程序将调用 Prometheus HTTP
    处理程序，该处理程序将返回一系列运行时和应用指标：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Then, import the following package to use the `promhttp` struct:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，导入以下包以使用 `promhttp` 结构体：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Next, redeploy the application. If you navigate to [http://localhost:8080/prometheus](http://localhost:8080/prometheus),
    you should see the following metrics:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，重新部署应用。如果你导航到 [http://localhost:8080/prometheus](http://localhost:8080/prometheus)，你应该看到以下指标：
- en: '![Figure 10.1 – Prometheus default metrics'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 10.1 – Prometheus 默认指标'
- en: '](img/Figure_10.1_B17115.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 10.1 – Prometheus 默认指标'
- en: Figure 10.1 – Prometheus default metrics
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.1 – Prometheus 默认指标
- en: This application only exposes the default metrics. You can also expose your
    own custom metrics by instrumenting the Gin application code. Let's learn how
    to do that.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 此应用仅暴露默认指标。你也可以通过仪表化 Gin 应用代码来暴露你自己的自定义指标。让我们学习如何做到这一点。
- en: Instrumenting a Gin application
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对 Gin 应用进行仪表化
- en: Instrumentation is the ability to monitor and measure performance, detect errors,
    and get trace information that represents the application's state. Prometheus
    allows us to inject code to monitor a Gin application up close.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 仪表化是监控和测量性能、检测错误以及获取表示应用状态的跟踪信息的能力。Prometheus 允许我们注入代码来近距离监控 Gin 应用。
- en: 'To add a custom metric, such as counting the number of incoming requests, follow
    these steps:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 要添加一个自定义指标，例如计算传入请求数量，请按照以下步骤操作：
- en: 'First, we need to create a piece of middleware to intercept incoming HTTP requests
    and increment the counter:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要创建一个中间件来拦截传入的HTTP请求并增加计数器：
- en: '[PRE3]'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Then, we must define a piece of Gin middleware with the following code block:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们必须定义一个Gin中间件，如下所示：
- en: '[PRE4]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Next, register the `totalRequests` counter within the `init()` method''s body:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`init()`方法体内注册`totalRequests`计数器：
- en: '[PRE5]'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Then, pass the `PrometheusMiddleware` middleware to the Gin router:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，将`PrometheusMiddleware`中间件传递给Gin路由器：
- en: '[PRE6]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Restart the application and then refresh the `/prometheus` URL.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新启动应用程序，然后刷新`/prometheus` URL。
- en: 'In the response, you''ll see the number of requests per path:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在响应中，您将看到每个路径的请求数量：
- en: '![Figure 10.2 – Instrumenting Gin code'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.2 – 仪表化Gin代码'
- en: '](img/Figure_10.2_B17115.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.2_B17115.jpg)'
- en: Figure 10.2 – Instrumenting Gin code
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2 – 仪表化Gin代码
- en: Note
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Your output might not display as much data as mine since you have not accessed
    the application that often. The best way to get more data is to issue multiple
    HTTP requests to the Recipes API.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 您的输出可能不会显示像我那么多数据，因为您没有经常访问该应用程序。获取更多数据最好的方法是向Recipes API发出多个HTTP请求。
- en: 'Another useful metric you can expose is the number of HTTP requests that have
    been received per HTTP method. Similarly, define a global counter and increment
    the counter for the corresponding HTTP method:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以公开的另一个有用指标是每个HTTP方法接收到的HTTP请求数量。同样，定义一个全局计数器并为相应的HTTP方法增加计数器：
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Register the `totalHTTPMethods` counter within the `init()` method body and
    restart the application.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在`init()`方法体内注册`totalHTTPMethods`计数器并重新启动应用程序。
- en: 'Once the application has been restarted, in the response payload, you should
    see the number of requests partitioned by the HTTP method:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序重新启动后，在响应负载中，您应该看到按HTTP方法分区的请求数量：
- en: '![Figure 10.3 – Number of requests per HTTP method'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.3 – 每个HTTP方法的请求数量'
- en: '](img/Figure_10.3_B17115.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.3_B17115.jpg)'
- en: Figure 10.3 – Number of requests per HTTP method
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3 – 每个HTTP方法的请求数量
- en: 'You can also record the HTTP request latencies in seconds with the following
    code block. We''re using `Histogram` instead of `Counter` to count individual
    observations from incoming HTTP requests:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用以下代码块记录每秒的HTTP请求延迟。我们使用`Histogram`而不是`Counter`来计数来自HTTP请求的个别观察值：
- en: '[PRE8]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'As a result, you should have something similar to the following:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，您应该有类似以下的内容：
- en: '![Figure 10.4 – Duration of the HTTP requests'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.4 – HTTP请求的持续时间'
- en: '](img/Figure_10.4_B17115.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.4_B17115.jpg)'
- en: Figure 10.4 – Duration of the HTTP requests
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.4 – HTTP请求的持续时间
- en: Now that the metrics have been exposed, you can store them in a time-series
    database and build an interactive dashboard on top of that. Getting regular insights
    into how the app works can help you identify ways to optimize its performance.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在指标已经公开，您可以将它们存储在时间序列数据库中，并在其上构建一个交互式仪表板。定期了解应用程序的工作方式可以帮助您识别优化其性能的方法。
- en: Note
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'Another alternative is to use the following Go library, written by the open
    source community: [https://github.com/zsais/go-gin-prometheus](https://github.com/zsais/go-gin-prometheus).
    It comes with a generic set of metrics.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个选择是使用以下由开源社区编写的Go库：[https://github.com/zsais/go-gin-prometheus](https://github.com/zsais/go-gin-prometheus)。它包含一组通用的指标。
- en: 'To get started, follow these steps:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，请按照以下步骤操作：
- en: 'Deploy Prometheus by using the official Docker image with the following `docker-compose.yml`
    file:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下`docker-compose.yml`文件通过官方Docker镜像部署Prometheus：
- en: '[PRE9]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The Prometheus container uses a `prometheus.yml` configuration file, which
    defines a background job to scrape the Golang Prometheus metrics endpoint:'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Prometheus容器使用一个`prometheus.yml`配置文件，它定义了一个后台作业来抓取Golang Prometheus指标端点：
- en: '[PRE10]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Redeploy the application stack with the following command:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令重新部署应用程序堆栈：
- en: '[PRE11]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The stack logs should look similar to this:'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 栈日志应类似于以下内容：
- en: '![Figure 10.5 – Docker stack logs'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图10.5 – Docker堆栈日志'
- en: '](img/Figure_10.5_B17115.jpg)'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_10.5_B17115.jpg)'
- en: Figure 10.5 – Docker stack logs
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图10.5 – Docker堆栈日志
- en: Navigate to the Prometheus dashboard by visiting `localhost:9090` in your favorite
    browser. You can explore the available metrics by using the search bar and writing
    queries using the **Prometheus Query Language** (**PromQL**). Prometheus collects
    metrics by polling (scraping) instrumented Gin code:![Figure 10.6 – Exploring
    metrics from the Prometheus dashboard
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过访问您最喜欢的浏览器中的`localhost:9090`导航到 Prometheus 仪表板。您可以通过使用搜索栏和编写使用**Prometheus
    查询语言**（**PromQL**）的查询来探索可用的指标：![图 10.6 – 从 Prometheus 仪表板探索指标
- en: '](img/Figure_10.6_B17115.jpg)'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 Figure_10.6_B17115.jpg]'
- en: Figure 10.6 – Exploring metrics from the Prometheus dashboard
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 10.6 – 从 Prometheus 仪表板探索指标
- en: Turn the metrics into a chart by clicking on the **Graph** tab:![Figure 10.7
    – Using the built-in graph feature of Prometheus
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过点击**图形**选项卡将指标转换为图表：![图 10.7 – 使用 Prometheus 内置的图形功能
- en: '](img/B17115_10_07_v2.jpg)'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B17115_10_07_v2.jpg]'
- en: Figure 10.7 – Using the built-in graph feature of Prometheus
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 10.7 – 使用 Prometheus 内置的图形功能
- en: 'You can build advanced charts by using a visualization platform such as Grafana.
    It summarizes and visualizes data stored in Prometheus and provides a wide range
    of UI components to build user-friendly dashboards. The monitoring workflow is
    illustrated in the following schema:'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您可以使用如 Grafana 这样的可视化平台构建高级图表。它总结了 Prometheus 中存储的数据并提供了广泛的 UI 组件来构建用户友好的仪表板。监控工作流程在以下图中说明：
- en: '![Figure 10.8 – Collecting Gin metrics with Prometheus and Grafana'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 10.8 – 使用 Prometheus 和 Grafana 收集 Gin 指标'
- en: '](img/Figure_10.8_B17115.jpg)'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 Figure_10.8_B17115.jpg]'
- en: Figure 10.8 – Collecting Gin metrics with Prometheus and Grafana
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 10.8 – 使用 Prometheus 和 Grafana 收集 Gin 指标
- en: 'Deploy Grafana inside a Docker container with the following code snippet:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码片段在 Docker 容器中部署 Grafana：
- en: '[PRE12]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Spin up the container using the following command:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令启动容器：
- en: '[PRE13]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Head to `localhost:3000`; you'll be asked to enter some user credentials. The
    defaults are admin for both the username and password:![Figure 10.9 – Grafana
    login page
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到`localhost:3000`；您将被要求输入一些用户凭据。默认的用户名和密码都是admin：![图 10.9 – Grafana 登录页面
- en: '](img/Figure_10.9_B17115.jpg)'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 Figure_10.9_B17115.jpg]'
- en: Figure 10.9 – Grafana login page
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 10.9 – Grafana 登录页面
- en: Next, connect to Prometheus by creating a data source. Click on **Configuration**
    from the sidebar. Within the **Data Sources** tab, click on the **Add data source**
    button:![Figure 10.10 – Adding a new data source
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，通过创建数据源来连接到 Prometheus。点击侧边栏中的**配置**。在**数据源**选项卡中，点击**添加数据源**按钮：![图 10.10
    – 添加新的数据源
- en: '](img/Figure_10.10_B17115.jpg)'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 Figure_10.10_B17115.jpg]'
- en: Figure 10.10 – Adding a new data source
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 10.10 – 添加新的数据源
- en: 'After that, select **Prometheus** and then fill in the fields, as shown in
    the following screenshot. Then, click on the **Save & Test** button at the bottom
    of the page:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，选择**Prometheus**并填写字段，如图所示。然后，点击页面底部的**保存 & 测试**按钮：
- en: '![Figure 10.11 – Configuring a Prometheus data source'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.11 – 配置 Prometheus 数据源'
- en: '](img/Figure_10.11_B17115.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 Figure_10.11_B17115.jpg]'
- en: Figure 10.11 – Configuring a Prometheus data source
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.11 – 配置 Prometheus 数据源
- en: You're now ready to create your first Grafana dashboard!
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以创建您的第一个 Grafana 仪表板了！
- en: You can start by clicking on `http_requests_total` expression into the query
    field while using the `{{path}}` keyword in the `legend` field.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过在`legend`字段中使用`{{path}}`关键字的同时，点击`http_requests_total`表达式进入查询字段来开始。
- en: 'You should now have the following graph configuration, which represents the
    total number of HTTP requests over time per path:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在应该拥有以下图表配置，它表示每个路径随时间变化的HTTP请求总数：
- en: '![Figure 10.12 – Total number of HTTP requests'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.12 – HTTP 请求总数'
- en: '](img/B17115_10_12_v2.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17115_10_12_v2.jpg]'
- en: Figure 10.12 – Total number of HTTP requests
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.12 – HTTP 请求总数
- en: 'Save the panel and create a new one to display the response time of the served
    HTTP requests over time by using the `http_response_time_seconds_sum` expression:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 保存面板并创建一个新的面板，使用`http_response_time_seconds_sum`表达式显示随时间变化的已服务HTTP请求的响应时间：
- en: '![Figure 10.13 – HTTP response time'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.13 – HTTP 响应时间'
- en: '](img/B17115_10_13_v2.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 B17115_10_13_v2.jpg]'
- en: Figure 10.13 – HTTP response time
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.13 – HTTP 响应时间
- en: 'You can also create a single stat counter to display the total number of requests
    per HTTP method using the following configuration:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以创建一个单独的统计计数器来显示每个HTTP方法的总请求数，使用以下配置：
- en: '![Figure 10.14 – Using Grafana''s single stat component'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.14 – 使用 Grafana 的单统计组件'
- en: '](img/B17115_10_14_v2.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 B17115_10_14_v2.jpg]'
- en: Figure 10.14 – Using Grafana's single stat component
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.14 – 使用Grafana的单个统计组件
- en: 'You can experiment with the dashboard by adding other panels with metrics and
    customize it to your liking:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过添加其他带有指标的面板并按您的喜好自定义来实验仪表板：
- en: '![Figure 10.15 – Interactive and dynamic Grafana dashboard'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.15 – 交互式和动态的Grafana仪表板'
- en: '](img/B17115_10_15_v2.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17115_10_15_v2.jpg)'
- en: Figure 10.15 – Interactive and dynamic Grafana dashboard
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.15 – 交互式和动态的Grafana仪表板
- en: Note
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You can download `dashboard.json`, which contains the Grafana configuration
    for the preceding dashboard, from the GitHub repository under the `chapter10`
    folder.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从GitHub仓库下的`chapter10`文件夹中下载`dashboard.json`，它包含前面仪表板的Grafana配置。
- en: Monitoring server-side metrics
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控服务器端指标
- en: So far, you have learned how to monitor application-side metrics by instrumenting
    the Gin application code. In this section, you will learn how to expose server-side
    metrics and monitor the overall health of the containers running on the Gin distributed
    web application.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您已经学习了如何通过为Gin应用程序代码添加工具来监控应用侧的指标。在本节中，您将学习如何暴露服务器端指标并监控运行在Gin分布式Web应用程序上的容器的整体健康状况。
- en: 'To collect server-side metrics, you can use an open source solution called
    **Telegraf** ([https://github.com/influxdata/telegraf](https://github.com/influxdata/telegraf)),
    a **data collection agent** (**DCA**) that can collect metrics from multiple inputs
    and forward them to different sources:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 要收集服务器端指标，您可以使用一个名为**Telegraf** ([https://github.com/influxdata/telegraf](https://github.com/influxdata/telegraf))的开源解决方案，这是一个**数据收集代理**（**DCA**），可以从多个输入收集指标并将它们转发到不同的来源：
- en: '![Figure 10.16 – Collecting server-side metrics with the Telegraf agent'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.16 – 使用Telegraf代理收集服务器端指标'
- en: '](img/Figure_10.16_B17115.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/Figure_10.16_B17115.jpg)'
- en: Figure 10.16 – Collecting server-side metrics with the Telegraf agent
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.16 – 使用Telegraf代理收集服务器端指标
- en: 'Telegraf can be easily deployed using Docker. Add the following code block
    to `docker-compose.yml`:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: Telegraf可以很容易地使用Docker部署。将以下代码块添加到`docker-compose.yml`中：
- en: '[PRE14]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '`telegraf.conf` contains a list of data sources (**inputs**) where Telegraf
    will fetch data from. It also contains a list of destinations (**outputs**) where
    the data will be forwarded to. In the following configuration file, Telegraf will
    collect the metrics about the server resources (memory, CPU, disk, and network
    traffic) and Docker daemon (usage of resources per container), and then forward
    these metrics to the Prometheus server:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`telegraf.conf`包含Telegraf将从其中获取数据的数据源（**输入**）列表。它还包含数据将被转发到的目的地（**输出**）列表。在以下配置文件中，Telegraf将收集关于服务器资源（内存、CPU、磁盘和网络流量）和Docker守护进程（每个容器的资源使用情况）的指标，然后将这些指标转发到Prometheus服务器：'
- en: '[PRE15]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Note
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You can also forward these metrics to InfluxDB ([https://github.com/influxdata/influxdb](https://github.com/influxdata/influxdb)),
    a scalable time-series database, and connect it to Grafana.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以将这些指标转发到InfluxDB ([https://github.com/influxdata/influxdb](https://github.com/influxdata/influxdb))，一个可扩展的时间序列数据库，并将其连接到Grafana。
- en: 'Next, define a new job in `prometheus.yml` to scrape the metrics that have
    been exposed by the Telegraf container:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在`prometheus.yml`中定义一个新的作业以抓取Telegraf容器暴露的指标：
- en: '[PRE16]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'With that done, restart the stack with the following command:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些后，使用以下命令重新启动堆栈：
- en: '[PRE17]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Then, head back to the Prometheus dashboard and navigate to **Targets** from
    the **Status** dropdown list. A Telegraf target should have been added to the
    list:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，返回到Prometheus仪表板，并从**状态**下拉列表中选择**目标**。应该已经添加了一个Telegraf目标到列表中：
- en: '![Figure 10.17 – Telegraf job up and running'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.17 – Telegraf作业正在运行'
- en: '](img/Figure_10.17_B17115.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/Figure_10.17_B17115.jpg)'
- en: Figure 10.17 – Telegraf job up and running
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.17 – Telegraf作业正在运行
- en: With the server-side metrics now available in Prometheus, you can create additional
    panels in Grafana.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在服务器端指标已在Prometheus中可用，您可以在Grafana中创建额外的面板。
- en: 'For instance, you can select the `docker_container_mem_usage_percent` expression
    from the **Metrics** dropdown to monitor the memory usage per container over time:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，您可以从**指标**下拉菜单中选择`docker_container_mem_usage_percent`表达式来监控每个容器随时间变化的内存使用情况：
- en: '![Figure 10.18 – Memory usage per container'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.18 – 每个容器的内存使用情况'
- en: '](img/B17115_10_18_v2.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17115_10_18_v2.jpg)'
- en: Figure 10.18 – Memory usage per container
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.18 – 每个容器的内存使用情况
- en: 'Add additional metrics so that you can monitor the CPU, disk usage, or the
    overall health metrics of the running containers:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 添加额外的指标，以便您可以监控CPU、磁盘使用情况或运行容器的整体健康指标：
- en: '![Figure 10.19 – Server-side and application-side metrics'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.19 – 服务器端和应用端指标'
- en: '](img/B17115_10_19_v2.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.19 – 图 B17115_10_19_v2.jpg](img/Figure_10.19_B17115.jpg)'
- en: Figure 10.19 – Server-side and application-side metrics
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.19 – 服务器端和应用端指标
- en: Well done! Now, you have a pretty interactive dashboard for a minimum amount
    of time.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 干得好！现在，你有一个相当互动的仪表板，只需花费最少的时间。
- en: Creating a Grafana notification channel
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建 Grafana 通知渠道
- en: In the previous chapter, you learned how to use Slack to raise awareness about
    the CI/CD status for teams to take immediate actions. You can use the same approach
    while monitoring Gin applications by configuring a Slack alert on your **Grafana**
    dashboard when a certain threshold is reached.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你学习了如何使用 Slack 来提高团队对 CI/CD 状态的认识，以便团队可以立即采取行动。当达到某个阈值时，你可以通过在 **Grafana**
    仪表板上配置 Slack 警报来监控 Gin 应用程序，采用相同的方法。
- en: 'From the Grafana dashboard, click on the **Alerting** icon and click on **Notification
    channels**. Click on the **Add Channel** button and change the type to **Slack**.
    Then, input a Webhook URL:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 从 Grafana 仪表板中，点击 **警报** 图标，然后点击 **通知渠道**。点击 **添加渠道** 按钮，将类型更改为 **Slack**。然后输入
    Webhook URL：
- en: '![Figure 10.20 – Configuring a Slack notification channel'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.20 – 配置 Slack 通知渠道'
- en: '](img/Figure_10.20_B17115.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.20 – 图 10.20_B17115.jpg](img/Figure_10.20_B17115.jpg)'
- en: Figure 10.20 – Configuring a Slack notification channel
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.20 – 配置 Slack 通知渠道
- en: Note
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: For a step-by-step guide on how to create a Slack application and generate a
    Webhook URL, check out [*Chapter 9*](B17115_09_Final_JM_ePub.xhtml#_idTextAnchor146),
    *Implementing a CI/CD Pipeline.*
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取如何创建 Slack 应用程序并生成 Webhook URL 的分步指南，请查看 [*第 9 章*](B17115_09_Final_JM_ePub.xhtml#_idTextAnchor146)，*实现
    CI/CD 管道*。
- en: 'To test out the configuration, click on the **Test** button. You should get
    a message similar to the following in your configured Slack channel:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试配置，请点击 **测试** 按钮。你应该会在配置的 Slack 频道中收到类似以下的消息：
- en: '![Figure 10.21 – Slack test message from Grafana'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.21 – 来自 Grafana 的 Slack 测试消息'
- en: '](img/Figure_10.21_B17115.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.21 – 图 10.21_B17115.jpg](img/Figure_10.21_B17115.jpg)'
- en: Figure 10.21 – Slack test message from Grafana
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.21 – 来自 Grafana 的 Slack 测试消息
- en: 'Now that you have a notification channel, you can create an alerting rule on
    the dashboard panel. For instance, create an alert rule on the **HTTP Requests**
    graph that you created earlier and select the notification channel in the **Notifications**
    section. The rule will look as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你有了通知渠道，你可以在仪表板面板上创建一个警报规则。例如，在之前创建的 **HTTP 请求** 图表上创建一个警报规则，并在 **通知** 部分选择通知渠道。规则将如下所示：
- en: '![Figure 10.22 – Creating an alert rule in Grafana'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.22 – 在 Grafana 中创建警报规则'
- en: '](img/Figure_10.22_B17115.jpg)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.22 – 图 10.22_B17115.jpg](img/Figure_10.22_B17115.jpg)'
- en: Figure 10.22 – Creating an alert rule in Grafana
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.22 – 在 Grafana 中创建警报规则
- en: Every 30 seconds, Grafana will evaluate if the average number of HTTP requests
    is over 1,000 requests. If the metrics violate this rule, Grafana will wait for
    2 minutes. If, after 2 minutes, the metrics have not been recovered, Grafana will
    trigger an alert and a Slack notification will be sent.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 每 30 秒，Grafana 将评估平均 HTTP 请求次数是否超过 1,000 次。如果指标违反此规则，Grafana 将等待 2 分钟。如果 2 分钟后指标仍未恢复，Grafana
    将触发警报，并发送 Slack 通知。
- en: 'To test out the alert rule, you need to generate a workload. You can use **Apache
    Benchmark** to send 1,500 requests in parallel to the Recipes API with the following
    command:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试警报规则，你需要生成工作负载。你可以使用 **Apache Benchmark** 通过以下命令以并行方式向 Recipes API 发送 1,500
    个请求：
- en: '[PRE18]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Here, the number of requests for the `/recipes` endpoint will cross the 1,000
    threshold, as shown in the following graph:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`/recipes` 端点的请求数量将超过 1,000 的阈值，如下面的图表所示：
- en: '![Figure 10.23 – Reaching the 1,000 requests limit'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.23 – 达到 1,000 请求限制'
- en: '](img/Figure_10.23_B17115.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.23 – 图 10.23_B17115.jpg](img/Figure_10.23_B17115.jpg)'
- en: Figure 10.23 – Reaching the 1,000 requests limit
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.23 – 达到 1,000 请求限制
- en: 'After 2 minutes, the alert will be triggered, and you will see the following
    message on your Slack channel:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 2 分钟后，警报将被触发，你将在 Slack 频道中看到以下消息：
- en: '![Figure 10.24 – Slack alert from Grafana'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.24 – 来自 Grafana 的 Slack 警报'
- en: '](img/Figure_10.24_B17115.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.24 – 图 10.24_B17115.jpg](img/Figure_10.24_B17115.jpg)'
- en: Figure 10.24 – Slack alert from Grafana
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.24 – 来自 Grafana 的 Slack 警报
- en: Note
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Another option for setting up metrics alerts is using Prometheus Alertmanager
    ([https://prometheus.io/docs/alerting/latest/alertmanager](https://prometheus.io/docs/alerting/latest/alertmanager)).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 设置指标警报的另一种选项是使用 Prometheus Alertmanager ([https://prometheus.io/docs/alerting/latest/alertmanager](https://prometheus.io/docs/alerting/latest/alertmanager))。
- en: Having Slack notifications can help you take immediate action before things
    go horribly wrong in your production environment.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有Slack通知可以帮助你在生产环境中事情变得非常糟糕之前立即采取行动。
- en: Streaming Gin logs to the ELK platform
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将Gin日志流式传输到ELK平台
- en: Another beneficial aspect to keep an eye on while deploying a Gin web application
    in production is **logs**. Logs can help you find the root cause of bad application
    performance or crashes.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署Gin Web应用程序到生产环境中时，另一个需要关注的益处是**日志**。日志可以帮助你找到应用程序性能不佳或崩溃的根本原因。
- en: 'However, logs can be verbose and spammy – that''s why you''ll need a centralized
    platform to be able to apply filters and keep an eye on important events. That''s
    where a solution such as **Elasticsearch**, **Logstash**, and **Kibana** (**ELK**)
    is needed. The following schema illustrates how such a solution can be implemented:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，日志可能非常冗长且垃圾信息多 – 这就是为什么你需要一个集中式平台来应用过滤器并关注重要事件。这就是为什么需要一个像**Elasticsearch**、**Logstash**和**Kibana**（**ELK**）这样的解决方案。以下方案说明了如何实现这样的解决方案：
- en: '![Figure 10.25 – Streaming Gin logs to ELK'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.25 – 将Gin日志流式传输到ELK'
- en: '](img/Figure_10.25_B17115.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.25_B17115.jpg)'
- en: Figure 10.25 – Streaming Gin logs to ELK
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.25 – 将Gin日志流式传输到ELK
- en: Gin application logs will be shipped to Logstash using the Docker GELF driver
    ([https://docs.docker.com/config/containers/logging/gelf/](https://docs.docker.com/config/containers/logging/gelf/)).
    From there, Logstash will process the incoming logs and store them in Elasticsearch.
    Finally, the logs can be visualized in Kibana through interactive dashboards.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: Gin应用程序日志将通过Docker GELF驱动程序（[https://docs.docker.com/config/containers/logging/gelf/](https://docs.docker.com/config/containers/logging/gelf/））发送到Logstash。从那里，Logstash将处理传入的日志并将它们存储在Elasticsearch中。最后，日志可以通过Kibana的交互式仪表板进行可视化。
- en: Deploying the ELK stack with Docker
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Docker部署ELK堆栈
- en: 'By now, you should be familiar with Docker and be able to use it to deploy
    a Dockerized ELK stack using Docker Compose. To do so, follow these steps:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，你应该已经熟悉了Docker，并且能够使用它通过Docker Compose部署Docker化的ELK堆栈。为此，请按照以下步骤操作：
- en: 'Start with `docker-compose.yml`. The container uses the latest Docker image
    v7.12.1 (at the time of writing this chapter):'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`docker-compose.yml`开始。容器使用最新的Docker镜像v7.12.1（在撰写本章时）：
- en: '[PRE19]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The container uses a `logstash.conf` with the following content:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 容器使用以下内容的`logstash.conf`：
- en: '[PRE20]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Next, deploy the second component responsible for storing and indexing incoming
    logs. Elasticsearch can be deployed in a single-node mode with the following configuration:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，部署负责存储和索引传入日志的第二个组件。Elasticsearch可以以单节点模式部署，以下配置：
- en: '[PRE21]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Note
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: For production usage, it's highly recommended deploying Elasticsearch in a cluster
    mode with multiple data nodes to achieve high availability and resiliency.
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于生产使用，强烈建议以集群模式部署Elasticsearch，并使用多个数据节点以实现高可用性和弹性。
- en: 'Then, deploy the third component to visualize the incoming Gin logs in an interactive
    way. The following YAML block is responsible for deploying Kibana:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，部署第三个组件以交互式方式可视化传入的Gin日志。以下YAML块负责部署Kibana：
- en: '[PRE22]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Your ELK stack is now configured!
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 你的ELK堆栈现在已配置完成！
- en: 'With the ELK stack configured, you need to stream the Gin application logs
    to Logstash. Luckily, Docker has a built-in `GELF` driver that supports Logstash.
    To stream the Gin application logs to Logstash, apply the following steps:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 配置好ELK堆栈后，你需要将Gin应用程序日志流式传输到Logstash。幸运的是，Docker内置了支持Logstash的`GELF`驱动程序。要将Gin应用程序日志流式传输到Logstash，请执行以下步骤：
- en: 'Add the following `logging` section to the Recipes API YAML block:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下`logging`部分添加到Recipes API YAML块中：
- en: '[PRE23]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Redeploy the entire stack with `docker-compose up –d`. You can check whether
    all the services are up and running by running the `docker-compose ps` command:![Figure
    10.26 – List of running Docker services
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`docker-compose up –d`重新部署整个堆栈。你可以通过运行`docker-compose ps`命令来检查是否所有服务都在运行：![图10.26
    – 运行中的Docker服务列表
- en: '](img/Figure_10.26_B17115.jpg)'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_10.26_B17115.jpg)'
- en: Figure 10.26 – List of running Docker services
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图10.26 – 运行中的Docker服务列表
- en: Note
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Make sure Docker Engine is allotted at least 4 GiB of memory. In Docker Desktop,
    you can configure resource usage of the **Advanced** tab in **Preferences**.
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 确保Docker Engine至少分配了4 GiB的内存。在Docker Desktop中，你可以在**首选项**中的**高级**选项卡中配置资源使用情况。
- en: Then, point your browser to `localhost:5601`. You should be welcomed with the
    Kibana dashboard:![Figure 10.27 – Kibana welcome page
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，将你的浏览器指向`localhost:5601`。你应该会看到Kibana仪表板：![图10.27 – Kibana欢迎页面
- en: '](img/Figure_10.27_B17115.jpg)'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_10.27_B17115.jpg)'
- en: Figure 10.27 – Kibana welcome page
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图10.27 – Kibana欢迎页面
- en: Next, click on **Add data** and select **Elasticsearch logs** as a data source:![Figure
    10.28 – Adding data from Elasticsearch
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，点击**添加数据**并选择**Elasticsearch日志**作为数据源：![图10.28 – 从Elasticsearch添加数据
- en: '](img/B17115_10_28_v2.jpg)'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B17115_10_28_v2.jpg)'
- en: Figure 10.28 – Adding data from Elasticsearch
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图10.28 – 从Elasticsearch添加数据
- en: Click on `containers-*` in the **Index pattern name** field. The *asterix* is
    used to include all the logs coming from Logstash. Then, click on the **Next step**
    button:![Figure 10.29 – Creating an index pattern
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**索引模式名称**字段中点击`containers-*`。星号用于包含来自Logstash的所有日志。然后，点击**下一步**按钮：![图10.29
    – 创建索引模式
- en: '](img/Figure_10.29_B17115.jpg)'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/Figure_10.29_B17115.jpg)'
- en: Figure 10.29 – Creating an index pattern
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图10.29 – 创建索引模式
- en: Select `@timestamp` as the primary time field to use with the global time filter.
    Then, click on `containers` index:![Figure 10.31 – List of available fields in
    the containers index
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择`@timestamp`作为与全局时间过滤器一起使用的首选时间字段。然后，点击`containers`索引：![图10.31 – containers索引中可用的字段列表
- en: '](img/B17115_10_31_v2.jpg)'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B17115_10_31_v2.jpg)'
- en: Figure 10.31 – List of available fields in the containers index
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图10.31 – containers索引中可用的字段列表
- en: With Elasticsearch being connected with Kibana, click on **Discover** from the
    sidebar in the **Analytics** section. You should see a stream of logs coming from
    the Gin RESTful API:![Figure 10.32 – Gin logs in Kibana
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当Elasticsearch与Kibana连接时，点击**分析**部分侧边栏中的**发现**。您应该看到来自Gin RESTful API的日志流：![图10.32
    – Kibana中的Gin日志
- en: '](img/B17115_10_32_v2.jpg)'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B17115_10_32_v2.jpg)'
- en: Figure 10.32 – Gin logs in Kibana
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图10.32 – Kibana中的Gin日志
- en: Note
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: For production usage, you can use the curator tool ([https://www.elastic.co/guide/en/elasticsearch/client/curator/index.html](https://www.elastic.co/guide/en/elasticsearch/client/curator/index.html))
    to remove indices that are older than X days from Elasticsearch.
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于生产使用，您可以使用curator工具（[https://www.elastic.co/guide/en/elasticsearch/client/curator/index.html](https://www.elastic.co/guide/en/elasticsearch/client/curator/index.html)）从Elasticsearch中删除X天前的索引。
- en: Expand a row from the list of logs.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 展开日志列表中的一个行。
- en: 'You should see that the Gin application log is stored in a field called `message`:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到Gin应用程序日志存储在一个名为`message`的字段中：
- en: '![Figure 10.33 – Message field content'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.33 – 消息字段内容'
- en: '](img/B17115_10_33_v2.jpg)'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17115_10_33_v2.jpg)'
- en: Figure 10.33 – Message field content
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.33 – 消息字段内容
- en: Now, you have a working pipeline that reads Gin logs. However, you'll notice
    that the format of the log messages is not ideal. You can parse this field and
    split the important information into multiple fields using Grok expressions.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您有一个可以读取Gin日志的工作管道。然而，您会注意到日志消息的格式并不理想。您可以使用Grok表达式解析此字段并将重要信息拆分到多个字段中。
- en: Writing Grok expressions
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写Grok表达式
- en: 'Grok expressions work by parsing text patterns by using regular expressions
    and assigning them to an identifier. The syntax is `%{PATTERN:IDENTIFIER}`. We
    can write a sequence of Grok patterns and assign various pieces of the following
    log message to various identifiers:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: Grok表达式通过使用正则表达式解析文本模式并将它们分配给一个标识符来工作。语法是`%{PATTERN:IDENTIFIER}`。我们可以编写一系列Grok模式并将以下日志消息的各个部分分配给不同的标识符：
- en: '[PRE24]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The Grok pattern is as follows:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: Grok模式如下：
- en: '[PRE25]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Note
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Grok comes with its own dictionary of patterns that you can use out of the box.
    However, you can always define your own custom pattern.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: Grok自带一组模式字典，您可以直接使用。然而，您始终可以定义自己的自定义模式。
- en: You can test the pattern using the **Grok Debugger** feature on the **Dev Tools**
    page. In the **Sample Data** field, enter the previous message and in **Grok Pattern**,
    enter the Grok pattern.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用**Dev Tools**页面上的**Grok调试器**功能测试模式。在**样本数据**字段中输入前面的消息，在**Grok模式**中输入Grok模式。
- en: 'Then, click on **Simulate**; you''ll see the simulated event that results from
    applying the Grok pattern:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，点击**模拟**；您将看到应用Grok模式后产生的模拟事件：
- en: '![Figure 10.34 – Applying a Grok pattern to sample data'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.34 – 将Grok模式应用于样本数据'
- en: '](img/B17115_10_34_v2.jpg)'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17115_10_34_v2.jpg)'
- en: Figure 10.34 – Applying a Grok pattern to sample data
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.34 – 将Grok模式应用于样本数据
- en: Note
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: If an error occurs, you can continue iterating over the custom pattern until
    the output matches the event that you expect.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 如果发生错误，您可以继续迭代自定义模式，直到输出与您期望的事件匹配。
- en: 'Now that you have a working Grok pattern, you can apply parsing at the Logstash
    level. To do this, update the `logstash.conf` file so that it includes a filter
    section, as follows:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经有一个工作的Grok模式，您可以在Logstash级别应用解析。为此，更新`logstash.conf`文件，使其包括一个过滤器部分，如下所示：
- en: '[PRE26]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now, if you restart the Logstash container, the incoming logs should be parsed
    and split into multiple fields:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果您重新启动 Logstash 容器，传入的日志应该被解析并分割成多个字段：
- en: '![Figure 10.35 – Message field split into multiple fields'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.35 – 消息字段分割成多个字段'
- en: '](img/Figure_10.35_B17115.jpg)'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.35_B17115.jpg)'
- en: Figure 10.35 – Message field split into multiple fields
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.35 – 消息字段分割成多个字段
- en: 'Create a new dashboard and click on **Create panel** to create a new chart:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的仪表板并单击 **创建面板** 以创建一个新的图表：
- en: '![Figure 10.36 – Creating a new Kibana dashboard'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.36 – 创建新的 Kibana 仪表板'
- en: '](img/Figure_10.36_B17115.jpg)'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.36_B17115.jpg)'
- en: Figure 10.36 – Creating a new Kibana dashboard
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.36 – 创建新的 Kibana 仪表板
- en: 'Drag the `status.keyword` field and drop it into the panel. Then, select a
    **Stacked bar** chart. You should get the following chart, which represents the
    number of requests per HTTP status code:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 将 `status.keyword` 字段拖放到面板中。然后，选择一个 **堆叠柱状图**。您应该得到以下图表，它表示每个 HTTP 状态码的请求数量：
- en: '![Figure 10.37 – Building a chart with the Kibana chart builder'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.37 – 使用 Kibana 图表构建器构建图表'
- en: '](img/B17115_10_37_v2.jpg)'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17115_10_37_v2.jpg)'
- en: Figure 10.37 – Building a chart with the Kibana chart builder
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.37 – 使用 Kibana 图表构建器构建图表
- en: You can save the stacked bar chart as a widget and import it into a dashboard.
    With a dashboard, you can combine multiple visualizations onto a single page,
    then filter them by providing a search query or by selecting filters by clicking
    elements in the visualization. Dashboards are useful when you want to get an overview
    of your Gin application logs and make correlations among various visualizations
    and logs.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以将堆叠柱状图保存为小部件并将其导入仪表板。使用仪表板，您可以将多个可视化组合到单个页面上，然后通过提供搜索查询或通过在可视化中单击元素来选择过滤器来过滤它们。仪表板在您想要获取
    Gin 应用程序日志的概览并在不同可视化之间建立关联时非常有用。
- en: Updating the Gin logging format
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更新 Gin 日志格式
- en: By default, Gin records every request field to **standard output** (**stdout**),
    which is awesome for troubleshooting and debugging HTTP request errors. However,
    this can be too verbose for other developers and they can get lost easily and
    miss the important events. Luckily, you can override this default behavior by
    creating a custom log formatter.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Gin 将每个请求字段记录到 **标准输出**（**stdout**），这对于故障排除和调试 HTTP 请求错误非常棒。然而，对于其他开发者来说，这可能过于冗长，他们可能会很快迷失方向并错过重要事件。幸运的是，您可以通过创建自定义日志格式来覆盖此默认行为。
- en: 'To create a custom log format with Gin, start with the following code block:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 Gin 创建自定义日志格式，请从以下代码块开始：
- en: '[PRE27]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The code will log the request timestamp, HTTP method, path, status code, and
    duration:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 代码将记录请求时间戳、HTTP 方法、路径、状态码和持续时间：
- en: '![Figure 10.38 – Gin custom log format'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.38 – Gin 自定义日志格式'
- en: '](img/Figure_10.38_B17115.jpg)'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.38_B17115.jpg)'
- en: Figure 10.38 – Gin custom log format
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.38 – Gin 自定义日志格式
- en: 'By default, Gin will output all logs to `stdout`, but you can disable them
    by setting `GIN_MODE` to release mode with the following command:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Gin 将所有日志输出到 `stdout`，但您可以通过设置 `GIN_MODE` 为发布模式来禁用它们，以下命令：
- en: '[PRE28]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '![Figure 10.39 – Running Gin in release mode'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.39 – 以发布模式运行 Gin'
- en: '](img/Figure_10.39_B17115.jpg)'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.39_B17115.jpg)'
- en: Figure 10.39 – Running Gin in release mode
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.39 – 以发布模式运行 Gin
- en: 'You can also override the log destination so that it''s a file instead of `stdout`
    with the following code block:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以通过以下代码块覆盖日志目标，使其成为文件而不是 `stdout`：
- en: '[PRE29]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'As a result, a new file called `debug.log` should be created alongside the
    application logs:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，应该会创建一个名为 `debug.log` 的新文件，与应用程序日志一起：
- en: '![Figure 10.40 – Streaming logs to a file'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.40 – 将日志流式传输到文件'
- en: '](img/Figure_10.40_B17115.jpg)'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.40_B17115.jpg)'
- en: Figure 10.40 – Streaming logs to a file
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.40 – 将日志流式传输到文件
- en: 'You can stream the file''s content to Elasticsearch with Filebeat. **Filebeat**
    can be used as a replacement for Logstash:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用 Filebeat 将文件内容流式传输到 Elasticsearch。**Filebeat** 可以作为 Logstash 的替代品：
- en: '![Figure 10.41 – Shipping log files with Filebeat to ELK'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.41 – 使用 Filebeat 将日志文件发送到 ELK'
- en: '](img/Figure_10.41_B17115.jpg)'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.41_B17115.jpg)'
- en: Figure 10.41 – Shipping log files with Filebeat to ELK
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.41 – 使用 Filebeat 将日志文件发送到 ELK
- en: 'Add the following YAML block to `docker-compose.yml` to deploy a container
    based on the Filebeat v7.12.1 image:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 将以下 YAML 块添加到 `docker-compose.yml` 以基于 Filebeat v7.12.1 映像部署容器：
- en: '[PRE30]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The container will look in `/usr/share/filebeat` for the configuration file.
    The configuration file is provided through bind mounts (see the *volumes* section).
    The file''s content is as follows. It will listen for logs coming from `/var/log/api/debug.log`
    and echo any that are received by Elasticsearch:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 容器将在 `/usr/share/filebeat` 中查找配置文件。配置文件通过绑定挂载提供（见 *卷* 部分）。文件的内容如下。它将监听来自 `/var/log/api/debug.log`
    的日志，并将接收到的任何日志回显到 Elasticsearch：
- en: '[PRE31]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Restart the stack with the `docker-compose up –d` command. The list of running
    Docker services is as follows:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `docker-compose up –d` 命令重新启动堆栈。正在运行的 Docker 服务列表如下：
- en: '![Figure 10.42 – Filebeat running as a Docker container'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.42 – 以 Docker 容器形式运行的 Filebeat'
- en: '](img/Figure_10.42_B17115.jpg)'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.42_B17115.jpg)'
- en: Figure 10.42 – Filebeat running as a Docker container
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.42 – 以 Docker 容器形式运行的 Filebeat
- en: 'Issue a few requests to the Recipes API. At this point, Gin will forward the
    logs to `debug.log` and Filebeat will stream them into Elasticsearch. From there,
    you can visualize them in real time in Kibana:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 向 Recipes API 发出几项请求。此时，Gin 将将日志转发到 `debug.log`，Filebeat 将它们流式传输到 Elasticsearch。从那里，你可以在
    Kibana 中实时可视化它们：
- en: '![Figure 10.43 – Visualizing logs coming from Filebeat'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.43 – 来自 Filebeat 的日志可视化'
- en: '](img/Figure_10.43_B17115.jpg)'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_10.43_B17115.jpg)'
- en: Figure 10.43 – Visualizing logs coming from Filebeat
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.43 – 来自 Filebeat 的日志可视化
- en: Great! You can now use the Kibana dashboard to analyze Gin logs in real time.
    Analyzing those logs can provide a lot of information that helps with troubleshooting
    the root cause of Gin application failure.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了！你现在可以使用 Kibana 仪表板实时分析 Gin 日志。分析这些日志可以提供大量信息，有助于解决 Gin 应用程序失败的根本原因。
- en: Summary
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned how to instrument Gin application code to expose
    application-side metrics using Prometheus. You saw how to build a dynamic dashboard
    with Grafana to monitor the overall health of a Gin application in near-real time,
    as well as how to trigger a Slack alert when certain thresholds are crossed.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了如何使用 Prometheus 仪器化 Gin 应用程序代码以暴露应用程序端指标。你看到了如何使用 Grafana 构建动态仪表板，以近乎实时地监控
    Gin 应用程序的整体健康状况，以及当某些阈值被跨越时如何触发 Slack 警报。
- en: Then, you learned how to stream Gin logs to a centralized logging platform built
    using open source tools such as Logstash, Elasticsearch, and Kibana. Along the
    way, you learned how to parse Gin logs with Grok patterns and how to build charts
    on top of these parsed fields.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你学习了如何将 Gin 日志流式传输到使用开源工具（如 Logstash、Elasticsearch 和 Kibana）构建的集中式日志平台。在这个过程中，你学习了如何使用
    Grok 模式解析 Gin 日志，以及如何在这些解析字段之上构建图表。
- en: Congratulations! Now, you can design, build, and deploy a distributed Gin application
    from scratch. You also have a solid foundation regarding how to automate the deployment
    workflow and monitor a running Gin application in production.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！现在，你可以从头开始设计、构建和部署分布式 Gin 应用程序。你还有一个关于如何自动化部署工作流程和在生产中监控运行中的 Gin 应用程序的良好基础。
- en: Further reading
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '*Learn Grafana 7.0* by Eric Salituro, Packt publishing'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《学习 Grafana 7.0》* 由 Eric Salituro 著，Packt 出版'
- en: '*Hands-On Infrastructure Monitoring with Prometheus* by Joel Bastos and Pedro
    Arajo, Packt publishing'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《使用 Prometheus 进行动手基础设施监控》* 由 Joel Bastos 和 Pedro Arajo 著，Packt 出版'
- en: Conclusion
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: We're at the end of our journey through this book! You've made it to the very
    end. I hope that you're proud of the journey you've taken. You've learned the
    ins and outs of the Gin framework and put together a fully functional distributed
    Gin application.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了这本书的旅程！你已经走到了尽头。我希望你对这段旅程感到自豪。你已经了解了 Gin 框架的方方面面，并构建了一个完全功能化的分布式 Gin
    应用程序。
- en: By now, you should know all you need to know to build a scalable Dockerized
    Gin application, from handling multiple Git branches with GitFlow to automating
    the build on AWS with a CI/CD pipeline, troubleshooting and monitoring in near-real-time,
    and generating API documentation with OpenAPI.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，你应该已经知道如何构建一个可扩展的 Docker 化 Gin 应用程序了，从处理多个 Git 分支的 GitFlow 到在 AWS 上使用
    CI/CD 管道自动化构建，再到近乎实时地故障排除和监控，以及使用 OpenAPI 生成 API 文档。
- en: There's a lot to absorb and learn in this book, especially if this is your first
    exposure to the Gin framework. I find that the best way to learn is by doing,
    so take the RESTful API you've built and add new features to it. And if you do
    build something, reach out to me and tell me what you've done.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中有很多东西需要吸收和学习，尤其是如果你这是第一次接触 Gin 框架。我发现最好的学习方式是通过实践，所以请将你构建的 RESTful API
    添加新功能。如果你真的构建了什么，请与我联系并告诉我你做了什么。
