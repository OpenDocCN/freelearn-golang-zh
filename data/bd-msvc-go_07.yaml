- en: Logging and Monitoring
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日志和监控
- en: Logging and monitoring are not advanced topics. However, they are one of those
    things that you do not realize just how important they are until you do not have
    them. Useful data about your service is essential to understanding the load and
    environment that your service is operating in so that you can make sure that it
    is finely tuned to give the very best performance.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 日志和监控不是高级话题。然而，它们是那些你直到没有它们才意识到它们有多重要的事情之一。关于你的服务的有用数据对于理解你的服务正在运行的负载和环境至关重要，这样你就可以确保它被精细调整以提供最佳性能。
- en: 'Consider this example: when you first launch your service, you have an endpoint
    which returns a list of kittens. Initially, this service is responding promptly
    with a 20 ms response time; however, as people start to add items to the service,
    the speed slows to 200 ms. The first part of this problem is that you need to
    know about this slowdown. If you work in e-commerce, there is a direct correlation
    between the time it takes to process a request or a page to load and the likelihood
    that your customers will buy something.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑这个例子：当你首次推出你的服务时，你有一个返回小猫列表的端点。最初，这个服务响应迅速，响应时间为20毫秒；然而，随着人们开始向服务中添加项目，速度减慢到200毫秒。这个问题的第一部分是你需要了解这种减速。如果你从事电子商务，处理请求或页面加载所需的时间与客户购买东西的可能性之间存在直接关联。
- en: One of the traditional methods for determining speed has always been to look
    at things from the edge; you use something such as Google Analytics, and you measure
    page load speed as experienced by the end user.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 确定速度的传统方法之一一直是查看边缘的情况；你使用像谷歌分析这样的工具，并测量最终用户所体验到的页面加载速度。
- en: The first problem with this is that you have no idea where the slowdown originates.
    When we built monolithic applications, this was simple; the slowdown was either
    extra cruft which had been added to the HTML or it was the monolithic app server.
    So the app server may have some metrics output to a log file; however, due to
    the nature of the application only having one attached data store you did not
    have to look at many places before you found the source.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题的第一个问题是，你不知道减速是从哪里开始的。当我们构建单体应用时，这很简单；减速要么是添加到HTML中的额外冗余，要么是单体应用服务器。因此，应用服务器可能将一些指标输出到日志文件；然而，由于应用程序只有一个附加的数据存储，你不需要查看很多地方就能找到源头。
- en: Everything changes with microservices; instead of one application, you may have
    1,000, instead of one data store, you may have 100, and dozens of other associated
    services such as cloud storage queues and message routers. You could take the
    same approach to guess and test, but you will end up with a deep-seated hatred
    for yourself and all your colleagues who built the system.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务出现后，一切都会改变；你可能有1000个应用，而不是一个；你可能有一个数据存储，而不是100个，还有数十个其他相关服务，如云存储队列和消息路由器。你可以采取相同的猜测和测试方法，但最终你可能会对你自己和所有构建该系统的同事产生深深的厌恶。
- en: 'Problem number 2: using Google Analytics will not easily tell you if the site
    is slowing down when it is under load. How will you know when you experience an
    outage? If the page is not loading because the back end server is not responding,
    then the JavaScript which fires data to Google Analytics will not fire. Can you
    even set up an alert in Google Analytics to fire an alarm when the average load
    time drops below a threshold?'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 第2个问题：使用谷歌分析并不能轻易告诉你当网站在负载下时是否会变慢。当你遇到故障时，你将如何知道？如果页面没有加载是因为后端服务器没有响应，那么向谷歌分析发送数据的JavaScript将不会触发。你甚至能在谷歌分析中设置一个警报，当平均加载时间低于某个阈值时发出警报吗？
- en: 'Problem number 3: you don''t have a website only an API; bye bye Google analytics.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 第3个问题：你只有一个API，没有网站；再见了，谷歌分析。
- en: Now, I am not saying you should not use Google Analytics; what I am saying is
    that it should form part of a larger strategy.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我并不是说你不应该使用谷歌分析；我想要说的是，它应该成为更大策略的一部分。
- en: 'Stack traces and other application output which helps you diagnose a problem
    can be broken down into three categories::'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 堆栈跟踪和其他有助于诊断问题的应用程序输出可以分为三类：
- en: '**Metrics**: These are things such as time series data (for example, transaction
    or individual component timings).'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指标**：这些是诸如时间序列数据（例如，交易或单个组件的计时）之类的东西。'
- en: '**Text-based logs**: Text-based records are your real old-fashioned logs which
    are spat out by things such as Nginx or a text log from your application software.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于文本的日志**：基于文本的记录是真正的老式日志，由Nginx或其他应用程序软件的文本日志等生成。'
- en: '**Exceptions**: Exceptions potentially could fall into the two previous categories;
    however, I like to break these out into a separate category since exceptions should
    be, well, exceptional.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异常**：异常可能属于前两个类别之一；然而，我喜欢将这些内容分开成单独的类别，因为异常应该是，嗯，异常的。'
- en: As always the source code for this chapter is available on GitHub you can find
    it at [https://github.com/building-microservices-with-go/chapter7](https://github.com/building-microservices-with-go/chapter7)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如往常一样，本章的源代码可在GitHub上找到，你可以在[https://github.com/building-microservices-with-go/chapter7](https://github.com/building-microservices-with-go/chapter7)找到。
- en: Logging best practices
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日志最佳实践
- en: 'In the free e-book, *The pragmatic logging handbook*, by Jon Gifford of Loggly
    (www.loggly.com), Jon proposes the following eight best practices to apply when
    determining your logging strategy:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在免费的电子书《实用日志手册》中，Jon Gifford（Loggly，www.loggly.com）提出了以下八个最佳实践，这些实践适用于确定你的日志策略：
- en: Treat application logging as an ongoing iterative process. Log at a high level
    and then add deeper instrumentation.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将应用程序日志视为一个持续迭代的流程。先进行高层次记录，然后添加更深入的仪表化。
- en: Always instrument anything that goes out of the process because distributed
    system problems are not well behaved.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总是记录任何超出流程范围的内容，因为分布式系统的问题表现不佳。
- en: Always log unacceptable performance. Log anything outside the range in which
    you expect your system to perform.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总是记录不可接受的性能。记录任何超出你期望系统性能范围的任何内容。
- en: If possible, always log enough context for a complete picture of what happened
    from a single log event.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果可能，始终记录足够多的上下文，以便从单个日志事件中获得完整的事件画面。
- en: View machines as your end consumer, not humans. Create records that your log
    management solution can interpret.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将机器视为你的最终消费者，而不是人类。创建你的日志管理解决方案可以解释的记录。
- en: Trends tell the story better than data points.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 趋势比数据点更能讲述故事。
- en: Instrumentation is NOT a substitute for profiling and vice versa.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仪表化不能替代分析，反之亦然。
- en: Flying more slowly is better than flying blind. So the debate is not whether
    to instrument, just how much.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 慢速飞行比盲目飞行要好。因此，争论的焦点不是是否要进行仪表化，而是仪表化的程度。
- en: I think there is one of these points which need a little more explanation, that
    is "Instrumentation is NOT a substitute for profiling and vice versa." What Jon
    is referring to is that while your application may have high levels of logging
    and monitoring, you should still run through a pre-release process of profiling
    the application code. We looked at tools like Go's profiler, and we have also
    done some basic performance testing with the bench tool. However for a production
    service a more thorough approach should be taken, it is beyond the scope of this
    book to look at performance testing in depth, however, I would encourage you to
    read "Performance Testing with JMeter 3" by Bayo Erinle published by Packt for
    further information on this topic.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为其中有一个观点需要更多的解释，那就是“仪表化不能替代分析，反之亦然。”乔恩指的是，虽然你的应用程序可能有高水平的日志和监控，但你仍然应该运行一个预发布流程来分析应用程序代码。我们研究了Go的剖析工具，并且我们也使用bench工具进行了一些基本的性能测试。然而，对于生产服务，应该采取更彻底的方法，本书的范围不包括深入探讨性能测试，但我鼓励你阅读Packt出版的Bayo
    Erinle所著的《使用JMeter 3进行性能测试》以获取更多关于这个主题的信息。
- en: Metrics
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指标
- en: In my opinion, metrics are the most useful form of logging for day-to-day operations.
    Metrics are useful because we have simple numeric data. We can plot this onto
    a time series dashboard and quite quickly set up alerting from the output as the
    data is incredibly cheap to process and collect.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来，指标是日常运营中最有用的日志形式。指标之所以有用，是因为我们有简单的数值数据。我们可以将这些数据绘制到时间序列仪表板上，并且可以相当快速地从输出中设置警报，因为数据处理和收集的成本极低。
- en: No matter what you are storing, the superior efficiency of metrics is that you
    are storing numeric data in a time-series database using a unique key as an identifier.
    Numeric data allows the computation and comparison of the data to be incredibly
    efficient. It also allows the data store to reduce the resolution of the data
    as time progresses, enabling you to have granular data when you need it most at
    the right time and retain historical reference data without requiring petabytes
    of data storage.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你存储什么，指标的高效性在于你使用唯一键作为标识符，在时间序列数据库中存储数值数据。数值数据允许数据的计算和比较非常高效。它还允许数据存储在时间推移时降低数据的分辨率，使你在需要时能够拥有细粒度数据，同时保留历史参考数据，而无需需要PB级的数据存储。
- en: Types of data best represented by metrics
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指标最适合表示的数据类型
- en: 'This is quite simple: it is the data that is meaningful when expressed by simple
    numbers, such as request timings and counts. How granular you want to be with
    your metrics depends upon your requirements; generally, when I am building a microservice
    I start with top line metrics such as request timings, success, and failure counts
    for handlers, and if I am using a datastore, then I would include these too. As
    the service develops and I start performance testing things, I will start to add
    new items that help me diagnose performance problems with the service.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这相当简单：这是通过简单的数字表达时具有意义的数值数据，例如请求定时和计数。你希望你的指标有多细取决于你的需求；通常，当我构建微服务时，我会从顶线指标开始，例如处理器的请求定时、成功和失败计数，如果我在使用数据存储，那么我也会包括这些。随着服务的发展，我开始进行性能测试，我将会开始添加帮助我诊断服务性能问题的新的项目。
- en: Naming conventions
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 命名规范
- en: 'Defining a naming convention is incredibly important, as once you start to
    collect data, a point will come where you need to analyze it. The key thing for
    me is not to define a convention for your service but a convention that is useful
    for your entire estate. When you start to investigate issues with your service,
    more often than not, you will find that the problem is not necessarily with your
    service but could be due to a multitude of things:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 定义命名规范非常重要，因为一旦你开始收集数据，就会有一个需要分析数据的时候。对我来说，关键不是为你的服务定义一个规范，而是一个对你的整个环境有用的规范。当你开始调查你的服务问题时，往往你会发现问题并不一定出在你的服务上，而可能是由于许多其他因素：
- en: Exhausted CPU on host server
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主机服务器上的CPU耗尽
- en: Exhausted memory
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存耗尽
- en: Network latency
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络延迟
- en: Slow data store queries
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 慢速数据存储查询
- en: Latency with downstream service caused by any of the preceding factors
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于任何前面的因素导致的下游服务的延迟
- en: 'I recommend you break up the name of your service using dot notation such as
    the following:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我建议你使用点符号如以下方式拆分你的服务名称：
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '`environment`: This is the working environment; for example: production, staging'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`environment`: 这是工作环境；例如：生产，预发布'
- en: '`host`: This is the hostname of the server running the application'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`host`: 这是运行应用程序的服务器的主机名'
- en: '`service`: The name of your service'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`service`: 你的服务名称'
- en: '`group`: This is the top level grouping; for an API, this might be handlers'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`group`: 这是顶级分组；对于API，这可能是处理器'
- en: '`segment`: The child level information for the group; this will typically be
    the name of the handler in the instance of an API'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`segment`: 该组的孩子级信息；这通常是在API实例中处理器的名称'
- en: '`outcome`: This is something which denotes the result of the operation, in
    an API you may have called, success, or you may choose to use HTTP status codes'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`outcome`: 这表示操作的结果，在API中你可能已经调用，成功，或者你可能选择使用HTTP状态码'
- en: 'Here is an example of how to use the following dot notation:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个如何使用以下点符号的示例：
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'If your monitoring solution supports tags in addition to the event name, then
    I recommend you use tags for the environment and host, this will make querying
    the data store a little easier. For example, if I have a handler which lists kittens
    which are running on my production server then I may choose to add the following
    events to be emitted when the handler is called:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的监控解决方案支持事件名称之外的标签，那么我建议你使用标签来表示环境和主机，这将使查询数据存储变得更容易。例如，如果我有一个处理器，它列出了在我的生产服务器上运行的猫咪，那么我可能会选择在处理器被调用时发出以下事件：
- en: '[PRE2]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This is a pseudo code, but you can see that we are dispatching three events
    from this handler:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个伪代码，但你可以看到我们从该处理器派发了三个事件：
- en: The first event is that we are going so send some timing information.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一件事是我们将要发送一些定时信息。
- en: In the next, we are simply going to send an increment count which is simply
    going to state that the handler has been called.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在接下来的操作中，我们只是将要发送一个增量计数，这仅仅表明处理程序已被调用。
- en: Finally, we are going to check if the operation has been successful. If not,
    we increment our handler-failed metric; if successful, we increment our success
    metric.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将检查操作是否成功。如果不成功，我们将增加我们的处理失败指标；如果成功，我们将增加我们的成功指标。
- en: 'Naming our metrics in this way allows us to graph errors either on a granular
    level or makes it possible to write a query which is at a higher level. For example,
    we may be interested in the total number of failed requests for the entire service,
    not just this endpoint. Using this naming convention, we can query using wildcards;
    so to query all failures for this service, we could write a metric like the following
    code:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式命名我们的指标允许我们在粒度级别或更高层次上绘制错误。例如，我们可能对整个服务的总失败请求数量感兴趣，而不仅仅是这个端点。使用这种命名约定，我们可以使用通配符进行查询；因此，为了查询这个服务的所有失败，我们可以编写如下代码：
- en: '[PRE3]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'If we were interested in all failed requests to handlers for all services,
    we could write the following query:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们对所有服务的处理程序的所有失败请求都感兴趣，我们可以编写以下查询：
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Having a consistent naming convention for metrics is essential. Add this to
    your upfront design when building a service and implement this as a company-wide
    standard, not just on a team level. Let''s take a look at some example code to
    see just how easy it is to implement `statsD`. If we take a look at `chapter7/main.go`,
    we can see that on line **19**, we are initializing our `statsD` client:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 为指标保持一致的命名约定是至关重要的。在构建服务时，将此添加到你的前期设计中，并作为公司范围内的标准实现，而不仅仅是团队层面的标准。让我们看看一些示例代码，看看实现
    `statsD` 是多么简单。如果我们查看 `chapter7/main.go`，我们可以在第 **19** 行看到我们初始化了我们的 `statsD` 客户端：
- en: '[PRE5]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We are using an open source package by Alex Cesaro ([https://github.com/alexcesaro/statsd](https://github.com/alexcesaro/statsd)).
    This has a very simple interface; to create our client, we call the new function
    and pass it a list of options. In this instance, we are only passing through the
    address of the `statsD` server, which has been set by an environment variable:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用由 Alex Cesaro 开发的开源包（[https://github.com/alexcesaro/statsd](https://github.com/alexcesaro/statsd)）。这个接口非常简单；为了创建我们的客户端，我们调用新函数并传递一个选项列表。在这个例子中，我们只传递
    `statsD` 服务器的地址，该地址已由环境变量设置：
- en: '[PRE6]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'If we look at line **27** in the file `cserver/handlers/helloworld.go`, we
    are deferring the sending of the timing data until the handler completes:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看文件 `cserver/handlers/helloworld.go` 中的第 **27** 行，我们是在处理程序完成之前延迟发送定时数据：
- en: '[PRE7]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The start time will be the time of execution of the defer statement so this
    should be the first line of your file; the end time will be once the deferred
    statement executes. If this handler is middleware and you are calling a downstream
    in a chain, then remember that the execution time of all the downstream calls
    will also be included in this metric. To exclude this, we can create a new `Timing`
    in line **27** and then call the send method manually just before we execute the
    next middleware in the chain:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 开始时间将是延迟语句执行的时间，因此这应该是你文件的第一行；结束时间将在延迟语句执行后。如果你在这个链中调用下游，并且这个处理程序是中间件，那么请记住，所有下游调用的执行时间也将包含在这个指标中。为了排除这一点，我们可以在第
    **27** 行创建一个新的 `Timing`，然后在执行链中的下一个中间件之前手动调用发送方法：
- en: '[PRE8]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'If you take a look at line **35**, you will see we are calling the increment
    method when the request completes successfully:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看第 **35** 行，你会看到我们在请求成功完成时调用增量方法：
- en: '[PRE9]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The `Increment` function will increase the count for the given bucket by one,
    and these are fascinating metrics to have in your application as they give you
    a really interesting picture of the health and status:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`Increment` 函数将给定的桶的计数增加一个，这些是在你的应用程序中非常有吸引力的指标，因为它们为你提供了一个关于健康和状态的真正有趣的画面：'
- en: '[PRE10]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The `statsD` client does not work synchronously, sending each metric when you
    make a call to the client; instead, it buffers all the calls, and there is an
    internal goroutine which sends the data at a predetermined interval. This makes
    the operation highly efficient, and you should not have to worry about any application
    slowdown.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '`statsD` 客户端不是同步工作的，每次调用客户端时都会发送每个指标；相反，它将所有调用缓冲起来，并且有一个内部goroutine会在预定的时间间隔发送数据。这使得操作非常高效，你不需要担心任何应用程序的减速。'
- en: Storage and querying
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 存储和查询
- en: There are multiple options for storing and querying metric data; you have the
    possibility for self-hosting, or you can utilize a software as a service. How
    you manage this is dependent upon your company's scale and the security requirement
    for your data.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 存储和查询度量数据有多种选择；你可以选择自托管，或者你可以利用软件即服务。如何管理这取决于你公司的规模和对你数据的安全要求。
- en: Software as a service
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 软件即服务
- en: 'For software as a service (SaaS), I recommend looking at Datadog. To send metrics
    to Datadog, you have two options: one is to communicate with the API directly;
    the other is to run the Datadog collector as a container inside your cluster.
    The Datadog collector allows you to use `StatsD` as your data format and it supports
    a couple of nice extensions which standard `StatsD` does not, such as the ability
    to add additional tags or metadata to your metrics. Tagging allows you to categorize
    your data by user-defined tags, this allows you to keep your metric names specific
    to what they are monitoring without having to add environmental information.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 对于软件即服务（SaaS），我建议查看Datadog。要将度量标准发送到Datadog，你有两种选择：一种是与API直接通信；另一种是在你的集群内部运行Datadog收集器作为容器。Datadog收集器允许你使用`StatsD`作为数据格式，并且它支持一些标准的`StatsD`不支持的扩展，例如添加额外的标签或元数据到你的度量标准。标签允许你通过用户定义的标签对数据进行分类，这允许你保持度量标准名称与它们所监控的内容相关，而无需添加环境信息。
- en: Self-hosted
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自托管
- en: While it may be desirable to use a SaaS service for your production data, it
    is always useful to be able to run a server locally for local development. There
    are many options for backend data stores such as Graphite, Prometheus, InfluxDB,
    and ElasticSearch; however, when it comes to graphing, Grafana leads the way.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然使用SaaS服务来处理生产数据可能是可取的，但始终能够本地运行服务器进行本地开发是有用的。有多个后端数据存储选项，如Graphite、Prometheus、InfluxDB和ElasticSearch；然而，当涉及到图形化时，Grafana是领先的选择。
- en: Let's spin up a Docker Compose stack for our list, kittenservice, so we can
    run through the simple steps of setting up Prometheus with Grafana with Docker
    Compose.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为我们的列表，kittenservice，启动一个Docker Compose堆栈，这样我们就可以通过Docker Compose来运行设置Prometheus与Grafana的简单步骤。
- en: 'If we look at the Docker compose file, we can see that we have three entries:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看Docker compose文件，我们可以看到我们有三个条目：
- en: '`statsD`'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`statsD`'
- en: '`grafana`'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`grafana`'
- en: '`prometheus`'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prometheus`'
- en: StatsD is not a `statsD` server as such but a `statsD` exporter; this exposes
    an endpoint which Prometheus can use to collect the statistics. Unlike Graphite,
    which you push metrics to, Prometheus pulls stats.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: StatsD不是一个`statsD`服务器，而是一个`statsD`导出器；它暴露了一个端点，Prometheus可以使用它来收集统计数据。与将度量标准推送到Graphite不同，Prometheus是拉取统计数据。
- en: Prometheus is the database server which is used for collecting the data.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus是用于收集数据的数据库服务器。
- en: Grafana is what we will use for graphing our data.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana是我们将用于图形化我们的数据。
- en: 'If we take a look at the Docker Compose file `docker-compose.yml`, which is
    located at the root of our source repository, we will see that the Prometheus
    section requires some particular configuration:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看位于我们源代码库根目录的Docker Compose文件`docker-compose.yml`，我们会看到Prometheus部分需要一些特定的配置：
- en: '[PRE11]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We are mounting a volume which contains the Prometheus configuration. Let''s
    take a look at it:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在挂载一个包含Prometheus配置的卷。让我们看看它：
- en: '[PRE12]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The first part of this configuration sets the intervals for fetching the data
    from our sources and also the intervals upon which they will be evaluated. The
    default value for the scrape interval is one minute. We have reduced this for
    our example, as we are impatient and we would like to see our metrics update almost
    immediately after we have made a request to the server. However, in practice,
    we are not really interested in real-time data. A lag of a minute is OK. The next
    part is the scrape configs; these are the settings which define our data which
    we would like to import into Prometheus. The first element is our `statsD` collector;
    we point this to the collector defined in our `docker-compose` file. As we are
    using a link between our two containers, we can use the link name in the config.
    The next item is the configuration for Prometheus' performance metrics. We do
    not have to enable this; however, metrics are critical so it would make sense
    to monitor the health of our metrics database.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 此配置的第一部分设置了从我们的数据源获取数据的时间间隔以及它们将被评估的时间间隔。抓取间隔的默认值为一分钟。在我们的示例中，我们将其减少，因为我们没有耐心，并且希望在向服务器发出请求后几乎立即看到我们的指标更新。然而，在实践中，我们并不真正对实时数据感兴趣。一分钟的时间延迟是可以接受的。下一部分是抓取配置；这些是我们希望导入Prometheus的数据的设置。第一个元素是我们的`statsD`收集器；我们将它指向在`docker-compose`文件中定义的收集器。由于我们在这两个容器之间使用了一个链接，我们可以在配置中使用链接名称。下一个项目是Prometheus性能指标的配置。我们不必启用它；然而，指标是至关重要的，因此监控我们的指标数据库的健康状况是有意义的。
- en: Grafana
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Grafana
- en: 'To display these metrics, we are going to use Grafana. If we start our stack
    by using the `make runserver` command and wait for a few moments for the server
    to start, we can then execute a few curls to the endpoint to start populating
    the system with data:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 为了显示这些指标，我们将使用Grafana。如果我们通过使用`make runserver`命令启动我们的堆栈并等待服务器启动几分钟，然后我们可以执行几个curl到端点以开始向系统中填充数据：
- en: '[PRE13]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Let''s log into Grafana and have a look at some of the data we have collected.
    Point your browser at `[docker host ip]:3000` and you should be presented with
    a login screen. The default username and password is `admin`:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们登录到Grafana，查看我们收集的一些数据。将您的浏览器指向`[docker host ip]:3000`，您应该会看到一个登录界面。默认用户名和密码是`admin`：
- en: '![](img/f0845d43-63cd-4e9c-9631-915e01fb3197.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f0845d43-63cd-4e9c-9631-915e01fb3197.png)'
- en: 'Once you have logged in, the first thing we want to do is to configure our
    data source. Unfortunately, there seems to be no way to set up this automatically
    with configuration files. There is an API if you need to provision in an environment
    outside of your local machine; it should be pretty trivial to write something
    which syncs data using this:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 登录后，我们首先想做的就是配置我们的数据源。不幸的是，似乎没有方法可以通过配置文件自动设置。如果您需要在本地机器之外的环境中配置，有一个API；如果您需要使用这个API来同步数据，应该很容易编写一些代码：
- en: '[http://docs.grafana.org/http_api/data_source/](http://docs.grafana.org/http_api/data_source/)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://docs.grafana.org/http_api/data_source/](http://docs.grafana.org/http_api/data_source/)'
- en: 'Configuring the data source is relatively straightforward. All we need to do
    is to select Prometheus as our data type and then fill in the connection details.
    You need to ensure that you select proxy as opposed to direct. Proxy makes the
    calls for data from the Grafana server; direct will use your browser. Once we
    have done that, let''s add the default dashboard for the Prometheus server:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 配置数据源相对简单。我们所需做的只是选择Prometheus作为我们的数据类型，然后填写连接细节。您需要确保您选择代理而不是直接连接。代理会从Grafana服务器调用数据；直接连接将使用您的浏览器。一旦我们完成这些，让我们添加Prometheus服务器的默认仪表板：
- en: '![](img/83a732df-b4a7-44af-85c0-47849ec1c702.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/83a732df-b4a7-44af-85c0-47849ec1c702.png)'
- en: 'If you click the dashboards tab, you will see that you have the ability to
    import a pre-created dashboard. This is useful but what we want to do is create
    our own dashboard from our server. To do this, hit the dashboards link and then
    choose new dashboard. This will take you to the dashboards creation page. We are
    going to add a graph of our requests. So let''s select the Graph option. In the
    bottom panel, we have the ability to add the metrics we would like to show; if
    we already know the name of the dashboard, then all we need to do is type the
    expression into the box:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你点击仪表板选项卡，你会看到你可以导入预创建的仪表板。这很有用，但我们想从我们的服务器创建自己的仪表板。为此，点击仪表板链接，然后选择新的仪表板。这将带你去仪表板创建页面。我们将添加一个请求的图表。所以让我们选择图形选项。在底部面板中，我们有添加我们想要显示的指标的能力；如果我们已经知道仪表板的名称，那么我们只需要在框中输入表达式：
- en: '![](img/79023681-8e3f-4c46-91d2-a12e1d36ea2f.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/79023681-8e3f-4c46-91d2-a12e1d36ea2f.png)'
- en: 'The metrics lookup allows us to search for metrics based on part of the name.
    If we type `kitten` into this box, then all the metrics from our simple API that
    have been tagged with kitten will show up in the box. For now, let''s select the
    validation success metric. By default, this metric is a count of all the times
    that the metric was reported for the given time interval. This is why you see
    the graph. While this may be useful in some instances, what we would like to see
    is a nice bar chart showing the successes for a given period. To do this, we can
    use one of the many expressions to group this data:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 指标查找允许我们根据名称的一部分搜索指标。如果我们在这个框中输入`kitten`，那么所有标记为kitten的简单API指标都会显示在这个框中。目前，让我们选择验证成功指标。默认情况下，这个指标是给定时间间隔内指标报告次数的总数。这就是为什么你会看到图表。虽然这可能在某些情况下很有用，但我们想看到的是显示给定期间成功的良好条形图。为此，我们可以使用许多表达式之一来分组这些数据：
- en: '[PRE14]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This expression will group the data into buckets of 30 seconds and will return
    the difference between the current and the previous bucket. In effect, what this
    gives us is a chart showing the number of successes every 30 seconds. To present
    the information, a bar graph would most likely be better, so we can change this
    option in the display tab. Changing the step setting to the same interval as the
    duration we set in our increase expression, will make the chart look a little
    more readable. Now add a second query for the timings of our hello world handler.
    This time we do not need to aggregate the data into buckets, as we are fine displaying
    it on the graph as it is. Timing metrics show three lines, the average (quartile,
    0.5), the top 10% (quartile, 0.9), and the top 1% (quartile, 0.99). In general,
    we would like to see these lines quite tightly grouped together, which indicates
    little variance in our service calls. We do not see this in our graph, even though
    we are performing the same operation time and time again, due to line 149 in the
    code:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这个表达式会将数据分组到30秒的桶中，并返回当前桶与上一个桶之间的差异。实际上，这给我们的是一个每30秒显示成功次数的图表。为了展示信息，条形图可能更合适，因此我们可以在显示选项卡中更改此选项。将步长设置与我们在增加表达式中设置的持续时间相同的间隔，会使图表看起来更易于阅读。现在添加第二个查询以获取hello
    world处理程序的计时。这次我们不需要将数据聚合到桶中，因为我们可以在图表上直接显示它。计时指标显示三条线，平均（四分位数，0.5），顶部10%（四分位数，0.9），以及顶部1%（四分位数，0.99）。一般来说，我们希望这些线非常紧密地聚集在一起，这表明我们的服务调用变化很小。尽管我们一次又一次地执行相同的操作，但我们没有在图表中看到这一点，这是由于代码中的第149行：
- en: '[PRE15]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Our handler was running just too fast to measure < 1 ms so I added a little
    random wait to make the graph more interesting:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的处理程序运行得太快，以至于无法测量< 1 ms，所以我添加了一点点随机等待，使图表更有趣：
- en: '![](img/7383b913-f642-4dc7-9eec-a028f330d4f8.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7383b913-f642-4dc7-9eec-a028f330d4f8.png)'
- en: That is the basics for simple metrics; for logging more detailed information,
    we need to fall back to trusty log files. The days of pulling data from servers
    are long gone, and in our highly distributed world this would be a nightmare.
    Thankfully, we have tools such as Elasticsearch and Kibana.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是简单指标的基本知识；要记录更详细的信息，我们需要回到可靠的日志文件。从服务器中提取数据的日子已经一去不复返了，在我们高度分布的世界里，这将是一场噩梦。幸运的是，我们有像Elasticsearch和Kibana这样的工具。
- en: Logging
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 记录
- en: When working with highly distributed containers, you may have 100 instances
    of your application running rather than one or two. This means that if you need
    to grep your log files, you will be doing this over hundreds of files instead
    of just a couple. In addition, Docker-based applications should be stateless and
    the scheduler may be moving them around on multiple hosts. This adds an extra
    layer of complexity to manage. To save the trouble, the best way to solve this
    problem is not to write the logs to disk in the first place. A distributed logging
    store, such as an ELK stack, or software as a service platform, such as Logmatic
    or Loggly, solve this problem for us and give us a fantastic insight into the
    health and operating condition of our system. Regarding the cost, you will most
    likely find that one of the SasS providers is cheaper than running and maintaining
    your ELK stack. However, your security needs may not always allow this. Retention
    is also an interesting problem while looking at logging. My personal preference
    is to only store log data for short periods of time, such as 30 days; this allows
    you to maintain diagnostic traces which could be useful for troubleshooting without
    the cost of maintaining historical data. For historical data, a metrics platform
    is best, as you can cheaply store this data over a period of years, which can
    be useful to compare current performance with that of a historic event.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 当与高度分布式的容器一起工作时，你可能会有100个你的应用程序实例在运行，而不是一个或两个。这意味着，如果你需要grep你的日志文件，你将需要在数百个文件上执行此操作，而不是仅仅在几个文件上。此外，基于Docker的应用程序应该是无状态的，调度器可能会在多个主机之间移动它们。这增加了管理复杂性的一层。为了避免麻烦，最好的解决方法是从一开始就不将日志写入磁盘。一个分布式的日志存储，如ELK堆栈，或者软件即服务平台，如Logmatic或Loggly，为我们解决了这个问题，并为我们提供了关于系统健康和运行状况的绝佳洞察。至于成本，你很可能会发现，SaaS提供商中有一个比运行和维护你的ELK堆栈更便宜。然而，你的安全需求可能并不总是允许这样做。在查看日志时，保留也是一个有趣的问题。我个人的偏好是只存储日志数据短时间，例如30天；这允许你维护诊断跟踪，这对于故障排除可能是有用的，而不必承担维护历史数据的成本。对于历史数据，一个度量平台是最好的，因为你可以以低廉的成本存储这些数据数年，这可以用来比较当前性能与历史事件。
- en: Distributed tracing with Correlation IDs
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用关联ID进行分布式跟踪
- en: 'In [Chapter 2](b4c0c222-3d5d-458d-bd03-25a2a9082230.xhtml), *Designing a Great
    API*, we looked at the header `X-Request-ID` which allows us to mark all the service
    calls for an individual request with the same ID so that we can later query them.
    This is an incredibly important concept when it comes to debugging a request as
    it can dramatically help you understand why a service may be failing or misbehaving
    by looking at the tree of requests and the parameters passed to them. If you take
    a look at the file `handlers/correlation.go`, we can implement this quite simply:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第2章](b4c0c222-3d5d-458d-bd03-25a2a9082230.xhtml)“设计一个优秀的API”中，我们探讨了头部`X-Request-ID`，它允许我们使用相同的ID标记所有针对单个请求的服务调用，这样我们就可以稍后查询它们。当涉及到调试请求时，这是一个极其重要的概念，因为它可以极大地帮助你通过查看请求树和传递给它们的参数来理解为什么一个服务可能会失败或行为异常。如果你查看`handlers/correlation.go`文件，我们可以非常简单地实现这一点：
- en: '[PRE16]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The handler is implemented using the middleware pattern when we wish to use
    it all we need to do is wrap the actual handler like so:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们希望使用处理器时，它是通过中间件模式实现的，我们只需要像这样包装实际的处理器即可：
- en: '[PRE17]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Now every time a request is made to the `/helloworld` endpoint, the header `X-Request-ID`
    will be appended to the request with a random UUID if it is not already present.
    This is a very simple method of adding distributed tracing into your application,
    depending upon your requirements you may like to check out Zipkin is a distributed
    tracing system designed to trouble shoot latency, which is becoming incredibly
    popular [http://zipkin.io.](http://zipkin.io) There are also tools from DataDog,
    NewRelic, and AWS X-Ray, it is too much to go into depth into these applications,
    however, please spend an hour and familiarize yourself with their capabilities
    as you never know when you are going to need them.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在每次向`/helloworld`端点发出请求时，如果请求中尚未包含，`X-Request-ID`头部将附加一个随机UUID。这是一种非常简单的方法将分布式跟踪添加到你的应用程序中，根据你的需求，你可能想了解一下Zipkin，这是一个设计用来解决延迟问题的分布式跟踪系统，它正变得越来越流行[http://zipkin.io.](http://zipkin.io)。还有来自DataDog、NewRelic和AWS
    X-Ray的工具，不过深入探讨这些应用程序可能有些过于复杂。然而，请花一个小时熟悉它们的特性，因为你永远不知道何时会需要它们。
- en: Elasticsearch, Logstash, and Kibana (ELK)
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Elasticsearch、Logstash和Kibana（ELK）
- en: Elasticsearch, Logstash, and Kibana are pretty much the industry standard when
    it comes to logging verbose data. All of the output which would traditionally
    be streamed to a log file is stored in a central location which you can query
    with a graphical interface tool, Kibana.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到日志详细数据时，Elasticsearch、Logstash 和 Kibana 几乎是行业标准。所有传统上会流式传输到日志文件的输出都存储在中央位置，你可以使用图形界面工具
    Kibana 进行查询。
- en: 'If we look at our Docker Compose file, you will see three entries for our ELK
    stack:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看我们的 Docker Compose 文件，你会看到三个条目用于我们的 ELK 堆栈：
- en: '[PRE18]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Elasticsearch is our datastore for our logging data, Kibana is the application
    we will use for querying this data, and Logstash is used for reading the data
    from your application logs and storing it in Elasticsearch. The only configuration,
    besides a few environment variables, is the logstash config:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Elasticsearch 是我们日志数据的存储库，Kibana 是我们将用于查询这些数据的应用程序，Logstash 用于从应用程序日志中读取数据并将其存储在
    Elasticsearch 中。除了几个环境变量之外，唯一的配置是 logstash 配置：
- en: '[PRE19]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The input configuration allows us to send our logs direct over TCP to the Logstash
    server. This saves us the problem of writing to disk and then Logstash having
    to read these files. In general, TCP is probably going to be faster, disk I/O
    is not free, and the contention caused by writing a log file sequentially can
    slow down your application. Dependent upon your appetite for risk, you may choose
    to use UDP as transport for your logs. This will be faster than TCP; however,
    this speed comes at the expense that you will not get a confirmation that the
    data has been received and you may lose some logs.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 输入配置允许我们直接通过 TCP 将日志发送到 Logstash 服务器。这避免了写入磁盘的问题，并且 Logstash 需要读取这些文件。一般来说，TCP
    可能会更快，磁盘 I/O 不是免费的，并且顺序写入日志文件引起的竞争可能会减慢你的应用程序。根据你对风险的承受能力，你可能选择使用 UDP 作为日志的传输协议。这比
    TCP 快，然而，这种速度是以你不会收到数据已接收的确认，并且可能会丢失一些日志为代价的。
- en: '"I would tell you a joke about UDP, but you might not get it."'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: “我要给你讲一个关于 UDP 的笑话，但你可能听不懂。”
- en: 'In general, this is not too much of a problem unless you need your logs for
    security auditing. In this instance, you could always configure multiple inputs
    for different log types. Logstash has the capability to grep many common output
    formats for logs and transform these into JSON format which can be indexed by
    Elasticsearch. Since our logs in our example application area are already in JSON
    format, we can set the type to JSON and Logstash will not apply any transformation.
    In the output section, we are defining our datastore; again, like the Prometheus
    configuration, we can use the link address provided by Docker for our URI:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，这不会造成太大的问题，除非你需要日志进行安全审计。在这种情况下，你可以为不同的日志类型配置多个输入。Logstash 有能力 grep 许多常见的日志输出格式，并将这些转换为
    JSON 格式，以便由 Elasticsearch 索引。由于我们示例应用程序区域的日志已经以 JSON 格式存在，我们可以将类型设置为 JSON，Logstash
    不会应用任何转换。在输出部分，我们定义了我们的数据存储库；同样，就像 Prometheus 配置一样，我们可以使用 Docker 提供的链接地址作为我们的
    URI：
- en: '[https://www.elastic.co/guide/en/logstash/current/configuration.html](https://www.elastic.co/guide/en/logstash/current/configuration.html)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.elastic.co/guide/en/logstash/current/configuration.html](https://www.elastic.co/guide/en/logstash/current/configuration.html)'
- en: Kibana
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kibana
- en: 'Start your stack if it is not already running and send a little data to Elasticsearch:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如果堆栈尚未运行，请启动它并向 Elasticsearch 发送少量数据：
- en: '[PRE20]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now point your browser at `http://192.168.165.129:5601`. The first screen you
    should see if you are starting with a new setup is the one which prompts you to
    create a new index in Elasticsearch. Go ahead and create this using the defaults;
    you will now see the list of fields that Elasticsearch can index from your logs:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，将你的浏览器指向 `http://192.168.165.129:5601`。如果你是第一次设置，你应该看到的第一个屏幕是提示你在 Elasticsearch
    中创建新索引的屏幕。使用默认设置创建这个索引；现在，你应该会看到 Elasticsearch 可以从你的日志中索引的字段列表：
- en: '![](img/9bf720f8-bb47-48e3-8e1e-0acc1ad5dd08.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9bf720f8-bb47-48e3-8e1e-0acc1ad5dd08.png)'
- en: 'If need be, you can change these settings. However, generally you will be fine
    with the defaults. The Kibana screen is relatively straightforward. If you switch
    to the Discover tab, you will be able to see some of the logs that have been collected:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，你可以更改这些设置。然而，通常情况下，默认设置就足够了。Kibana 的屏幕相对简单。如果你切换到“发现”标签，你将能够看到一些已收集的日志：
- en: '![](img/b6bc674f-ade7-43e6-9390-d6f4ed5d56f9.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b6bc674f-ade7-43e6-9390-d6f4ed5d56f9.png)'
- en: 'Expanding one of the entries will show the indexed fields in more detail:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 展开其中一个条目将显示索引字段的更多详细信息：
- en: '![](img/d2e55101-6519-40a3-a6b1-1ea52d313d67.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d2e55101-6519-40a3-a6b1-1ea52d313d67.png)'
- en: 'To filter the logs by one of these fields, you can enter the filter in the
    search bar at the top of the window. Search criteria must be written in Lucene
    format, so to filter our list by status code, we can enter the following query:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 要通过这些字段之一过滤日志，你可以在窗口顶部的搜索栏中输入过滤器。搜索条件必须以Lucene格式编写，因此要按状态码过滤我们的列表，我们可以输入以下查询：
- en: '[PRE21]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This filters the by `status` field containing the numeric value `200`. Whilst
    searching indexed fields is relatively straightforward, we have added the bulk
    of our data into the message field where it is stored as a JSON string:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过滤器通过包含数字值`200`的`status`字段进行过滤。虽然搜索索引字段相对简单，但我们已经将大部分数据添加到`message`字段中，该字段以JSON字符串的形式存储：
- en: '[PRE22]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'To filter our list to only show `POST` actions, we can use a query containing
    a REGEX search:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 要将我们的列表过滤为仅显示`POST`操作，我们可以使用包含正则表达式搜索的查询：
- en: '![](img/5d691f4c-e193-45d8-9e1c-1ce5b9129285.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/5d691f4c-e193-45d8-9e1c-1ce5b9129285.png)'
- en: 'REGEX search terms will be slower than indexed queries, as each item has to
    be evaluated. If we find that there is a particular field we are always referring
    to and would like to speed up these filters, then we have two options. The first
    and the most awkward is to add a *grok* section to our Logstash configuration:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式搜索项将比索引查询慢，因为每个项目都必须被评估。如果我们发现有一个特定的字段我们总是引用并且希望加快这些过滤速度，那么我们有两个选项。第一个也是最尴尬的选项是向我们的Logstash配置中添加一个`*grok*`部分：
- en: '[https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html#plugins-filters-grok-add\_field](https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html#plugins-filters-grok-add/_field)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html#plugins-filters-grok-add\_field](https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html#plugins-filters-grok-add/_field)'
- en: 'The other option is to specify these fields when we are preparing the data
    to log. If you look at the example code, you can see that we are extracting the
    method out and while this is also going into the `message` field, we are logging
    this using the `WithFields` method, which will allow Logstash to index this. If
    you take a look at line **37** of the `chandlers/helloworld.go` file, you can
    see this in action:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个选项是在我们准备记录数据时指定这些字段。如果你查看示例代码，你会看到我们正在提取方法，并且虽然这也会进入`message`字段，但我们使用`WithFields`方法来记录这个，这将允许Logstash对其进行索引。如果你查看`chandlers/helloworld.go`文件的**第37行**，你可以看到这个操作的实际应用：
- en: '[PRE23]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'In our example, we are using the Logrus logger. Logrus is a structured logger
    for Go which supports many different plugins. In our example, we are using the
    Logstash plugin which allows you to send our logs direct to the Logstash endpoint
    rather than writing them to a file and then having Logstash pick them up:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，我们使用Logrus日志记录器。Logrus是Go的一个结构化日志记录器，支持许多不同的插件。在我们的示例中，我们使用Logstash插件，该插件允许你将日志直接发送到Logstash端点，而不是将它们写入文件然后让Logstash拾取：
- en: '[PRE24]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Adding plugins to Logrus is very simple. We define the hook which is in a separate
    package, specifying the connection protocol, address, application name, and a
    fields collection which is always sent to the logger:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 向Logrus添加插件非常简单。我们定义一个钩子，该钩子位于一个单独的包中，指定连接协议、地址、应用程序名称以及一个始终发送到日志记录器的字段集合：
- en: '[PRE25]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We then register the plugin with the logger using the hooks method:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们使用钩子方法将插件与日志记录器注册：
- en: '[PRE26]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Logrus has many configurable options and the standard Log, Info, Debug, and
    Error logging levels will enable you to log any object. It will, however, use
    Go''s built in `ToString` unless there is a particular implementation. To get
    around this and to be able to have more parsable data in our logfiles, I have
    added a simple serialization method which converts the relevant methods from the
    `http.Request` into a JSON object:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: Logrus有许多可配置的选项，标准的Log、Info、Debug和Error日志级别将使你能够记录任何对象。然而，除非有特定的实现，否则它将使用Go的内置`ToString`方法。为了解决这个问题，并能够在我们的日志文件中拥有更多可解析的数据，我添加了一个简单的序列化方法，该方法将`http.Request`中的相关方法转换为JSON对象：
- en: '[PRE27]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Full source code for this example can be found in the example code at `chapter7/httputil/request.go`.
    This is only a simple implementation at the moment but could be extended if required.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例的完整源代码可以在`chapter7/httputil/request.go`的示例代码中找到。这目前只是一个简单的实现，但如果需要可以扩展。
- en: Exceptions
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异常
- en: One of the great things about Go is that the standard patterns are that you
    should always handle errors when they occur instead of bubbling them up to the
    top and presenting them to the user. Having said that, there is always a case
    when the unexpected happens. The secret to this is to know about it and to fix
    the problem when it occurs. There are many exception logging platforms on the
    market. However, the two techniques we have discussed are, in my opinion, more
    than sufficient for tracing the few errors that we hopefully will find in our
    web application.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: Go语言的一大优点是，标准的模式是当错误发生时应该始终处理它们，而不是将它们向上冒泡并展示给用户。话虽如此，总有意外发生的情况。这个秘诀就是了解它，并在它发生时解决问题。市场上有很多异常日志平台。然而，在我看来，我们讨论的两种技术对于追踪我们希望在Web应用程序中找到的少量错误已经足够了。
- en: Panic and recover
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 恐慌和恢复
- en: 'Golang has two great methods for handling unexpected errors:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: Go语言处理意外错误有两种优秀的方法：
- en: Panic
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 恐慌
- en: Recover
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 恢复
- en: Panic
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 恐慌
- en: 'The built-in panic function stops the normal execution of the current goroutine.
    All the deferred functions are run in the normal way then the program is terminated:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 内置的panic函数停止当前goroutine的正常执行。然后以正常方式运行所有延迟函数，然后程序终止：
- en: '[PRE28]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Recover
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 恢复
- en: 'The recover function allows an application to manage the behavior of a panicking
    goroutine. When called inside a deferred function, recover stops the execution
    of the panic and returns the error passed to the call of panic:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: recover函数允许应用程序管理恐慌goroutine的行为。当在延迟函数内部调用时，recover停止panic的执行并返回传递给panic调用的错误：
- en: '[PRE29]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'If our handler panics for some reason, the HTTP server will recover this panic
    and write the output to the `std` error. While this is fine if we are running
    the application locally, it does not allow us to manage the errors when we have
    our application distributed across many remote servers. Since we have already
    logged into an ELK stack setup, we can write a simple handler which will wrap
    our main handler and allow the capture of any panic and forward it to the logger:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的处理程序由于某种原因发生恐慌，HTTP服务器将恢复这个恐慌并将输出写入`std`错误。虽然如果我们本地运行应用程序，这是可以的，但它不允许我们在应用程序分布到许多远程服务器时管理错误。由于我们已经登录到ELK堆栈设置，我们可以编写一个简单的处理程序，它将包装我们的主要处理程序并允许捕获任何恐慌并将其转发到记录器：
- en: '[PRE30]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'This is relatively straightforward. In line **19**, we are deferring the call
    to recover. When this runs, if we have an error message, that is, something has
    panicked, we want to log this. Like in the previous examples, we are adding fields
    to the log entry so that Elasicsearch will index these but instead of logging
    the request we are writing the error message. This message most likely will not
    have enough context for us to be able to debug the application, so to get the
    context, we make a call to `debug.Stack()`:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这相对简单。在行**19**中，我们延迟调用recover。当它运行时，如果我们有一个错误消息，也就是说，有东西发生了恐慌，我们希望记录这个。就像在先前的例子中一样，我们正在向日志条目添加字段，以便Elasticsearch可以索引这些字段，但我们不是记录请求，而是写入错误消息。这个消息可能不会提供足够的信息，使我们能够调试应用程序，因此为了获取上下文，我们调用`debug.Stack()`：
- en: '[PRE31]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The stack is part of the runtime/debug package and returns a formatted stack
    trace of the goroutine that calls it. You can test this by running the example
    code of this chapter, and curl the `bang` endpoint:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 栈是runtime/debug包的一部分，并返回调用它的goroutine的格式化堆栈跟踪。你可以通过运行本章的示例代码并curl `bang`端点来测试它：
- en: '[PRE32]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We are writing this along with the error message to Elasticsearch when we query
    Kibana. For this message, we will see the captured details which look something
    like the following:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们查询Kibana时，我们将此消息与错误信息一起写入Elasticsearch。对于此消息，我们将看到捕获的详细信息，如下所示：
- en: '![](img/32517d9d-5ab1-46c7-b2c3-539fc891ba74.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![](img/32517d9d-5ab1-46c7-b2c3-539fc891ba74.png)'
- en: Finally, we return the status code 500 to the client with no message body.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们向客户端返回状态码500，不包含消息体。
- en: The message should give us enough context to understand where the problem area
    lies. The input which caused the exception will, however, be missing so if we
    are unable to replicate the error then it is probably time to add more instrumentation
    to our service and re-run.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 消息应该提供足够的信息，使我们能够理解问题区域在哪里。然而，导致异常的输入将丢失，所以如果我们无法重现错误，那么可能是时候向我们的服务添加更多监控工具并重新运行了。
- en: As part of the application life cycle of your service, you should always endeavor
    to keep on top of exceptions. This will greatly enhance your ability to react
    when something goes wrong. More often than not, I see exception trackers which
    are so full of problems the teams lose all hope of ever cleaning them up and stop
    trying. Don't let your new services get this way when a new exception appears
    to fix it. This way you can set up alerting on your exceptions as you will be
    pretty confident there is a problem.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 作为您服务应用生命周期的一部分，您应该始终努力跟踪异常。这将大大提高您在出现问题时做出反应的能力。通常情况下，我看到异常跟踪器中充满了问题，以至于团队失去了清理它们的希望并停止了尝试。当出现新的异常时，不要让您的服务以这种方式发展，而应该修复它。这样，您可以在异常上设置警报，因为您将非常有信心存在问题。
- en: Summary
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: That is it for this chapter. Logging and monitoring is a topic which you can
    tailor to your particular use case and environment, but I hope you have learned
    how easy it is to set up. Using software as a service, such as Datadog or Logmatic,
    is an excellent way to get up and running very quickly, and alerts integration
    with OpsGenie or PagerDuty will allow you to receive instant alerts whenever a
    problem may occur.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 本章内容到此结束。日志记录和监控是一个可以根据您的特定用例和环境进行调整的话题，但我希望您已经学会了设置它的简便性。使用软件即服务（SaaS），例如 Datadog
    或 Logmatic，是一种快速启动和运行的好方法，与 OpsGenie 或 PagerDuty 的警报集成将允许您在出现问题时立即收到警报。
