- en: Monitoring Your Application
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控您的应用程序
- en: In the previous chapters, you learned how to build a Microservice application
    with the Go programming language and how to (continuously) deploy it into various
    environments.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的章节中，您学习了如何使用Go编程语言构建微服务应用程序，以及如何（持续）将其部署到各种环境中。
- en: However, our work is not yet complete. When you have an application running
    in a production environment, you will need to ensure that it stays up and running
    and behaves the way that you as a developer intended. This is what monitoring
    is for.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们的工作还没有完成。当您在生产环境中运行应用程序时，您需要确保它保持运行并且表现出您作为开发人员预期的行为。这就是监控的作用。
- en: In this chapter, we will introduce you to **Prometheus**, an open source monitoring
    software that has quickly gained popularity for monitoring cloud-based distributed
    applications. It is often used together with **Grafana**, a frontend for visualizing
    metrics data collected by Prometheus. Both applications are licensed under the
    Apache license. You will learn how to set up Prometheus and Grafana and how to
    integrate them into your own applications.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将向您介绍**Prometheus**，这是一款开源监控软件，它在监控基于云的分布式应用程序方面迅速赢得了人气。它通常与**Grafana**一起使用，后者是用于可视化Prometheus收集的指标数据的前端。这两个应用程序都是根据Apache许可证授权的。您将学习如何设置Prometheus和Grafana，以及如何将它们集成到您自己的应用程序中。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Installing and using Prometheus
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装和使用Prometheus
- en: Installing Grafana
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装Grafana
- en: Exporting metrics to Prometheus from your own application
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从您自己的应用程序向Prometheus导出指标
- en: Setting up Prometheus and Grafana
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置Prometheus和Grafana
- en: Before using Prometheus and Grafana in our own application, let's take a look
    at how Prometheus works in principle.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们自己的应用程序中使用Prometheus和Grafana之前，让我们先看一下Prometheus的工作原理。
- en: Prometheus's basics
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Prometheus的基础知识
- en: Unlike other monitoring solutions, Prometheus works by pulling data (called
    **metrics** in Prometheus jargon) from clients at regular intervals. This process
    is called **scraping**. Clients monitored by Prometheus have to implement an HTTP
    endpoint that can be scraped by Prometheus in a regular interval (by default,
    1 minute). These metrics endpoints can then return application-specific metrics
    in a predefined format.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他监控解决方案不同，Prometheus通过定期从客户端拉取数据（在Prometheus行话中称为**指标**）来工作。这个过程称为**抓取**。被Prometheus监控的客户端必须实现一个HTTP端点，可以被Prometheus定期抓取（默认为1分钟）。然后，这些指标端点可以以预定义的格式返回特定于应用程序的指标。
- en: 'For example, an application could offer an HTTP endpoint at `/metrics` that
    responds to `GET` requests and returns the following body:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个应用程序可以在`/metrics`上提供一个HTTP端点，响应`GET`请求并返回以下内容：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This document exposes two metrics—`memory_consumption_bytes` and `http_requests_count`.
    Each metric is associated with a value (for example, the current memory consumption
    of 6,168,432 bytes). Since Prometheus scrapes these metrics from your application
    at fixed intervals, it can use these point-in-time values to build a time series
    of this metric.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 此文档公开了两个指标——`memory_consumption_bytes`和`http_requests_count`。每个指标都与一个值相关联（例如，当前内存消耗为6,168,432字节）。由于Prometheus以固定间隔从您的应用程序抓取这些指标，它可以使用这些瞬时值来构建此指标的时间序列。
- en: Prometheus metrics can also have labels. In the preceding example, you may note
    that the `http_request_count` metric actually has three different values for different
    combinations of the `path` and `method` labels. Later, you will be able to use
    these labels to query data from Prometheus using a custom query language, **PromQL**.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus指标也可以有标签。在前面的示例中，您可能注意到`http_request_count`指标实际上具有不同组合的`path`和`method`标签的三个不同值。稍后，您将能够使用这些标签使用自定义查询语言**PromQL**从Prometheus查询数据。
- en: 'Metrics exported to Prometheus by applications can get quite complex. For example,
    using labels and different metrics names, a client could export a histogram where
    data is aggregated in different buckets:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序导出到Prometheus的指标可能会变得非常复杂。例如，使用标签和不同的指标名称，客户端可以导出一个直方图，其中数据聚合在不同的桶中：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The preceding metrics describe a histogram of your application's HTTP response
    times. In this case, 6,835 requests were processed with a response time of less
    than 0.1 seconds; 79,447 requests with a response time of less than 0.5 seconds
    (which includes the previous 6,835 requests); and so on. The last two metrics
    export the total amount of processed HTTP requests and the sum of time needed
    to process these requests. Both of these values together can be used to compute
    the average request duration.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的指标描述了您的应用程序的HTTP响应时间的直方图。在这种情况下，处理了6,835个响应时间小于0.1秒的请求；79,447个响应时间小于0.5秒的请求（包括前面的6,835个请求）；等等。最后两个指标导出了处理的HTTP请求总数和处理这些请求所需的时间总和。这两个值可以一起用于计算平均请求持续时间。
- en: Do not worry, you will not need to build these complex histogram metrics by
    yourself; that's what the Prometheus client library is for. However, first, let's
    get started by actually setting up a Prometheus instance.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 不用担心，您不需要自己构建这些复杂的直方图指标；这就是Prometheus客户端库的作用。然而，首先，让我们通过实际设置一个Prometheus实例来开始。
- en: Creating an initial Prometheus configuration file
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建初始的Prometheus配置文件
- en: Before using Prometheus and Grafana in our own application, we will need to
    set it up first. Luckily, you can find Docker images for both applications on
    the Docker Hub. Before starting our own Prometheus container, we just need to
    create a configuration file that we can then inject into the container.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们自己的应用程序中使用Prometheus和Grafana之前，我们需要先设置它。幸运的是，您可以在Docker Hub上找到这两个应用程序的Docker镜像。在启动我们自己的Prometheus容器之前，我们只需要创建一个配置文件，然后将其注入到容器中。
- en: 'Start by creating a new directory somewhere on your local machine and placing
    a new `prometheus.yml` file in it:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在本地机器上创建一个新目录，并在其中放置一个新的`prometheus.yml`文件：
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This configuration defines a global scraping interval of 15 seconds (the default
    is 1 minute) and already configures the first scraping target, which is Prometheus
    itself (yes, you have read correctly; Prometheus exports Prometheus metrics that
    you can then monitor with Prometheus).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 此配置定义了全局的抓取间隔为15秒（默认值为1分钟），并且已经配置了第一个抓取目标，即Prometheus本身（是的，您读对了；Prometheus导出Prometheus指标，然后您可以使用Prometheus监控）。
- en: Later, we will add more configuration items to the `scape_configs` property.
    For the time being, it will suffice.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 稍后，我们将向`scape_configs`属性添加更多配置项。目前，这就足够了。
- en: Running Prometheus on Docker
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Docker上运行Prometheus
- en: After having created the configuration file, we can use a volume mount to inject
    this configuration file into the Docker containers we are about to start.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 创建配置文件后，我们可以使用卷挂载将此配置文件注入我们即将启动的Docker容器中。
- en: For this example, we will assume that you have the MyEvents application running
    in Docker containers on your local machine and that the containers are attached
    to a container network named `myevents` (whether you created the containers manually
    or via Docker Compose does not really matter).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，我们假设您在本地机器上的Docker容器中运行了MyEvents应用程序，并且这些容器连接到名为`myevents`的容器网络（无论您是手动创建容器还是通过Docker
    Compose创建都无关紧要）。
- en: 'For this reason, starting both applications is easy enough. We''ll start by
    defining a separate container network for the monitoring components:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，启动这两个应用程序非常容易。我们将首先为监控组件定义一个单独的容器网络：
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Next, create a new volume in which the Prometheus server can store its data:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，创建一个新的卷，Prometheus服务器可以在其中存储其数据：
- en: '[PRE4]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, you can use both the newly created network and volume to create a Prometheus
    container:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以使用新创建的网络和卷来创建一个Prometheus容器：
- en: '[PRE5]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note that in the preceding example, we are attaching the `prometheus` container
    to both the `myevents` and `monitoring` networks. This is because later, the Prometheus
    server will need to access the MyEvents service via the network to scrape metrics
    from them.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在上面的示例中，我们将`prometheus`容器连接到`myevents`和`monitoring`网络。这是因为稍后，Prometheus服务器将需要通过网络访问MyEvents服务，以从中抓取指标。
- en: 'After starting the Prometheus container, you will be able to open the Prometheus
    web UI in your browser by navigating to [http://localhost:9090](http://localhost:9090/):'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 启动Prometheus容器后，您可以通过在浏览器中导航到[http://localhost:9090](http://localhost:9090/)来打开Prometheus
    Web UI：
- en: '![](img/3ad455d1-5604-4c92-9d13-6137d85c1a60.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3ad455d1-5604-4c92-9d13-6137d85c1a60.png)'
- en: Prometheus web UI
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus Web UI
- en: 'In our configuration file, we have already configured our first scraping target—the
    Prometheus server itself. You will find an overview of all configured scraping
    targets by selecting the Status menu item and then the Targets item:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的配置文件中，我们已经配置了第一个抓取目标——Prometheus服务器本身。您可以通过选择“状态”菜单项，然后选择“目标”项来查看所有配置的抓取目标的概述：
- en: '![](img/46a650c2-6df3-4475-bb76-3d038e7dd0fb.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/46a650c2-6df3-4475-bb76-3d038e7dd0fb.png)'
- en: Targets item in Prometheus web UI
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在Prometheus Web UI中的目标项
- en: As you can see in the preceding screenshot, Prometheus reports the current state
    of the scrape target (UP, in this case) and when it was last scraped.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的截图所示，Prometheus报告了抓取目标的当前状态（在本例中为UP）以及上次抓取的时间。
- en: 'You can now use the Graph menu item to inspect the metrics that Prometheus
    has already collected about itself. There, enter `go_memstats_alloc_bytes` into
    the Expression input field and click on Execute. After that, switch to the Graph
    tab. Prometheus will now print its own memory usage over the past 1 hour. You
    can change the observation period using the controls above the graph. By default,
    Prometheus will keep its time series data for 2 weeks:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以使用“图形”菜单项来检查Prometheus已经收集的有关自身的指标。在那里，将`go_memstats_alloc_bytes`输入到表达式输入字段中，然后单击“执行”。之后，切换到“图形”选项卡。Prometheus现在将打印其过去1小时的内存使用情况。您可以使用图表上方的控件更改观察期。默认情况下，Prometheus将保留其时间序列数据2周：
- en: '![](img/c64c97ef-6549-4af0-807b-eea5ad923242.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c64c97ef-6549-4af0-807b-eea5ad923242.png)'
- en: Prometheus web UI graph
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus Web UI图形
- en: 'Prometheus also supports more complex expressions. For example, consider the `process_cpu_seconds_total` metric.
    When displaying it as a graph, you will note that it is monotonically increasing.
    This is because that specific metric describes the sum of all CPU seconds that
    the program used over its entire lifetime (which, by definition, must always be
    increasing). However, for monitoring purposes, it is often more interesting to
    know the current CPU usage of a process. For this, PromQL offers the `rate()`
    method that calculates the per-second average increase of a time series. Try this
    out using the following expression:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus还支持更复杂的表达式。例如，考虑`process_cpu_seconds_total`指标。当将其显示为图形时，您会注意到它是单调递增的。这是因为该特定指标描述了程序在其整个生命周期内使用的所有CPU秒数的总和（根据定义，这必须始终是递增的）。然而，出于监控目的，了解进程的当前CPU使用情况通常更有趣。为此，PromQL提供了`rate()`方法，用于计算时间序列的每秒平均增加量。尝试使用以下表达式：
- en: '[PRE6]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In the graph view, you will now find the 1-minute average CPU usage per second
    (which is probably a more comprehensible metric than the total sum of all used
    CPU seconds ever):'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在图形视图中，您现在将找到每秒的1分钟平均CPU使用率（这可能是一个比所有已使用的CPU秒数总和更易理解的指标）：
- en: '![](img/ae1cd1d5-19fd-4c3c-bf9c-5e27cd34d623.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ae1cd1d5-19fd-4c3c-bf9c-5e27cd34d623.png)'
- en: The Prometheus web UI is good for quick analyses and ad-hoc queries. However,
    Prometheus does not support saving queries for later use or presenting more than
    one graph on the same page. This is where Grafana comes into play.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus Web UI非常适合快速分析和临时查询。但是，Prometheus不支持保存查询以供以后使用，也不支持在同一页上呈现多个图形。这就是Grafana发挥作用的地方。
- en: Running Grafana on Docker
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Docker上运行Grafana
- en: 'Running Grafana is equally as easy as running Prometheus. Start by setting
    up a volume for persistent storage:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 运行Grafana与运行Prometheus一样简单。首先设置一个用于持久存储的卷：
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Then, start the actual container and attach it to the `monitoring` network
    (not the `myevents` network; Grafana needs to communicate with the Prometheus
    server, but it will not have any need to communicate with your backend services
    directly):'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，启动实际容器并将其附加到`monitoring`网络（而不是`myevents`网络；Grafana需要与Prometheus服务器通信，但不需要直接与您的后端服务通信）：
- en: '[PRE8]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: After this, you will be able to access Grafana in your browser on `http://localhost:3000`.
    The default credentials are the username `admin` and the password `admin`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，您将能够在浏览器中访问`http://localhost:3000`上的Grafana。默认凭据是用户名`admin`和密码`admin`。
- en: '![](img/2e0ae6ea-2552-419b-99ea-0f89751f2a43.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2e0ae6ea-2552-419b-99ea-0f89751f2a43.png)'
- en: Gafana home page
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Gafana主页
- en: On your first access, you will be prompted to configure a data source for your
    Grafana instance. Click on the Add data source button and configure access to
    your Prometheus server on the next page. There, select Prometheusas *Type*, enter
    `http://prometheus:9090` as URL, and select Proxy *as* Access mode.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在您第一次访问时，您将被提示为Grafana实例配置数据源。单击“添加数据源”按钮，并在下一页配置访问您的Prometheus服务器。在那里，选择Prometheus作为*类型*，输入`http://prometheus:9090`作为URL，并选择代理*作为*访问模式。
- en: 'After adding your Data Source, continue by creating a dashboard (select the
    Button in the top-left corner, select Dashboards, and then New). Then, add a new
    Graph to the dashboard by clicking on the respective button. After adding the
    graph panel, edit the panel by clicking on the Panel Title and selecting Edit:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 添加数据源后，继续创建仪表板（选择左上角的按钮，选择仪表板，然后选择新建）。然后，通过单击相应按钮向仪表板添加新图形。添加图形面板后，单击面板标题并选择编辑以编辑面板：
- en: '![](img/92a7aafc-85bf-4350-9aeb-47c78c673dec.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](img/92a7aafc-85bf-4350-9aeb-47c78c673dec.png)'
- en: Panel
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 面板
- en: 'Then, in the Metrics tab, enter the CPU usage query from before into the Query
    input field. To further customize the panel, you might want to enter `{{ job }}`
    as a legend to make the graph legend more comprehensible and change the Y axis
    format (in the Axes tab, Left Y section, and Unit field) to Percent (0.0-1.0):'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在指标选项卡中，将之前的CPU使用率查询输入到查询输入字段中。为了进一步自定义面板，您可能希望输入`{{ job }}`作为图例，以使图例更易理解，并将Y轴格式（在轴选项卡，左Y部分和单位字段）更改为百分比（0.0-1.0）：
- en: '![](img/0b35c2ab-936f-4eb0-b813-6503c27ca6d3.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0b35c2ab-936f-4eb0-b813-6503c27ca6d3.png)'
- en: Gafana new dashboard
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Gafana新仪表板
- en: Close the editing panel and save your dashboard by clicking on the Save button
    or pressing *Ctrl* + *S*. Your dashboard is now saved. You can view it again at
    a later point in time with updated metrics or share this dashboard with other
    users.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 关闭编辑面板，并通过单击保存按钮或按*Ctrl* + *S*保存您的仪表板。您的仪表板现在已保存。您可以在以后的时间点查看它，其中包括更新的指标，或与其他用户共享此仪表板。
- en: You can also experiment by adding more panels to your dashboard in which you
    visualize other metrics (by default, Prometheus already exports a boatload of
    metrics about itself that you can experiment with). For a detailed reference on
    the Prometheus Query Language, you can also take a look at the official documentation
    at the following URL: [https://prometheus.io/docs/querying/basics/](https://prometheus.io/docs/querying/basics/).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以通过向仪表板添加更多面板来进行实验，以可视化其他指标（默认情况下，Prometheus已经导出了大量关于自身的指标，您可以进行实验）。有关Prometheus查询语言的详细参考，请参阅以下网址的官方文档：[https://prometheus.io/docs/querying/basics/](https://prometheus.io/docs/querying/basics/)。
- en: Now that we have a working Prometheus and Grafana setup up and running, we can
    take a look at how to get metrics from your own application into Prometheus.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了一个正常运行的Prometheus和Grafana设置，我们可以看看如何将您自己的应用程序的指标导入到Prometheus中。
- en: Exporting metrics
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导出指标
- en: As already shown, exporting metrics from your own application is easy, at least
    in principle. All your application needs to do is offer an HTTP endpoint that
    returns arbitrary metrics that can then be saved in Prometheus. In practice, this
    gets more difficult, especially when you care about the status of the Go runtime
    (for example, CPU and memory usage, Goroutine count, and so on). For this reason,
    it is usually a good idea to use the Prometheus client library for Go, which takes
    care of collecting all possible Go runtime metrics.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如已经显示的那样，从您自己的应用程序导出指标在原则上是很容易的。您的应用程序只需要提供一个返回任意指标的HTTP端点，然后可以将这些指标保存在Prometheus中。实际上，这变得更加困难，特别是当您关心Go运行时的状态时（例如，CPU和内存使用情况，Goroutine计数等）。因此，通常最好使用Go的Prometheus客户端库，该库负责收集所有可能的Go运行时指标。
- en: As a matter of fact, Prometheus is itself written in Go and also uses its own
    client library to export metrics about the Go runtime (for example, the `go_memstats_alloc_bytes`
    or `process_cpu_seconds_total` metrics that you have worked with before).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，Prometheus本身是用Go编写的，并且还使用自己的客户端库来导出有关Go运行时的指标（例如，您之前使用过的`go_memstats_alloc_bytes`或`process_cpu_seconds_total`指标）。
- en: Using the Prometheus client in your Go application
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在您的Go应用程序中使用Prometheus客户端
- en: 'You can get the Prometheus client library using `go get`, as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`go get`获取Prometheus客户端库，如下所示：
- en: '[PRE9]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In case your application uses a dependency management tool (such as Glide,
    which we introduced in the preceding chapter), you will also probably want to
    declare this new dependency in your `glide.yaml` file and add a stable release
    to your application''s `vendor/` directory. To do all this in one step, simply
    run `glide get` instead of `go get` within your application directory:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的应用程序使用依赖管理工具（例如我们在前一章中介绍的Glide），您可能还希望在您的`glide.yaml`文件中声明此新依赖项，并将稳定版本添加到应用程序的`vendor/`目录中。要一次完成所有这些操作，只需在应用程序目录中运行`glide
    get`而不是`go get`：
- en: '[PRE10]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: For security reasons, we will expose our metrics API on a different TCP port
    than the event service's and booking service's REST APIs. Otherwise, it would
    be too easy to accidentally expose the metrics API to the outside world.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 出于安全原因，我们将在与事件服务和预订服务的REST API不同的TCP端口上公开我们的指标API。否则，意外地将指标API暴露给外部世界将太容易了。
- en: 'Let''s start with the event service. Setting up the metrics APIs does not require
    much code, so we will do this directly in the `main.go` file. Add the following
    code to the main function before the `rest.ServeAPI` method is called:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从事件服务开始。设置指标API不需要太多的代码，所以我们将直接在`main.go`文件中进行。在调用`rest.ServeAPI`方法之前，将以下代码添加到主函数中：
- en: '[PRE11]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now, compile your application and run it. Try opening the address at `http://localhost:9100/metrics`
    in your browser, and you should see a large number of metrics being returned by
    the new endpoint:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，编译您的应用程序并运行它。尝试在浏览器中打开地址`http://localhost:9100/metrics`，您应该会看到新端点返回大量的指标：
- en: '![](img/ecb16ed5-5998-4cd1-a67a-0f501e2c0952.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ecb16ed5-5998-4cd1-a67a-0f501e2c0952.png)'
- en: Page shown at localhost:9100/metrics
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在localhost:9100/metrics显示的页面
- en: Now, make the same adjustment to the booking service. Also, remember to add
    an `EXPOSE 9100` statement to both service's Dockerfiles and to recreate any containers
    with an updated image and the `-p 9100:9100` flag (or `-p 9101:9100` to prevent
    port conflicts).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，对预订服务进行相同的调整。还要记得在两个服务的Dockerfile中添加`EXPOSE 9100`语句，并使用更新后的镜像和`-p 9100:9100`标志（或`-p
    9101:9100`以防止端口冲突）重新创建任何容器。
- en: Configuring Prometheus scrape targets
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置Prometheus抓取目标
- en: 'Now that we have two services up and running that expose Prometheus metrics,
    we can configure Prometheus to scrape these services. For this, we can modify
    the `prometheus.yml` file that you created earlier. Add the following sections
    to the `scrape_configs` property:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有两个正在运行并公开Prometheus指标的服务，我们可以配置Prometheus来抓取这些服务。为此，我们可以修改之前创建的`prometheus.yml`文件。将以下部分添加到`scrape_configs`属性中：
- en: '[PRE12]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'After adding the new scraping targets, restart the Prometheus container by
    running `docker container restart prometheus`. After that, the two new scraping
    targets should show up in the Prometheus web UI:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 添加新的抓取目标后，通过运行`docker container restart prometheus`来重新启动Prometheus容器。之后，这两个新的抓取目标应该会显示在Prometheus
    web UI中：
- en: '![](img/9c508298-984f-4e2a-8280-ce15c5b80974.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9c508298-984f-4e2a-8280-ce15c5b80974.png)'
- en: Prometheus web UI targets
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus web UI targets
- en: 'Now, for the best part—remember the Grafana dashboard that you have created
    a few sections earlier? Now that you have added two new services to be scraped
    by Prometheus, take another look at it:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，最好的部分——还记得之前几节创建的Grafana仪表板吗？现在您已经添加了两个新服务以供Prometheus抓取，再看一下它：
- en: '![](img/fbf352c1-0262-4a68-a2ef-12daf019ee5e.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fbf352c1-0262-4a68-a2ef-12daf019ee5e.png)'
- en: Gafana
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Gafana
- en: As you can see, Grafana and Prometheus pick up metrics from the new services
    instantly. This is because the `process_cpu_seconds_total` and `go_memstats_alloc_bytes`
    metrics that we have worked with until now are actually exported by all three
    of our services since they're all using the Prometheus Go client library. However,
    Prometheus adds an additional job label to each metrics that is scraped; this
    allows Prometheus and Grafana to distinguish the same metrics coming from different
    scraping targets and present them accordingly.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，Grafana和Prometheus立即从新服务中获取指标。这是因为我们到目前为止使用的`process_cpu_seconds_total`和`go_memstats_alloc_bytes`指标实际上是由我们的三个服务中的所有服务导出的，因为它们都使用Prometheus
    Go客户端库。但是，Prometheus为每个被抓取的指标添加了一个额外的作业标签；这允许Prometheus和Grafana区分来自不同抓取目标的相同指标并相应地呈现它们。
- en: Exporting custom metrics
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导出自定义指标
- en: Of course, you can also use the Prometheus client library to export your own
    metrics. These do not need to be technical metrics that reflect some aspect of
    the Go runtime (such as CPU usage and memory allocation), but it could also be
    business metrics. One possible example could be the amount of booked tickets with
    different labels per event.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，您也可以使用Prometheus客户端库导出自己的指标。这些不需要是反映Go运行时某些方面的技术指标（如CPU使用率和内存分配），而可以是业务指标。一个可能的例子是每个事件的不同标签的预订票数。
- en: 'For example, within the `todo.com/myevents/bookingservice/rest` package, you
    could add a new file—let''s call it `metrics.go`*—*that declares and registers
    a new Prometheus metrics:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在`todo.com/myevents/bookingservice/rest`包中，您可以添加一个新文件——让我们称之为`metrics.go`*——*声明并注册一个新的Prometheus指标：
- en: '[PRE13]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The Prometheus client library tracks all created metric objects in a package,
    a global registry that is automatically initialized. By calling the `prometheus.MustRegister`
    function, you can add new metrics to this registry. All registered metrics will
    automatically be exposed when a Prometheus server scrapes the `/metrics` endpoint.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus客户端库在一个包中跟踪所有创建的指标对象，这是一个全局注册表，会自动初始化。通过调用`prometheus.MustRegister`函数，您可以将新的指标添加到此注册表中。当Prometheus服务器抓取`/metrics`端点时，所有注册的指标将自动暴露出来。
- en: 'The `NewCounterVec` function used creates a collection of metrics that are
    all named `myevents_bookings_count` but are differentiated by two labels, `eventID`
    and `eventName` (in reality, these are functionally dependent and you wouldn''t
    really need both; but having the event name as a label comes in handy when visualizing
    this metric in Grafana). When scraped, these metrics might look like this:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`NewCounterVec`函数创建了一个名为`myevents_bookings_count`的指标集合，但通过两个标签`eventID`和`eventName`进行区分（实际上，这些是功能相关的，您不需要两者都需要；但在Grafana中可视化此指标时，将事件名称作为标签非常方便）。当抓取时，这些指标可能看起来像这样：'
- en: '[PRE14]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The Prometheus client library knows different types of metrics. The Counter
    that we used in the preceding code is one of the simpler ones. In one of the previous
    sections, you saw how a complex histogram was represented as a number of different
    metrics. This is also possible with the Prometheus client library. Just to demonstrate,
    let''s add another metric—this time, a histogram:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus客户端库知道不同类型的指标。我们在前面的代码中使用的Counter是其中较简单的一种。在之前的某个部分中，您看到了一个复杂的直方图是如何表示为多个不同的指标的。这在Prometheus客户端库中也是可能的。为了演示，让我们添加另一个指标——这次是一个直方图：
- en: '[PRE15]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'When being scraped, this histogram will be exported as seven individual metrics:
    you will get five histogram buckets (*Number of bookings with one seat or less* up
    to *Four seats or less* and *Infinitely many seats or less*), and one metric for
    the sum of all seats and sum of all observations, respectively:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在被抓取时，此直方图将导出为七个单独的指标：您将获得五个直方图桶（*具有一个或更少座位的预订数量* 到*具有四个或更少座位* 和*具有无限多座位或更少*），以及一个用于所有座位和所有观察的总和的指标：
- en: '[PRE16]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Of course, we will need to tell the Prometheus library the values that should
    be exported for these metrics when scraped by the Prometheus server. Since both
    metrics (amount of bookings and amount of seats per booking) can only change when
    a new booking is made, we can add this code to the REST handler function that
    handles POST requests on the `/events/{id}/bookings` route.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们需要告诉Prometheus库在被Prometheus服务器抓取时应该导出哪些指标值。由于这两个指标（预订数量和每个预订的座位数量）只有在进行新预订时才会改变，因此我们可以将此代码添加到处理`/events/{id}/bookings`路由上的POST请求的REST处理程序函数中。
- en: 'In the `booking_create.go` file, add the following code somewhere after the
    original request has been processed (for example, after the `EventBooked` event
    is emitted on the event emitter):'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在`booking_create.go`文件中，在原始请求处理后的某个位置添加以下代码（例如，在事件发射器上发出`EventBooked`事件之后）：
- en: '[PRE17]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The first statement adds the amount of booked seats (`request.Seats`) to the
    counter metric. Since you defined one label named `event` in the `CounterVec`
    declaration, you will need to call the `WithLabelValues` method with the respective
    label values (if the metric declaration consisted of two labels, you would need
    to pass two parameters into `WithLabelValues`).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 第一条语句将预订的座位数量（`request.Seats`）添加到计数器指标中。由于在`CounterVec`声明中定义了一个名为`event`的标签，因此您需要使用相应的标签值调用`WithLabelValues`方法（如果指标声明包含两个标签，则需要将两个参数传递给`WithLabelValues`）。
- en: The second statement adds a new `observation` to the histogram. It will automatically
    find the correct bucket and increment it by one (for example if three seats are
    added with the same booking, the `myevents_seats_per_booking_bucket{le="3"}` metric
    will be increased by one).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 第二条语句向直方图添加了一个新的`observation`。它将自动找到正确的桶并将其增加一个（例如，如果使用相同预订添加了三个座位，则`myevents_seats_per_booking_bucket{le="3"}`指标将增加一个）。
- en: 'Now, start your application and make sure that Prometheus is scraping it at
    regular intervals. Take the time and add a few example records to your application.
    Also, add a few event bookings at the booking service; ensure that you do not
    create them all at once. After that, you can use the `myevents_bookings_count`
    metric to create a new graph in your Grafana dashboard:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，启动您的应用程序，并确保Prometheus定期对其进行抓取。花点时间向您的应用程序添加一些示例记录。还在预订服务中添加一些事件预订；确保您不是一次创建它们。之后，您可以使用`myevents_bookings_count`指标在Grafana仪表板中创建一个新图表：
- en: '>![](img/a6a1c84f-56d9-4b27-9cab-92b427f8b42a.png)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '>![](img/a6a1c84f-56d9-4b27-9cab-92b427f8b42a.png)'
- en: Gafana graph
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: Gafana图表
- en: 'By default, Prometheus will create one time series per scraped instance. This
    means that when you have multiple instances of the booking service, you will get
    multiple time series, each with a different `job` label:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Prometheus将为每个抓取实例创建一个时间序列。这意味着当您有多个预订服务实例时，您将获得多个时间序列，每个时间序列都有不同的`job`标签：
- en: '[PRE18]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'When displaying a business metric (for example, the number of tickets sold),
    you may not actually care at which instance each particular booking was placed
    and prefer an aggregated time series over all instances, instead. For this, you
    can use the PromQL function `sum()` when building your dashboard:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在显示业务指标（例如，售出的门票数量）时，您可能实际上并不关心每个特定预订是在哪个实例上放置的，并且更喜欢在所有实例上使用聚合时间序列。为此，构建仪表板时可以使用PromQL函数`sum()`：
- en: '[PRE19]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Running Prometheus on Kubernetes
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Kubernetes上运行Prometheus
- en: Up until now, we have configured all scraping targets for Prometheus manually
    by adding them to the `prometheus.yml` configuration file. This works well for
    testing, but becomes tedious quickly in larger production setups (and completely
    pointless as soon as you introduce feature such as autoscaling).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们通过将它们添加到`prometheus.yml`配置文件中手动配置了Prometheus的所有抓取目标。这对于测试很有效，但在更大的生产设置中很快变得乏味（并且在引入自动缩放等功能后完全没有意义）。
- en: When running your application within a Kubernetes cluster, Prometheus offers
    a turn-key solution for this—using the `prometheus.yml` configuration file, you
    can actually configure Prometheus to automatically load its scraping targets from
    the Kubernetes API. For example, if you have a Deployment defined for your booking
    service, Prometheus can automatically find all Pods that are managed by this Deployment
    and scrape them all. If the Deployment is scaled up, the additional instances
    will be automatically added to Prometheus.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes集群中运行应用程序时，Prometheus为此提供了一种一站式解决方案——使用`prometheus.yml`配置文件，您实际上可以配置Prometheus自动从Kubernetes
    API加载其抓取目标。例如，如果为您的预订服务定义了一个部署，Prometheus可以自动找到由此部署管理的所有Pod，并对它们进行抓取。如果扩展了部署，附加实例将自动添加到Prometheus中。
- en: 'For the following examples, we will assume that you have either a Minikube
    VM running on your local machine or a Kubernetes cluster somewhere in a cloud
    environment. We''ll start by deploying the Prometheus server first. To manage
    the Prometheus configuration file, we will be using a Kubernetes resource that
    we have not used before—a `ConfigMap`. A `ConfigMap` is basically just an arbitrary
    key-value map that you can save in Kubernetes. When creating a Pod (or Deployment
    or StatefulSet), you can mount these values into your container as files, which
    makes `ConfigMaps` ideal for managing configuration files:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将假设您在本地计算机上运行Minikube VM或在云环境中的某个Kubernetes集群。我们将首先部署Prometheus服务器。为了管理Prometheus配置文件，我们将使用一个以前未使用过的Kubernetes资源——`ConfigMap`。`ConfigMap`基本上只是一个您可以保存在Kubernetes中的任意键值映射。在创建Pod（或部署或StatefulSet）时，您可以将这些值挂载到容器中作为文件，这使得`ConfigMaps`非常适合管理配置文件：
- en: '[PRE20]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: You can create the `ConfigMap` just like any other resource by saving it to
    a `.yaml` file and then calling `kubectl apply -f` on that file. You can also
    use the same command to update the `ConfigMap` when you have modified the `.yaml`
    file.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以像保存其他资源一样创建`ConfigMap`，将其保存到`.yaml`文件中，然后在该文件上调用`kubectl apply -f`。当您修改了`.yaml`文件时，也可以使用相同的命令来更新`ConfigMap`。
- en: 'With the `ConfigMap` created, let''s deploy the actual Prometheus server. Since
    Prometheus is a stateful application, we will deploy it as a `StatefulSet`:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 创建了`ConfigMap`后，让我们部署实际的Prometheus服务器。由于Prometheus是一个有状态的应用程序，我们将其部署为`StatefulSet`：
- en: '[PRE21]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Also, create the associated `Service`:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 还要创建相关的`Service`：
- en: '[PRE22]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Now, you have a Prometheus server running inside your Kubernetes cluster; however,
    at the moment, that server only scrapes its own metrics endpoint, and not yet
    any of the other pods running in your cluster.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您在Kubernetes集群内运行了一个Prometheus服务器；但是，目前该服务器只抓取自己的指标端点，而尚未抓取集群中运行的任何其他Pod。
- en: 'To enable the automatic scraping of Pods, add the following section to the
    `scrape_configs` section of your `prometheus.yml` file in your `ConfigMap`:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 要启用对Pod的自动抓取，请将以下部分添加到`prometheus.yml`文件的`ConfigMap`中的`scrape_configs`部分：
- en: '[PRE23]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Yes, this is quite a lot of configuration, but do not panic. Most of these configurations
    is for mapping the properties of known Kubernetes pods (such as the Pod names
    and labels defined by users) to Prometheus labels that will be attached to all
    metrics that are scraped from these Pods.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，这是相当多的配置，但不要惊慌。大多数这些配置是为了将已知Kubernetes Pod的属性（例如用户定义的Pod名称和标签）映射到将附加到从这些Pod中抓取的所有指标的Prometheus标签。
- en: 'Note that after updating the `ConfigMap`, you may need to destroy your Prometheus
    Pod for the updated configuration to become active. Do not worry; even if you
    delete the Pod, the `StatefulSet` controller will create a new one almost immediately:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在更新`ConfigMap`后，您可能需要销毁您的Prometheus Pod，以使更新后的配置生效。不用担心；即使您删除了Pod，`StatefulSet`控制器也会立即创建一个新的：
- en: '[PRE24]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This configuration also defines that Prometheus will scrape all Pods found
    in the cluster that have an annotation named `prometheus.io/scrape`. This annotation
    can be set when defining a Pod template, for example, in a Deployment. Also, you
    can now adjust your event service deployment as follows (remember to add the TCP
    port `9100` to the list of exposed ports):'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 此配置还定义了Prometheus将抓取集群中具有名为`prometheus.io/scrape`的注释的所有Pod。在定义Pod模板时可以设置此注释，例如在部署中。此外，您现在可以调整您的事件服务部署如下（记得将TCP端口`9100`添加到暴露端口列表中）：
- en: '[PRE25]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: After updating the Deployment, Kubernetes should automatically start recreating
    the event service Pods. As soon as new Pods with the `prometheus.io/scrape` annotation
    are created, Prometheus will automatically pick them up and scrape them for metrics.
    If they are deleted again (for example, after updating or downscaling a Deployment),
    Prometheus will keep the metrics collected from these pods, but stop scraping
    them.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 更新部署后，Kubernetes应该会自动开始重新创建事件服务Pod。一旦创建了带有`prometheus.io/scrape`注释的新Pod，Prometheus将自动捕获并抓取它们的指标。如果它们再次被删除（例如在更新或缩减部署后），Prometheus将保留从这些Pod中收集的指标，但停止抓取它们。
- en: By having Prometheus pick up new scraping targets automatically based on annotations,
    managing the Prometheus server becomes very easy; after the initial setup, you
    probably will not need to edit the configuration file again.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 通过让Prometheus根据注释自动捕获新的抓取目标，管理Prometheus服务器变得非常容易；在初始设置之后，您可能不需要再次编辑配置文件。
- en: Summary
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you learned how to use Prometheus and Grafana to set up a monitoring
    stack to monitor both your application's health on a technical level (by keeping
    an eye on system metrics, such as RAM and CPU usage) and custom, application-specific
    metrics, such as, in this case, the amount of booked tickets.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您学习了如何使用Prometheus和Grafana来设置监控堆栈，以监视应用程序在技术层面上的健康状况（通过关注系统指标，如RAM和CPU使用情况）以及自定义的应用程序特定指标，例如，在这种情况下，预订票数的数量。
- en: Over the course of this book, we have covered almost the entire lifecycle of
    a typical Go cloud application, starting at architecture and the actual programming,
    building container images, continuously deploying them in various cloud environments,
    and monitoring your applications.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的过程中，我们几乎涵盖了典型Go云应用程序的整个生命周期，从架构和实际编程开始，构建容器映像，不断在各种云环境中部署它们，并监视您的应用程序。
- en: In the following chapter, we will take the opportunity to look back in detail
    at what we have achieved so far and also point out where to go from here.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将有机会详细回顾我们迄今为止取得的成就，并指出接下来要做什么。
