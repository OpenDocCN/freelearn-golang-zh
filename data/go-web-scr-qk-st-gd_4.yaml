- en: Parsing HTML
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解析HTML
- en: In the previous chapters, we have dealt with whole web pages, which is not really
    practical for most web scrapers. Although it is nice to have all of the content
    from a web page, most of the time, you will only need small pieces of information
    from each page. In order to extract this information, you must learn to parse
    the standard formats of the web, the most common of these being HTML.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的章节中，我们处理了整个网页，这对大多数网络爬虫来说并不是很实用。虽然从网页中获取所有内容很好，但大多数情况下，你只需要从每个页面中获取一小部分信息。为了提取这些信息，你必须学会解析网络的标准格式，其中最常见的是HTML。
- en: 'This chapter will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: What is the HTML format
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HTML格式是什么
- en: Searching using the strings package
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用字符串包进行搜索
- en: Searching using the regexp package
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用正则表达式包进行搜索
- en: Searching using XPath queries
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用XPath查询进行搜索
- en: Searching using Cascading Style Sheets selectors
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用层叠样式表选择器进行搜索
- en: What is the HTML format?
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HTML格式是什么？
- en: 'HTML is the standard format used to provide web page context. An HTML page
    defines which elements a browser should draw, the content and style of the elements,
    and how the page should respond to interactions from the user. Looking back at
    our [http://example.com/index.html](http://example.com/index.html) response, you
    can see the following, which is what an HTML document looks like:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: HTML是用于提供网页上下文的标准格式。HTML页面定义了浏览器应该绘制哪些元素，元素的内容和样式，以及页面应该如何响应用户的交互。回顾我们的[http://example.com/index.html](http://example.com/index.html)响应，你可以看到以下内容，这就是HTML文档的样子：
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Files that adhere to the HTML specification follow a strict set of rules that
    define the syntax and structure of the document. By learning these rules, you
    can quickly and easily retrieve any information from any web page.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 遵循HTML规范的文件遵循一套严格的规则，定义了文档的语法和结构。通过学习这些规则，你可以快速轻松地从任何网页中检索任何信息。
- en: Syntax
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 语法
- en: HTML documents define elements of a web page by using tags with element names.
    Tags are always surrounded by angle brackets, such as the `<body>` tag. Each element
    defines the end of a tag set by using a forward slash before the tag name, such
    as `</body>`. The contents of the element lie between a set of opening and closing
    tags. For example, everything between the `<body>`, and matching `</body>` tag,
    defines the content of the body element.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: HTML文档通过使用带有元素名称的标签来定义网页的元素。标签总是被尖括号包围，比如`<body>`标签。每个元素通过在标签名称之前使用斜杠来定义标签集的结束，比如`</body>`。元素的内容位于一对开放和关闭标签之间。例如，`<body>`和匹配的`</body>`标签之间的所有内容定义了body元素的内容。
- en: Some tags also have extra properties defined in key-value pairs called attributes.
    These are used to describe extra information about the element. In the example
    shown, there is an `<a>` tag that has an attribute called `href`, whose value
    is [https://www.iana.org/domains/example](https://www.iana.org/domains/example).
    In this case, the `href` is a property of the `<a>` tag and tells the browser
    that this element links to the URL provided. We'll look deeper into navigating
    these links in a later chapter.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一些标签还有额外的属性，以键值对的形式定义，称为属性。这些属性用于描述元素的额外信息。在所示的示例中，有一个带有名为`href`的属性的`<a>`标签，其值为[https://www.iana.org/domains/example](https://www.iana.org/domains/example)。在这种情况下，`href`是`<a>`标签的一个属性，并告诉浏览器这个元素链接到提供的URL。我们将在后面的章节中更深入地了解如何导航这些链接。
- en: Structure
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结构
- en: 'Each HTML document has a specific layout starting with the `<!doctype>` tag.
    This tag is used to define the version of the HTML specification used to validate
    this specific document. In our case, the `<!doctype html>` refers to the HTML
    5 specification. You may sometimes see tags such as this:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 每个HTML文档都有一个特定的布局，从`<!doctype>`标签开始。这个标签用于定义用于验证特定文档的HTML规范的版本。在我们的情况下，`<!doctype
    html>`指的是HTML 5规范。有时你可能会看到这样的标签：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This would describe an `HTML 4.01` (strict) web page that follows definitions
    provided at the URL provided. We will not go into using the provided definition
    to validate the page in this book, as it is usually not necessary to do so.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这将描述一个遵循提供的URL提供的定义的`HTML 4.01`（严格）网页。我们不会在本书中使用提供的定义来验证页面，因为通常不需要这样做。
- en: Following the `<!doctype>` tag is the `<html>` tag, which holds the actual content
    of the web page. Inside the `<html>` tag, you will find the `<head>` and `<body>`
    tags for the document. The `<head>` tag contains metadata about the page itself,
    such as the title, as well as external files to include for building the web page.
    These files may be for styling, or for describing how elements react to user interactions.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在`<!doctype>`标签之后是`<html>`标签，其中包含网页的实际内容。在`<html>`标签内，你会找到文档的`<head>`和`<body>`标签。`<head>`标签包含有关页面本身的元数据，比如标题，以及用于构建网页的外部文件。这些文件可能是用于样式，或者用于描述元素如何对用户交互做出反应。
- en: On the actual web page at [http://example.com/index.html](http://example.com/index.html),
    you can see the `<style>` tag used to describe the sizes, colors, fonts, and spacing
    for various types of elements on the web page. This information was removed from
    the HTML document in this book to preserve space.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际网页[http://example.com/index.html](http://example.com/index.html)上，你可以看到`<style>`标签用于描述网页上各种类型元素的大小、颜色、字体和间距。为了节省空间，本书中删除了HTML文档中的这些信息。
- en: The `<body>` tag contains the bulk of the data that you will be interested in
    scraping. Inside the `<body>` element, you will find all of the text, images,
    videos, and links containing information for your web scraping needs. Collecting
    the data you need from the web page can be done in many different ways; you will
    see some of the common ways in the following sections.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '`<body>`标签包含了你感兴趣的大部分数据。在`<body>`元素内，你会找到所有文本、图片、视频和包含你网页抓取需求信息的链接。从网页中收集你需要的数据可以通过许多不同的方式完成；你将在接下来的章节中看到一些常见的方法。'
- en: Searching using the strings package
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用字符串包进行搜索
- en: The most basic way to search for content is to use the `strings` package from
    the Go standard library. The `strings` package allows you to perform various operations
    on String objects, including searching for matches, counting occurrences, and
    splitting strings into arrays. The utility of this package can cover some use
    cases that you may run into.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索内容的最基本方法是使用Go标准库中的`strings`包。`strings`包允许您对String对象执行各种操作，包括搜索匹配项，计算出现次数以及将字符串拆分为数组。此包的实用性可以涵盖您可能遇到的一些用例。
- en: Example – Counting links
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例-计算链接
- en: 'One quick and easy piece of information that we could extract using the `strings`
    package is to count the number of links that are contained in a web page. The
    `strings` package has a function called `Count()`, which returns the number of
    times a substring occurs in a string. As we have seen before, links are contained
    in `<a>` tags. By counting the number of occurrences of `"<a"`, we can get a general
    idea of the number of links in a page. An example would look like the one given
    here:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`strings`包提取的一条快速且简单的信息是计算网页中包含的链接数量。`strings`包有一个名为`Count()`的函数，它返回字符串中子字符串出现的次数。正如我们之前所见，链接包含在`<a>`标记中。通过计算`"<a"`的出现次数，我们可以大致了解页面中链接的数量。示例如下所示：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In this example, the `Count()` function is used to find the number of occurrences
    of `"<a"` in the home page for the Packt Publishing website.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，`Count()`函数用于查找Packt Publishing网站主页中`"<a"`的出现次数。
- en: Example – Doctype check
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例-Doctype检查
- en: 'Another useful method in the `strings` package is the `Contains()` method.
    This is used to check for the existence of a substring in a string. For example,
    you could check for the HTML Version used to build a web page similar to the one
    given here:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '`strings`包中的另一个有用方法是`Contains()`方法。这用于检查字符串中子字符串的存在。例如，您可以检查用于构建网页的HTML版本，类似于此处给出的示例：'
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This example looks for information contained in a `<!doctype>` tag to check
    if it contains certain indicators for the HTML Version. Running this code will
    show you that the home page for Packt Publishing is built to the HTML 5 specification.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例查找包含在`<!doctype>`标记中的信息，以检查它是否包含HTML版本的特定指示符。运行此代码将向您显示Packt Publishing的主页是按照HTML
    5规范构建的。
- en: Relying on the `strings` package can reveal some very light information about
    a web page, but it does have its shortcomings. In both of the previous examples,
    the matches could be misleading if there are sentences in the document that contain
    the strings in unexpected places. Over generalizing a string search can lead to
    misinformation that can be avoided using more robust tools.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 依赖`strings`包可以揭示有关网页的一些非常轻的信息，但它也有其缺点。在前面的两个示例中，如果文档中包含字符串的句子出现在意想不到的位置，匹配可能会误导。过于概括的字符串搜索可能导致误导，可以通过使用更健壮的工具避免。
- en: Searching using the regexp package
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用regexp包进行搜索
- en: The `regexp` package in the Go standard library provides a deeper level of search
    by using regular expressions. This defines a syntax that allows you to search
    for strings in more complex terms, as well as retrieving strings from a document.
    By using capture groups in regular expressions, you can extract data matching
    a query from the web page. Here are a few useful tasks that the `regexp` package
    can help you achieve.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Go标准库中的`regexp`包通过使用正则表达式提供了更深层次的搜索。这定义了一种语法，允许您以更复杂的术语搜索字符串，并从文档中检索字符串。通过在正则表达式中使用捕获组，您可以从网页中提取与查询匹配的数据。以下是`regexp`包可以帮助您实现的一些有用任务。
- en: Example – Finding links
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例-查找链接
- en: 'In the previous section, we used the `strings` package to count the number
    of links on a page. By using the `regexp` package, we can take this example further
    and retrieve the actual links with the following regular expression:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们使用了`strings`包来计算页面上链接的数量。通过使用`regexp`包，我们可以进一步使用以下正则表达式检索实际链接：
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This query should match any string that looks like a URL, inside an `href` attribute,
    inside of `<a>` tags.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 此查询应匹配任何看起来像URL的字符串，位于`<a>`标记内的`href`属性内。
- en: 'The following program prints all of the links on the Packt Publishing home
    page. This same technique could be used to collect all of the images using querying
    for the `src` attributes of `<img>` tags:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 以下程序打印Packt Publishing主页上的所有链接。使用相同的技术可以用于收集所有图像，通过查询`<img>`标记的`src`属性：
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Example – Finding prices
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例-查找价格
- en: 'Regular expressions can also be used to find content displayed on the web page
    itself. For example, you may be trying to find the price of an item. Let''s look
    at the following example that shows the price of the *Hands-On Go Programming*
    book from Packt Publishing''s website:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式也可以用于查找网页本身显示的内容。例如，您可能正在尝试查找物品的价格。让我们看一下以下示例，显示了Packt Publishing网站上*Hands-On
    Go Programming*书的价格：
- en: '[PRE6]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This program looks for a text string matching `main-book-price`, then looks
    for a USD-formatted decimal on the following line.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 该程序查找与`main-book-price`匹配的文本字符串，然后查找以下行中的USD格式的小数。
- en: 'You can see that regular expressions can be used to extract strings in a document
    where the `strings` package is used mostly for discovering strings. Both of these
    techniques suffer from the same issue: you might match strings in unexpected places.
    In order to have a more fine-grained approach, the search needs to be more structured.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到，正则表达式可用于提取文档中的字符串，而`strings`包主要用于发现字符串。这两种技术都存在同样的问题：您可能会在意想不到的地方匹配字符串。为了更细粒度地进行搜索，搜索需要更加结构化。
- en: Searching using XPath queries
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用XPath查询进行搜索
- en: In the previous examples for parsing HTML documents, we treated HTML simply
    as searchable text, where you can discover information by looking for specific
    strings. Fortunately, HTML documents actually have a structure. You can see that
    each set of tags can be viewed as some object, called a node, which can, in turn,
    contain more nodes. This creates a hierarchy of root, parent, and child nodes,
    providing a structured document. In particular, HTML documents are very similar
    to XML documents, although they are not fully XML-compliant. Because of this XML-like
    structure, we can search for content in the pages using XPath queries.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在以前的解析HTML文档的示例中，我们将HTML简单地视为可搜索的文本，您可以通过查找特定字符串来发现信息。幸运的是，HTML文档实际上是有结构的。您可以看到每组标签可以被视为某个对象，称为节点，它又可以包含更多的节点。这创建了一个根节点、父节点和子节点的层次结构，提供了一个结构化的文档。特别是，HTML文档与XML文档非常相似，尽管它们并非完全符合XML标准。由于这种类似XML的结构，我们可以使用XPath查询在页面中搜索内容。
- en: XPath queries define a way to traverse the hierarchy of nodes in an XML document,
    and return matching elements. In our previous examples, where we were looking
    for `<a>` tags in order to count and retrieve links, we needed to search for the
    tags by string. This method can be problematic if similar matching strings are
    found in unexpected places in an HTML document, such as in a code comment or escaped
    text. If we use XPath queries such as `//a/@href`, we can traverse the HTML document
    structure for the actual `<a>` tag node and retrieve the `href` attribute.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: XPath查询定义了在XML文档中遍历节点层次结构并返回匹配元素的方法。在我们之前的示例中，我们需要搜索字符串来查找`<a>`标签以计算和检索链接。如果在HTML文档的意外位置（如代码注释或转义文本）中找到类似的匹配字符串，这种方法可能会有问题。如果我们使用XPath查询，如`//a/@href`，我们可以遍历HTML文档结构以找到实际的`<a>`标签节点并检索`href`属性。
- en: Example – Daily deals
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例 - 每日优惠
- en: Using a structured querying language like XPath, you can easily collect unformatted
    data as well. In our previous examples, we've mostly looked at the prices of products.
    Prices are simpler to deal with because they generally follow a specific format.
    For example, you can use regular expressions to look for a dollar sign, followed
    by a one or more digits, a period, and two more digits. On the other hand, if
    you wanted to retrieve a block or multiple blocks of text where the content had
    no format, it would become more difficult to do so with basic string searches.
    XPath simplifies this by allowing you to retrieve all of the text content inside
    of a node.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 使用结构化查询语言如XPath，您也可以轻松收集未格式化的数据。在我们之前的示例中，我们主要关注产品的价格。价格更容易处理，因为它们通常遵循特定的格式。例如，您可以使用正则表达式来查找美元符号，后跟一个或多个数字，一个句点和两个更多数字。另一方面，如果您想要检索没有格式的文本块或多个文本块，那么使用基本的字符串搜索将变得更加困难。XPath通过允许您检索节点内的所有文本内容来简化此过程。
- en: The Go standard library has basic support for the handling of XML documents
    and elements; unfortunately, there is no XPath support. However, the open source
    community has built various XPath libraries for Go. The one I would recommend
    is `htmlquery` by GitHub user `antchfx`.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Go标准库对XML文档和元素的处理有基本支持；不幸的是，它不支持XPath。然而，开源社区已经为Go构建了各种XPath库。我推荐的是GitHub用户`antchfx`的`htmlquery`。
- en: 'You can obtain this library by using the following command:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下命令获取此库：
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The following example demonstrates how you can scrape daily deals using an
    XPath query to discover some basic product information:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例演示了如何使用XPath查询来获取一些基本产品信息来抓取每日优惠：
- en: '[PRE8]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This program selects any `text()` found in the `div` element containing a `class`
    attribute, with the matching value of `dotd-main-book-summary`. This query also
    returns the names of the nodes that are children of targeted `div` elements, for
    example, `div` and `h2`, as well as empty text nodes. For this reason, we drop
    any known HTML tags (using a regular expression) and only print the remaining
    text nodes that are not empty strings.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 该程序选择包含`class`属性的`div`元素中找到的任何`text()`。此查询还返回目标`div`元素的子节点的名称，例如`div`和`h2`，以及空文本节点。因此，我们放弃任何已知的HTML标签（使用正则表达式），并且只打印不是空字符串的剩余文本节点。
- en: Example – Collecting products
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例 - 收集产品
- en: In this example, we will use an XPath query to retrieve the latest releases
    from the Packt Publishing website. On this web page, there are a series of `<div>`
    tags that contain more `<div>` tags, which will eventually lead to our information.
    Each of these `<div>` tags hold an attribute called `class`, which describes what
    the purpose of the node is. In particular, we are concerned with the `landing-page-row` class.
    The book-related `<div>` tags within the `landing-page-row` class have an attribute
    called `itemtype`, which tells us that the `div` is for a book and should contain
    other attributes holding the names and prices. It would not be possible to achieve
    this with the `strings` package, and a regular expression would be very laborious
    to design.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将使用XPath查询来从Packt Publishing网站检索最新的发布信息。在这个网页上，有一系列包含更多`<div>`标签的`<div>`标签，最终会导致我们的信息。这些`<div>`标签中的每一个都有一个称为`class`的属性，描述了节点的用途。特别是，我们关注`landing-page-row`类。`landing-page-row`类中与书籍相关的`<div>`标签有一个称为`itemtype`的属性，告诉我们这个`div`是用于书籍的，并且应该包含其他包含名称和价格的属性。使用`strings`包无法实现这一点，而使用正则表达式将非常费力。
- en: 'Let''s take a look at the following example:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看以下示例：
- en: '[PRE9]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Using an XPath query that directly targets the elements in the document directly,
    we are able to navigate to the exact attribute of the exact node to retrieve the
    name and price of each of the books.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用直接针对文档中的元素的XPath查询，我们能够导航到确切节点的确切属性，以检索每本书的名称和价格。
- en: Searching using Cascading Style Sheets selectors
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用层叠样式表选择器进行搜索
- en: You can see how using a structured query language makes searching for, and retrieving,
    information much easier than basic string searches. However, XPath was designed
    for generic XML documents, not HTML. There is another structured query language
    that is made specifically for HTML. **Cascading Style Sheets** (**CSS**) were
    created to provide a way to add stylistic elements to HTML pages. In a CSS file,
    you would define a path to an element or multiple elements, and what describes
    the appearance. The definitions for the path to the element are called CSS selectors
    and are written specifically for HTML documents.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到，使用结构化查询语言比基本字符串搜索更容易搜索和检索信息。但是，XPath是为通用XML文档设计的，而不是HTML。还有一种专门用于HTML的结构化查询语言。**层叠样式表**（**CSS**）是为HTML页面添加样式元素的一种方法。在CSS文件中，您可以定义到一个元素或多个元素的路径，以及描述外观。元素路径的定义称为CSS选择器，专门为HTML文档编写。
- en: CSS selectors understand common attributes that we could use in searching HTML
    documents. In the previous XPath examples, we often used a query such as `div[@class="some-class"]`
    in order to search for elements with the class name `some-class`. CSS selectors
    offer a shorthand for `class` attributes by simply using a `.`. The same XPath
    query would look like `div.some-class` as a CSS query. Another common shorthand
    used here is searching elements with an `id` attribute, which is represented in
    CSS as a `#` symbol. In order to find an element with the `id` of `main-body`,
    you would use `div#main-body` as a CSS selector. There are many other niceties
    in the CSS selector specification that expand what can be done via XPath, as well
    as simplifying common queries.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: CSS选择器了解我们可以在搜索HTML文档中使用的常见属性。在以前的XPath示例中，我们经常使用这样的查询`div[@class="some-class"]`来搜索具有类名`some-class`的元素。CSS选择器通过简单地使用`.`为`class`属性提供了一种简写。相同的XPath查询在CSS查询中看起来像`div.some-class`。这里使用的另一个常见简写是搜索具有`id`属性的元素，这在CSS中表示为`#`符号。为了找到具有`main-body`
    id的元素，您将使用`div#main-body`作为CSS选择器。CSS选择器规范中还有许多其他便利之处，可以扩展XPath的功能，同时简化常见查询。
- en: Although there is no support for CSS selectors in the Go standard library, once
    again, the open source community has many tools that provide this functionality,
    the best of which is `goquery` by GitHub user `PuerkitoBio`.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Go标准库中不支持CSS选择器，但再次，开源社区有许多工具提供了这种功能，其中最好的是GitHub用户`PuerkitoBio`的`goquery`。
- en: 'You can obtain the library by using the following command:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下命令获取该库：
- en: '[PRE10]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Example – Daily deals
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例-每日优惠
- en: 'The following examples will refine the XPath example, using `goquery` in place
    of `htmlquery`:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例将使用`goquery`代替`htmlquery`来完善XPath示例：
- en: '[PRE11]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Using `goquery`, the search for the daily deals becomes much more succinct.
    In this query, we use one of the helper features that CSS selectors offer by using
    the `$=` operator. Instead of looking for the `itemtype` attribute, matching the
    exact string `http://schema.org/Product`, we can simply match the string that
    *ends with* `/Product`. We also use the `.` operator to look for the `landing-page-row`
    class. One key difference to note between this example and the XPath example is
    that you do not need to match the entire value of the class attribute. When we
    were searching with XPath, we had to use `@class="landing-page-row cf"` as a query.
    In CSS, is it not necessary to have exact matches for classes. As long as the
    element contains the `landing-page-row class`, it matches.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`goquery`，搜索每日优惠变得更加简洁。在此查询中，我们使用CSS选择器提供的一个辅助功能，即使用`$=`运算符。我们不再寻找`itemtype`属性，匹配确切的字符串`http://schema.org/Product`，而是简单地匹配以`/Product`结尾的字符串。我们还使用`.`运算符来查找`landing-page-row`类。需要注意的一个关键区别是，与XPath示例之间的一个关键区别是，您不需要匹配类属性的整个值。当我们使用XPath搜索时，我们必须使用`@class="landing-page-row
    cf"`作为查询。在CSS中，不需要对类进行精确匹配。只要元素包含`landing-page-row`类，它就匹配。
- en: Example – Collecting products
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例-收集产品
- en: 'In the code given here, you can see the CSS selector version of the collecting
    products example:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在此提供的代码中，您可以看到收集产品示例的CSS选择器版本：
- en: '[PRE12]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In this example, you can use CSS queries to return all of the text from all
    of the child elements as well. We use the `:not()` operator to exclude the countdown
    timer, and finally, to process the lines of text to ignore spaces and blank lines.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，您可以使用CSS查询来返回所有子元素的所有文本。我们使用`:not()`运算符来排除倒计时器，并最终处理文本行以忽略空格和空行。
- en: Summary
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: You can see that there are various ways of extracting data from HTML pages using
    different tools. Basic string searches and `regex` searches can collect information
    using very simple techniques, but there are cases where more structured query
    languages are needed. XPath provides great searching capabilities by assuming
    the document is XML-formatted and can cover generic searches. CSS selectors are
    the simplest way to search for and extract data from HTML documents and provide
    many helpful features that are HTML-specific.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到有各种方法可以使用不同的工具从HTML页面中提取数据。基本字符串搜索和`regex`搜索可以使用非常简单的技术收集信息，但也有需要更多结构化查询语言的情况。XPath通过假设文档是XML格式并可以进行通用搜索，提供了出色的搜索功能。CSS选择器是搜索和提取HTML文档中数据的最简单方法，并提供了许多有用的HTML特定功能。
- en: In [Chapter 5](a4a15c5d-908d-4a1c-bce4-0bf2181c80e3.xhtml), *Web Scraping Navigation*,
    we will look at the best ways to crawl the internet efficiently and safely.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第5章](a4a15c5d-908d-4a1c-bce4-0bf2181c80e3.xhtml)中，*网络爬虫导航*，我们将探讨高效和安全地爬取互联网的最佳方法。
