- en: Web Scraping Navigation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络爬取导航
- en: So far, this book has focused on retrieving information for a single web page.
    Although this is the basis of web scraping, it does not cover the majority of
    use cases. More than likely, you will need to visit multiple web pages, or websites,
    in order to collect all of the information to fulfill your needs. This may entail
    visiting many known websites directly via a list or URLs, or following links discovered
    in some pages to more unknown places. There are many different ways of navigating
    your scraper through the web.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，本书侧重于为单个网页检索信息。虽然这是网络爬取的基础，但并不涵盖大多数用例。很可能，你需要访问多个网页或网站，以收集满足你需求的所有信息。这可能涉及直接通过URL列表访问许多已知网站，或者跟踪在某些页面上发现的链接到更多未知的地方。有许多不同的方式来引导你的网络爬虫浏览网页。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: How to follow links
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何跟踪链接
- en: How to submit forms with `POST` requests
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用`POST`请求提交表单
- en: How to track your history to avoid loops
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何跟踪你的历史记录以避免循环
- en: The difference between breadth-first and depth-first crawling
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 广度优先和深度优先爬取的区别
- en: Following links
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跟踪链接
- en: As you have seen in many examples throughout this book, there are HTML elements
    denoted by `<a>` tags that contain `href` attributes that reference different
    URLs. These tags, called anchor tags, are how links are generated on a web page.
    In a web browser, these links would typically have a different font color, often
    blue, with an underline. As a user in a web browser, if you wanted to follow a
    link, you would usually just click on it and you would be redirected to the URL.
    As a web scraper, the clicking action is usually not necessary. Instead, you can
    send a `GET` request to the URL in the `href` attribute itself.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在本书中许多示例中所看到的，有一些由`<a>`标签表示的HTML元素，其中包含`href`属性，引用不同的URL。这些标签称为锚标签，是网页上生成链接的方式。在网页浏览器中，这些链接通常会有不同的字体颜色，通常是蓝色，带有下划线。作为网页浏览器中的用户，如果你想要跟踪一个链接，通常只需点击它，你就会被重定向到URL。作为一个网络爬虫，点击操作通常是不必要的。相反，你可以向`href`属性本身发送一个`GET`请求。
- en: If you find that the `href` attribute lacks the `http://` or `https://` prefix
    and the hostname, you must use the prefix and hostname of the current web page.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你发现`href`属性缺少`http://`或`https://`前缀和主机名，你必须使用当前网页的前缀和主机名。
- en: Example – Daily deals
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例-每日特惠
- en: 'In [Chapter 4](e6f2de6a-420b-4691-9ba1-969ed6ad32ea.xhtml),* Parsing HTML*,
    we used an example where we retrieved the titles and the prices of the latest
    releases from the Packt Publishing website. You could collect more information
    about each book by following each link to the book''s main web page. In the following
    code example, we will add the navigation to make this possible:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第4章](e6f2de6a-420b-4691-9ba1-969ed6ad32ea.xhtml)中，*解析HTML*，我们使用了一个示例，从Packt
    Publishing网站上检索了最新发布的书籍的标题和价格。你可以通过跟踪每个链接到书籍的主要网页来收集更多关于每本书的信息。在下面的代码示例中，我们将添加导航以实现这一点：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As you can see, we have modified the `Each()` loop to extract the link for every
    product listed in the web page. Each link only contains the relative path to the
    book, so we prefix the [https://www.packtpub.com](https://www.packtpub.com) string
    to each link. Next, we navigate to the page itself by using the link we constructed,
    and scrape the desired information. At the end of each page, we sleep for `1`
    second so that our web scraper does not overburden the servers, observing the
    good etiquette we learned in [Chapter 3](16487efd-3a75-4823-ad19-627a83752cd4.xhtml),
    *Web Scraping Etiquette*.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，我们已经修改了`Each()`循环，以提取网页中列出的每个产品的链接。每个链接只包含到书籍的相对路径，所以我们在每个链接前缀中加入了[https://www.packtpub.com](https://www.packtpub.com)字符串。接下来，我们使用我们构建的链接导航到页面本身，并抓取所需的信息。在每页的末尾，我们休眠`1`秒，以便我们的网络爬虫不会过度负担服务器，遵守我们在[第3章](16487efd-3a75-4823-ad19-627a83752cd4.xhtml)中学到的良好礼仪，*网络爬取礼仪*。
- en: Submitting forms
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提交表单
- en: Up until this point, we have been able to request information from servers using
    only HTTP `GET` requests. These requests cover the vast majority of web scraping
    tasks that you will encounter as you build your own web scraper. However, there
    will come a time where you may need to submit some kind of form data in order
    to retrieve the information you are looking for. This form data could entail search
    queries, or a login screen, or any page that would require you to type into a
    box and click a Submit button.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经能够使用HTTP `GET`请求从服务器请求信息。这些请求涵盖了你在构建自己的网络爬虫时会遇到的绝大多数网络爬取任务。然而，总会有一些时候，你可能需要提交某种表单数据，以便检索你正在寻找的信息。这些表单数据可能包括搜索查询，或者登录界面，或者任何需要你在框中输入并点击提交按钮的页面。
- en: For simple websites, this is done using an HTML `<form>` element, containing
    one or more `<input>` elements and a Submit button. This `<form>` element usually
    has attributes defining the `action` (where to send the `<form>` data), and a
    `method` (the HTTP method to use). By default, the web page will use an HTTP `GET`
    request to send the form data, but it is very common to see HTTP `POST` requests
    as well.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对于简单的网站，这是通过一个包含一个或多个`<input>`元素和一个提交按钮的HTML `<form>`元素来完成的。这个`<form>`元素通常具有定义`action`（发送`<form>`数据的位置）和`method`（要使用的HTTP方法）的属性。默认情况下，网页将使用HTTP
    `GET`请求发送表单数据，但也很常见看到HTTP `POST`请求。
- en: Example – Submitting searches
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例-提交搜索
- en: 'In the following example, you will see how to simulate a form submission by
    using the properties and elements of an HTML form. We will use the form located
    at the [https://hub.packtpub.com/](https://hub.packtpub.com/) website to discover
    articles written about the Go programming language (commonly referred to as GoLang).
    On the home page of [https://hub.packtpub.com](https://hub.packtpub.com), there
    is a search box in the top-left corner of the page, as shown in the following
    screenshot:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，您将看到如何通过使用HTML表单的属性和元素来模拟表单提交。我们将使用位于[https://hub.packtpub.com/](https://hub.packtpub.com/)网站上的表单来发现有关Go编程语言（通常称为GoLang）的文章。在[https://hub.packtpub.com](https://hub.packtpub.com)的主页上，有一个搜索框位于页面的左上角，如下面的屏幕截图所示：
- en: '![](img/f8262a4d-c832-4b8e-80eb-b112ee0eeb3f.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f8262a4d-c832-4b8e-80eb-b112ee0eeb3f.png)'
- en: 'By right-clicking on the Search... box, you should be able to inspect the element
    using your browser''s Developer tools. This reveals the HTML source code for the
    page, showing that this box is located in an HTML form. In Google Chrome, it looks
    similar to the following screenshot:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 通过右键单击搜索框，您应该能够使用浏览器的开发者工具检查元素。这会显示页面的HTML源代码，显示该框位于HTML表单中。在Google Chrome中，它看起来类似于下面的屏幕截图：
- en: '![](img/aab70a2c-d612-4f8d-80eb-1911f3711ce1.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aab70a2c-d612-4f8d-80eb-1911f3711ce1.png)'
- en: This form uses the HTTP `GET` method, and submits to the [https://hub.packtpub.com/](https://hub.packtpub.com/)
    endpoint. The values for this form are taken from the `<input>` tags using the
    `name` attribute as a key, and the text within the Search box as the value. Because
    this form uses `GET` as a method, the key-value pairs are sent to the server as
    the query part of the URL. For our example, we want to submit GoLang as our search
    query. To do this, when you click the button to submit your query, your browser
    will send a `GET` request to [https://hub.packtpub.com/?s=Golang](https://hub.packtpub.com/?s=Golang).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这个表单使用HTTP `GET`方法，并提交到[https://hub.packtpub.com/](https://hub.packtpub.com/)端点。这个表单的值是从`<input>`标签中使用`name`属性作为键，搜索框中的文本作为值。因为这个表单使用`GET`作为方法，键值对被发送到服务器作为URL的查询部分。在我们的例子中，我们想要提交GoLang作为我们的搜索查询。为了做到这一点，当您点击按钮提交您的查询时，您的浏览器将发送一个`GET`请求到[https://hub.packtpub.com/?s=Golang](https://hub.packtpub.com/?s=Golang)。
- en: The resulting page will contain all articles related to Go. You could scrape
    the title, dates, authors, and so on in order to keep an index of Go articles.
    By submitting this query periodically, you could discover new articles as soon
    as they are released.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 结果页面将包含所有与Go相关的文章。您可以爬取标题、日期、作者等，以便保持Go文章的索引。通过定期提交此查询，您可以在发布时立即发现新文章。
- en: Example – POST method
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例-POST方法
- en: 'The form we used in the previous example used `GET` as a method. Hypothetically,
    if it were to use the `POST` method, there would be a slight difference in how
    the form is submitted. Instead of putting the values in the URL, you would need
    to build a request body instead. In the following example, the same form and search
    query will be structured as a `POST` request:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中使用的表单使用`GET`作为方法。假设，如果它使用`POST`方法，表单提交的方式将有所不同。您需要构建一个请求主体，而不是将值放在URL中。在下面的例子中，相同的表单和搜索查询将被构造为`POST`请求：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In Go, you build a form submission using the `url.Values` struct. You can use
    this to set the inputs of the form—`s=Golang` in our case—and submit it using
    the `http.Post()` function. This technique will only help if the form uses `POST`
    as its method.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在Go中，您可以使用`url.Values`结构构建表单提交。您可以使用此功能设置表单的输入——在我们的例子中是`s=Golang`——并使用`http.Post()`函数提交它。如果表单使用`POST`作为其方法，这种技术将只有帮助。
- en: Avoiding loops
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 避免循环
- en: If you are building a web scraper that follows links, you might need to be aware
    of which pages you've already visited. It's quite possible that a page you are
    visiting contains a link to a page you have already visited, sending you into
    an infinite loop. Therefore, it is very important to build a tracking system into
    your scraper that records its history.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在构建一个遵循链接的网络爬虫，您可能需要知道您已经访问过哪些页面。您正在访问的页面很可能包含一个指向您已经访问过的页面的链接，将您带入一个无限循环。因此，非常重要的是在您的爬虫中构建一个跟踪系统，记录其历史。
- en: The simplest data structure for storing a unique collection of items would be
    a set. The Go standard library does not have a set data structure, but it can
    be emulated by using a `map[string]interface{}{}`.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 存储唯一项目集合的最简单数据结构将是一个集合。Go标准库没有集合数据结构，但可以通过使用`map[string]interface{}]`来模拟。
- en: An `interface{}` in Go is a generic object, similar to `java.lang.Object`.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在Go中，`interface{}`是一个通用对象，类似于`java.lang.Object`。
- en: 'In Go, you can define a map as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在Go中，您可以定义一个地图如下：
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In this case, we would use the visited URL as the key, and anything you want
    as the value. We will just use `nil`, because as long as the key is present, we
    know we have visited the site. Adding a site that we have visited would simply
    insert the URL as the key and `nil` as a value, as given in the following code
    block:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们将使用访问的URL作为键，以及您想要的任何值。我们将只使用`nil`，因为只要键存在，我们就知道我们已经访问了该站点。添加我们已经访问的站点将简单地将URL插入为键，`nil`作为值，如下面的代码块所示：
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'When you try to retrieve a value from a map, using a given key, Go will return
    two values: the value for the key if it exists, and a Boolean, stating whether
    or not the key exists in the map. In our case, we are only concerned about the
    latter.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 当您尝试从地图中检索一个值时，Go将返回两个值：如果存在，键的值和一个布尔值，说明键是否存在于地图中。在我们的例子中，我们只关心后者。
- en: 'We would check for a site visit like the one demonstrated in the following
    code block:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将检查类似于以下代码块中演示的站点访问：
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Breadth-first versus depth-first crawling
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 广度优先与深度优先爬行
- en: 'Now that you have the ability to navigate to different pages, as well as the
    ability to avoid getting stuck in a loop, you have one more important choice to
    make when crawling a website. In general, there are two main approaches to covering
    all pages by following links: breadth-first, and depth-first. Imagine that you
    are scraping a single web page that contains 20 links. Naturally, you would follow
    the first link on the page. On the second page, there are ten more links. Herein
    lies your decision: follow the first link on the second page, or go back to the
    second link on the first page.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以导航到不同的页面，并且可以避免陷入循环，当爬行网站时，您还有一个重要的选择要做。一般来说，有两种主要方法可以通过跟随链接来覆盖所有页面：广度优先和深度优先。想象一下，您正在爬取一个包含20个链接的单个网页。自然地，您会跟随页面上的第一个链接。在第二页上，还有十个链接。在这里就是您的决定：跟随第二页上的第一个链接，还是返回到第一页上的第二个链接。
- en: Depth-first
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度优先
- en: 'If you choose to follow the first link on the second page, this would be considered
    depth-first crawling:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您选择在第二页上跟随第一个链接，这将被视为深度优先爬行：
- en: '![](img/da7a1fd2-dfee-4cd0-9c7d-ce7f8233b4ca.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](img/da7a1fd2-dfee-4cd0-9c7d-ce7f8233b4ca.png)'
- en: Your scraper will continue to follow the links as deeply as possible to collect
    all of the pages. In the case of products, you might be following a path of recommendations
    or similar items. This might take you to products far outside the original starting
    point of your scraper. On the other hand, it may also help build a tighter network
    of related items quickly. On websites containing articles, depth-first crawling
    will send you back in time quickly, as linked pages would most likely be a reference
    to a previously written article. This will help you reach the origins of many
    linked paths quickly.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 您的爬虫将继续尽可能深入地跟随链接以收集所有页面。在产品的情况下，您可能会跟随推荐或类似项目的路径。这可能会将您带到远离爬虫的原始起点的产品。另一方面，它也可能帮助快速构建相关项目的更紧密网络。在包含文章的网站上，深度优先爬行将迅速将您带回到过去，因为链接的页面很可能是对先前撰写的文章的引用。这将帮助您迅速到达许多链接路径的起源。
- en: In [Chapter 6](a1ed8fec-44c3-4798-beab-27a3c08dc151.xhtml),*Protecting Your
    Web Scraper*, we will learn how to avoid some of the pitfalls of depth-first crawling
    by ensuring we have the proper boundaries in place.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第6章](a1ed8fec-44c3-4798-beab-27a3c08dc151.xhtml)中，*保护您的网络爬虫*，我们将学习如何通过确保我们有适当的边界来避免深度优先爬行的一些陷阱。
- en: Breadth-first
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 广度优先
- en: 'If you choose to follow the second link on the first page, this would be considered
    breadth-first crawling:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您选择在第一页上跟随第二个链接，这将被视为广度优先爬行：
- en: '![](img/f9a154db-834e-47a8-af96-2dddb69ced25.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f9a154db-834e-47a8-af96-2dddb69ced25.png)'
- en: Using this technique, you would most likely stay within your original search
    domain for longer. For example, if you were on a website with products and initiated
    a search for shoes, the majority of the links on the page would be related to
    shoes. You would be collecting the links within the same domain first. As you
    move deeper within the website, recommended items may lead you to other types
    of clothing. Breadth-first crawling would help you collect full clusters of pages
    more quickly.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种技术，您很可能会在原始搜索域内停留更长时间。例如，如果您在一个包含产品的网站上搜索鞋子，页面上大多数链接都与鞋子相关。您将首先收集同一域内的链接。随着您在网站内部的深入，推荐项目可能会将您带到其他类型的服装。广度优先爬行将帮助您更快地收集完整的页面集群。
- en: There is no right or wrong technique for how to navigate your scraper; it all
    depends on your specific needs. Depth-first crawling will reveal the origins of
    specific topics, whereas breadth-first crawling will complete a full cluster before
    discovering new content. You might even use a combination of techniques if this
    suits your requirements.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如何导航您的爬虫没有对错之分；这完全取决于您的具体需求。深度优先爬行将揭示特定主题的起源，而广度优先爬行将在发现新内容之前完成整个集群。如果这符合您的要求，您甚至可以使用多种技术的组合。
- en: Navigating with JavaScript
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用JavaScript导航
- en: So far we have focused on simple web pages where all of the information needed
    is only available in the HTML file. This is not always the case for more modern
    websites, which contain JavaScript code responsible for loading extra information
    after the initial page loads. In many websites, when you perform a search, the
    initial page might display with an empty table and, in the background, make a
    second request to collect the actual results to display. In order to do this,
    custom code written in JavaScript is run by your web browser. Using the standard
    HTTP client would not be sufficient in this case and you would need to use an
    external browser that supports JavaScript execution.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经专注于简单的网页，所有所需的信息都只在HTML文件中。对于更现代的网站来说，情况并非总是如此，它们包含负责在初始页面加载后加载额外信息的JavaScript代码。在许多网站上，当您执行搜索时，初始页面可能会显示一个空表，并在后台发出第二个请求以收集要显示的实际结果。为了做到这一点，您的Web浏览器会运行JavaScript中编写的自定义代码。在这种情况下，使用标准的HTTP客户端是不够的，您需要使用支持JavaScript执行的外部浏览器。
- en: In Go, there are many options for integrating scraper code with web browsers
    thanks to a few standard protocols. The WebDriver protocol is the original standard
    developed by Selenium and is supported by most major browsers. This protocol allows
    programs to send a browser's commands, such as load a web page, wait for an element,
    click a button, and capture the HTML. These commands would be necessary to collect
    results from a web page where items are loaded via JavaScript. One such library
    supporting the WebDriver client protocol is `selenium` by GitHub user `tebeka`.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在Go中，由于几个标准协议的存在，有许多选项可以将爬虫代码与Web浏览器集成。WebDriver协议是由Selenium开发的最初的标准，并得到大多数主要浏览器的支持。该协议允许程序发送浏览器的命令，例如加载网页，等待元素，点击按钮和捕获HTML。这些命令对于从通过JavaScript加载项目的网页收集结果是必要的。支持WebDriver客户端协议的一个库是GitHub用户`tebeka`的`selenium`。
- en: Example – Book reviews
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例 - 书评
- en: On the Packt Publishing website, book reviews are loaded via JavaScript and
    are not visible when the page is first loaded. This example demonstrates how to
    use the `selenium` package to scrape reviews from a book listing on the Packt
    Publishing site.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在Packt Publishing网站上，书评是通过JavaScript加载的，在页面首次加载时是不可见的。此示例演示了如何使用`selenium`包从Packt
    Publishing网站上的书目录中爬取评论。
- en: 'The `selenium` package relies on four external dependencies in order to function
    properly:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`selenium`包依赖于四个外部依赖项才能正常运行：'
- en: A Google Chrome or Mozilla Firefox web browser
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google Chrome或Mozilla Firefox网络浏览器
- en: A WebDriver that is compatible with Chrome or Firefox, respectively
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与Chrome或Firefox兼容的WebDriver
- en: The Selenium Server binary
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Selenium服务器二进制文件
- en: Java
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Java
- en: All of these dependencies will be downloaded by the `selenium` script during
    installation, except for Java.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些依赖项都将在安装期间由`selenium`脚本下载，除了Java。
- en: Please ensure that you have Java installed on your machine. If not, please download
    and install the official version from [https://www.java.com/en/download/help/download_options.xml](https://www.java.com/en/download/help/download_options.xml).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 请确保您的计算机上已安装Java。如果没有，请从[https://www.java.com/en/download/help/download_options.xml](https://www.java.com/en/download/help/download_options.xml)下载并安装官方版本。
- en: 'First, install the package via the following:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，通过以下方式安装软件包：
- en: '[PRE5]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This will install `selenium` inside your `GOPATH` at `$GOPATH/src/github.com/tebeka/selenium`.
    This installation script relies on a number of other packages in order to run.
    You can install them using the following commands:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在您的`GOPATH`中的`$GOPATH/src/github.com/tebeka/selenium`内安装`selenium`。此安装脚本依赖于其他一些软件包才能运行。您可以使用以下命令安装它们：
- en: '[PRE6]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Next, we install the browsers, drivers, and `selenium` binary that the code
    example needs. Navigate to the `Vendor` folder inside the `selenium` directory
    and complete the installation by running the following command:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们安装代码示例需要的浏览器、驱动程序和`selenium`二进制文件。转到`selenium`目录内的`Vendor`文件夹，并通过运行以下命令完成安装：
- en: '[PRE7]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now that `selenium` and all of its dependencies are set up, you can create
    a new folder in your `$GOPATH/src` with a `main.go` file. Let''s step through
    the code that you will need to write in order to collect reviews from a book.
    First, let''s look at the `import` statement:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在`selenium`及其所有依赖项都已设置好，您可以在`$GOPATH/src`中创建一个带有`main.go`文件的新文件夹。让我们逐步了解您需要编写的代码，以便收集一本书的评论。首先，让我们看一下`import`语句：
- en: '[PRE8]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'As you can see, our program only relies on the `selenium` package to run the
    example! Next, we can see the beginning of the `main` function and define a few
    important variables:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，我们的程序只依赖于`selenium`包来运行示例！接下来，我们可以看到`main`函数的开始，并定义一些重要的变量：
- en: '[PRE9]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Here, we render the constants for the paths to the `selenium` server executable,
    and the path for the Firefox WebDriver, known as the `geckodriver`. If you were
    to run this example with Chrome, you would provide the path to your `chromedriver`
    instead. All of these files were installed by the `init.go` program run earlier
    and your paths will be different from the ones written here. Please be sure to
    change these to suit your environment. The next part of the function initializes
    the `selenium` driver:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们为`selenium`服务器可执行文件的路径和Firefox WebDriver的路径（称为`geckodriver`）渲染常量。如果您要使用Chrome运行此示例，您将提供路径到您的`chromedriver`。所有这些文件都是由之前运行的`init.go`程序安装的，您的路径将与此处写的路径不同。请确保更改这些以适应您的环境。函数的下一部分初始化了`selenium`驱动程序：
- en: '[PRE10]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '`defer` statements tell Go to run the following command at the end of the function.
    It is good practice to defer your cleanup statements so you don''t forget to put
    them at the end of your function!'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '`defer`语句告诉Go在函数结束时运行以下命令。推迟清理语句是一个好习惯，这样您就不会忘记将它们放在函数的末尾！'
- en: 'Here, we create the `selenium` driver by providing the paths to the executable
    that it needs, as well as the port through which our code will communicate with
    the `selenium` server. We also obtain a connection to the WebDriver by calling
    `NewRemote()`. The `wd` object is the WebDriver connection that we will use to
    send commands to the Firefox browser, as demonstrated in the following code snippet:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们通过提供它所需的可执行文件的路径以及我们的代码将与`selenium`服务器通信的端口来创建`selenium`驱动程序。我们还通过调用`NewRemote()`来获取与WebDriver的连接。`wd`对象是我们将用于向Firefox浏览器发送命令的WebDriver连接，如下面的代码片段所示：
- en: '[PRE11]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We tell the browser to load the web page for *Mastering Go*, by Mihalis Tsoukalos,
    and wait for our CSS query for product reviews to return more than one result.
    This will loop indefinitely until the reviews appear. Once we discover the reviews,
    we print the text for each one.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们告诉浏览器加载*Mihalis Tsoukalos*的*Mastering Go*网页，并等待我们的产品评论的CSS查询返回多于一个结果。这将一直循环，直到评论出现。一旦我们发现评论，我们就打印每一个评论的文本。
- en: Summary
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we covered the basics of how to navigate your web scraper through
    a website. We looked into the anatomy of a web link, and how to use HTTP `GET`
    requests to simulate following a link. We looked at how HTTP forms, such as search
    boxes, generate HTTP requests. We also saw the difference between HTTP `GET` and
    `POST` requests, and how to send `POST` requests in Go. We also covered how to
    avoid loops by tracking your history. Finally, the differences between breadth-first
    and depth-first web crawling, and their respective trade-offs were covered.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了如何通过网站导航您的网络爬虫的基础知识。我们研究了网页链接的结构，以及如何使用HTTP `GET`请求来模拟跟踪链接。我们研究了HTTP表单（如搜索框）如何生成HTTP请求。我们还看到了HTTP
    `GET`和`POST`请求之间的区别，以及如何在Go中发送`POST`请求。我们还介绍了如何通过跟踪历史记录来避免循环。最后，我们介绍了广度优先和深度优先网络爬行之间的差异，以及它们各自的权衡。
- en: In [Chapter 6](a1ed8fec-44c3-4798-beab-27a3c08dc151.xhtml), *Protecting Your
    Web Scraper*, we will look at ways to ensure your safety as you crawl the web.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第6章](a1ed8fec-44c3-4798-beab-27a3c08dc151.xhtml)中，*保护您的网络爬虫*，我们将探讨在爬取网络时如何确保您的安全。
