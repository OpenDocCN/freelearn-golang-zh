- en: Comparing Code Quality Across Versions
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跨版本比较代码质量
- en: After you've written, debugged, profiled, and monitored your Go code, you need
    to monitor your application in the long term for performance regressions. Adding
    new features to your code is useless if you can't continue to deliver a level
    of performance that other systems in your infrastructure depend on.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写、调试、分析和监视您的Go代码之后，您需要长期监视您的应用程序性能回归。如果您无法继续提供基础架构中其他系统所依赖的性能水平，那么向您的代码添加新功能是没有用的。
- en: 'In this chapter, we will learn about the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习以下主题：
- en: Utilizing the Go Prometheus exporter
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用Go Prometheus导出器
- en: '**Application performance monitoring** (**APM**) tools'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**应用程序性能监控**（**APM**）工具'
- en: '**Service-level indicators** and **service-level objectives** (**SLIs** and
    **SLOs**)'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务级指标**和**服务级目标**（**SLIs**和**SLOs**）'
- en: Utilizing logging
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用日志记录
- en: Understanding these concepts should help drive you to write performant code
    over the longer term. When working on larger-scale projects, work often doesn't
    scale well. Having 10 times the number of engineers often does not guarantee 10
    times the output. Being able to programmatically quantify code performance is
    important as software teams grow and features are added to products. Evangelizing
    performant code is something that is always taken in a positive light, and using
    some of the techniques described in this chapter will help you to improve your
    code performance in the long term, whether you're working in an enterprise setting
    or on a small open source project.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 了解这些概念应该有助于驱使您在长期内编写高性能的代码。在处理大规模项目时，工作通常不会很好地扩展。拥有10倍数量的工程师通常并不意味着能够提供10倍的产出。能够以编程方式量化代码性能在软件团队增长并向产品添加功能时非常重要。宣传高性能代码总是会受到积极的评价，使用本章描述的一些技术将有助于您长期改进代码性能，无论您是在企业环境中工作还是在一个小型开源项目中。
- en: Go Prometheus exporter – exporting data from your Go application
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Go Prometheus导出器 - 从您的Go应用程序导出数据
- en: One of the best ways to track long-term changes to your application is to use
    time-series data to monitor and alert us about important changes. Prometheus
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪应用程序长期变化的最佳方法之一是使用时间序列数据来监视并警告我们重要的变化。Prometheus
- en: '([https://prometheus.io/](https://prometheus.io/)) is a great way to perform
    this task. Prometheus is an open source time-series monitoring tool that utilizes
    a pull model via HTTP in order to drive monitoring and alerting. It is written
    in Go and has first-class client libraries for Go programs. The following steps
    show a very simple implementation of the Go Prometheus HTTP library:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ([https://prometheus.io/](https://prometheus.io/))是执行此任务的一个很好的方法。Prometheus是一个开源的时间序列监控工具，通过HTTP使用拉模型来驱动监控和警报。它是用Go编写的，并且为Go程序提供了一流的客户端库。以下步骤展示了Go
    Prometheus HTTP库的一个非常简单的实现：
- en: 'First, we instantiate our package and import our necessary libraries:'
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们实例化我们的包并导入我们需要的库：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, in our `main` function, we instantiate a new server and have it serve
    a `NewServeMux` that returns a Prometheus handler (`promhttp.Handler()`):'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，在我们的`main`函数中，我们实例化一个新的服务器，并让它提供一个返回Prometheus处理程序（`promhttp.Handler()`）的`NewServeMux`：
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'After we do this, we can see that we return values from the default Prometheus
    exporter. These are all well commented, and include the following:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在这之后，我们可以看到我们从默认的Prometheus导出器返回值。这些都有很好的注释，并包括以下内容：
- en: Go garbage collection information
  id: totrans-16
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: Go垃圾收集信息
- en: Goroutine information
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goroutine信息
- en: Go environment version
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Go环境版本
- en: Go memory statistics
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Go内存统计
- en: Go CPU utilization statistics
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Go CPU利用率统计
- en: HTTP handler statistics
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HTTP处理程序统计
- en: 'We next build the binary for our Go service:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们构建我们Go服务的二进制文件：
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We next create a docker network for linking our services together:'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们创建一个docker网络来链接我们的服务：
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We then follow this by creating our Prometheus exporter service:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们创建我们的Prometheus导出器服务：
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Next, we run our Prometheus exporter service on our Docker host:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在我们的Docker主机上运行我们的Prometheus导出器服务：
- en: '[PRE5]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In the following screenshot, we can see a truncated output of this response.
    Excluded are the comments and the built-in Go statistics for brevity. You can
    see the key–value responses in the response from the server:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的截图中，我们可以看到这个响应的截断输出。出于简洁起见，我们排除了注释和内置的Go统计信息。您可以在服务器的响应中看到键-值响应：
- en: '![](img/acfa975f-460e-4fe2-8bc0-63a759934df5.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/acfa975f-460e-4fe2-8bc0-63a759934df5.png)'
- en: 'After we have set up this server, we can monitor it at a given cadence. We
    can run both our metrics service and Prometheus in containers and let them talk
    to each other. We can use a simple `prometheus.yml` definition for our Prometheus
    container:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置了这个服务器之后，我们可以以给定的节奏监视它。我们可以在容器中运行我们的度量服务和Prometheus，并让它们相互通信。我们可以为我们的Prometheus容器使用一个简单的`prometheus.yml`定义：
- en: '![](img/3a9cdc6c-b28c-4191-996e-3a8e0d80a7e0.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3a9cdc6c-b28c-4191-996e-3a8e0d80a7e0.png)'
- en: You can replace `promExporter` within the `scrape_configs`->`static_configs`->`targets`
    portion of the YAML with an IP address or hostname if you'd like to use something
    besides your docker host for this.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想要使用除了docker主机之外的IP地址或主机名，您可以在YAML的`scrape_configs`->`static_configs`->`targets`部分中用IP地址或主机名替换`promExporter`。
- en: 'After we have our binary build, we can create two separate Dockerfiles: one
    for the container that will contain our Prometheus exporter service and one that
    will contain our Prometheus service. Our Dockerfile for our Prometheus service
    takes the baseline Prometheus image and adds our YAML configuration to the appropriate
    place in our image. Our `Dockerfile.promservice` configuration is as follows:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们构建了二进制文件之后，我们可以创建两个单独的Dockerfile：一个用于包含我们的Prometheus导出器服务的容器，另一个用于包含我们的Prometheus服务的容器。我们的Prometheus服务的Dockerfile采用基线Prometheus镜像，并将我们的YAML配置添加到图像的适当位置。我们的`Dockerfile.promservice`配置如下：
- en: '[PRE6]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Once we have our `Dockerfile.promservice` created, we can build our Prometheus
    service:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们创建了`Dockerfile.promservice`，我们就可以构建我们的Prometheus服务：
- en: '[PRE7]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We can then run our Prometheus service on our Docker host:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们可以在我们的Docker主机上运行我们的Prometheus服务：
- en: '[PRE8]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Now we have a Prometheus instance running on our local environment.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们在本地环境上运行了一个Prometheus实例。
- en: 'After we have our Prometheus service up and running, we can go to `http://[IPADDRESS]:9090/`
    and we''ll see our Prometheus instance:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们的Prometheus服务运行起来后，我们可以访问 `http://[IPADDRESS]:9090/`，就能看到我们的Prometheus实例：
- en: '![](img/a63a59c1-4eee-478d-aa04-d6950f0f1dc1.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a63a59c1-4eee-478d-aa04-d6950f0f1dc1.png)'
- en: 'We can validate that we are scraping our target by looking at the `/targets`
    path in the same URL:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过查看相同URL中的`/targets`路径来验证我们正在抓取我们的目标：
- en: '![](img/0135088e-d9d5-45b6-82cf-14fefaa31be6.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0135088e-d9d5-45b6-82cf-14fefaa31be6.png)'
- en: 'Next, we can make a couple of requests to our host:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们可以向我们的主机发出一些请求：
- en: '[PRE9]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Next, we can see the results of our `curl` in our Prometheus instance:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们可以在我们的Prometheus实例中看到我们的`curl`的结果：
- en: '![](img/206eb2a0-6f9f-48b1-a63a-2cef366a27f1.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/206eb2a0-6f9f-48b1-a63a-2cef366a27f1.png)'
- en: With these results, we can see the total number HTTP responses that we have
    served with a 200, 500, and 503 status code. Our example is simple, but we can
    use many different types of metrics here in order to validate any assumptions
    that we have. We will do a more involved metric-gathering example in our SLI/SLO
    example later in this chapter.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些结果，我们可以看到我们提供的总HTTP响应次数，其中包括200、500和503状态码。我们的示例很简单，但我们可以在这里使用许多不同类型的指标来验证我们的任何假设。在本章后面的SLI/SLO示例中，我们将进行更多涉及指标收集的示例。
- en: In the next section, we are going to talk about APM and how it can be used in
    maintaining a performant distributed system.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将讨论APM以及如何在维护高性能分布式系统中使用它。
- en: APM – watching your distributed system performance
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: APM – 监控你的分布式系统性能
- en: 'There are many APM tools on the market today. They are frequently used to monitor
    the performance and reliability of software over time. Some of the products available
    for Go at the time of writing this book are as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 今天市场上有许多APM工具。它们经常用于随时间监视软件的性能和可靠性。在撰写本书时，Go语言可用的一些产品如下：
- en: '**Elastic APM agent**: [https://www.elastic.co/guide/en/apm/agent/go/current/index.html](https://www.elastic.co/guide/en/apm/agent/go/current/index.html)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Elastic APM agent**: [https://www.elastic.co/guide/en/apm/agent/go/current/index.html](https://www.elastic.co/guide/en/apm/agent/go/current/index.html)'
- en: '**New Relic APM**: [https://newrelic.com/golang](https://newrelic.com/golang)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**New Relic APM**: [https://newrelic.com/golang](https://newrelic.com/golang)'
- en: '**Datadog**: [https://docs.datadoghq.com/tracing/setup/go/](https://docs.datadoghq.com/tracing/setup/go/)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Datadog**: [https://docs.datadoghq.com/tracing/setup/go/](https://docs.datadoghq.com/tracing/setup/go/)'
- en: '**SignalFX**: [https://docs.signalfx.com/en/latest/apm/apm-instrument/apm-go.html](https://docs.signalfx.com/en/latest/apm/apm-instrument/apm-go.html)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SignalFX**: [https://docs.signalfx.com/en/latest/apm/apm-instrument/apm-go.html](https://docs.signalfx.com/en/latest/apm/apm-instrument/apm-go.html)'
- en: '**AppDynamics** : [https://www.appdynamics.com/supported-technologies/go](https://www.appdynamics.com/supported-technologies/go)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AppDynamics** : [https://www.appdynamics.com/supported-technologies/go](https://www.appdynamics.com/supported-technologies/go)'
- en: '**Honeycomb APM**: [https://docs.honeycomb.io/getting-data-in/go/](https://docs.honeycomb.io/getting-data-in/go/)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Honeycomb APM**: [https://docs.honeycomb.io/getting-data-in/go/](https://docs.honeycomb.io/getting-data-in/go/)'
- en: '**AWS XRay**: [https://docs.aws.amazon.com/xray/latest/devguide/xray-sdk-go.html](https://docs.aws.amazon.com/xray/latest/devguide/xray-sdk-go.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS XRay**: [https://docs.aws.amazon.com/xray/latest/devguide/xray-sdk-go.html](https://docs.aws.amazon.com/xray/latest/devguide/xray-sdk-go.html)'
- en: '**Google''s suite of APM products**: [https://cloud.google.com/apm/](https://cloud.google.com/apm/)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Google的APM产品套件**: [https://cloud.google.com/apm/](https://cloud.google.com/apm/)'
- en: Most of these tools are closed source and paid services. Aggregating distributed
    traces is a difficult value proposition. The vendors listed here (as well as some
    that are not mentioned) combine data storage, aggregation, and analysis in order
    to have a one-stop shop for APM. We can also use the OpenCensus/Zipkin open source
    example that we created in [Chapter 13](ec12b9e7-c528-45c2-b0b8-dea297659b3e.xhtml), *Tracing
    Go Code*, to perform distributed tracing in our system. Implementing spans around
    particular bits of our code base can help us to monitor long-term application
    performance.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工具大多是闭源和付费服务。聚合分布式跟踪是一个困难的价值主张。这里列出的供应商（以及一些未提及的供应商）结合了数据存储、聚合和分析，以便为APM提供一站式服务。我们还可以使用我们在[第13章](ec12b9e7-c528-45c2-b0b8-dea297659b3e.xhtml)中创建的OpenCensus/Zipkin开源示例，在我们的系统中执行分布式跟踪。在我们的代码库周围实现跨度可以帮助我们监视长期的应用程序性能。
- en: Let's take a look at an example of Google's APM solutions. At the time of writing,
    Google Cloud offers 2.5 million span ingestions and 25 million span scans per
    month, which is more than adequate for an example.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个Google的APM解决方案示例。在撰写本文时，Google Cloud每月提供250万个跨度摄取和2500万个跨度扫描，这对于一个示例来说已经足够了。
- en: Google Cloud environment setup
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Google Cloud环境设置
- en: 'The first thing we need to do is to create a GCP project and retrieve the application
    credentials:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要创建一个GCP项目并检索应用凭据：
- en: 'First, we''ll log into [https://console.cloud.google.com/](https://console.cloud.google.com/).
    Once logged in, we can hit the project selector dropdown at the top of the page:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们要登录 [https://console.cloud.google.com/](https://console.cloud.google.com/)。登录后，我们可以点击页面顶部的项目选择器下拉菜单：
- en: '![](img/ecb57374-6123-4223-9163-a94127915405.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ecb57374-6123-4223-9163-a94127915405.png)'
- en: 'We can then create a new project for our particular application at the top
    right of the screen, as shown in the following screenshot:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们可以在屏幕右上角创建一个新项目，如下截图所示：
- en: '![](img/ca13a97e-ed0e-4c20-88f2-d249eb7fcb3e.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ca13a97e-ed0e-4c20-88f2-d249eb7fcb3e.png)'
- en: We can then visit the service account key page at [https://console.cloud.google.com/apis/credentials/serviceaccountkey](https://console.cloud.google.com/apis/credentials/serviceaccountkey),
    which will let us create a service account key.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们可以访问服务账号密钥页面 [https://console.cloud.google.com/apis/credentials/serviceaccountkey](https://console.cloud.google.com/apis/credentials/serviceaccountkey)，这将让我们创建一个服务账号密钥。
- en: 'We can create a service account key for our application. Make sure you select
    the Cloud Trace Agent, as this is necessary for us to add traces to Google Cloud
    Trace. This is depicted in the following screenshot:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以为我们的应用程序创建一个服务帐号密钥。确保您选择Cloud Trace代理，因为这对我们向Google Cloud Trace添加跟踪是必要的。这在以下截图中有所体现：
- en: '![](img/ced82271-b1aa-421a-83c2-fe958418d501.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ced82271-b1aa-421a-83c2-fe958418d501.png)'
- en: After we click Create, the browser will prompt us to download our new credentials.
    For reference, we will call this key `high-performance-in-go-tracing.json`. You
    can name your key whatever you like.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击创建后，浏览器将提示我们下载新的凭据。供参考，我们将称此密钥为`high-performance-in-go-tracing.json`。您可以根据需要命名密钥。
- en: 'Once we have this key saved locally, we can turn it into an environment variable.
    In your Terminal, enter the following command:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们将此密钥保存在本地，我们可以将其转换为环境变量。在您的终端中，输入以下命令：
- en: '[PRE10]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This will save your service account credentials as a special environment variable,
    `GOOGLE_APPLICATION_CREDENTIALS`, which we will use in our next example.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这将把您的服务帐号凭据保存为一个特殊的环境变量，`GOOGLE_APPLICATION_CREDENTIALS`，我们将在下一个示例中使用它。
- en: Google Cloud Trace code
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Google Cloud Trace代码
- en: 'Once we have our application credentials all set up; we are off to the races
    to write our first trace that will be captured by our APM:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们的应用程序凭据全部设置好，我们就可以开始编写我们的第一个将被我们的APM捕获的跟踪：
- en: 'First, we instantiate the necessary packages and set a server host/port constant:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们实例化必要的包并设置服务器主机/端口常量：
- en: '[PRE11]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Next, in our `init()` function, we set up our StackDriver exporter and register
    our tracer to sample every web request that comes in. In production, we should
    probably sample fewer requests, as sampling adds additional latency to our requests:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在我们的`init()`函数中，我们设置了StackDriver导出器，并注册了我们的跟踪器以对每个进来的网络请求进行采样。在生产环境中，我们可能应该对更少的请求进行采样，因为采样会给我们的请求增加额外的延迟：
- en: '[PRE12]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Next, we are going to have a sleep function that takes a context, sleeps, and
    writes a message to the end user. In this function, I am deferring the end of
    the span to the end of the function:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将有一个休眠函数，它接受一个上下文，休眠，并向最终用户写入一条消息。在这个函数中，我将跨度的结束推迟到函数的末尾：
- en: '[PRE13]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Our GitHub request function makes a request to [https://github.com](https://github.com)
    and returns the status to our end user. In this function, I''m explicitly calling
    the end of the span:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的GitHub请求函数向[https://github.com](https://github.com)发出请求，并将状态返回给我们的最终用户。在这个函数中，我明确调用了跨度的结束：
- en: '[PRE14]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Our main function sets up an HTTP handler function that performs the `githubRequest`
    and `sleep` functions:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的主函数设置了一个执行`githubRequest`和`sleep`函数的HTTP处理程序函数：
- en: '[PRE15]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'After we execute our main function, we make a request to `localhost:1234` and
    see a response:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们执行主函数后，向`localhost:1234`发出请求并看到响应：
- en: '![](img/46cc3921-ed8c-4c9f-8dbc-9428236fd65d.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](img/46cc3921-ed8c-4c9f-8dbc-9428236fd65d.png)'
- en: 'After this, we visit the Google Cloud console and select the trace that we
    made:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，我们访问Google Cloud控制台并选择我们创建的跟踪：
- en: '![](img/053fbe63-4e43-4fb1-8723-5f9cb5640f14.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](img/053fbe63-4e43-4fb1-8723-5f9cb5640f14.png)'
- en: 'In this trace example, we can see all sorts of relevant details:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个跟踪示例中，我们可以看到各种相关细节：
- en: All of the trace samples that have been taken (I added a bunch of different
    samples here to populate the fields).
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已经采取的所有跟踪样本（我在这里添加了一堆不同的样本来填充字段）。
- en: Our waterfall graph of the request flow. This is a bit small for our example
    with just the web request and the sleep, but as we pass context around in a distributed
    system, this graph quickly gets much bigger.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的请求流的瀑布图。对于我们的示例来说有点小，只有网络请求和休眠，但是在分布式系统中传递上下文时，这个图很快就会变得更大。
- en: The summary for each trace. If you click on one of the tracing bars in the graph,
    you can see more details about the particular trace.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个跟踪的摘要。如果您点击图表中的一个跟踪条，您可以查看有关特定跟踪的更多详细信息。
- en: 'Adding distributed tracing as an APM solution can be extremely helpful in determining
    the location of the web request that takes the most time. Finding real-life bottlenecks
    can often be much more practical than diving through logs. Google''s APM also
    gives you the ability to run reports based on the traces you''ve made. After you
    have made more than 100 requests, you can execute an analysis report and see the
    results. The density distribution latency chart shows you where your request latencies
    lie in a graph. Our example should have mostly similar results, as we performed
    a long sleep and made one solitary request to an external service. We can see
    the density distribution graph in the following screenshot:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 将分布式跟踪作为APM解决方案添加到确定花费最多时间的网络请求的位置中可能非常有帮助。找到现实生活中的瓶颈通常比深入日志更实际。Google的APM还可以让您根据您所做的跟踪运行报告。在您进行了100多次请求之后，您可以执行分析报告并查看结果。密度分布延迟图表显示了您的请求延迟在图表中的位置。我们的示例应该有大致相似的结果，因为我们进行了长时间的休眠，并且只向外部服务发出了一个请求。我们可以在以下截图中看到密度分布图：
- en: '![](img/fffa4640-94a6-4dd9-9539-07377ae888fa.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fffa4640-94a6-4dd9-9539-07377ae888fa.png)'
- en: 'We can also look at the cumulative latency in this portal, which will show
    us the percentage of requests that are shorter than the value on the *x* axis:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以在此门户中查看累积延迟，这将显示比*x*轴上的值短的请求的百分比：
- en: '![](img/73ccd8c4-1aef-4706-b576-9a8e5eae5700.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](img/73ccd8c4-1aef-4706-b576-9a8e5eae5700.png)'
- en: 'We can also see latency profiles with correlated requests:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以看到与相关请求相关的延迟配置文件：
- en: '![](img/3204ba3b-bc64-4f0e-8b5e-2c19fa41d0af.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3204ba3b-bc64-4f0e-8b5e-2c19fa41d0af.png)'
- en: 'Furthermore, we can also see the perceived bottlenecks within the distributed
    system:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还可以看到分布式系统中的感知瓶颈：
- en: '![](img/586c57f2-b4e7-4790-84d2-9ff3b0245fbe.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](img/586c57f2-b4e7-4790-84d2-9ff3b0245fbe.png)'
- en: These analysis tools help us to deduce where we can make improvements in our
    distributed system. APMs help many companies to deliver performant applications
    to their customers. These tools are extra valuable because they look at performance
    through the lens of customer experience. In the next section, we will talk about
    setting goals with SLIs and SLOs.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这些分析工具帮助我们推断出我们在分布式系统中可以进行改进的地方。APM帮助许多公司向客户交付高性能的应用程序。这些工具非常有价值，因为它们从客户体验的角度来看待性能。在下一节中，我们将讨论使用SLIs和SLOs设定目标。
- en: SLIs and SLOs – setting goals
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SLIs和SLOs - 设定目标
- en: SLIs and SLOs are two paradigms that were brought to the computer science world
    by Google. They are defined in the SRE workbook
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: SLIs和SLOs是由Google引入计算机科学领域的两种范式。它们在SRE工作手册中有定义
- en: '([https://landing.google.com/sre/sre-book/chapters/service-level-objectives/](https://landing.google.com/sre/sre-book/chapters/service-level-objectives/))
    and are an excellent way to measure actionable items within your computing system.
    These measurements normally follow Google''s four golden signals:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: （[https://landing.google.com/sre/sre-book/chapters/service-level-objectives/](https://landing.google.com/sre/sre-book/chapters/service-level-objectives/)）是衡量计算系统中可操作项目的绝佳方式。这些测量通常遵循Google的四个黄金信号：
- en: '**Latency**: The amount of time a request takes to complete (usually measured
    in milliseconds)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**延迟**：请求完成所需的时间（通常以毫秒为单位衡量）'
- en: '**Traffic**: The volume of traffic that your service is receiving (usually
    measured in requests per second)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流量**：您的服务接收的流量量（通常以每秒请求次数来衡量）'
- en: '**Errors**: The percentage of failed requests over total requests (usually
    measured with a  percentage)'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**错误**：失败请求占总请求的百分比（通常用百分比来衡量）'
- en: '**Saturation**: The measure of hardware saturation (usually measured by queued
    request counts)'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**饱和度**：硬件饱和度的测量（通常以排队请求计数来衡量）'
- en: These measurements can then be used to create one or more SLAs. These are frequently
    delivered to customers who expect a specific level of service from your application.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这些测量结果可以用来创建一个或多个SLA。这些通常提供给期望从您的应用程序中获得特定服务水平的客户。
- en: We can use Prometheus to measure these metrics. Prometheus has a bunch of different
    methodologies for counting things, including gauges, counters, and histograms.
    We will use all of these different tools to measure these metrics within our system.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用Prometheus来测量这些指标。Prometheus有很多不同的计数方法，包括饱和度计、计数器和直方图。我们将使用所有这些不同的工具来测量我们系统中的这些指标。
- en: 'To test our system, we''ll use the `hey` load generator. This is a tool that
    is similar to `ab`, which we used in previous chapters, but it''ll show our distribution
    a little better for this particular scenario. We can grab it by running the following command:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试我们的系统，我们将使用`hey`负载生成器。这是一个类似于我们在之前章节中使用的`ab`的工具，但是对于这种特定情况，它会更好地显示我们的分布。我们可以通过运行以下命令来获取它：
- en: '[PRE16]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We are going to need to stand up our Prometheus service in order to read some
    of these values. If yours isn''t still standing from our previous example, we
    can perform the following commands:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要搭建我们的Prometheus服务，以便读取其中一些值。如果您的服务还没有从我们之前的示例中搭建起来，我们可以执行以下命令：
- en: '[PRE17]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This will get our Prometheus instance to stand up and measure requests:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这将使我们的Prometheus实例搭建起来并测量请求：
- en: 'Our code starts by instantiating the `main` package and importing the necessary
    Prometheus packages:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的代码首先实例化`main`包并导入必要的Prometheus包：
- en: '[PRE18]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We then gather our saturation, requests, and latency numbers in our `main`
    function. We use a gauge for saturation, a counter for requests, and a histogram
    for latency:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们在我们的`main`函数中收集饱和度、请求和延迟数字。我们使用饱和度计、请求计数器和延迟直方图：
- en: '[PRE19]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We then create our `goldenSignalHandler`, which randomly generates a latency
    from 0 to 1 seconds. For added visibility of our signals, if the random number
    is divisible by 4, we return a 404 error status, and if it's divisible by 5, we
    return a 500 error. We then return a response and log that the request has been
    completed.
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们创建我们的`goldenSignalHandler`，它会随机生成一个0到1秒的延迟。为了更好地显示我们的信号，如果随机数能被4整除，我们返回404错误状态，如果能被5整除，我们返回500错误。然后我们返回一个响应并记录请求已完成。
- en: 'Our `goldenSignalChain` ties these metrics together:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`goldenSignalChain`将这些指标联系在一起：
- en: '[PRE20]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We then register all of our measurements (saturation, requests, and latency)
    with Prometheus, handle our HTTP requests, and start our HTTP server:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们在Prometheus中注册所有的测量（饱和度、请求和延迟），处理我们的HTTP请求，并启动我们的HTTP服务器：
- en: '[PRE21]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'After we start our HTTP server by executing `go run SLISLO.go`, we can then
    make a `hey` request to our HTTP server. The output from our `hey` call is visible
    in the following screenshot. Remember that these are all random values and will
    be different if you execute this same test:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在执行`go run SLISLO.go`启动HTTP服务器后，我们可以向我们的HTTP服务器发出`hey`请求。`hey`调用的输出在以下截图中可见。请记住，这些都是随机值，如果您执行相同的测试，结果将不同：
- en: '![](img/2dbed159-6c95-40f8-8952-de203f66852e.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2dbed159-6c95-40f8-8952-de203f66852e.png)'
- en: We can then take a look at our individual golden signals.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以查看我们的个体黄金信号。
- en: Measuring traffic
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测量流量
- en: To measure our traffic, we can use the Prometheus query `sum(rate(requests[1m]))`.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 要测量我们的流量，我们可以使用Prometheus查询`sum(rate(requests[1m]))`。
- en: We can measure the rate at any given interval. Configure this rate in a couple
    of different ways and see which is most conducive to your system's requirements.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在任何给定的时间间隔内测量速率。以几种不同的方式配置这个速率，看看哪种对您系统的要求最有利。
- en: Measuring latency
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测量延迟
- en: To measure latency, we can look at the `latency_bucket` Prometheus query. Our
    requests were lumped into a histogram with different latency numbers, and this
    query reflects that.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 要测量延迟，我们可以查看`latency_bucket` Prometheus查询。我们的请求被分成了一个包含不同延迟数字的直方图，这个查询反映了这一点。
- en: Measuring errors
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测量错误
- en: To measure the number of errors in our system, we need to find the ratio of
    requests that had a successful response code to those that did not have a successful
    response code. We can find this with the following query `sum(requests {code!="200"})
    / (sum(requests {code="200"})) + sum(requests {code!="200"})`.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 要衡量系统中的错误数量，我们需要找到具有成功响应代码的请求与没有成功响应代码的请求的比率。我们可以使用以下查询找到这个比率`sum(requests {code!="200"})
    / (sum(requests {code="200"})) + sum(requests {code!="200"})`。
- en: This ratio is important to monitor. Computer systems fail and people make incorrect
    requests, but your ratio of 200 responses to non-200 responses should be relatively
    small.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这个比率是重要的监控指标。计算机系统会出现故障，人们会发出不正确的请求，但您的200响应与非200响应的比率应该相对较小。
- en: Measuring saturation
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 衡量饱和度
- en: We can measure saturation using the `saturation` **Prometheus** query. We want
    to validate that our system isn't saturated, and this query can help us to perform
    this action.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`饱和度`的**Prometheus**查询来衡量饱和度。我们想要验证我们的系统是否饱和，这个查询可以帮助我们执行这个操作。
- en: Grafana
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Grafana
- en: 'We can encapsulate all of these golden signals into a Grafana dashboard. We
    can run Grafana locally by invoking:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将所有这些黄金信号封装到Grafana仪表板中。我们可以通过调用在本地运行Grafana来运行Grafana：
- en: '[PRE22]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'We need to log into the Grafana portal by visiting `http://localhost:3000` and
    using the default username and password combination:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要通过访问`http://localhost:3000`并使用默认的用户名和密码组合来登录Grafana门户网站：
- en: '**Username**: admin'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '**用户名**：admin'
- en: '**Password**: admin'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '**密码**：admin'
- en: We can then set up a new password to our liking after we've logged in.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 登录后，我们可以设置新的密码。
- en: 'After we''ve logged in, we click Add data source at the top of the page and
    select Prometheus on the next page. We then enter our local IP address and click
    Save & Test. If all works as expected, we should see the Data source is working
    popup at the bottom of the screen:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 登录后，我们点击页面顶部的添加数据源，并在下一页选择Prometheus。然后输入我们的本地IP地址并点击保存并测试。如果一切正常，我们应该在屏幕底部看到数据源正在工作的弹出窗口：
- en: '![](img/e7de906b-9d13-4a64-8582-231fed7be4cc.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e7de906b-9d13-4a64-8582-231fed7be4cc.png)'
- en: After we complete this, we visit [http://localhost:3000/dashboard/import](http://localhost:3000/dashboard/import).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，我们访问[http://localhost:3000/dashboard/import](http://localhost:3000/dashboard/import)。
- en: We then choose Upload .json file in the top-right corner, and we upload the
    JSON file that has been created for this dashboard at [https://github.com/bobstrecansky/HighPerformanceWithGo/blob/master/15-code-quality-across-versions/SLISLO/four_golden_signals_grafana_dashboard.json](https://github.com/bobstrecansky/HighPerformanceWithGo/blob/master/15-code-quality-across-versions/SLISLO/four_golden_signals_grafana_dashboard.json).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们在右上角选择上传.json文件，并上传为此仪表板创建的JSON文件，位于[https://github.com/bobstrecansky/HighPerformanceWithGo/blob/master/15-code-quality-across-versions/SLISLO/four_golden_signals_grafana_dashboard.json](https://github.com/bobstrecansky/HighPerformanceWithGo/blob/master/15-code-quality-across-versions/SLISLO/four_golden_signals_grafana_dashboard.json)。
- en: 'After we have uploaded this JSON file, we import this data source, and we''ll
    be able to see our Request Rate, Duration Latency Buckets, Error Rate, and Saturation
    charts, as shown in the following screenshot:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 上传了这个JSON文件后，我们导入这个数据源，就能够看到我们的请求速率、持续延迟桶、错误率和饱和度图表，如下面的截图所示：
- en: '![](img/89634aef-43de-4594-bf92-fa0ed2edecd9.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](img/89634aef-43de-4594-bf92-fa0ed2edecd9.png)'
- en: Having visibility into these statistics can be helpful in maintaining a stable
    system. After you have these statistics captured, you can use Prometheus Alertmanager
    to set alerts on thresholds you're interested in monitoring.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 了解这些统计数据可以帮助维护稳定的系统。在捕获了这些统计数据之后，您可以使用Prometheus Alertmanager来设置您感兴趣的监控阈值的警报。
- en: More information on configuring Alertmanager can be found at
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 有关配置Alertmanager的更多信息，请访问
- en: '[https://prometheus.io/docs/alerting/alertmanager/](https://prometheus.io/docs/alerting/alertmanager/).'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://prometheus.io/docs/alerting/alertmanager/](https://prometheus.io/docs/alerting/alertmanager/)'
- en: In the next section, we will learn how to keep track of our data, also known
    as logging.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将学习如何跟踪我们的数据，也称为日志记录。
- en: Logging – keeping track of your data
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日志记录-跟踪您的数据
- en: Logging, the act of recording events that occur in a system, is essential to
    creating performant software systems. Being able to record and validate events
    within a programming system is a great way to ensure that you're maintaining code
    quality across versions of your applications. Logs can often quickly show a bug
    in your software, and being able to consume that information in a quick fashion
    can often help lower your **mean time to recovery** (**MTTR**).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 记录系统中发生的事件的日志记录是创建高性能软件系统的重要组成部分。能够记录和验证编程系统中的事件是确保您在应用程序的各个版本中保持代码质量的一个很好的方法。日志通常可以快速显示软件中的错误，并且能够快速消化这些信息通常可以帮助降低您的**平均恢复时间**（**MTTR**）。
- en: 'There are many different logging packages for Go. A few of the most popular
    packages are as follows:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: Go有许多不同的日志包。以下是一些最受欢迎的包：
- en: The standard built-in log package provided by the Go maintainers
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Go维护者提供的标准内置日志包
- en: '**The Glog package**: [https://github.com/golang/glog](https://github.com/golang/glog)'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Glog包**：[https://github.com/golang/glog](https://github.com/golang/glog)'
- en: '**Uber''s Zap package**: [https://github.com/uber-go/zap](https://github.com/uber-go/zap)'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Uber的Zap包**：[https://github.com/uber-go/zap](https://github.com/uber-go/zap)'
- en: '**The Zero Allocation JSON logger**: [https://github.com/rs/zerolog](https://github.com/rs/zerolog)'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**零分配JSON记录器**：[https://github.com/rs/zerolog](https://github.com/rs/zerolog)'
- en: '**The Logrus package**: [https://github.com/sirupsen/logrus](https://github.com/sirupsen/logrus)'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Logrus包**：[https://github.com/sirupsen/logrus](https://github.com/sirupsen/logrus)'
- en: 'We are going to use the Zap package as our example, as benchmarks have shown.
    Using the standard library logger is often sufficient (if you''ve noticed, this
    is the package that I''ve used for logging in the book thus far). Having a structured
    logging package such as Zap available can make up for a pleasant experience because
    it offers a couple of features that the standard library logger doesn''t offer
    out of the box, such as the following:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将以Zap包作为示例，因为基准测试表明。通常使用标准库记录器就足够了（如果你注意到了，这是我迄今为止在书中用于记录的包）。拥有诸如Zap这样的结构化日志包可以弥补愉快的体验，因为它提供了一些标准库记录器无法直接提供的功能，例如以下内容：
- en: Logging levels
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志级别
- en: Structured logs (JSON in particular)
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结构化日志（特别是JSON）
- en: Typed logs
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类型化日志
- en: It also performs best in comparison benchmarks among the loggers. Zap has two
    different types of logging available, the sugared logger and the structured logger.
    The structured logger is slightly more performant, whereas the sugared logger
    is more loosely typed. As this is a book about performance, we are going to take
    a look at the structured logger as it's more performant, but both logging options
    are more than adequate for production use.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在日志记录器之间进行比较基准测试时，它的性能表现最佳。Zap有两种不同类型的日志记录可用，即sugared记录器和结构化记录器。结构化记录器性能略高，而sugared记录器类型较松散。由于这是一本关于性能的书，我们将看一下结构化记录器，因为它的性能更高，但这两种记录选项都非常适合生产使用。
- en: Having a logger that has different logging levels is important because it allows
    you to determine which logs need dire attention and which logs are just returning
    information. This also lets you set a priority for your team depending on how
    urgent a fix is when you hit a logging inflection point.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有具有不同日志级别的记录器很重要，因为它可以帮助您确定哪些日志需要紧急关注，哪些日志只是返回信息。这还可以根据日志的紧急程度为您的团队设置优先级，当您达到日志拐点时，可以确定修复的紧急程度。
- en: 'Having logs that can be structured is helpful for ingestion into other systems.
    JSON logging is quickly becoming more and more popular because log aggregation
    tools such as the following accept JSON logging:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 具有可结构化的日志对于将其摄入到其他系统中非常有帮助。JSON日志记录迅速变得越来越受欢迎，因为诸如以下的日志聚合工具接受JSON日志记录：
- en: The ELK Stack (ElasticSearch, Logstash, and Kibana)
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ELK Stack（ElasticSearch，Logstash和Kibana）
- en: Loggly
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Loggly
- en: Splunk
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Splunk
- en: Sumologic
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sumologic
- en: Datadog
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Datadog
- en: Google Stackdriver Logging
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google Stackdriver日志记录
- en: As we saw with our APM solutions, we can utilize these logging services to aggregate
    large groupings of logs in a centralized location, whether it be on premise or
    in the cloud.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在APM解决方案中看到的，我们可以利用这些日志记录服务在集中位置聚合大量日志，无论是在本地还是在云中。
- en: Having typed logs allows you to organize your logging data in a way that makes
    sense to your program or business. Maintaining consistency in your logging can
    allow for your system operators and site reliability engineers to more quickly
    diagnose problems, resulting in a shorter MTTR for production incidents.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有类型化日志可以让您以对程序或业务有意义的方式组织日志数据。保持日志记录的一致性可以让系统操作员和站点可靠性工程师更快地诊断问题，从而缩短生产事故的MTTR。
- en: 'Let''s have a look at a logging example with Zap:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个使用Zap的日志示例：
- en: 'First, we instantiate our package and import the `time` package and the Zap
    logger:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们实例化我们的包并导入`time`包和Zap记录器：
- en: '[PRE23]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We then set up a logging production configuration that will return logs to
    `stdout` (following the twelve-factor app process). These can often go to log
    routers such as Fluentd ([https://www.fluentd.org/](https://www.fluentd.org/)),
    and we can test all of the different log levels available in Zap:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们设置一个生产配置，将日志返回到`stdout`（遵循十二要素应用程序流程）。这些通常可以发送到诸如Fluentd（[https://www.fluentd.org/](https://www.fluentd.org/)）之类的日志路由器，我们可以测试Zap中提供的所有不同日志级别：
- en: '[PRE24]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'After we run our logger, we can see some pretty clean JSON output. We can also
    use a utility such as jq ([https://stedolan.github.io/jq/](https://stedolan.github.io/jq/))
    in order to make this easily consumable in your local environment:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 运行记录器后，我们可以看到一些非常干净的JSON输出。我们还可以使用诸如jq（[https://stedolan.github.io/jq/](https://stedolan.github.io/jq/)）之类的实用程序，以便在本地环境中轻松消耗这些输出：
- en: '![](img/ec3d0e6f-18db-4a17-8be5-8e0916416543.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ec3d0e6f-18db-4a17-8be5-8e0916416543.png)'
- en: As we mentioned, having a structured, leveled logger in your Go application
    will help you to troubleshoot more quickly and effectively.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们提到的，在您的Go应用程序中拥有结构化、分级的记录器将帮助您更快速、更有效地进行故障排除。
- en: Summary
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we discussed the different methodologies of comparing code
    quality across versions:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了比较代码质量的不同方法：
- en: Utilizing the Go Prometheus exporter
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用Go Prometheus导出器
- en: APM tools
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: APM工具
- en: SLIs and SLOs
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SLIs和SLOs
- en: Utilizing logging
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用日志记录
- en: Utilizing all of these techniques can help you to determine where your application
    isn't performing as it is expected to. Knowing these things can help you to iterate
    rapidly and produce the best software that you can.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 利用所有这些技术可以帮助您确定应用程序的性能不如预期的地方。了解这些情况可以帮助您快速迭代并产生最好的软件。
- en: Throughout the course of this book, you've learned about application performance
    and how it pertains to Go. I hope this book will help you to think about web performance
    while you are writing applications. Always keep performance in the forefront of
    your mind. Everyone enjoys performant applications, and hopefully this book will
    help you do your part as a developer in making them.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的过程中，您已经了解了应用程序性能及其与Go的关系。我希望这本书能帮助您在编写应用程序时考虑Web性能。始终将性能放在首要位置。每个人都喜欢高性能的应用程序，希望这本书能帮助您作为开发人员尽自己的一份力。
