["```go\n# openapi/concierge.yaml\n\nopenapi: 3.0.0\nservers: \n  - url: /api \ninfo: \n  title: Goophr Concierge API \n  version: '1.0' \n  description: > \n    API responsible for responding to user input and communicating with Goophr \n    Librarian. \npaths: \n  /feeder: \n    post: \n      description: | \n        Register new document to be indexed. \n      responses: \n        '200': \n          description: | \n            Request was successfully completed. \n          content: \n            application/json: \n              schema: \n                $ref: '#/components/schemas/response' \n        '400': \n          description: > \n            Request was not processed because payload was incomplete or incorrect. \n          content: \n            application/json: \n              schema: \n                $ref: '#/components/schemas/response' \n      requestBody: \n        content: \n          application/json: \n            schema: \n              $ref: '#/components/schemas/document' \n        required: true \n  /query: \n    post: \n      description: | \n        Search query \n      responses: \n        '200': \n          description: | \n            Response consists of links to document \n          content: \n            application/json: \n              schema: \n                type: array \n                items: \n                  $ref: '#/components/schemas/document' \n      requestBody: \n        content: \n          application/json: \n            schema: \n              type: array \n              items: \n                type: string \n        required: true \ncomponents: \n  schemas: \n    response: \n      type: object \n      properties: \n        code: \n          type: integer \n          description: Status code to send in response \n        msg: \n          type: string \n          description: Message to send in response \n    document: \n      type: object \n      required: \n        - title \n        - link \n      properties: \n        title: \n          type: string \n          description: Title of the document \n        link: \n          type: string \n          description: Link to the document \n```", "```go\n$ tree \n. \n\u2514\u2500\u2500 goophr \n    \u2514\u2500\u2500 concierge \n        \u251c\u2500\u2500 api \n        \u2502   \u251c\u2500\u2500 feeder.go \n        \u2502   \u251c\u2500\u2500 feeder_test.go \n        \u2502   \u2514\u2500\u2500 query.go \n        \u251c\u2500\u2500 common \n        \u2502   \u251c\u2500\u2500 helpers.go \n        \u251c\u2500\u2500 Dockerfile \n        \u2514\u2500\u2500 main.go \n\n4 directories, 6 files \n```", "```go\npackage main \n\nimport ( \n    \"net/http\" \n\n    \"github.com/last-ent/distributed-go/chapter6/goophr/concierge/api\" \n    \"github.com/last-ent/distributed-go/chapter6/goophr/concierge/common\" \n) \n\nfunc main() { \n    common.Log(\"Adding API handlers...\") \n    http.HandleFunc(\"/api/feeder\", api.FeedHandler) \n\n    common.Log(\"Starting feeder...\") \n    api.StartFeederSystem() \n\n    common.Log(\"Starting Goophr Concierge server on port :8080...\") \n    http.ListenAndServe(\":8080\", nil) \n} \n```", "```go\npackage common \n\nimport ( \n    \"fmt\" \n    \"log\" \n    \"regexp\" \n    \"strings\" \n) \n\n// Log is used for simple logging to console. \nfunc Log(msg string) { \n    log.Println(\"INFO - \", msg) \n} \n\n// Warn is used to log warning messages to console. \nfunc Warn(msg string) { \n    log.Println(\"---------------------------\") \n    log.Println(fmt.Sprintf(\"WARN: %s\", msg)) \n    log.Println(\"---------------------------\") \n} \n\nvar punctuations = regexp.MustCompile('^\\p{P}+|\\p{P}+$') \n\n// List of stop words that we want to ignore in our index. \nvar stopWords = []string{ \n    \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"aren't\", \"as\", \"at\", \n    \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"can't\", \"cannot\", \"could\", \n    \"couldn't\", \"did\", \"didn't\", \"do\", \"does\", \"doesn't\", \"doing\", \"don't\", \"down\", \"during\", \"each\", \"few\", \"for\", \n    \"from\", \"further\", \"had\", \"hadn't\", \"has\", \"hasn't\", \"have\", \"haven't\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \n    \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \n    \"i've\", \"if\", \"in\", \"into\", \"is\", \"isn't\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"mustn't\", \n    \"my\", \"myself\", \"no\", \"nor\", \"not\", \"of\", \"off\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \n    \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"shan't\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"shouldn't\", \n    \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \n    \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \n    \"under\", \"until\", \"up\", \"very\", \"was\", \"wasn't\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"weren't\", \"what\", \n    \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \n    \"won't\", \"would\", \"wouldn't\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\"} \n\n// SimplifyToken is responsible to normalizing a string token and \n// also checks whether the token should be indexed or not. \nfunc SimplifyToken(token string) (string, bool) { \n    simpleToken := strings.ToLower(punctuations.ReplaceAllString(token, \"\")) \n\n    for _, stopWord := range stopWords { \n        if stopWord == simpleToken { \n            return \"\", false \n        } \n    } \n\n    return simpleToken, true \n} \n```", "```go\npackage api \n\nimport ( \n    \"crypto/sha1\" \n    \"encoding/json\" \n    \"fmt\" \n    \"io/ioutil\" \n    \"net/http\" \n    \"strings\" \n    \"time\" \n\n    \"github.com/last-ent/distributed-go/chapter6/goophr/concierge/common\" \n) \n\ntype payload struct { \n    URL   string 'json:\"url\"' \n    Title string 'json:\"title\"' \n} \n\ntype document struct { \n    Doc   string 'json:\"-\"' \n    Title string 'json:\"title\"' \n    DocID string 'json:\"DocID\"'\n\n} \n\ntype token struct { \n    Line   string 'json:\"-\"' \n    Token  string 'json:\"token\"' \n    Title  string 'json:\"title\"' \n    DocID  string 'json:\"doc_id\"' \n    LIndex int    'json:\"line_index\"' \n    Index  int    'json:\"token_index\"' \n} \n\ntype dMsg struct { \n    DocID string \n    Ch    chan document \n} \n\ntype lMsg struct { \n    LIndex int \n    DocID  string \n    Ch     chan string \n} \n\ntype lMeta struct { \n    LIndex int \n    DocID  string \n    Line   string \n} \n\ntype dAllMsg struct { \n    Ch chan []document \n} \n\n// done signals all listening goroutines to stop. \nvar done chan bool \n\n// dGetCh is used to retrieve a single document from store. \nvar dGetCh chan dMsg \n\n// lGetCh is used to retrieve a single line from store. \nvar lGetCh chan lMsg \n\n// lStoreCh is used to put a line into store. \nvar lStoreCh chan lMeta \n\n// iAddCh is used to add token to index (Librarian). \nvar iAddCh chan token \n\n// dStoreCh is used to put a document into store. \nvar dStoreCh chan document \n\n// dProcessCh is used to process a document and convert it to tokens. \nvar dProcessCh chan document \n\n// dGetAllCh is used to retrieve all documents in store. \nvar dGetAllCh chan dAllMsg \n\n// pProcessCh is used to process the /feeder's payload and start the indexing process. \nvar pProcessCh chan payload \n\n// StartFeederSystem initializes all channels and starts all goroutines. \n// We are using a standard function instead of 'init()' \n// because we don't want the channels & goroutines to be initialized during testing. \n// Unless explicitly required by a particular test. \nfunc StartFeederSystem() { \n    done = make(chan bool) \n\n    dGetCh = make(chan dMsg, 8) \n    dGetAllCh = make(chan dAllMsg) \n\n    iAddCh = make(chan token, 8) \n    pProcessCh = make(chan payload, 8) \n\n    dStoreCh = make(chan document, 8) \n    dProcessCh = make(chan document, 8) \n    lGetCh = make(chan lMsg) \n    lStoreCh = make(chan lMeta, 8) \n\n    for i := 0; i < 4; i++ { \n        go indexAdder(iAddCh, done) \n        go docProcessor(pProcessCh, dStoreCh, dProcessCh, done) \n        go indexProcessor(dProcessCh, lStoreCh, iAddCh, done) \n    } \n\n    go docStore(dStoreCh, dGetCh, dGetAllCh, done) \n    go lineStore(lStoreCh, lGetCh, done) \n} \n\n// indexAdder adds token to index (Librarian). \nfunc indexAdder(ch chan token, done chan bool) { \n    for { \n        select { \n        case tok := <-ch: \n            fmt.Println(\"adding to librarian:\", tok.Token) \n\n        case <-done: \n            common.Log(\"Exiting indexAdder.\") \n            return \n        } \n    } \n} \n\n// lineStore maintains a catalog of all lines for all documents being indexed. \nfunc lineStore(ch chan lMeta, callback chan lMsg, done chan bool) { \n    store := map[string]string{} \n    for { \n        select { \n        case line := <-ch: \n            id := fmt.Sprintf(\"%s-%d\", line.DocID, line.LIndex) \n            store[id] = line.Line \n\n        case ch := <-callback: \n            line := \"\" \n            id := fmt.Sprintf(\"%s-%d\", ch.DocID, ch.LIndex) \n            if l, exists := store[id]; exists { \n                line = l \n            } \n            ch.Ch <- line \n        case <-done: \n            common.Log(\"Exiting docStore.\") \n            return \n        } \n    } \n} \n\n// indexProcessor is responsible for converting a document into tokens for indexing. \nfunc indexProcessor(ch chan document, lStoreCh chan lMeta, iAddCh chan token, done chan bool) { \n    for { \n        select { \n        case doc := <-ch: \n            docLines := strings.Split(doc.Doc, \"\\n\") \n\n            lin := 0 \n            for _, line := range docLines { \n                if strings.TrimSpace(line) == \"\" { \n                    continue \n                } \n\n                lStoreCh <- lMeta{ \n                    LIndex: lin, \n                    Line:   line, \n                    DocID:  doc.DocID, \n                } \n\n                index := 0 \n                words := strings.Fields(line) \n                for _, word := range words { \n                    if tok, valid := common.SimplifyToken(word); valid { \n                        iAddCh <- token{ \n                            Token:  tok, \n                            LIndex: lin, \n                            Line:   line, \n                            Index:  index, \n                            DocID:  doc.DocID, \n                            Title:  doc.Title, \n                        } \n                        index++ \n                    } \n                } \n                lin++ \n            } \n\n        case <-done: \n            common.Log(\"Exiting indexProcessor.\") \n            return \n        } \n    } \n} \n\n// docStore maintains a catalog of all documents being indexed. \nfunc docStore(add chan document, get chan dMsg, dGetAllCh chan dAllMsg, done chan bool) { \n    store := map[string]document{} \n\n    for { \n        select { \n        case doc := <-add: \n            store[doc.DocID] = doc \n        case m := <-get: \n            m.Ch <- store[m.DocID] \n        case ch := <-dGetAllCh: \n            docs := []document{} \n            for _, doc := range store { \n                docs = append(docs, doc) \n            } \n            ch.Ch <- docs \n        case <-done: \n            common.Log(\"Exiting docStore.\") \n            return \n        } \n    } \n} \n\n// docProcessor processes new document payloads. \nfunc docProcessor(in chan payload, dStoreCh chan document, dProcessCh chan document, done chan bool) { \n    for { \n        select { \n        case newDoc := <-in: \n            var err error \n            doc := \"\" \n\n            if doc, err = getFile(newDoc.URL); err != nil { \n                common.Warn(err.Error()) \n                continue \n            } \n\n            titleID := getTitleHash(newDoc.Title) \n            msg := document{ \n                Doc:   doc, \n                DocID: titleID, \n                Title: newDoc.Title, \n            } \n\n            dStoreCh <- msg \n            dProcessCh <- msg \n        case <-done: \n            common.Log(\"Exiting docProcessor.\") \n            return \n        } \n    } \n} \n\n// getTitleHash returns a new hash ID everytime it is called. \n// Based on: https://gobyexample.com/sha1-hashes\n\nfunc getTitleHash(title string) string {\n\n    hash := sha1.New() \n    title = strings.ToLower(title) \n\n    str := fmt.Sprintf(\"%s-%s\", time.Now(), title) \n    hash.Write([]byte(str)) \n\n    hByte := hash.Sum(nil) \n\n    return fmt.Sprintf(\"%x\", hByte) \n} \n\n// getFile returns file content after retrieving it from URL. \nfunc getFile(URL string) (string, error) { \n    var res *http.Response \n    var err error \n\n    if res, err = http.Get(URL); err != nil { \n        errMsg := fmt.Errorf(\"Unable to retrieve URL: %s.\\nError: %s\", URL, err) \n\n        return \"\", errMsg \n\n    } \n    if res.StatusCode > 200 { \n        errMsg := fmt.Errorf(\"Unable to retrieve URL: %s.\\nStatus Code: %d\", URL, res.StatusCode) \n\n        return \"\", errMsg \n    } \n\n    body, err := ioutil.ReadAll(res.Body) \n    defer res.Body.Close() \n\n    if err != nil { \n        errMsg := fmt.Errorf(\"Error while reading response: URL: %s.\\nError: %s\", URL, res.StatusCode, err.Error()) \n\n        return \"\", errMsg \n    } \n\n    return string(body), nil \n} \n\n// FeedHandler start processing the payload which contains the file to index. \nfunc FeedHandler(w http.ResponseWriter, r *http.Request) { \n    if r.Method == \"GET\" { \n        ch := make(chan []document) \n        dGetAllCh <- dAllMsg{Ch: ch} \n        docs := <-ch \n        close(ch) \n\n        if serializedPayload, err := json.Marshal(docs); err == nil { \n            w.Write(serializedPayload) \n        } else { \n            common.Warn(\"Unable to serialize all docs: \" + err.Error()) \n            w.WriteHeader(http.StatusInternalServerError) \n            w.Write([]byte('{\"code\": 500, \"msg\": \"Error occurred while trying to retrieve documents.\"}')) \n        } \n        return \n    } else if r.Method != \"POST\" { \n        w.WriteHeader(http.StatusMethodNotAllowed) \n        w.Write([]byte('{\"code\": 405, \"msg\": \"Method Not Allowed.\"}')) \n        return \n    } \n\n    decoder := json.NewDecoder(r.Body) \n    defer r.Body.Close() \n\n    var newDoc payload \n    decoder.Decode(&newDoc) \n    pProcessCh <- newDoc \n\n    w.Write([]byte('{\"code\": 200, \"msg\": \"Request is being processed.\"}')) \n} \n```", "```go\npackage api \n\nimport ( \n    \"fmt\" \n    \"net/http\" \n    \"net/http/httptest\" \n    \"testing\" \n) \n\nfunc TestGetTitleHash(t *testing.T) { \n\n    h1 := getTitleHash(\"A-Title\") \n    h2 := getTitleHash(\"Diff Title\") \n    hDup := getTitleHash(\"A-Title\") \n\n    for _, tc := range []struct { \n        name     string \n        hashes   []string \n        expected bool \n    }{ \n        {\"Different Titles\", []string{h1, h2}, false}, \n        {\"Duplicate Titles\", []string{h1, hDup}, false}, \n        {\"Same hashes\", []string{h2, h2}, true}, \n    } { \n        t.Run(tc.name, func(t *testing.T) { \n            actual := tc.hashes[0] == tc.hashes[1] \n            if actual != tc.expected { \n                t.Error(actual, tc.expected, tc.hashes) \n            } \n        }) \n    } \n} \n\nfunc TestGetFile(t *testing.T) { \n    doc := \"Server returned text!\" \n    testServer := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { \n        w.Write([]byte(doc)) \n    })) \n    defer testServer.Close() \n\n    rDoc, err := getFile(testServer.URL) \n    if err != nil { \n        t.Error(\"Error while retrieving document\", err) \n    } \n    if doc != rDoc { \n        t.Error(doc, \"!=\", rDoc) \n    } \n} \n\nfunc TestIndexProcessor(t *testing.T) { \n    ch1 := make(chan document, 1) \n    ch2 := make(chan lMeta, 1) \n    ch3 := make(chan token, 3) \n    done := make(chan bool) \n\n    go indexProcessor(ch1, ch2, ch3, done) \n\n    ch1 <- document{ \n        DocID: \"a-hash\", \n        Title: \"a-title\", \n        Doc:   \"Golang Programming rocks!\", \n    } \n\n    for i, tc := range []string{ \n        \"golang\", \"programming\", \"rocks\", \n    } { \n        t.Run(fmt.Sprintf(\"Testing if '%s' is returned. at index: %d\", tc, i), func(t *testing.T) { \n            tok := <-ch3 \n            if tok.Token != tc { \n                t.Error(tok.Token, \"!=\", tc) \n            } \n            if tok.Index != i { \n                t.Error(tok.Index, \"!=\", i) \n            } \n        }) \n    } \n    close(done) \n\n} \n```", "```go\n    $ go test -v ./... \n    ? github.com/last-ent/distributed-go/chapter6/goophr/concierge [no test files] \n    === RUN TestGetTitleHash \n    === RUN TestGetTitleHash/Different_Titles \n    === RUN TestGetTitleHash/Duplicate_Titles \n    === RUN TestGetTitleHash/Same_hashes \n    --- PASS: TestGetTitleHash (0.00s) \n    --- PASS: TestGetTitleHash/Different_Titles (0.00s) \n    --- PASS: TestGetTitleHash/Duplicate_Titles (0.00s) \n    --- PASS: TestGetTitleHash/Same_hashes (0.00s) \n    === RUN TestGetFile \n    --- PASS: TestGetFile (0.00s) \n    === RUN TestIndexProcessor \n    === RUN TestIndexProcessor/Testing_if_'golang'_is_returned._at_index:_1 \n    === RUN TestIndexProcessor/Testing_if_'programming'_is_returned._at_index:_2 \n    === RUN TestIndexProcessor/Testing_if_'rocks'_is_returned._at_index:_3 \n    --- PASS: TestIndexProcessor (0.00s) \n    --- PASS: TestIndexProcessor/Testing_if_'golang'_is_returned._at_index:_1 (0.00s) \n    --- PASS: TestIndexProcessor/Testing_if_'programming'_is_returned._at_index:_2 (0.00s) \n    --- PASS: TestIndexProcessor/Testing_if_'rocks'_is_returned._at_index:_3 (0.00s) \n    PASS \n    ok github.com/last-ent/distributed-go/chapter6/goophr/concierge/api 0.004s\n    ? github.com/last-ent/distributed-go/chapter6/goophr/concierge/common [no test files] \n\n```", "```go\n    $ curl -X POST -d '{\"title\": \"Hackers: Heroes of Computer Revolution\", \"url\": \"http://www.gutenberg.org/cache/epub/729/pg729.txt\"}' http://localhost:8080/api/feeder | jq \n     % Total % Received % Xferd Average Speed Time Time Time Current\n     Dload Upload Total Spent Left Speed\n    100 162 100 51 100 111 51 111 0:00:01 --:--:-- 0:00:01 54000\n    {\n     \"code\": 200,\n     \"msg\": \"Request is being processed.\"\n    }\n```", "```go\n    $ go run main.go\n    2017/11/18 21:05:57 INFO - Adding API handlers...\n    2017/11/18 21:05:57 INFO - Starting feeder...\n    2017/11/18 21:05:57 INFO - Starting Goophr Concierge server on port :8080...\n    // ...\n    adding to librarian: gutenberg-tm \n    adding to librarian: including \n    adding to librarian: make \n    adding to librarian: u.s \n    adding to librarian: project \n    adding to librarian: gutenberg \n    /...\n\n```"]