["```go\n* Book 1 (Index)\n - apple - 4, 10, 20\n - cat - 10, 21, 22\n - zebra - 15, 25, 63\n\n* Book 2 (Index)\n - banana - 14, 19, 66\n - cake - 10, 37, 45\n - zebra - 67, 100, 129\n\n* Book 3 (Index)\n - apple - 36, 55, 74\n - cake - 1, 9, 77\n - Whale - 11, 59, 79  \n```", "```go\n* Searching for 'apple'\n - Scanning Book 1\\. Result: Found.\n - Scanning Book 2\\. Result: Not Found.\n - Scanning Book 3\\. Result: Found.\n\n* Searching for 'banana'\n - Scanning Book 1\\. Result: Not Found.\n - Scanning Book 2\\. Result: Found.\n - Scanning Book 3\\. Result: Not Found.\n\n* Searching for 'parrot'\n - Scanning Book 1\\. Result: Not Found.\n - Scanning Book 2\\. Result: Not Found.\n - Scanning Book 3\\. Result: Not Found.  \n```", "```go\n* apple\n - Book 1 - 4, 10, 20\n - Book 3 - 36, 55, 74\n\n* banana\n - Book 2 - 14, 19, 66\n\n* cake\n - Book 2 - 10, 37, 45\n - Book 3 - 1, 9, 77\n\n* cat\n - Book 1 - 10, 21, 22\n\n* whale\n - Book 3 - 11, 59, 79\n\n* zebra\n - Book 1 - 15, 25, 63\n - Book 2 - 67, 100, 129  \n```", "```go\n* Searching for 'apple'\n - Scanning Inverted Index. Result: Found a list of books.\n\n* Searching for 'banana'\n - Scanning Inverted Index. Result: Found a list of books.\n\n* Searching for 'parrot'\n  - Scanning Inverted Index. Result: Not Found.  \n```", "```go\nopenapi: 3.0.0 \nservers: \n  - url: /api \ninfo: \n  title: Goophr Librarian API \n  version: '1.0' \n  description: | \n    API responsible for indexing & communicating with Goophr Concierge. \npaths: \n  /index: \n    post: \n      description: | \n        Add terms to index. \n      responses: \n        '200': \n          description: | \n            Terms were successfully added to the index. \n        '400': \n          description: > \n            Request was not processed because payload was incomplete or \n            incorrect. \n          content: \n            application/json: \n              schema: \n                $ref: '#/components/schemas/error' \n      requestBody: \n        content: \n          application/json: \n            schema: \n              $ref: '#/components/schemas/terms' \n        description: | \n          List of terms to be added to the index. \n        required: true \n  /query: \n    post: \n      description: | \n        Search for all terms in the payload. \n      responses: \n        '200': \n          description: | \n            Returns a list of all the terms along with their frequency, \n            documents the terms appear in and link to the said documents. \n          content: \n            application/json: \n              schema: \n                $ref: '#/components/schemas/results' \n        '400': \n          description: > \n            Request was not processed because payload was incomplete or \n            incorrect. \n          content: \n            application/json: \n              schema: \n                $ref: '#/components/schemas/error' \n    parameters: [] \ncomponents: \n  schemas: \n    error: \n      type: object \n      properties: \n        msg: \n          type: string \n    term: \n      type: object \n      required: \n        - title \n        - token \n        - doc_id \n        - line_index \n        - token_index \n      properties: \n        title: \n          description: | \n            Title of the document to which the term belongs. \n          type: string \n        token: \n          description: | \n            The term to be added to the index. \n          type: string \n        doc_id: \n          description: | \n            The unique hash for each document. \n          type: string \n        line_index: \n          description: | \n            Line index at which the term occurs in the document. \n          type: integer \n        token_index: \n          description: | \n            Position of the term in the document. \n          type: integer \n    terms: \n      type: object \n      properties: \n        code: \n          type: integer \n        data: \n          type: array \n          items: \n            $ref: '#/components/schemas/term' \n    results: \n      type: object \n      properties: \n        count: \n          type: integer \n        data: \n          type: array \n          items: \n            $ref: '#/components/schemas/result' \n    result: \n      type: object \n      properties: \n        doc_id: \n          type: string \n        score: \n          type: integer  \n```", "```go\n$ tree . \u251c\u2500\u2500 api \u2502 \u251c\u2500\u2500 index.go \u2502 \u2514\u2500\u2500 query.go \u251c\u2500\u2500 common \u2502 \u251c\u2500\u2500 helpers.go \u251c\u2500\u2500 Dockerfile \u251c\u2500\u2500 main.go                               \n```", "```go\npackage main \n\nimport ( \n    \"net/http\" \n\n    \"github.com/last-ent/distributed-go/chapter7/goophr/librarian/api\" \n    \"github.com/last-ent/distributed-go/chapter7/goophr/librarian/common\" \n) \n\nfunc main() { \n    common.Log(\"Adding API handlers...\") \n    http.HandleFunc(\"/api/index\", api.IndexHandler) \n    http.HandleFunc(\"/api/query\", api.QueryHandler) \n\n    common.Log(\"Starting index...\") \n    api.StartIndexSystem() \n\n    common.Log(\"Starting Goophr Librarian server on port :9090...\") \n    http.ListenAndServe(\":9090\", nil) \n} \n```", "```go\npackage common \n\nimport ( \n    \"fmt\" \n    \"log\" \n) \n\nfunc Log(msg string) { \n    log.Println(\"INFO - \", msg) \n} \n\nfunc Warn(msg string) { \n    log.Println(\"---------------------------\") \n    log.Println(fmt.Sprintf(\"WARN: %s\", msg)) \n    log.Println(\"---------------------------\") \n} \n```", "```go\npackage api \n\nimport ( \n    \"bytes\" \n    \"encoding/json\" \n    \"fmt\" \n    \"net/http\" \n) \n\n// tPayload is used to parse the JSON payload consisting of Token data. \ntype tPayload struct { \n    Token  string 'json:\"token\"' \n    Title  string 'json:\"title\"' \n    DocID  string 'json:\"doc_id\"' \n    LIndex int    'json:\"line_index\"' \n    Index  int    'json:\"token_index\"' \n} \n\ntype tIndex struct { \n    Index  int \n    LIndex int \n} \n\nfunc (ti *tIndex) String() string { \n    return fmt.Sprintf(\"i: %d, li: %d\", ti.Index, ti.LIndex) \n} \n\ntype tIndices []tIndex \n\n// document - key in Indices represent Line Index. \ntype document struct { \n    Count   int \n    DocID   string \n    Title   string \n    Indices map[int]tIndices \n} \n\nfunc (d *document) String() string { \n    str := fmt.Sprintf(\"%s (%s): %d\\n\", d.Title, d.DocID, d.Count) \n    var buffer bytes.Buffer \n\n    for lin, tis := range d.Indices { \n        var lBuffer bytes.Buffer \n        for _, ti := range tis { \n            lBuffer.WriteString(fmt.Sprintf(\"%s \", ti.String())) \n        } \n        buffer.WriteString(fmt.Sprintf(\"@%d -> %s\\n\", lin, lBuffer.String())) \n    } \n    return str + buffer.String() \n} \n\n// documentCatalog - key represents DocID. \ntype documentCatalog map[string]*document \n\nfunc (dc *documentCatalog) String() string { \n    return fmt.Sprintf(\"%#v\", dc) \n} \n\n// tCatalog - key in map represents Token. \ntype tCatalog map[string]documentCatalog \n\nfunc (tc *tCatalog) String() string { \n    return fmt.Sprintf(\"%#v\", tc) \n} \n\ntype tcCallback struct { \n    Token string \n    Ch    chan tcMsg \n} \n\ntype tcMsg struct { \n    Token string \n    DC    documentCatalog \n} \n\n// pProcessCh is used to process /index's payload and start process to add the token to catalog (tCatalog). \nvar pProcessCh chan tPayload \n\n// tcGet is used to retrieve a token's catalog (documentCatalog). \nvar tcGet chan tcCallback \n\nfunc StartIndexSystem() { \n    pProcessCh = make(chan tPayload, 100) \n    tcGet = make(chan tcCallback, 20) \n    go tIndexer(pProcessCh, tcGet) \n} \n\n// tIndexer maintains a catalog of all tokens along with where they occur within documents. \nfunc tIndexer(ch chan tPayload, callback chan tcCallback) { \n    store := tCatalog{} \n    for { \n        select { \n        case msg := <-callback: \n            dc := store[msg.Token] \n            msg.Ch <- tcMsg{ \n                DC:    dc, \n                Token: msg.Token, \n            } \n\n        case pd := <-ch: \n            dc, exists := store[pd.Token] \n            if !exists { \n                dc = documentCatalog{} \n                store[pd.Token] = dc \n            } \n\n            doc, exists := dc[pd.DocID] \n            if !exists { \n                doc = &document{ \n                    DocID:   pd.DocID, \n                    Title:   pd.Title, \n                    Indices: map[int]tIndices{}, \n                } \n                dc[pd.DocID] = doc \n            } \n\n            tin := tIndex{ \n                Index:  pd.Index, \n                LIndex: pd.LIndex, \n            } \n            doc.Indices[tin.LIndex] = append(doc.Indices[tin.LIndex], tin) \n            doc.Count++ \n        } \n    } \n} \n\nfunc IndexHandler(w http.ResponseWriter, r *http.Request) { \n    if r.Method != \"POST\" { \n        w.WriteHeader(http.StatusMethodNotAllowed) \n        w.Write([]byte('{\"code\": 405, \"msg\": \"Method Not Allowed.\"}')) \n        return \n    } \n\n    decoder := json.NewDecoder(r.Body) \n    defer r.Body.Close() \n\n    var tp tPayload \n    decoder.Decode(&tp)\n\n    log.Printf(\"Token received%#v\\n\", tp) \n\n    pProcessCh <- tp \n\n    w.Write([]byte('{\"code\": 200, \"msg\": \"Tokens are being added to index.\"}')) \n} \n```", "```go\npackage api \n\nimport ( \n    \"encoding/json\" \n    \"net/http\" \n    \"sort\" \n\n    \"github.com/last-ent/distributed-go/chapter7/goophr/librarian/common\" \n) \n\ntype docResult struct { \n    DocID   string   'json:\"doc_id\"' \n    Score   int      'json:\"doc_score\"' \n    Indices tIndices 'json:\"token_indices\"' \n} \n\ntype result struct { \n    Count int         'json:\"count\"' \n    Data  []docResult 'json:\"data\"' \n} \n\n// getResults returns unsorted search results & a map of documents containing tokens. \nfunc getResults(out chan tcMsg, count int) tCatalog { \n    tc := tCatalog{} \n    for i := 0; i < count; i++ { \n        dc := <-out \n        tc[dc.Token] = dc.DC \n    } \n    close(out) \n\n    return tc \n} \n\nfunc getFScores(docIDScore map[string]int) (map[int][]string, []int) { \n    // fScore maps frequency score to set of documents. \n    fScore := map[int][]string{} \n\n    fSorted := []int{} \n\n    for dID, score := range docIDScore { \n        fs := fScore[score] \n            fScore[score] = []string{} \n        } \n        fScore[score] = append(fs, dID) \n        fSorted = append(fSorted, score) \n    } \n\n    sort.Sort(sort.Reverse(sort.IntSlice(fSorted))) \n\n    return fScore, fSorted \n} \n\nfunc getDocMaps(tc tCatalog) (map[string]int, map[string]tIndices) { \n    // docIDScore maps DocIDs to occurences of all tokens. \n    // key: DocID. \n    // val: Sum of all occurences of tokens so far. \n    docIDScore := map[string]int{} \n    docIndices := map[string]tIndices{} \n\n    // for each token's catalog \n    for _, dc := range tc { \n        // for each document registered under the token \n        for dID, doc := range dc { \n            // add to docID score \n            var tokIndices tIndices \n            for _, tList := range doc.Indices { \n                tokIndices = append(tokIndices, tList...) \n            } \n            docIDScore[dID] += doc.Count \n\n            dti := docIndices[dID] \n\n            docIndices[dID] = append(dti, tokIndices...) \n        } \n    } \n\n    return docIDScore, docIndices \n} \n\nfunc sortResults(tc tCatalog) []docResult { \n    docIDScore, docIndices := getDocMaps(tc) \n    fScore, fSorted := getFScores(docIDScore) \n\n    results := []docResult{} \n    addedDocs := map[string]bool{} \n\n    for _, score := range fSorted { \n        for _, docID := range fScore[score] { \n            if _, exists := addedDocs[docID]; exists { \n                continue \n            } \n            results = append(results, docResult{ \n                DocID:   docID, \n                Score:   score, \n                Indices: docIndices[docID], \n            }) \n            addedDocs[docID] = false \n        } \n    } \n    return results \n} \n\n// getSearchResults returns a list of documents. \n// They are listed in descending order of occurences. \nfunc getSearchResults(sts []string) []docResult { \n\n    callback := make(chan tcMsg) \n\n    for _, st := range sts { \n        go func(term string) { \n            tcGet <- tcCallback{ \n                Token: term, \n                Ch:    callback, \n            } \n        }(st) \n    } \n\n    cts := getResults(callback, len(sts)) \n    results := sortResults(cts) \n    return results \n} \n\nfunc QueryHandler(w http.ResponseWriter, r *http.Request) { \n    if r.Method != \"POST\" { \n        w.WriteHeader(http.StatusMethodNotAllowed) \n        w.Write([]byte('{\"code\": 405, \"msg\": \"Method Not Allowed.\"}')) \n        return \n    } \n\n    decoder := json.NewDecoder(r.Body) \n    defer r.Body.Close() \n\n    var searchTerms []string \n    decoder.Decode(&searchTerms) \n\n    results := getSearchResults(searchTerms) \n\n    payload := result{ \n        Count: len(results), \n        Data:  results, \n    } \n\n    if serializedPayload, err := json.Marshal(payload); err == nil { \n        w.Header().Add(\"Content-Type\", \"application/json\") \n        w.Write(serializedPayload) \n    } else { \n        common.Warn(\"Unable to serialize all docs: \" + err.Error()) \n        w.WriteHeader(http.StatusInternalServerError) \n        w.Write([]byte('{\"code\": 500, \"msg\": \"Error occurred while trying to retrieve documents.\"}')) \n    } \n} \n```", "```go\npackage main \n\nimport ( \n    \"bytes\" \n    \"encoding/json\" \n    \"io/ioutil\" \n    \"log\" \n    \"net/http\" \n) \n\ntype tPayload struct { \n    Token  string 'json:\"token\"' \n    Title  string 'json:\"title\"' \n    DocID  string 'json:\"doc_id\"' \n    LIndex int    'json:\"line_index\"' \n    Index  int    'json:\"token_index\"' \n} \n\ntype msgS struct { \n    Code int    'json:\"code\"' \n    Msg  string 'json:\"msg\"' \n} \n\nfunc main() { \n    // Searching for \"apple\" should return Book 1 at the top of search results. \n    // Searching for \"cake\" should return Book 3 at the top. \n    for bookX, terms := range map[string][]string{ \n        \"Book 1\": []string{\"apple\", \"apple\", \"cat\", \"zebra\"}, \n        \"Book 2\": []string{\"banana\", \"cake\", \"zebra\"}, \n        \"Book 3\": []string{\"apple\", \"cake\", \"cake\", \"whale\"}, \n    } { \n        for lin, term := range terms { \n            payload, _ := json.Marshal(tPayload{ \n                Token:  term, \n                Title:  bookX + term, \n                DocID:  bookX, \n                LIndex: lin, \n            }) \n            resp, err := http.Post( \n                \"http://localhost:9090/api/index\", \n                \"application/json\", \n                bytes.NewBuffer(payload), \n            ) \n            if err != nil { \n                panic(err) \n            } \n            body, _ := ioutil.ReadAll(resp.Body) \n            defer resp.Body.Close() \n\n            var msg msgS \n            json.Unmarshal(body, &msg) \n            log.Println(msg) \n        } \n    } \n} \n```", "```go\n$ go run feeder.go \n2018/01/04 12:53:31 {200 Tokens are being added to index.} \n2018/01/04 12:53:31 {200 Tokens are being added to index.} \n2018/01/04 12:53:31 {200 Tokens are being added to index.} \n2018/01/04 12:53:31 {200 Tokens are being added to index.} \n2018/01/04 12:53:31 {200 Tokens are being added to index.} \n2018/01/04 12:53:31 {200 Tokens are being added to index.} \n2018/01/04 12:53:31 {200 Tokens are being added to index.} \n2018/01/04 12:53:31 {200 Tokens are being added to index.} \n2018/01/04 12:53:31 {200 Tokens are being added to index.} \n2018/01/04 12:53:31 {200 Tokens are being added to index.} \n2018/01/04 12:53:31 {200 Tokens are being added to index.} \n```", "```go\n$ go run goophr/librarian/main.go \n2018/01/04 12:53:25 INFO - Adding API handlers... \n2018/01/04 12:53:25 INFO - Starting index... \n2018/01/04 12:53:25 INFO - Starting Goophr Librarian server on port :9090... \n2018/01/04 12:53:31 Token received api.tPayload{Token:\"banana\", Title:\"Book 2banana\", DocID:\"Book 2\", LIndex:0, Index:0} \n2018/01/04 12:53:31 Token received api.tPayload{Token:\"cake\", Title:\"Book 2cake\", DocID:\"Book 2\", LIndex:1, Index:0} \n2018/01/04 12:53:31 Token received api.tPayload{Token:\"zebra\", Title:\"Book 2zebra\", DocID:\"Book 2\", LIndex:2, Index:0} \n2018/01/04 12:53:31 Token received api.tPayload{Token:\"apple\", Title:\"Book 3apple\", DocID:\"Book 3\", LIndex:0, Index:0} \n2018/01/04 12:53:31 Token received api.tPayload{Token:\"cake\", Title:\"Book 3cake\", DocID:\"Book 3\", LIndex:1, Index:0} \n2018/01/04 12:53:31 Token received api.tPayload{Token:\"cake\", Title:\"Book 3cake\", DocID:\"Book 3\", LIndex:2, Index:0} \n2018/01/04 12:53:31 Token received api.tPayload{Token:\"whale\", Title:\"Book 3whale\", DocID:\"Book 3\", LIndex:3, Index:0} \n2018/01/04 12:53:31 Token received api.tPayload{Token:\"apple\", Title:\"Book 1apple\", DocID:\"Book 1\", LIndex:0, Index:0} \n2018/01/04 12:53:31 Token received api.tPayload{Token:\"apple\", Title:\"Book 1apple\", DocID:\"Book 1\", LIndex:1, Index:0} \n2018/01/04 12:53:31 Token received api.tPayload{Token:\"cat\", Title:\"Book 1cat\", DocID:\"Book 1\", LIndex:2, Index:0} \n2018/01/04 12:53:31 Token received api.tPayload{Token:\"zebra\", Title:\"Book 1zebra\", DocID:\"Book 1\", LIndex:3, Index:0}   \n```", "```go\n$ # Querying for \"apple\" $ curl -LX POST -d '[\"apple\"]' localhost:9090/api/query | jq % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 202 100 193 100 9 193 9 0:00:01 --:--:-- 0:00:01 40400 { \"count\": 2, \"data\": [ { \"doc_id\": \"Book 1\", \"doc_score\": 2, \"token_indices\": [ { \"Index\": 0, \"LIndex\": 0 }, { \"Index\": 0, \"LIndex\": 1 } ] }, { \"doc_id\": \"Book 3\", \"doc_score\": 1, \"token_indices\": [ { \"Index\": 0, \"LIndex\": 0 } ] } ] } $ # Querying for \"cake\" \n$ curl -LX POST -d '[\"cake\"]' localhost:9090/api/query | jq % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 201 100 193 100 8 193 8 0:00:01 --:--:-- 0:00:01 33500 { \"count\": 2, \"data\": [ { \"doc_id\": \"Book 3\", \"doc_score\": 2, \"token_indices\": [ { \"Index\": 0, \"LIndex\": 1 }, { \"Index\": 0, \"LIndex\": 2 } ] }, { \"doc_id\": \"Book 2\", \"doc_score\": 1, \"token_indices\": [ { \"Index\": 0, \"LIndex\": 1 } ] } ] }  \n```"]