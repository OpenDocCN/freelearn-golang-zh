["```go\nUser-agent: *\nDisallow: /\n```", "```go\nUser-Agent: *\nDisallow: /m/\nDisallow: /me/\nDisallow: /@me$\nDisallow: /@me/\nDisallow: /*/edit$\nDisallow: /*/*/edit$\nAllow: /_/\nAllow: /_/api/users/*/meta\nAllow: /_/api/users/*/profile/stream\nAllow: /_/api/posts/*/responses\nAllow: /_/api/posts/*/responsesStream\nAllow: /_/api/posts/*/related\nSitemap: https://medium.com/sitemap/sitemap.xml\n```", "```go\nUser-agent: *\nDisallow: /*null*\nDisallow: /*Cart-MiniAddProduct\nDisallow: /jp/apps/shoplocator*\nDisallow: /com/apps/claimfreedom*\nDisallow: /us/help-topics-affiliates.html\nDisallow: /on/Demandware.store/Sites-adidas-US-Site/en_US/\nUser-Agent: bingbot\nCrawl-delay: 1\nSitemap: https://www.adidas.com/on/demandware.static/-/Sites-CustomerFileStore/default/adidas-US/en_US/sitemaps/adidas-US-sitemap.xml\nSitemap: https://www.adidas.com/on/demandware.static/-/Sites-CustomerFileStore/default/adidas-MLT/en_PT/sitemaps/adidas-MLT-sitemap.xml\n```", "```go\nMozilla/5.0 (X11; Linux x86_64; rv:57.0) Gecko/20100101 Firefox/57.0\n```", "```go\nGET /index.html HTTP/1.1\nHost: example.com\nUser-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:57.0) Gecko/20100101 Firefox/57.0\n```", "```go\ngo get github.com/temoto/robotstxt\n```", "```go\npackage main\n\nimport (\n  \"net/http\"\n\n  \"github.com/temoto/robotstxt\"\n)\n\nfunc main() {\n  // Get the contents of robots.txt from packtpub.com\n  resp, err := http.Get(\"https://www.packtpub.com/robots.txt\")\n  if err != nil {\n    panic(err)\n  }\n  // Process the response using temoto/robotstxt\n  data, err := robotstxt.FromResponse(resp)\n  if err != nil {\n    panic(err)\n  }\n  // Look for the definition in the robots.txt file that matches the default Go User-Agent string\n  grp := data.FindGroup(\"Go-http-client/1.1\")\n  if grp != nil {\n    testUrls := []string{\n      // These paths are all permissable\n      \"/all\",\n      \"/all?search=Go\",\n      \"/bundles\",\n\n      // These paths are not\n      \"/contact/\",\n      \"/search/\",\n      \"/user/password/\",\n    }\n\n    for _, url := range testUrls {\n      print(\"checking \" + url + \"...\")\n\n      // Test the path against the User-Agent group\n      if grp.Test(url) == true {\n        println(\"OK\")\n      } else {\n        println(\"X\")\n      }\n    }\n  }\n}\n```", "```go\npackage main\n\nimport (\n  \"fmt\"\n  \"net/http\"\n  \"time\"\n)\n\nfunc main() {\n  // Tracks the timestamp of the last request to the webserver\n  var lastRequestTime time.Time\n\n  // The maximum number of requests we will make to the webserver\n  maximumNumberOfRequests := 5\n\n  // Our scrape rate at 1 page per 5 seconds\n  pageDelay := 5 * time.Second\n\n  for i := 0; i < maximumNumberOfRequests; i++ {\n    // Calculate the time difference since our last request\n    elapsedTime := time.Now().Sub(lastRequestTime)\n    fmt.Printf(\"Elapsed Time: %.2f (s)\\n\", elapsedTime.Seconds())\n    //Check if there has been enough time\n    if elapsedTime < pageDelay {\n      // Sleep the difference between the pageDelay and elapsedTime\n      var timeDiff time.Duration = pageDelay - elapsedTime\n      fmt.Printf(\"Sleeping for %.2f (s)\\n\", timeDiff.Seconds())\n      time.Sleep(pageDelay - elapsedTime)\n    }\n\n    // Just for this example, we are not processing the response\n    println(\"GET example.com/index.html\")\n    _, err := http.Get(\"http://www.example.com/index.html\")\n    if err != nil {\n      panic(err)\n    }\n\n    // Update the last request time\n    lastRequestTime = time.Now()\n  }\n}\n```", "```go\nvar lastRequestMap map[string]time.Time = map[string]time.Time{\n  \"example.com\": time.Time{},\n  \"packtpub.com\": time.Time{},\n}\n```", "```go\n// Check if \"i\" is an even number\nif i%2 == 0 {\n  // Use the Packt Publishing site and elapsed time\n  webpage = packtPage\n  elapsedTime = time.Now().Sub(lastRequestMap[\"packtpub.com\"])\n} else {\n  // Use the example.com elapsed time\n  elapsedTime = time.Now().Sub(lastRequestMap[\"example.com\"])\n}\n```", "```go\n// Update the last request time\nif i%2 == 0 {\n  // Use the Packt Publishing elapsed time\n  lastRequestMap[\"packtpub.com\"] = time.Now()\n} else {\n  // Use the example.com elapsed time\n  lastRequestMap[\"example.com\"] = time.Now()\n}\n```", "```go\nHTTP/1.1 200 OK\nAccept-Ranges: bytes\nCache-Control: max-age=604800\nContent-Type: text/html; charset=UTF-8\nDate: Mon, 29 Oct 2018 13:31:23 GMT\nEtag: \"1541025663\"\nExpires: Mon, 05 Nov 2018 13:31:23 GMT\nLast-Modified: Fri, 09 Aug 2013 23:54:35 GMT\nServer: ECS (dca/53DB)\nVary: Accept-Encoding\nX-Cache: HIT\nContent-Length: 1270\n...\n```", "```go\nCache-Control: max-age=604800\n```", "```go\nDate: Mon, 29 Oct 2018 13:31:23 GMT\nExpires: Mon, 05 Nov 2018 13:31:23 GMT\n```", "```go\nHTTP/1.1 304 Not Modified\nAccept-Ranges: bytes\nCache-Control: max-age=604800\nDate: Fri, 02 Nov 2018 14:37:16 GMT\nEtag: \"1541025663\"\nExpires: Fri, 09 Nov 2018 14:37:16 GMT\nLast-Modified: Fri, 09 Aug 2013 23:54:35 GMT\nServer: ECS (dca/53DB)\nVary: Accept-Encoding\nX-Cache: HIT\n```", "```go\npackage main\n\nimport (\n  \"io/ioutil\"\n\n  \"github.com/gregjones/httpcache\"\n  \"github.com/gregjones/httpcache/diskcache\"\n)\n\nfunc main() {\n  // Set up the local disk cache\n  storage := diskcache.New(\"./cache\")\n  cache := httpcache.NewTransport(storage)\n\n  // Set this to true to inform us if the responses are being read from a cache\n  cache.MarkCachedResponses = true\n  cachedClient := cache.Client()\n\n  // Make the initial request\n  println(\"Caching: http://www.example.com/index.html\")\n  resp, err := cachedClient.Get(\"http://www.example.com/index.html\")\n  if err != nil {\n    panic(err)\n  }\n\n  // httpcache requires you to read the body in order to cache the response\n  ioutil.ReadAll(resp.Body)\n  resp.Body.Close()\n\n  // Request index.html again\n  println(\"Requesting: http://www.example.com/index.html\")\n  resp, err = cachedClient.Get(\"http://www.example.com/index.html\")\n  if err != nil {\n    panic(err)\n  }\n\n  // Look for the flag added by httpcache to show the result is read from the cache\n  _, ok = resp.Header[\"X-From-Cache\"]\n  if ok {\n    println(\"Result was pulled from the cache!\")\n  }\n}\n```"]