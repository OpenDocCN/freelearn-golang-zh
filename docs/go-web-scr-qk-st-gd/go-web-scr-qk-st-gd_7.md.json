["```go\nsiteStatus := map[string]string{\n  \"http://example.com/page1.html\" : \"READY\",\n  \"http://example.com/page2.html\" : \"READY\",\n  \"http://example.com/page3.html\" : \"READY\",\n}\n```", "```go\nmtx := *sync.Mutex{}\n\nmtx.Lock()\nif siteStatus[\"http://example.com/page1.html\"] == \"READY\" {\n  siteStatus[\"http://example.com/page1.html\"] = \"WORKING\"\n}\nmtx.Unlock()\n```", "```go\nmtx := *sync.RWMutex{}\n\nmtx.RLock()\nif siteStatus[\"http://example.com/page1.html\"] == \"READY\" {\n  mtx.RUnlock()\n  mtx.Lock()\n  siteStatus[\"http://example.com/page1.html\"] = \"WORKING\"\n  mtx.UnLock()\n} else{\n  mtx.RUnlock()\n}\n```", "```go\ndeadlock.Opts.DeadlockTimeout = 120 * time.Second // 2 minute timeout\ndeadlock.Opts.OnPotentialDeadlock = func() {\n  printf(\"Deadlock detected\")\n  beginGracefulShutdown()  // This is a hypothetical function\n}\n```", "```go\npackage main\n\nimport (\n \"fmt\"\n \"time\"\n)\n\nfunc startTicker() {\n ticks := 0\n for true {\n fmt.Println(ticks)\n ticks++\n time.Sleep(1 * time.Second)\n }\n}\n\nfunc main() {\n println(\"Starting ticker\")\n go startTicker()\n time.Sleep(10 * time.Second)\n}\n```", "```go\npackage main\n\nfunc scrapeSite(url string, statusChan chan map[string]string) {\n  // Performing scraping operations...\n  statusChan <- map[string]string{url: \"DONE\"}\n}\n\nfunc main() {\n  siteStatus := map[string]string{\n    \"http://example.com/page1.html\": \"READY\",\n    \"http://example.com/page2.html\": \"READY\",\n    \"http://example.com/page3.html\": \"READY\",\n  }\n\n  updatesChan := make(chan map[string]string)\n\n  numberCompleted := 0\n  for site := range siteStatus {\n    siteStatus[site] = \"WORKING\"\n    go scrapeSite(site, updatesChan)\n  }\n\n  for update := range updatesChan {\n    for url, status := range update {\n      siteStatus[url] = status\n      numberCompleted++\n    }\n    if numberCompleted == len(siteStatus) {\n      close(updatesChan)\n    }\n  }\n}\n```", "```go\npackage main\n\nimport (\n  \"sync\"\n  \"time\"\n)\n\nvar sites []string = []string{\n  \"http://example.com/site1.html\",\n  \"http://example.com/site2.html\",\n  \"http://example.com/site3.html\",\n}\nvar activeThreads = 0\nvar doneCount = 0\nconst maxActiveThreads = 1\n\nfunc scrapeSite(site string, condition *sync.Cond) {\n  condition.L.Lock()\n  if activeThreads >= maxActiveThreads {\n    condition.Wait()\n  }\n  activeThreads++\n  condition.L.Unlock()\n  println(\"scraping \" + site)\n  // Scraping code goes here ...\n  condition.L.Lock()\n\n  activeThreads--\n  doneCount++\n  condition.L.Unlock()\n  condition.Signal()\n}\n\nfunc main() {\n  var l = sync.Mutex{}\n  var c = sync.NewCond(&l)\n\n  for _, site := range sites {\n    println(\"starting scraper for \" + site)\n    go scrapeSite(site, c)\n  }\n  for doneCount < len(sites){\n    time.Sleep(1 * time.Second)\n  }\n  println(\"Done!\")\n}\n```", "```go\npackage main\n\nimport (\n  \"sync\"\n  \"sync/atomic\"\n)\n// ...\nvar activeThreads int32 = 0\n// ...\nfunc scrapeSite(site string, condition *sync.Cond) {\n condition.L.Lock()\n if activeThreads >= maxActiveThreads {\n condition.Wait()\n }\n condition.L.Unlock()\n\n atomic.AddInt32(&activeThreads, 1)\n // Scraping code goes here ...\n atomic.AddInt32(&activeThreads, -1)\n condition.Signal()\n}\n// ...\n```"]