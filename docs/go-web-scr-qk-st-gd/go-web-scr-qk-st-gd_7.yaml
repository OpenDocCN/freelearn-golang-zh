- en: Scraping with Concurrency
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并发爬取
- en: As you begin to add more and more target websites into your scraping requirements,
    you will eventually hit a point where you wish you could make more calls, faster.
    In a single program, the crawl delay might add extra time to your scraper, adding
    unnecessary time to process the other sites. Do you see the problem in the following
    diagram?
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 当您开始将更多目标网站添加到您的爬取需求中时，最终会达到一个希望能够更快地进行更多调用的点。在单个程序中，爬取延迟可能会为您的爬虫增加额外的时间，从而增加处理其他站点的不必要时间。您在下面的图表中看到问题了吗？
- en: '![](img/49cfec0e-bab5-4c02-ae06-151795e343f5.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/49cfec0e-bab5-4c02-ae06-151795e343f5.png)'
- en: 'If these two sites could be run in parallel, there would not be any interference.
    Maybe the time to access and parse a page is longer than the crawl delay for this
    website, and launching a second request before the processing of the first response
    completes could save you time as well. Look how the situation is improved in the
    following diagram:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这两个网站可以并行运行，就不会有任何干扰。也许访问和解析页面的时间比网站的爬取延迟长，而在第一个响应处理完成之前启动第二个请求可能也能节省时间。看看下面的图表，情况是如何改善的：
- en: '![](img/29436d6c-1b52-402c-b32b-0b8dff8dfb14.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](img/29436d6c-1b52-402c-b32b-0b8dff8dfb14.png)'
- en: In any of these cases, you will need to introduce concurrency into your web
    scraper.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何这些情况下，您都需要将并发引入您的网络爬虫中。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: What is concurrency
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并发是什么
- en: Concurrency pitfalls
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并发陷阱
- en: Go concurrency model
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Go并发模型
- en: sync package helpers
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同步包助手
- en: What is concurrency
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并发是什么
- en: 'Instructions in a program are run by a **central processing unit** (**CPU**).
    This CPU can run multiple threads, which can process instructions for separate
    tasks, together. This is achieved by switching between the two tasks and executing
    the instructions in an alternating fashion, like pulling together two sides of
    a zipper. This overlapping execution of tasks is called concurrency. For the sake
    of simplicity, we will describe it as performing multiple tasks at the same time.
    The following diagram shows how it may appear:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 程序中的指令由**中央处理单元**（**CPU**）运行。这个CPU可以运行多个线程，可以同时处理不同任务的指令。这是通过在两个任务之间切换并以交替方式执行指令来实现的，就像拉动拉链的两侧一样。这种重叠执行任务的方式称为并发。为了简单起见，我们将描述它为同时执行多个任务。下面的图表显示了它可能的外观：
- en: '![](img/4a8fe2d3-f970-4f80-ae76-2acedbf7a915.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4a8fe2d3-f970-4f80-ae76-2acedbf7a915.png)'
- en: Concurrency should not be confused with parallelism, where two things or instructions
    can literally be executed at the same time.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 并发不应与并行混淆，其中两个事物或指令可以实际上同时执行。
- en: By introducing a concurrent architecture to your web scraper, you will be able
    to make multiple web requests to different sites without waiting for one site
    to respond. In this way, a slow site or bad connection to one server will only
    affect the task of scraping that specific site and not the others. As the majority
    of the time spent in web scraping is communication over a network, this is a very
    good solution to your problem.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 通过向您的网络爬虫引入并发架构，您将能够在不等待一个站点响应的情况下对不同站点进行多次网络请求。这样，一个慢站点或与一个服务器的连接不佳只会影响到爬取特定站点的任务，而不会影响其他站点。由于网络爬取中花费的大部分时间是在网络通信上，这是您问题的一个很好的解决方案。
- en: Building a program with a concurrent architecture can sometimes be a daunting
    task, as it opens up a new set of issues that need to be taken into consideration.
    When multiple threads are running, they will typically need some mechanism for
    communication and must be very careful about trying to modify the same objects
    at the same time. Without a well-thought-out approach, your scraper is bound to
    encounter a variety of problems that can be very difficult to detect and fix.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 构建具有并发架构的程序有时可能是一项艰巨的任务，因为它会引发一系列需要考虑的新问题。当多个线程运行时，它们通常需要一些用于通信的机制，并且必须非常小心地尝试同时修改相同的对象。如果没有经过深思熟虑的方法，您的爬虫将遇到各种问题，这些问题可能非常难以检测和修复。
- en: Concurrency pitfalls
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并发陷阱
- en: The source of most issues with concurrency is figuring out how to share information
    safely, and provide access to that information, between multiple threads. The
    simplest solution would seem to be to have an object that both threads can have
    access to, and modify, in order to communicate with the other thread. This seemingly
    innocent strategy is easier suggested than done. Let's look at this example, where
    two threads are sharing the same stack of web pages to scrape. They will need
    to know which web pages have been completed, and which web pages the other thread
    is currently working on.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 并发的大部分问题的根源在于如何安全地共享信息，并在多个线程之间提供对该信息的访问。最简单的解决方案似乎是让两个线程都可以访问和修改的对象，以便与另一个线程进行通信。这种看似无害的策略更容易说得比做得。让我们看一个例子，在这个例子中，两个线程共享相同的网页堆栈进行爬取。它们需要知道哪些网页已经完成，另一个线程正在处理哪些网页。
- en: 'We will use a simple map for this example, as shown in the following code:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在这个例子中使用一个简单的地图，如下面的代码所示：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The `"READY"` status indicates that the site has not yet been scraped.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '`"READY"`状态表示该站点尚未被爬取。'
- en: Race conditions
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 竞争条件
- en: From the start, this strategy has a major issue. If both threads look at the
    map at the same time, they will see that `page1.html` is ready to be scraped.
    They would then both update the value for `page1.html` to `"WORKING"`, and go
    on to scrape the same site at the same time! This would not only be a duplicated
    effort, but it would also create an extra load on the [example.com](http://example.com)
    server. An even worse situation is if one thread is updating the status to `"WORKING"`
    while the other thread is attempting to read the status. Then, your scraper will
    crash. Concurrent read and/or write operations are not allowed in Go.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 从一开始，这种策略就存在一个主要问题。如果两个线程同时查看地图，它们会看到`page1.html`已经准备好被爬取。然后它们都会将`page1.html`的值更新为`"WORKING"`，并同时开始爬取同一个站点！这不仅会是重复的工作，还会给[example.com](http://example.com)服务器增加额外的负载。更糟糕的情况是，如果一个线程正在将状态更新为`"WORKING"`，而另一个线程正在尝试读取状态。那么，您的爬虫将崩溃。在Go中不允许并发读和/或写操作。
- en: This situation is known as a race condition and is one of the most common issues
    you will run into as you build concurrent programs. In order to prevent race conditions
    from happening, there needs to be a mechanism where one thread can block access
    to the map for all other threads. The Go standard library provides the `sync`
    package to hold many helpful tools for building concurrent applications. In our
    specific situation, a `sync.Mutex` would be a very helpful tool.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况被称为竞争条件，是您构建并发程序时会遇到的最常见的问题之一。为了防止竞争条件的发生，需要有一种机制，其中一个线程可以阻止所有其他线程访问地图。Go标准库提供了`sync`包，其中包含许多有用的工具来构建并发应用程序。在我们的特定情况下，`sync.Mutex`将是一个非常有用的工具。
- en: 'You can also use the `"-race"` flag with many of the Go commands (such as:
    `go run` and `go test`) to help detect race conditions and provide helpful information.
    See more in their blog post at [https://blog.golang.org/race-detector](https://blog.golang.org/race-detector).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用`"-race"`标志与许多Go命令（例如：`go run`和`go test`）一起，以帮助检测竞争条件并提供有用的信息。在他们的博客文章中了解更多信息[https://blog.golang.org/race-detector](https://blog.golang.org/race-detector)。
- en: 'The `sync.Mutex` is a lockable object that acts as a barrier for other objects,
    much like the lock on a door. In order to enter the room, you first check if the
    door is locked. If it is locked, you must wait for someone to unlock it before
    you can proceed. The following code is a sample of how you would use a `sync.Mutex`
    in Go to protect concurrent reads and writes to our map:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '`sync.Mutex`是一个可锁定的对象，就像门上的锁一样，对其他对象起着屏障的作用。为了进入房间，您首先检查门是否被锁上。如果被锁上，您必须等待有人解锁它才能继续。以下代码是在Go中如何使用`sync.Mutex`来保护对地图的并发读写的示例：'
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: When a thread calls `mtx.Lock()`, it first checks if there is an existing lock
    being held by any other thread. If there is already an existing lock being held,
    your thread will wait until the existing lock is released. Only one thread can
    hold a lock at any given time, just like the door mentioned before.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 当线程调用`mtx.Lock()`时，首先检查是否有其他线程持有的现有锁。如果已经有现有的锁被持有，您的线程将等待直到现有的锁被释放。在任何给定时间只有一个线程可以持有锁，就像之前提到的门一样。
- en: 'When access to an object allows for concurrent reads, but must protect the
    object when a write is in process, the `sync` package provides the `sync.RWMutex`
    struct. This works similarly to the `sync.Mutex`, except that it separates locking
    into two separate methods:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 当对象的访问允许并发读取，但必须在进行写操作时保护对象时，`sync`包提供了`sync.RWMutex`结构。这与`sync.Mutex`类似，只是它将锁定分为两个单独的方法：
- en: '`Lock()` / `Unlock()`: A lock used specifically when a write operation is in
    progress'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Lock()` / `Unlock()`: 写操作进行时专门使用的锁'
- en: '`RLock()` / `RUnlock()`: A lock used specifically when a read operation is
    in progress'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RLock()` / `RUnlock()`: 读操作进行时专门使用的锁'
- en: 'Multiple threads can obtain read locks without blocking access to the object,
    except for threads attempting to obtain a write lock. Along the same lines, a
    read lock cannot be obtained if the write lock exists. Using the `RWMutex`, the
    preceding example would look like the following one:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 多个线程可以获取读锁而不阻止访问对象，除了试图获取写锁的线程。同样，如果存在写锁，则无法获取读锁。使用`RWMutex`，前面的示例将如下所示：
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The thread obtains a read lock before checking the map, to ensure that no writes
    are being made. Then it releases the read lock, regardless of whether the `if` a
    statement is `true` or `false`, and obtains a write lock before updating the map.
    Using these two type of mutexes will help protect your scraper from race conditions.
    However, it can also add another common concurrency pitfall.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 线程在检查地图之前获取读锁，以确保没有进行写操作。然后释放读锁，无论`if`语句是`true`还是`false`，然后在更新地图之前获取写锁。使用这两种类型的互斥锁将有助于保护您的爬虫免受竞争条件的影响。但是，这也可能会增加另一个常见的并发陷阱。
- en: Deadlocks
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 死锁
- en: When adding locks and unlocking code to a concurrent application, at some point
    you may see that your application has completely stopped, but not crashed. After
    much time spent digging through the code, adding extra print statements, and stepping
    through a debugger, you finally see it; a lock was not released! This situation
    is what is known as a deadlock.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在并发应用程序中添加锁和解锁代码时，有一种情况是您可能会发现您的应用程序完全停止，但没有崩溃。在花费了大量时间挖掘代码，添加额外的打印语句和通过调试器逐步执行之后，您终于看到了它；一个锁没有被释放！这种情况就是所谓的死锁。
- en: The Go standard library does not have any tools to help detect and overcome
    deadlocks. However, there is support in the open source community. One such package
    being `go-deadlock` by GitHub user `sacha-s`. The `go-deadlock` package provides
    a drop-in replacement for the `sync.Mutex` and the `sync.RWMutex`, that monitors
    how long a lock on an object has been held. By default, when it detects a deadlock,
    it will exit the program.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Go标准库没有任何工具来帮助检测和克服死锁。但是，在开源社区中有支持。GitHub用户`sacha-s`的一个这样的包是`go-deadlock`。`go-deadlock`包提供了`sync.Mutex`和`sync.RWMutex`的一个可替换项，用于监视对象上的锁已经被持有多长时间。默认情况下，当它检测到死锁时，它将退出程序。
- en: 'The deadlock timeout duration and the action to take are both configurable
    through the `deadlock.Opts` object, as shown in the following example:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 死锁超时持续时间和采取的操作都可以通过`deadlock.Opts`对象进行配置，如以下示例所示：
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Using mutexes and deadlock detections are some of the standard ways of ensuring
    that concurrent threads can operate without getting in each other's way. These
    traditional methods are offered through the Go programming language. However,
    they provide a different perspective on how concurrent threads should communicate
    with one another.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 使用互斥锁和死锁检测是确保并发线程可以在不互相干扰的情况下运行的标准方法之一。这些传统方法是通过Go编程语言提供的。然而，它们提供了一个不同的视角，即并发线程应该如何相互通信。
- en: The Go concurrency model
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Go并发模型
- en: 'As you have seen, many of the problems with concurrent programs stem from sharing
    memory resources between multiple threads. This shared memory is used to communicate
    state and can be very fragile, with great care needed to ensure that everything
    stays up and running. In Go, concurrency is approached with the mantra:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所见，许多并发程序的问题源于多个线程之间共享内存资源。这种共享内存用于通信状态，可能非常脆弱，需要非常小心地确保一切正常运行。在Go中，并发是以以下口号为基础的：
- en: '*Do not communicate by sharing memory; instead, share memory by communicating.*'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*不要通过共享内存进行通信；相反，通过通信共享内存。*'
- en: When you use mutexes and locks around a common object, you are communicating
    by sharing memory. Multiple threads look to the same memory location to alert
    and to provide information for the other threads to use. Instead of doing this,
    Go provides tools to help share memory by communicating.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 当您在一个共同对象周围使用互斥锁和锁时，您是通过共享内存进行通信。多个线程查看相同的内存位置以通知其他线程并提供信息供其使用。Go提供了工具来帮助通过通信共享内存。
- en: Goroutines
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Goroutines
- en: 'Up until this point, we have been referring to concurrent paths of execution
    as threads. In Go, the synonymous tool for accomplishing this is called a **goroutine**.
    Goroutines are described as a:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 直到这一点，我们一直将执行的并发路径称为线程。在Go中，实现这一点的同义工具称为**goroutine**。Goroutines被描述为：
- en: '*Lightweight thread of execution*.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '*轻量级执行线程*。'
- en: Unlike traditional threads found in C and Java, goroutines are managed by the
    Go runtime and not the OS thread scheduler. This allows the Go runtime scheduler
    to be hyper-focused on only tasks in the Go program. It also leverages OS threads
    as needed, providing more granular units of operation. OS threads suffer from
    a large amount of overhead required to create each thread and a relatively slow
    ability to determine which thread a task should be run on. The Go runtime chooses
    much smaller footprints when creating separations of goroutines, allowing more
    of them to run simultaneously.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 与C和Java中找到的传统线程不同，goroutines由Go运行时管理，而不是由操作系统线程调度程序管理。这使得Go运行时调度程序能够专注于Go程序中的任务。它还根据需要利用操作系统线程，提供更精细的操作单元。操作系统线程需要大量的开销来创建每个线程，并且相对较慢地确定应在哪个线程上运行任务。Go运行时在创建goroutines的分离时选择了更小的占用空间，允许更多的goroutines同时运行。
- en: 'Creating goroutines is, by design, a very simple task in Go. By prefixing any
    function call with the word `go`, it will run the function in a new goroutine.
    The following example is a simple program that runs a small goroutine:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 创建goroutines在Go中是一个非常简单的任务。通过在任何函数调用前加上`go`这个词，它将在一个新的goroutine中运行该函数。以下示例是一个简单的程序，运行一个小的goroutine：
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: When you run this code, you can see that the numbers from `startTicker()` are
    printed, even though the main goroutine sleeps for 10 seconds. If you modify this
    code, changing the Go `startTicker()` with just `startTicker()`, this code will
    run forever, printing each second until the process is killed forcefully.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 当您运行此代码时，您会看到`startTicker()`中的数字被打印出来，即使主goroutine睡眠了10秒。如果修改此代码，将`startTicker()`改为`startTicker()`，则此代码将永远运行，每秒打印一次，直到进程被强制终止。
- en: When multiple goroutines need to communicate with each other, Go provides a
    simple tool for them to use.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当多个goroutines需要相互通信时，Go为它们提供了一个简单的工具。
- en: Channels
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通道
- en: 'Channels are conduits through which goroutines can send and receive information.
    This sits at the core of the Go''s concurrency model for sharing memory through
    communicating. Channels allow for goroutines to each other rather than trying
    to access the same information. Channels are also unidirectional, meaning that
    data can only flow in one direction, as shown in the following diagram:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 通道是goroutines可以发送和接收信息的通道。这是Go共享内存的并发模型的核心所在。通道允许goroutines彼此之间进行通信，而不是尝试访问相同的信息。通道也是单向的，意味着数据只能在一个方向流动，如下图所示：
- en: '![](img/c585b8d7-d38f-48d1-9999-f75436f8a483.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c585b8d7-d38f-48d1-9999-f75436f8a483.png)'
- en: If communication is needed in both directions, two channels will need to be
    used.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要双向通信，将需要使用两个通道。
- en: 'In our previous example using mutexes, multiple threads attempted to access
    the map containing the status of each website by creating a release lock. We can
    use channels as a safer approach by launching the scraper threads as separate
    goroutines and having them communicate their status back to the main goroutine
    through a channel. This is shown in the following example:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前使用互斥锁的示例中，多个线程试图通过创建释放锁来访问包含每个网站状态的地图。我们可以通过将刮削器线程作为单独的goroutines启动，并通过通道将它们的状态传递回主goroutine来使用通道作为更安全的方法。这在以下示例中显示：
- en: '[PRE5]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In the main function for this program, the `updatesChan` is created to act as
    the means through which goroutines can provide their status back to the main goroutine.
    These goroutines are started in the first `for` loop by calling Go `scrapeSite`,
    which takes the URL of the website to be scraped, and a reference to the `updatesChan`.
    The main goroutine then enters a second `for` loop where it listens for data to
    come through `updatesChan`, providing a new status update for any of the URLs.
    As each site provides an update, the number of completed sites is incremented
    until all of the sites have completed. At this point, the main goroutine closes
    the channel.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在此程序的主函数中，创建了`updatesChan`作为goroutine向主goroutine提供其状态的手段。这些goroutine通过调用Go `scrapeSite`在第一个`for`循环中启动，该函数接受要爬取的网站的URL和对`updatesChan`的引用。然后，主goroutine进入第二个`for`循环，监听`updatesChan`传递的数据，为任何URL提供新的状态更新。随着每个站点提供更新，完成的站点数量递增，直到所有站点都完成。此时，主goroutine关闭通道。
- en: Closing a channel prevents the sending and receiving of any more data through
    that channel. As far as for-range operations are concerned, this marks the end
    of the stream, exiting to loop.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 关闭通道会阻止通过该通道发送和接收更多数据。就for-range操作而言，这标志着流的结束，退出循环。
- en: By converting the method of communication to use channels, there is only one
    owner of the shared data and the responsibility of updating the map falls back
    on a single goroutine. This allows each worker of goroutine to provide status
    updates safely, without the need for locks, or sharing memory.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将通信方法转换为使用通道，共享数据只有一个所有者，并且更新映射的责任重新落在单个goroutine身上。这允许每个goroutine的工作人员安全地提供状态更新，而无需锁定或共享内存。
- en: sync package helpers
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: sync包助手
- en: Goroutines and channels, being the core constructs of concurrent programming
    in Go, will provide most of the utility that you will need. However, there are
    many helpful objects that the Go standard library provides that are also useful
    to know. We have already seen how `sync.Mutex` and `sync.RWMutex` work, but let's
    take a look at some of the other objects offered.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Goroutine和通道是Go中并发编程的核心构造，它们将提供大部分您所需的实用程序。然而，Go标准库提供了许多有用的对象，也很有用。我们已经看到了`sync.Mutex`和`sync.RWMutex`的工作原理，但让我们看看其他提供的一些对象。
- en: Conditions
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 条件
- en: Now that you are able to launch scraper tasks into multiple threads, some controls
    will need to be put into place so things don't get too out of hand. It is very
    simple in Go to launch 1,000 goroutines to scrape 1,000 pages simultaneously from
    a single program. However, your machine most likely cannot handle the same load.
    The `sync` package provides a few utilities to help maintain order in your web
    scraper.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以将爬虫任务启动到多个线程中，需要放置一些控件以防止事情失控。在Go中，很容易启动1,000个goroutine同时从单个程序中爬取1,000个页面。然而，您的计算机很可能无法承受相同的负载。`sync`包提供了一些实用程序来帮助维护您的网络爬虫的顺序。
- en: One common control that you will want to put into place is the number of active
    concurrent scraping threads. Before you launch a new goroutine, you will need
    to satisfy a certain condition, being that the number of active threads is less
    than some value. If this condition fails the check, your new goroutine will have
    to wait, until it is signaled that the condition passes. This scenario is solved
    using the `sync.Cond` object.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要放置的一个常见控件是活动并发爬取线程的数量。在启动新的goroutine之前，您需要满足某个条件，即活动线程的数量小于某个值。如果此条件未通过检查，您的新goroutine将不得不等待，直到收到条件通过的信号。使用`sync.Cond`对象解决了这种情况。
- en: 'The `sync.Cond` object provides a mechanism to tell goroutines to wait until
    a signal is received, based on any defined condition. A `sync.Cond` struct wraps
    a `sync.Locker` (usually a `sync.Mutex` or `sync.RWMutex`) to control access to
    the condition itself. There follows an example of how you might use a `sync.Cond`
    to control the number of active scraper threads:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`sync.Cond`对象提供了一种机制，告诉goroutine等待直到收到信号，基于任何定义的条件。`sync.Cond`结构包装了一个`sync.Locker`（通常是`sync.Mutex`或`sync.RWMutex`），以控制对条件本身的访问。以下是如何使用`sync.Cond`来控制活动爬虫线程数量的示例：'
- en: '[PRE6]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The main focus of this code is inside the `scrapeSite()` function. In this part
    of the code, the program first checks if it has reached the maximum number of
    concurrent threads. If this condition is true, it will wait. This pauses the goroutine
    until a `Signal()` or a `Broadcast()` is called from the `sync.Cond`. We use `Signal()`
    in our case to notify a single goroutine that the condition has passed, and that
    it can proceed. If `Broadcast()` was used here, it would release all of the goroutines
    which are currently waiting on the condition. A good use case for that could be
    pausing the entire system to make some configuration change on the `fly`, then
    resuming all paused goroutines.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的主要重点在于`scrapeSite()`函数。在代码的这部分中，程序首先检查是否已达到最大并发线程数。如果条件为真，它将等待。这会暂停goroutine，直到从`sync.Cond`调用`Signal()`或`Broadcast()`。在我们的情况下，我们使用`Signal()`来通知单个goroutine条件已经通过，可以继续。如果这里使用`Broadcast()`，它将释放当前正在等待条件的所有goroutine。一个很好的用例是暂停整个系统以对`fly`进行一些配置更改，然后恢复所有暂停的goroutine。
- en: Atomic counters
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原子计数器
- en: 'In the previous example, we surrounded any increment or decrement of `activeThreads`
    with a `Lock()` / `Unlock()`. This can become quite verbose if it needs to be
    done multiple times, as in our case. The `sync` package offers a subpackage called
    atomic that provides methods for updating objects without the need for locks.
    This is done by creating a new variable each time a change is made, while preventing
    multiple writes from occurring at the same time. The following example shows some
    of the changes necessary to use `activeThreads` as an `atomic` counter:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个例子中，我们用`Lock()`/`Unlock()`包围了`activeThreads`的任何增量或减量。如果需要多次执行此操作，这可能会变得非常冗长，就像我们的情况一样。`sync`包提供了一个名为atomic的子包，它提供了更新对象的方法，而无需使用锁。这是通过在每次进行更改时创建一个新变量来完成的，同时防止多次写入同时发生。以下示例显示了使用`activeThreads`作为`atomic`计数器所需的一些更改：
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Summary
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we discussed many topics surrounding concurrency in web scraping.
    We looked at what concurrency is and how we can benefit from it. We reviewed some
    of the common issues that must be avoided when building concurrent programs. We
    also learned about the Go concurrency model and how to use its primitive objects
    to build concurrent Go applications. Finally, we looked at a few of the niceties
    Go has included in its `sync` package. In our final chapter, we will look at taking
    our scraper to the highest level.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了许多关于网络爬虫并发性的主题。我们看了并发是什么以及我们如何从中受益。我们回顾了在构建并发程序时必须避免的一些常见问题。我们还了解了Go并发模型以及如何使用其原始对象来构建并发的Go应用程序。最后，我们看了一些Go在其`sync`包中包含的便利功能。在我们的最后一章中，我们将探讨如何将我们的爬虫提升到最高水平。
