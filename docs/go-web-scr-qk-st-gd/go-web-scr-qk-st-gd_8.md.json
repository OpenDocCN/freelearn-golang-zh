["```go\npackage main\n\nimport (\n  \"github.com/gocolly/colly\"\n  \"fmt\"\n)\n\nfunc main() {\n  c := colly.NewCollector(colly.AllowedDomains(\"go-colly.org\"))\n\n  // Find and visit all links\n  c.OnHTML(\"a[href]\", func(e *colly.HTMLElement) {\n    e.Request.Visit(e.Attr(\"href\"))\n  })\n\n  c.OnRequest(func(r *colly.Request) {\n    fmt.Println(\"Visiting\", r.URL)\n  })\n\n  c.Visit(\"http://go-colly.org/\")\n}\n```", "```go\npackage main\n\nimport (\n  \"encoding/json\"\n  \"fmt\"\n  \"strings\"\n  \"time\"\n\n  \"github.com/4ydx/cdp/protocol/dom\"\n  \"github.com/4ydx/chrome-protocol\"\n  \"github.com/4ydx/chrome-protocol/actions\"\n  \"github.com/PuerkitoBio/goquery\"\n)\n```", "```go\nfunc getHTML() string {\n  browser := cdp.NewBrowser(\"/usr/bin/google-chrome\", 9222, \"browser.log\")\n  handle := cdp.Start(browser, cdp.LogBasic)\n  err := actions.EnableAll(handle, 2*time.Second)\n  if err != nil {\n    panic(err)\n  }\n  _, err = actions.Navigate(handle, \"https://www.amazon.com/gp/goldbox\", \n     30*time.Second)\n  if err != nil {\n    panic(err)}\n\n  var nodes []dom.Node\n  retries := 5\n\n  for len(nodes) == 0 && retries > 0 {\n    nodes, err = actions.FindAll(\n      handle,\n      \"div.GB-M-COMMON.GB-SUPPLE:first-child #widgetContent\",\n      10*time.Second)\n    retries--\n    time.Sleep(1 * time.Second)\n  }\n\n  if len(nodes) == 0 || retries == 0 {\n    panic(\"could not find results\")\n  }\n\n  reply, err := actions.Evaluate(handle, \"document.body.outerHTML;\", 30*time.Second)\n  if err != nil {\n    panic(err)\n  }\n\n  a := struct{\n    Value string\n  }{}\n  json.Unmarshal([]byte(\"{\\\"value\\\":\" + string(*reply.Result.Value)+\"}\"), &a)\n  body := a.Value\n\n  handle.Stop(false)\n  browser.Stop()\n  return body\n}\n```", "```go\nfunc parseProducts(htmlBody string) []string {\n  rdr := strings.NewReader(htmlBody)\n  body, err := goquery.NewDocumentFromReader(rdr)\n  if err != nil {\n    panic(err)\n  }\n\n  products := []string{}\n  details := body.Find(\"div.dealDetailContainer\")\n  details.Each(func(_ int, detail *goquery.Selection) {\n    println(\".\")\n    title := detail.Find(\"a#dealTitle\").Text()\n    price := detail.Find(\"div.priceBlock\").Text()\n\n    title = strings.TrimSpace(title)\n    price = strings.TrimSpace(price)\n\n    products = append(products, title + \"\\n\"+price)\n  })\n  return products\n}\n```", "```go\nfunc main() {\n  println(\"getting HTML...\")\n  html := getHTML()\n  println(\"parsing HTML...\")\n  products := parseProducts(html)\n\n  println(\"Results:\")\n  for _, product := range products {\n    fmt.Println(product + \"\\n\")\n  }\n}\n```", "```go\ngit clone https://github.com/slotix/dataflowkit\n```", "```go\ngo get github.com/slotix/dataflowkit/...\n```", "```go\n./fetch.cli -u example.com\n```", "```go\npackage main\n\nimport (\n  \"bytes\"\n  \"encoding/json\"\n  \"fmt\"\n  \"io/ioutil\"\n  \"net/http\"\n\n  \"github.com/slotix/dataflowkit/fetch\"\n)\n\nfunc main() {\n  r := fetch.Request{\n    Type: \"base\",\n    URL: \"http://example.com\",\n    Method: \"GET\",\n    UserToken: \"randomString\",\n    Actions: \"\",\n  }\n\n  data, err := json.Marshal(&r)\n\n  if err != nil {\n    panic(err)\n  }\n  resp, err := http.Post(\"http://localhost:8000/fetch\", \"application/json\", bytes.NewBuffer(data))\n  if err != nil {\n    panic(err)\n  }\n\n  body, err := ioutil.ReadAll(resp.Body)\n  if err != nil {\n    panic(err)\n  }\n\n  fmt.Println(string(body))\n}\n```", "```go\nr := fetch.Request{\n    Type: \"chrome\",\n    URL: \"http://example.com\",\n    Method: \"GET\",\n    UserToken: \"randomString\",\n    Actions: `[{\"click\":{\"element\":\"a\"}}]`,\n}\n```", "```go\npackage main\n\nimport (\n  \"bytes\"\n  \"encoding/json\"\n  \"fmt\"\n  \"io/ioutil\"\n  \"net/http\"\n\n  \"github.com/slotix/dataflowkit/fetch\"\n  \"github.com/slotix/dataflowkit/scrape\"\n)\n```", "```go\nfunc main() {\n  r := scrape.Payload{\n    Name: \"Daily Deals\",\n    Request: fetch.Request{\n      Type: \"Base\",\n      URL: \"https://www.packtpub.com/latest-releases\",\n      Method: \"GET\",\n    },\n    Fields: []scrape.Field{\n      {\n        Name: \"Title\",\n        Selector: `div.landing-page-row div[itemtype$=\"/Product\"]  \n         div.book-block-title`,\n        Extractor: scrape.Extractor{\n          Types: []string{\"text\"},\n          Filters: []string{\"trim\"},\n        },\n      }, {\n        Name: \"Price\",\n        Selector: `div.landing-page-row div[itemtype$=\"/Product\"] div.book-block-\n        price-discounted`,\n        Extractor: scrape.Extractor{\n          Types: []string{\"text\"},\n          Filters: []string{\"trim\"},\n        },\n      },\n    },\n    Format: \"CSV\",\n  }\n```", "```go\n  data, err := json.Marshal(&r)\n\n  if err != nil {\n    panic(err)\n  }\n  resp, err := http.Post(\"http://localhost:8001/parse\", \"application/json\", \n  bytes.NewBuffer(data))\n  if err != nil {\n    panic(err)\n  }\n\n  body, err := ioutil.ReadAll(resp.Body)\n  if err != nil {\n    panic(err)\n  }\n\n  fmt.Println(string(body))\n}\n```", "```go\n{\n  \"Output file\":\"results/f5ae68fa_2019-01-13_22:53.CSV\",\n  \"Requests\":{\n    \"initial\":1\n  },\n  \"Responses\":1,\n  \"Task ID\":\"1Fk0qAso17vNnKpzddCyWUcVv6r\",\n  \"Took\":\"3.209452023s\"\n}\n```"]