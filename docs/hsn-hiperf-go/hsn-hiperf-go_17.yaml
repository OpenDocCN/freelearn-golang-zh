- en: Clusters and Job Queues
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 簇和作业队列
- en: Clustering and job queues in Go are good ways to get distributed systems to
    work synchronously and deliver a consistent message. Distributed computing is
    difficult and it becomes very important to watch for potential performance optimizations
    within both clustering and job queues.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在Go中的聚类和作业队列是使分布式系统同步工作并传递一致消息的好方法。分布式计算很困难，因此在聚类和作业队列中都非常重要地观察潜在的性能优化。
- en: 'In this chapter, we will learn about the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习以下主题：
- en: Clustering with hierarchical and centroid algorithms
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用分层和质心算法进行聚类
- en: Goroutines as queues
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goroutines作为队列
- en: Buffered channels as job queues
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作业队列中的缓冲通道
- en: Implementing third-party queuing systems (Kafka and RabbitMQ)
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现第三方排队系统（Kafka和RabbitMQ）
- en: Learning about different clustering systems can help you identify large groups
    of data and how to accurately classify them in your datasets. Learning about queueing
    systems will help you move large amounts of information from your data structures
    into specific queueing mechanisms in order to pass large amounts of data to different
    systems in real time.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 了解不同的聚类系统可以帮助您识别数据中的大型群组，以及如何在数据集中准确对其进行分类。了解排队系统将帮助您将大量信息从数据结构传输到特定的排队机制，以便实时将大量数据传递给不同的系统。
- en: Clustering in Go
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Go中的聚类
- en: Clustering is a methodology that you can use in order to search for consistent
    groups of data within a given dataset. Using comparison techniques, we can look
    for groups of items within the dataset that contain similar characteristics. These
    individual datapoints are then divided into clusters. Clustering is commonly used
    in order to solve multi-objective problems.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类是一种方法，您可以使用它来搜索给定数据集中一致的数据组。使用比较技术，我们可以寻找数据集中包含相似特征的项目组。然后将这些单个数据点划分为簇。聚类通常用于解决多目标问题。
- en: 'There are two general classifications of clustering, both of which have distinct
    subclassifications:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类有两种一般分类，都有不同的子分类：
- en: '**Hard clustering**: The datapoints within the dataset are either explicitly
    a part of a cluster or not explicitly part of a cluster. Hard clustering can be
    further classified as follows:'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**硬聚类**：数据集中的数据点要么明确属于一个簇，要么明确不属于一个簇。硬聚类可以进一步分类如下：'
- en: '**Strict partitioning**: An object can belong to exactly one cluster.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**严格分区**：一个对象只能属于一个簇。'
- en: '**Strict partitioning with outliers**: Strict partitioning, which also includes
    a concept that objects can be classified as outliers (meaning they belong to no
    cluster).'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**带异常值的严格分区**：严格分区，还包括一个对象可以被分类为异常值的概念（意味着它们不属于任何簇）。'
- en: '**Overlapping clustering**: Individual objects can be associated with one or
    more clusters.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重叠聚类**：个体对象可以与一个或多个簇相关联。'
- en: '**Soft clustering**: Datapoints are assigned a probability that they are associated
    with a particular cluster based on explicit criteria. They can be further classified
    as follows:'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**软聚类**：根据明确的标准，数据点被分配与特定簇相关联的概率。它们可以进一步分类如下：'
- en: '**Subspace**: Clusters use a two-dimensional subspace in order to be further
    classified into two dimensions.'
  id: totrans-16
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**子空间**：簇使用二维子空间，以便进一步分类为两个维度。'
- en: '**Hierarchical**: Clustering using a hierarchical model; an object that is
    associated with a child cluster is also associated with the parent clusters.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分层**：使用分层模型进行聚类；与子簇相关联的对象也与父簇相关联。'
- en: 'There are also many different algorithm types that are used for clustering.
    Some examples are shown in the following table:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多不同类型的算法用于聚类。以下表格中显示了一些示例：
- en: '| **Name** | **Definition** |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| **名称** | **定义** |'
- en: '| Hierarchical | Used to attempt to build a hierarchy of clusters. Usually
    based on a top-down or a bottom-up approach, attempting to segment datapoints
    either from one to many clusters (top-down) or many to few clusters (bottom-up).
    |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '|分层|用于尝试构建簇的层次结构。通常基于自顶向下或自底向上的方法，试图将数据点分割为一对多个簇（自顶向下）或多对少个簇（自底向上）。'
- en: '| Centroid | Used to find a specific point location that acts as the center
    of a cluster. |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '|质心|用于找到作为簇中心的特定点位置。|'
- en: '| Density | Used to look for places in the dataset that have dense regions
    of datapoints. |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '|密度|用于寻找数据集中具有数据点密集区域的位置。|'
- en: '| Distribution | Used to utilize distribution models to order and classify
    datapoints within a cluster. |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '|分布|用于利用分布模型对簇内的数据点进行排序和分类。|'
- en: In this book, we're going to focus on hierarchical and centroid algorithms as
    they are commonly used in computer science (namely in machine learning).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将专注于分层和质心算法，因为它们在计算机科学中（特别是在机器学习中）通常被使用。
- en: K-nearest neighbors
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: K最近邻
- en: Hierarchical clustering is a clustering method in which an object that is associated
    with a child cluster is also associated with the parent clusters. The algorithm
    begins with all of the individual datapoints in the data struct being assigned
    to individual clusters. The nearest clusters to one another merge. This pattern
    continues until all the datapoints have an association with another datapoint.
    Hierarchical clustering is often displayed using a charting technique called a
    **dendrogram**. Hierarchical clustering is *O(n²)*, so it's not typically used
    for large datasets.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 分层聚类是一种聚类方法，其中与子簇相关联的对象也与父簇相关联。该算法从数据结构中的所有单个数据点开始，分配到单个簇。最近的簇合并。这种模式持续进行，直到所有数据点都与另一个数据点相关联。分层聚类通常使用一种称为**树状图**的图表技术来显示。分层聚类的时间复杂度为*O(n²)*，因此通常不用于大型数据集。
- en: The **K-nearest neighbors** (**KNN**) algorithm is a hierarchical algorithm
    often used in machine learning. One of the most popular ways to find KNN data
    in Go is with the `golearn` package. A classic KNN example that gets used as a
    machine learning example is the classification of iris flowers, which can be seen
    at [https://github.com/sjwhitworth/golearn/blob/master/examples/knnclassifier/knnclassifier_iris.go](https://github.com/sjwhitworth/golearn/blob/master/examples/knnclassifier/knnclassifier_iris.go).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**K最近邻**（**KNN**）算法是机器学习中经常使用的一种分层算法。在Go中查找KNN数据的最流行的方法之一是使用`golearn`包。作为机器学习示例经常使用的经典KNN示例是鸢尾花的分类，可以在[https://github.com/sjwhitworth/golearn/blob/master/examples/knnclassifier/knnclassifier_iris.go](https://github.com/sjwhitworth/golearn/blob/master/examples/knnclassifier/knnclassifier_iris.go)中看到。'
- en: 'Given a dataset with sepal and petal lengths and widths, we can see calculated
    data about this dataset:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个具有萼片和花瓣长度和宽度的数据集，我们可以看到关于该数据集的计算数据：
- en: '![](img/7fb62e91-76e2-436a-9266-d4a7993c2271.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7fb62e91-76e2-436a-9266-d4a7993c2271.png)'
- en: 'We can see the calculated accuracy in this prediction model. In the preceding
    output, we have the following descriptors:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在此预测模型中看到计算出的准确度。在前面的输出中，我们有以下描述：
- en: '| **Descriptor** | **Definition** |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| **描述符** | **定义** |'
- en: '| Reference Class | A title associated with the output. |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 参考类 | 与输出相关联的标题。'
- en: '| True Positives | The model correctly predicts a positive response. |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 真阳性 | 模型正确预测了正面响应。|'
- en: '| False Positives | The model incorrectly predicts a positive response. |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 假阳性 | 模型错误地预测了正面响应。'
- en: '| True Negatives | The model correctly predicts a negative response. |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 真阴性 | 模型正确预测了负面响应。'
- en: '| Precision | Ability to not label an instance positive that''s actually negative.
    |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 精确度 | 不将实际上是负面的实例标记为正面的能力。'
- en: '| Recall | A ratio of *True Positives / (Sum of True Positives + False Negatives)*.
    |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 召回率 | *真阳性/（真阳性总和+假阴性）*的比率。'
- en: '| F1 Score | The weighted harmonic mean of precision and recall. This value
    is somewhere between 0.0 and 1.0, with 1.0 being the best possible outcome for
    this value. |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| F1分数 | 精确度和召回率的加权调和平均值。该值介于0.0和1.0之间，1.0是该值的最佳可能结果。'
- en: Last but certainly not least, we have an overall accuracy, which tells us how
    accurately our algorithm predicted our outcomes.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但肯定不是最不重要的，我们有一个总体准确度，告诉我们算法如何准确地预测了我们的结果。
- en: K-means clustering
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: K-means聚类
- en: K-means clustering is one of the most commonly utilized clustering algorithms
    in machine learning. K-means attempts to identify the underlying patterns of datapoints
    in a dataset. In K-means, we define *k* as the number of centroids (the center
    of an object with uniform density) that our cluster has. Then, we categorize the
    different datapoints with respect to those centroids.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: K-means聚类是机器学习中最常用的聚类算法之一。K-means试图识别数据集中数据点的潜在模式。在K-means中，我们将*k*定义为我们的聚类具有的质心数（具有均匀密度的对象的中心）。然后，我们根据这些质心对不同的数据点进行分类。
- en: 'We can use the K-means library, which can be found at [https://github.com/muesli/kmeans](https://github.com/muesli/kmeans),
    in order to perform K-means clustering on a dataset. Let''s take a look:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用K-means库，在[https://github.com/muesli/kmeans](https://github.com/muesli/kmeans)中找到，对数据集执行K-means聚类。让我们来看一下：
- en: 'First, we instantiate the `main` package and import our required packages:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们实例化`main`包并导入我们所需的包：
- en: '[PRE0]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, we create a random two-dimensional dataset with the `createDataset` function:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们使用`createDataset`函数创建一个随机的二维数据集：
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Next, we create a function that allows us to print our data for consumption:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们创建一个允许我们打印数据以供使用的函数：
- en: '[PRE2]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In our `main` function, we define our cluster size, our dataset size, and our
    threshold size.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的`main`函数中，我们定义了我们的聚类大小，数据集大小和阈值大小。
- en: 'Now, we can create a new random 2D dataset and perform K-means clustering on
    that dataset. We plot the result and print our clusters as follows:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以创建一个新的随机2D数据集，并对该数据集执行K-means聚类。我们按如下方式绘制结果并打印我们的聚类：
- en: '[PRE3]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'After we execute this function, we will be able to see our datapoints grouped
    together in their respective clusters:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此函数后，我们将能够看到我们的数据点分组在各自的聚类中：
- en: '![](img/2569c1a4-10e2-4215-bc8d-1ed8556cbf77.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2569c1a4-10e2-4215-bc8d-1ed8556cbf77.png)'
- en: 'In our results, we can see the following:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的结果中，我们可以看到以下内容：
- en: Our initial (randomly generated) 2D dataset
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的初始（随机生成的）2D数据集
- en: Our three defined clusters
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们定义的三个聚类
- en: The associated datapoints that are assigned to each cluster
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分配给每个聚类的相关数据点
- en: 'This program also generates `.png` images of each step of clustering. The one
    that was created last is a visualization of the clustering of the datapoints:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 该程序还生成了每个聚类步骤的`.png`图像。最后创建的图像是数据点聚类的可视化：
- en: '![](img/7319abcf-10d1-4f28-9995-4ac9319a7783.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7319abcf-10d1-4f28-9995-4ac9319a7783.png)'
- en: 'K-means clustering is a very good algorithm to use if you want to group a large
    dataset into smaller groups. It has an O notation of *O(n)*, so it is often practical
    to use for large datasets. Practical applications of K-means clustering may include
    two-dimensional datasets for the following:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果要将大型数据集分组为较小的组，K-means聚类是一个非常好的算法。它的O符号是*O(n)*，因此通常适用于大型数据集。K-means聚类的实际应用可能包括以下的二维数据集：
- en: Identifying crime-prone areas on a map using GPS coordinates
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用GPS坐标在地图上识别犯罪多发区
- en: Identifying clustering of pages for on-call developers
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为值班开发人员识别页面聚类
- en: Identifying athlete performance characteristics based on step output compared
    to the number of rest days
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据步数输出与休息天数的比较来识别运动员表现特征
- en: In the next section, let's explore job queues in Go.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，让我们探索Go中的作业队列。
- en: Exploring job queues in Go
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Go中探索作业队列
- en: Job queues are frequently used to process units of work in a computer system.
    They are often used to schedule both synchronous and asynchronous functions. While
    working with larger datasets, there can be data structures and algorithms that
    take quite a bit of time to process. Either the system is processing a very large
    segment of data, the algorithm that is being applied to the dataset is very complex,
    or there's a combination of the two. Being able to add these jobs to a job queue
    and perform them in a different order or at different times can be very helpful
    to maintain the stability of a system and give an end user a better experience.
    Job queues are also frequently used for asynchronous jobs since the time when
    the job completes isn't as impactful for the end user. The job system can also
    prioritize the jobs in a priority queue if one is implemented. This allows the
    system to process the most important jobs first, followed by the jobs that don't
    have as much of an explicit deadline.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 作业队列经常用于在计算机系统中处理工作单元。它们通常用于调度同步和异步函数。在处理较大的数据集时，可能会有需要花费相当长时间来处理的数据结构和算法。系统正在处理非常大的数据段，应用于数据集的算法非常复杂，或者两者兼而有之。能够将这些作业添加到作业队列中，并以不同的顺序或不同的时间执行它们，对于维护系统的稳定性并为最终用户提供更好的体验非常有帮助。作业队列也经常用于异步作业，因为作业完成的时间对最终用户来说并不那么重要。如果实现了优先级队列，作业系统还可以对作业进行优先处理。这允许系统首先处理最重要的作业，然后处理没有明确截止日期的作业。
- en: Goroutines as job queues
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Goroutines作为作业队列
- en: Perhaps you don't need a job queue for your particular task. Using a goroutine
    for a task is often sufficient. Let's say that we want to send an email asynchronously
    during some particular task. We can send this email using a goroutine within our
    function.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 也许您的特定任务并不需要作业队列。对于任务，使用goroutine通常就足够了。假设我们想在某个特定任务期间异步发送电子邮件。我们可以在我们的函数中使用goroutine发送这封电子邮件。
- en: 'For this example, I''m going to send an email via Gmail. To do so, you may
    need to allow less secure app access for email authentication to work ([https://myaccount.google.com/lesssecureapps?pli=1](https://myaccount.google.com/lesssecureapps?pli=1)).
    This is not recommended to do in the long term; it''s just a simple way to show
    a real-world email interaction. If you''re interested in building a more robust
    email solution, you can use the Gmail API at [https://developers.google.com/gmail/api/quickstart/go](https://developers.google.com/gmail/api/quickstart/go).
    Let''s get started:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我将通过Gmail发送电子邮件。为了做到这一点，您可能需要允许不太安全的应用程序访问电子邮件验证工作（[https://myaccount.google.com/lesssecureapps?pli=1](https://myaccount.google.com/lesssecureapps?pli=1)）。这并不是长期推荐的做法；这只是一个展示真实世界电子邮件交互的简单方法。如果您有兴趣构建更健壮的电子邮件解决方案，您可以使用Gmail
    API（[https://developers.google.com/gmail/api/quickstart/go](https://developers.google.com/gmail/api/quickstart/go)）。让我们开始吧：
- en: 'First, we''ll instantiate our `main` package and import the necessary packages
    into our sample program:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将实例化我们的`main`包，并将必要的包导入到我们的示例程序中：
- en: '[PRE4]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Then, we will create our `main` function, which will do the following:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将创建我们的`main`函数，它将执行以下操作：
- en: Log a `Doing Work` line (representative of doing other things in our function).
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录一个`Doing Work`行（代表在我们的函数中做其他事情）。
- en: Log a `Sending Emails` line (representative of the time where the email is added
    to the goroutine).
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录一个`Sending Emails`行（代表电子邮件被添加到goroutine的时间）。
- en: Spawn a goroutine to send the email.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成一个goroutine来发送电子邮件。
- en: 'Sleep to ensure the goroutine completes (we could use a `WaitGroup` here too
    if we''d like):'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保goroutine完成后再休眠（如果需要，我们也可以在这里使用`WaitGroup`）：
- en: '[PRE5]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In our `sendMail` function, we take in a recipient, set the proper email headers
    we need to send our email, and send it using the `gomail` dialer. You''ll need
    to change the `sender`, `recipient`, `username`, and `password` variables if you''d
    like to see this program execute successfully:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的`sendMail`函数中，我们接收一个收件人，设置我们需要发送电子邮件的正确电子邮件头，并使用`gomail`拨号器发送它。如果您希望看到此程序成功执行，您需要更改`sender`、`recipient`、`username`和`password`变量：
- en: '[PRE6]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can see from our resulting output that we are able to effectively do some
    work and send an email:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们的输出结果中可以看出，我们能够有效地完成一些工作并发送电子邮件：
- en: '![](img/052fc4f2-e76f-42bd-bb2f-a0c295ca6763.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/052fc4f2-e76f-42bd-bb2f-a0c295ca6763.png)'
- en: It's been noted as a core tenant in this book that the most performant method
    to perform a task can often be the simplest one. If you don't need to build a
    new job-queueing system to perform a simple task, you should avoid it. At larger
    companies, there are often dedicated teams to maintaining job queue systems for
    large-scale data. They are expensive from both performance and cost perspectives.
    They are often important to manage large-scale data systems, but I feel as if
    I'd be remiss if I didn't mention that you should take careful consideration before
    you add a distributed job queue to your technology stack.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 本书已经指出，执行任务的最有效方法通常是最简单的方法。如果不需要构建新的作业排队系统来执行简单的任务，就应该避免这样做。在大公司中，通常有专门的团队来维护大规模数据的作业队列系统。从性能和成本的角度来看，它们是昂贵的。它们通常是管理大规模数据系统的重要组成部分，但我觉得如果不提到在将分布式作业队列添加到技术栈之前应该仔细考虑，我会感到遗憾。
- en: Buffered channels as job queues
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 作业队列作为缓冲通道
- en: 'Go''s buffered channels are a perfect example of a worker queue. As we learned
    in [Chapter 3](61b73482-0431-4b8f-a069-d647ac1c1b87.xhtml), *Understanding Concurrency*,
    buffered channels are channels that have a bounded size. They are typically more
    performant than their unbounded counterpart. They are useful for retrieving values
    from an explicit number of goroutines you''ve launched. Because they are **first
    in first out** (**FIFO**) queuing mechanisms, they can be effectively used as
    a fixed-size queuing mechanism, and we can process requests in the order that
    they came in. We can write a simple job queue using a buffered channel. Let''s
    take a look:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: Go的缓冲通道是一个完美的工作队列示例。正如我们在[第3章](61b73482-0431-4b8f-a069-d647ac1c1b87.xhtml)中学到的*理解并发*，缓冲通道是具有有界大小的通道。它们通常比无界通道更高效。它们用于从您启动的显式数量的goroutine中检索值。因为它们是**先进先出**（**FIFO**）的排队机制，它们可以有效地用作固定大小的排队机制，我们可以按照它们进来的顺序处理请求。我们可以使用缓冲通道编写一个简单的作业队列。让我们来看一下：
- en: 'We start by instantiating our `main` package, importing our required libraries,
    and setting our constants:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先实例化我们的`main`包，导入所需的库，并设置我们的常量：
- en: '[PRE7]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Then, we create a `job` struct. This keeps track of the job name and the payload,
    as shown in the following code block:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们创建一个`job`结构。这个结构跟踪作业名称和有效载荷，如下面的代码块所示：
- en: '[PRE8]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Our `runJob` function just prints a success message. This is where we could
    add more intense work if we were so inclined:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的`runJob`函数只是打印一个成功的消息。如果我们愿意，这里可以添加更多的工作：
- en: '[PRE9]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Our main function creates a `jobQueue` channel of a defined `queueSize`. Then,
    it iterates through the workers and spawns goroutines for each of the workers.
    Lastly, it iterates through the job queue and runs the necessary jobs:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的主函数创建了一个定义的`queueSize`的`jobQueue`通道。然后，它遍历工作人员并为每个工作人员生成goroutine。最后，它遍历作业队列并运行必要的作业：
- en: '[PRE10]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We also have an HTTP handler function here to take requests from an external
    source (in our case, it''s going to be a simple cURL request, but you could have
    many different requests from external systems):'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还在这里有一个HTTP处理函数，用于接收来自外部来源的请求（在我们的情况下，它将是一个简单的cURL请求，但您可以从外部系统接收许多不同的请求）：
- en: '[PRE11]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'After this, we start the job queue and execute a request to test the command:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此之后，我们启动作业队列并执行请求以测试命令：
- en: '[PRE12]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The following screenshot shows a resulting set that shows the different workers
    completing the different jobs:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了一个结果集，显示了不同的工作人员完成了不同的工作：
- en: '![](img/a6a32e02-7046-4aed-be59-9e3a188beb89.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a6a32e02-7046-4aed-be59-9e3a188beb89.png)'
- en: Note that the individual workers picked up the jobs as they were able to. This
    is helpful as we continue to grow our system, which requires these jobs.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，个别的工作人员会根据自己的能力接手工作。这对我们继续发展需要这些工作的系统是有帮助的。
- en: Integrating job queues
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集成作业队列
- en: There are times where we may not want to use built-in Go queueing systems. Perhaps
    we already have a pipeline that contains other message-queueing systems or perhaps
    we know that we are going to have to maintain a very large data ingress. Two systems
    that are commonly used for this task are Apache Kafka and RabbitMQ. Let's take
    a quick look at how to integrate with both of these systems using Go.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 有时我们可能不想使用内置的Go队列系统。也许我们已经有一个包含其他消息队列系统的流水线，或者我们知道我们将不得不维护一个非常大的数据输入。用于这项任务的两个常用系统是Apache
    Kafka和RabbitMQ。让我们快速看一下如何使用Go与这两个系统集成。
- en: Kafka
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kafka
- en: Apache Kafka is referred to as a *distributed streaming system*, which is just
    another way of saying a distributed job queue. Kafka, which is written in Java,
    uses the idea of a publish/subscribe model for message queueing. It's often used
    for writing real-time streaming data pipelines.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Kafka被称为*分布式流系统*，这只是说分布式作业队列的另一种方式。Kafka是用Java编写的，使用发布/订阅模型进行消息队列。它通常用于编写实时流数据管道。
- en: 'We''ll assume you have a Kafka instance set up already. If you don''t, you
    can use the following bash script to get a quick Kafka instance:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设您已经设置了Kafka实例。如果没有，您可以使用以下bash脚本快速获取Kafka实例：
- en: '[PRE13]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We can execute this bash script as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以执行以下bash脚本：
- en: '[PRE14]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: After we do this, we can run the `kafka` read and write Go programs to read
    and write from Kafka. Let's investigate each of these.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在这之后，我们可以运行`kafka`读取和写入Go程序来读取和写入Kafka。让我们分别调查一下。
- en: 'We can use the `writeToKafka.go` program to write to Kafka. Let''s take a look:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`writeToKafka.go`程序来写入Kafka。让我们来看一下：
- en: 'First, we initialize our `main` package and import the required packages:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们初始化我们的`main`包并导入所需的包：
- en: '[PRE15]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'In our `main` function, we create a connection to Kafka, set a write deadline,
    and then we write messages to our Kafka topic/partition. In this case, it''s just
    a simple message count from 1 to 10:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们的`main`函数中，我们创建了一个连接到Kafka，设置了写入截止日期，然后写入了我们的Kafka主题/分区的消息。在这种情况下，它只是从1到10的简单消息计数：
- en: '[PRE16]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The `readFromKafka.go` program instantiates the `main` package and imports
    all the necessary packages, as follows:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`readFromKafka.go`程序实例化`main`包并导入所有必要的包，如下所示：'
- en: '[PRE17]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Our `main` function then sets a Kafka topic and partition, followed by creating
    a connection, setting a connection deadline, and setting a batch size.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的`main`函数然后设置了一个Kafka主题和分区，然后创建了一个连接，设置了连接截止日期，并设置了批处理大小。
- en: 'More information about Kafka topics and partitions can be found at: [http://kafka.apache.org/documentation/#intro_topics](http://kafka.apache.org/documentation/#intro_topics).'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 有关Kafka主题和分区的更多信息，请访问：[http://kafka.apache.org/documentation/#intro_topics](http://kafka.apache.org/documentation/#intro_topics)。
- en: 'We can see that our `topic` and `partition` have been set as variables and
    that our connection has been instantiated:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以看到我们的`topic`和`partition`已经被设置为变量，并且我们的连接已经被实例化：
- en: '[PRE18]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Then, we set a deadline on our connection and read our batches. Lastly, we
    close our connections:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们在连接上设置了截止日期并读取我们的批处理。最后，我们关闭我们的连接：
- en: '[PRE19]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'After we execute our `readFromKafka.go` and `writeFromKafka.go` files, we can
    see the resulting output:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们执行`readFromKafka.go`和`writeFromKafka.go`文件之后，我们可以看到生成的输出：
- en: '![](img/35f8e1a7-6cba-4c62-afa4-f1e751bd8cbc.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](img/35f8e1a7-6cba-4c62-afa4-f1e751bd8cbc.png)'
- en: Our Kafka instance now has the messages that we sent from our `writeToKafka.go`
    program, which can now be consumed by our `readFromKafka.go` program.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的Kafka实例现在有了我们从`writeToKafka.go`程序发送的消息，现在可以被我们的`readFromKafka.go`程序消费。
- en: 'To stop our Kafka and zookeeper services after we are finished with them, we
    can execute the following commands:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成Kafka和zookeeper服务后，我们可以执行以下命令来停止它们：
- en: '[PRE20]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Many enterprises use Kafka as a message brokering system, so being able to understand
    how to read and write from these systems in Go can be helpful for creating things
    at scale in an enterprise setting.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 许多企业使用Kafka作为消息代理系统，因此能够理解如何在Go中从这些系统中读取和写入对于在企业环境中创建规模化的东西是有帮助的。
- en: RabbitMQ
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RabbitMQ
- en: 'RabbitMQ is a popular open source message broker written in Erlang. It uses
    a protocol called the **Advanced Message Queueing Protocol** (**AMQP**) in order
    to pass messages through its queueing system. Without further ado, let''s set
    up a RabbitMQ instance and pass messages to and from it using Go:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: RabbitMQ是一个流行的开源消息代理，用Erlang编写。它使用一种称为**高级消息队列协议**（**AMQP**）的协议来通过其排队系统传递消息。话不多说，让我们设置一个RabbitMQ实例，并使用Go来传递消息到它和从它那里接收消息：
- en: 'First, we need to start up a RabbitMQ instance using Docker:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要使用Docker启动RabbitMQ实例：
- en: '[PRE21]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Then, we have a RabbitMQ instance, complete with the management portal, running
    on our host.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们在我们的主机上运行了一个带有管理门户的RabbitMQ实例。
- en: Now, we can use the Go AMQP library ([https://github.com/streadway/amqp](https://github.com/streadway/amqp))
    in order to pass messages to and from our RabbitMQ system with Go.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以使用Go AMQP库（[https://github.com/streadway/amqp](https://github.com/streadway/amqp)）来通过Go与我们的RabbitMQ系统传递消息。
- en: 'We will start by creating a listener. Let''s see this procedure step by step:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先创建一个监听器。让我们一步一步地看这个过程：
- en: 'First, we instantiate the `main` package and import the necessary dependencies,
    as well as set the explicit variables:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们实例化`main`包并导入必要的依赖项，以及设置显式变量：
- en: '[PRE22]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Then, we create a connection to the `amqp` server:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们创建到`amqp`服务器的连接：
- en: '[PRE23]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Next, we declare the queue that we are listening on and consume messages from
    the queue:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们声明我们正在监听的队列，并从队列中消费消息：
- en: '[PRE24]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Now, we can create the sending function. Again, we declare our package and
    import our dependencies, as well as set our variables:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以创建发送函数。同样，我们声明我们的包并导入我们的依赖项，以及设置我们的变量：
- en: '[PRE25]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We use the same connection methodology that we used in our listener. We might
    abstract this away in a production instance, but it was included here for ease
    of understanding:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用了与我们的监听器中使用的相同的连接方法。在生产实例中，我们可能会将其抽象化，但在这里包含它是为了方便理解：
- en: '[PRE26]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Then, we declare the queue we''d like to use and publish a message body to
    that queue:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们声明我们想要使用的队列并将消息主体发布到该队列：
- en: '[PRE27]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'After we''ve created both of these programs, we can test them out. We''ll iterate
    over our message-sending program with a while true loop:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建了这两个程序后，我们可以测试它们。我们将使用一个while true循环迭代我们的消息发送程序：
- en: '![](img/480ad6b8-ec58-42d6-8666-0a3c28fe1268.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](img/480ad6b8-ec58-42d6-8666-0a3c28fe1268.png)'
- en: 'After we do this, we should see the messages coming into our receiver:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成这些操作后，我们应该能看到消息进入我们的接收器：
- en: '![](img/ba78ccd7-da8f-4ae6-92ea-a8a17e3cdfc2.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ba78ccd7-da8f-4ae6-92ea-a8a17e3cdfc2.png)'
- en: 'We can also see the output from this activity by looking at the RabbitMQ management
    portal, located at `http://0.0.0.0:15672`, using the username and password of
    guest by default:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过查看位于`http://0.0.0.0:15672`的RabbitMQ管理门户的输出来查看此活动的输出，默认情况下使用guest作为用户名和密码：
- en: '![](img/6cf9a660-ad49-4116-9877-ff10d226515e.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6cf9a660-ad49-4116-9877-ff10d226515e.png)'
- en: This portal gives us all sorts of different information about the RabbitMQ job
    queue, from the number of messages queued, the publish/subscribe model state,
    and results about individual parts of the RabbitMQ system (connections, channels,
    exchanges, and queues). Understanding how this queueing system works will help
    you, should you ever need to communicate with a RabbitMQ queue.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 该门户为我们提供了有关RabbitMQ作业队列的各种不同信息，从排队的消息数量，发布/订阅模型状态，到有关RabbitMQ系统的各个部分（连接、通道、交换和队列）的结果。了解这个排队系统的工作原理将有助于您，如果您将来需要与RabbitMQ队列通信的话。
- en: Summary
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned about clustering with hierarchical and centroid
    algorithms, goroutines as queues, buffered channels as job queues, and implementing
    third-party queuing systems (Kafka and RabbitMQ).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了使用分层和质心算法进行集群化，使用goroutines作为队列，使用缓冲通道作为作业队列，以及实现第三方排队系统（Kafka和RabbitMQ）。
- en: Learning about all of these clustering and job-queueing techniques will help
    make you better at using algorithms and distributed systems and solving computer
    science problems. In the next chapter, we are going to learn about how to measure
    and compare code quality across versions using the Prometheus exporter, APMs,
    SLIs/SLOs, and logging.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 学习所有这些集群和作业队列技术将帮助您更好地使用算法和分布式系统，并解决计算机科学问题。在下一章中，我们将学习如何使用Prometheus导出器、APMs、SLIs/SLOs和日志来衡量和比较不同版本的代码质量。
