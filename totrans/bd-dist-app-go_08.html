<html><head></head><body>
		<div id="_idContainer229">
			<h1 id="_idParaDest-97"><a id="_idTextAnchor103"/>Chapter 6: Scaling a Gin Application</h1>
			<p>In this chapter, you will learn how to improve the performance and scalability of a distributed web application written with the Gin framework. This chapter will cover how to use caching mechanisms to alleviate performance bottlenecks. Along the way, you will learn how to scale a web app using a message broker solution such as RabbitMQ. Finally, you will learn how to <strong class="bold">containerize</strong> the application and scale it out with <strong class="bold">Docker Compose</strong>.</p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>Scaling workloads with a message broker</li>
				<li>Scaling horizontally with Docker replicas</li>
				<li>Using the Nginx reverse proxy</li>
				<li>Caching assets with HTTP cache headers</li>
			</ul>
			<p>By the end of this chapter, you will be able to build a highly available and distributed web application with the Gin framework, Docker, and RabbitMQ. </p>
			<h1 id="_idParaDest-98"><a id="_idTextAnchor104"/>Technical requirements</h1>
			<p>To follow the content in this chapter, you will need the following:</p>
			<ul>
				<li>A complete understanding of the previous chapter. This chapter is a follow-up to the previous one as it will use the same source code. Hence, some snippets won't be explained to avoid repetition.</li>
				<li>An understanding of Docker and its architecture. Ideally, some previous experience with a message queue service such as RabbitMQ, ActiveMQ, Kafka, and so on would be beneficial.</li>
			</ul>
			<p>The code bundle for this chapter is hosted on GitHub at <a href="https://github.com/PacktPublishing/Building-Distributed-Applications-in-Gin/tree/main/chapter06">https://github.com/PacktPublishing/Building-Distributed-Applications-in-Gin/tree/main/chapter06</a>.</p>
			<h1 id="_idParaDest-99"><a id="_idTextAnchor105"/>Scaling workloads with a message broker</h1>
			<p>When developing a web application, one important aspect of the user experience that is often <a id="_idIndexMarker438"/>overlooked is the response time. Nothing can turn away a user more quickly than an application that is slow and sluggish. In the <a id="_idIndexMarker439"/>previous chapters, you learned how to reduce database queries with Redis for faster data access. In this chapter, you will take things further and cover how to scale a web application written with the Gin framework.</p>
			<p>Before we get into why you need to scale the application workload, let's add another block to the architecture. The new service will parse a Reddit RSS feed and insert feed entries into the MongoDB <strong class="source-inline">recipes</strong> collection. The following diagram illustrates how the new service integrates with the architecture:</p>
			<div>
				<div id="_idContainer191" class="IMG---Figure">
					<img src="image/Figure_6.1_B17115.jpg" alt="Figure 6.1 – Parsing a Reddit RSS feed &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.1 – Parsing a Reddit RSS feed </p>
			<p>The service will take a subreddit RSS URL as a parameter. We can create an RSS feed by adding <strong class="source-inline">.rss</strong> to the end of an existing subreddit URL:</p>
			<p><a href="https://www.reddit.com/r/THREAD_NAME/.rss">https://www.reddit.com/r/THREAD_NAME/.rss</a></p>
			<p>For instance, let's <a id="_idIndexMarker440"/>have a look at the recipes <a id="_idIndexMarker441"/>subreddit shown in the following screenshot:</p>
			<div>
				<div id="_idContainer192" class="IMG---Figure">
					<img src="image/Figure_6.2_B17115.jpg" alt="Figure 6.2 – Recipes subreddit&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.2 – Recipes subreddit</p>
			<p>This subreddit will have the following URL for the RSS feed:</p>
			<p><a href="https://www.reddit.com/r/recipes/.rss">https://www.reddit.com/r/recipes/.rss</a></p>
			<p>If you visit the aforementioned URL, you should receive an XML response. The following is an example of the XML structure that's returned by the recipes subreddit's RSS URL: </p>
			<p class="source-code">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</p>
			<p class="source-code">&lt;feed</p>
			<p class="source-code">   xmlns="http://www.w3.org/2005/Atom"</p>
			<p class="source-code">   xmlns:media="http://search.yahoo.com/mrss/"&gt;</p>
			<p class="source-code">   &lt;title&gt;recipes&lt;/title&gt;</p>
			<p class="source-code">   &lt;entry&gt;</p>
			<p class="source-code">       &lt;author&gt;</p>
			<p class="source-code">           &lt;name&gt;/u/nolynskitchen&lt;/name&gt;</p>
			<p class="source-code">           &lt;uri&gt;https://www.reddit.com/user/nolynskitchen</p>
			<p class="source-code">           &lt;/uri&gt;</p>
			<p class="source-code">       &lt;/author&gt;</p>
			<p class="source-code">       &lt;category term="recipes" label="r/recipes"/&gt;</p>
			<p class="source-code">       &lt;id&gt;t3_m4uvlm&lt;/id&gt;</p>
			<p class="source-code">       &lt;media:thumbnail url="https://b.thumbs.</p>
			<p class="source-code">          redditmedia.com</p>
			<p class="source-code">          /vDz3xCmo10TFkokqy9y1chopeIXdOqtGA33joNBtTDA.jpg" </p>
			<p class="source-code">        /&gt;</p>
			<p class="source-code">       &lt;link href="https://www.reddit.com/r/recipes</p>
			<p class="source-code">                  /comments/m4uvlm/best_butter_cookies/" /&gt;</p>
			<p class="source-code">       &lt;updated&gt;2021-03-14T12:57:05+00:00&lt;/updated&gt;</p>
			<p class="source-code">       &lt;title&gt;Best Butter Cookies!&lt;/title&gt;</p>
			<p class="source-code">   &lt;/entry&gt;</p>
			<p class="source-code">&lt;/feed&gt;</p>
			<p>To get <a id="_idIndexMarker442"/>started, follow these steps:</p>
			<ol>
				<li>Create <a id="_idIndexMarker443"/>an <strong class="source-inline">rss-parser</strong> project, load it into the VSCode editor, and write a <strong class="source-inline">main.go</strong> file. Within the file, declare a <strong class="source-inline">Feed</strong> struct to mirror the XML structure:<p class="source-code">type Feed struct {</p><p class="source-code">   Entries []Entry `xml:"entry"`</p><p class="source-code">}</p><p class="source-code">type Entry struct {</p><p class="source-code">   Link struct {</p><p class="source-code">       Href string `xml:"href,attr"`</p><p class="source-code">   } `xml:"link"`</p><p class="source-code">   Thumbnail struct {</p><p class="source-code">       URL string `xml:"url,attr"`</p><p class="source-code">   } `xml:"thumbnail"`</p><p class="source-code">   Title string `xml:"title"`</p><p class="source-code">} </p></li>
				<li>Next, write <a id="_idIndexMarker444"/>a <strong class="source-inline">GetFeedEntries</strong> method, which <a id="_idIndexMarker445"/>takes the RSS URL as a parameter, and return a list of entries:<p class="source-code">func GetFeedEntries(url string) ([]Entry, error) {</p><p class="source-code">   client := &amp;http.Client{}</p><p class="source-code">   req, err := http.NewRequest("GET", url, nil)</p><p class="source-code">   if err != nil {</p><p class="source-code">       return nil, err</p><p class="source-code">   }</p><p class="source-code">   req.Header.Add("User-Agent", "Mozilla/5.0 (</p><p class="source-code">      Windows NT 10.0; Win64; x64) AppleWebKit/537.36 </p><p class="source-code">      (KHTML, like Gecko) Chrome/70.0.3538.110 </p><p class="source-code">      Safari/537.36")</p><p class="source-code">   resp, err := client.Do(req)</p><p class="source-code">   if err != nil {</p><p class="source-code">       return nil, err</p><p class="source-code">   }</p><p class="source-code">   defer resp.Body.Close()</p><p class="source-code">   byteValue, _ := ioutil.ReadAll(resp.Body)</p><p class="source-code">   var feed Feed</p><p class="source-code">   xml.Unmarshal(byteValue, &amp;feed)</p><p class="source-code">   return feed.Entries, nil</p><p class="source-code">}</p><p>This method <a id="_idIndexMarker446"/>uses the HTTP client to <a id="_idIndexMarker447"/>issue a GET request into the URL given in the <strong class="source-inline">GetFeedEntries</strong> method parameter. Then, it encodes the response body into a <strong class="source-inline">Feed</strong> struct. Finally, it returns the <strong class="source-inline">Entries</strong> attribute.</p><p>Note the usage of the <strong class="source-inline">User-Agent</strong> request header to simulate a request being sent from the browser and avoiding being blocked by the Reddit servers:</p><p class="source-code">req.Header.Add("User-Agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36") </p><p class="callout-heading">Note</p><p class="callout">A list of valid User-Agents can be found at the following URL (it's updated regularly): <a href="https://developers.whatismybrowser.com/useragents/explore/">https://developers.whatismybrowser.com/useragents/explore/</a>.</p></li>
				<li>Next, create a web server with the Gin router and expose a POST request on the <strong class="source-inline">/parse</strong> endpoint. Then, define a route handler called <strong class="source-inline">ParserHandler</strong>:<p class="source-code">func main() {</p><p class="source-code">   router := gin.Default()</p><p class="source-code">   router.POST("/parse", ParserHandler)</p><p class="source-code">   router.Run(":5000")</p><p class="source-code">}</p><p><strong class="source-inline">ParserHandler</strong> is self-explanatory: it marshals the request payload into a <strong class="source-inline">Request</strong> struct. Then, it calls the <strong class="source-inline">GetFeedEntries</strong> method with the <strong class="source-inline">URL</strong> attribute <a id="_idIndexMarker448"/>of the <strong class="source-inline">Request</strong> struct. Finally, based <a id="_idIndexMarker449"/>on the method's response, it returns a 500 error code or a 200 status code, along with a list of feed entries:</p><p class="source-code">func ParserHandler(c *gin.Context) {</p><p class="source-code">   var request Request</p><p class="source-code">   if err := c.ShouldBindJSON(&amp;request); err != nil {</p><p class="source-code">       c.JSON(http.StatusBadRequest, gin.H{</p><p class="source-code">          "error": err.Error()})</p><p class="source-code">       return</p><p class="source-code">   }</p><p class="source-code">   entries, err := GetFeedEntries(request.URL)</p><p class="source-code">   if err != nil {</p><p class="source-code">       c.JSON(http.StatusInternalServerError, </p><p class="source-code">          gin.H{"error": "Error while parsing </p><p class="source-code">                 the rss feed"})</p><p class="source-code">       return</p><p class="source-code">   }</p><p class="source-code">   c.JSON(http.StatusOK, entries)</p><p class="source-code">} </p><p>The <strong class="source-inline">Request</strong> struct has a <strong class="source-inline">URL</strong> attribute:</p><p class="source-code">type Request struct {</p><p class="source-code">  URL string `json:"url"`</p><p class="source-code">}</p></li>
				<li>To test <a id="_idIndexMarker450"/>it out, run the server on a different <a id="_idIndexMarker451"/>port (for example, <strong class="source-inline">5000</strong>) to avoid port conflicts with the recipes API (already running on port <strong class="source-inline">8080</strong>):<div id="_idContainer193" class="IMG---Figure"><img src="image/Figure_6.3_B17115.jpg" alt="Figure 6.3 – RSS parser logs&#13;&#10;"/></div><p class="figure-caption">Figure 6.3 – RSS parser logs</p></li>
				<li>On the Postman client, issue a POST request on the <strong class="source-inline">/parse</strong> endpoint with the URL of a subreddit in the request body. The server will parse the RSS feed and return a list of feed entries, as shown in the following screenshot:<div id="_idContainer194" class="IMG---Figure"><img src="image/Figure_6.4_B17115.jpg" alt="Figure 6.4 – RSS feed entries &#13;&#10;"/></div><p class="figure-caption">Figure 6.4 – RSS feed entries </p></li>
				<li>Now, insert <a id="_idIndexMarker452"/>the results into MongoDB <a id="_idIndexMarker453"/>by connecting to the MongoDB server deployed in previous chapters. Define the connection instructions on the <strong class="source-inline">init()</strong> method, as follows:<p class="source-code">var client *mongo.Client</p><p class="source-code">var ctx context.Context</p><p class="source-code">func init() {</p><p class="source-code">   ctx = context.Background()</p><p class="source-code">   client, _ = mongo.Connect(ctx, </p><p class="source-code">      options.Client().ApplyURI(os.Getenv("MONGO_URI")))</p><p class="source-code">}</p></li>
				<li>Then, update <a id="_idIndexMarker454"/>the HTTP handler to insert <a id="_idIndexMarker455"/>entries into the <strong class="source-inline">recipes</strong> collection with the <strong class="source-inline">InsertOne</strong> operation:<p class="source-code">func ParserHandler(c *gin.Context) {</p><p class="source-code">   ...</p><p class="source-code">   collection := client.Database(os.Getenv(</p><p class="source-code">      "MONGO_DATABASE")).Collection("recipes")</p><p class="source-code">   for _, entry := range entries[2:] {</p><p class="source-code">       collection.InsertOne(ctx, bson.M{</p><p class="source-code">           "title":     entry.Title,</p><p class="source-code">           "thumbnail": entry.Thumbnail.URL,</p><p class="source-code">           "url":       entry.Link.Href,</p><p class="source-code">       })</p><p class="source-code">   }</p><p class="source-code">   ...</p><p class="source-code">}</p></li>
				<li>Rerun the application, but this time, provide the <strong class="source-inline">MONGO_URI</strong> and <strong class="source-inline">MONGO_DATABASE</strong> environment variables, as follows:<p class="source-code">MONGO_URI="mongodb://admin:password@localhost:27017/test?authSource=admin&amp;readPreference=primary&amp;appname=MongoDB%20Compass&amp;ssl=false" MONGO_DATABASE=demo go run main.go </p></li>
				<li>Reissue a POST request with Postman or the <strong class="source-inline">curl</strong> command. Head back to MongoDB Compass and refresh the <strong class="source-inline">recipes</strong> collection. The RSS entries should have been successfully inserted, as follows:</li>
			</ol>
			<div>
				<div id="_idContainer195" class="IMG---Figure">
					<img src="image/Figure_6.5_B17115.jpg" alt="Figure 6.5 – Recipes collection&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.5 – Recipes collection</p>
			<p class="callout-heading">Note</p>
			<p class="callout">If you're using the same database and collection that was shown in the previous chapters, you might need to drop existing documents before inserting new recipes. </p>
			<p>The <strong class="source-inline">recipes</strong> collection <a id="_idIndexMarker456"/>has now been initialized <a id="_idIndexMarker457"/>with a list of recipes.</p>
			<p>You can repeat the same steps to parse other subreddit RSS feeds. However, what if you want to parse thousands or millions of subreddits? Handling such a large number of workloads will take a lot of resources (CPU/RAM) and will be time-consuming. That's why we will separate the service logic into multiple loosely coupled services, and then scale them based on the incoming workload. </p>
			<p>Those services will need to communicate with each other, and the most effective communication approach is to use message brokers. That's where RabbitMQ comes into the picture.</p>
			<h2 id="_idParaDest-100"><a id="_idTextAnchor106"/>Deploying RabbitMQ with Docker</h2>
			<p><strong class="bold">RabbitMQ</strong> (<a href="https://www.rabbitmq.com/#getstarted">https://www.rabbitmq.com/#getstarted</a>) is <a id="_idIndexMarker458"/>a reliable, highly <a id="_idIndexMarker459"/>available message broker. The <a id="_idIndexMarker460"/>following schema describes <a id="_idIndexMarker461"/>how RabbitMQ will be used within the application architecture:</p>
			<div>
				<div id="_idContainer196" class="IMG---Figure">
					<img src="image/Figure_6.6_B17115.jpg" alt="Figure 6.6 – Scaling with RabbitMQ &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.6 – Scaling with RabbitMQ </p>
			<p>To deploy <a id="_idIndexMarker462"/>RabbitMQ with Docker, use the official RabbitMQ Docker image (<a href="https://hub.docker.com/_/rabbitmq">https://hub.docker.com/_/rabbitmq</a>) and implement the following steps: </p>
			<ol>
				<li value="1">Issue the following command to run a container from the RabbitMQ image: <p class="source-code"><strong class="bold">docker run -d --name rabbitmq -e RABBITMQ_DEFAULT_USER=user -e RABBITMQ_DEFAULT_PASS=password -p 8080:15672 -p 5672:5672 rabbitmq:3-management</strong></p><p>The username and password are set through environment variables. The preceding command exposes the RabbitMQ dashboard on port <strong class="source-inline">8080</strong> and the server on port <strong class="source-inline">5672</strong>.</p></li>
				<li>Once <a id="_idIndexMarker463"/>the container has been deployed, run <a id="_idIndexMarker464"/>the following command <a id="_idIndexMarker465"/>to display the server logs:<p class="source-code"><strong class="bold">docker logs -f CONTAINER_ID </strong></p><p>Here's how the startup logs will be displayed:</p><div id="_idContainer197" class="IMG---Figure"><img src="image/Figure_6.7_B17115.jpg" alt="Figure 6.7 – RabbitMQ startup logs &#13;&#10;"/></div><p class="figure-caption">Figure 6.7 – RabbitMQ startup logs </p></li>
				<li>Once the server initialization has been completed, navigate to <strong class="source-inline">localhost:8080</strong> via your browser. A RabbitMQ login page will be displayed. Sign in with your user/password credentials. You will land on the dashboard:<div id="_idContainer198" class="IMG---Figure"><img src="image/B17115_06_08_v2.jpg" alt="Figure 6.8 – RabbitMQ dashboard &#13;&#10;"/></div><p class="figure-caption">Figure 6.8 – RabbitMQ dashboard </p></li>
				<li>Now, create <a id="_idIndexMarker466"/>a messaging queue where the <a id="_idIndexMarker467"/>RSS URLs will be pushed <a id="_idIndexMarker468"/>to by the services. Click on <strong class="bold">Queues</strong> from the navigation bar and create a new queue by clicking on <strong class="bold">Add a new queue</strong>:<div id="_idContainer199" class="IMG---Figure"><img src="image/B17115_06_09_v2.jpg" alt="Figure 6.9 – Creating a new RabbitMQ queue &#13;&#10;"/></div><p class="figure-caption">Figure 6.9 – Creating a new RabbitMQ queue </p></li>
				<li>Make <a id="_idIndexMarker469"/>sure that you set the <strong class="bold">Durability</strong> field <a id="_idIndexMarker470"/>to <strong class="bold">Durable</strong> for the <a id="_idIndexMarker471"/>data to be persisted on disk if RabbitMQ ever goes down.</li>
			</ol>
			<p>With RabbitMQ up and running, we can move on and implement a producer service to push incoming RSS URLs to RabbitMQ, as well as a consumer service to consume the URLs from the queue.</p>
			<h2 id="_idParaDest-101"><a id="_idTextAnchor107"/>Exploring the Producer/Consumer pattern</h2>
			<p>Before <a id="_idIndexMarker472"/>we dig <a id="_idIndexMarker473"/>deeper <a id="_idIndexMarker474"/>into the implementation, we need to explore the Producer/Consumer pattern. The following schema illustrates these two concepts:</p>
			<div>
				<div id="_idContainer200" class="IMG---Figure">
					<img src="image/B17115_06_10_v2.jpg" alt="Figure 6.10 – Producer/Consumer pattern&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.10 – Producer/Consumer pattern</p>
			<p>Now that the main concepts are clear, let's get started:</p>
			<ol>
				<li value="1">Create <a id="_idIndexMarker475"/>a new Go project called <strong class="source-inline">producer</strong> and install <a id="_idIndexMarker476"/>the RabbitMQ SDK for Golang with the following command:<p class="source-code">go get github.com/streadway/amqp</p></li>
				<li>Write <a id="_idIndexMarker477"/>a <strong class="source-inline">main.go</strong> file and set up a TCP connection to the RabbitMQ server with the following code snippet:<p class="source-code">var channelAmqp *amqp.Channel</p><p class="source-code">func init() {</p><p class="source-code">   amqpConnection, err := amqp.Dial(os.Getenv(</p><p class="source-code">      "RABBITMQ_URI"))</p><p class="source-code">   if err != nil {</p><p class="source-code">       log.Fatal(err)</p><p class="source-code">   }</p><p class="source-code">   channelAmqp, _ = amqpConnection.Channel()</p><p class="source-code">}</p><p>The AMQP connection string will be provided, along with the password, through the <strong class="source-inline">RABBITMQ_URI</strong> environment variable. </p></li>
				<li>Next, define an HTTP handler on the <strong class="source-inline">/parse</strong> endpoint. The handler will push the URL <a id="_idIndexMarker478"/>given in the request <a id="_idIndexMarker479"/>body into the RabbitMQ queue using <a id="_idIndexMarker480"/>the <strong class="source-inline">Publish</strong> method:<p class="source-code">func ParserHandler(c *gin.Context) {</p><p class="source-code">   var request Request</p><p class="source-code">   if err := c.ShouldBindJSON(&amp;request); err != nil {</p><p class="source-code">       c.JSON(http.StatusBadRequest, gin.H{</p><p class="source-code">          "error": err.Error()})</p><p class="source-code">       return</p><p class="source-code">   }</p><p class="source-code">   data, _ := json.Marshal(request)</p><p class="source-code">   err := channelAmqp.Publish(</p><p class="source-code">       "",</p><p class="source-code">       os.Getenv("RABBITMQ_QUEUE"),</p><p class="source-code">       false,</p><p class="source-code">       false,</p><p class="source-code">       amqp.Publishing{</p><p class="source-code">           ContentType: "application/json",</p><p class="source-code">           Body:        []byte(data),</p><p class="source-code">       })</p><p class="source-code">   if err != nil {</p><p class="source-code">       fmt.Println(err)</p><p class="source-code">       c.JSON(http.StatusInternalServerError, </p><p class="source-code">          gin.H{"error": "Error while publishing </p><p class="source-code">          to RabbitMQ"})</p><p class="source-code">       return</p><p class="source-code">   }</p><p class="source-code">   c.JSON(http.StatusOK, map[string]string{</p><p class="source-code">      "message": "success"})</p><p class="source-code">}</p><p class="source-code">func main() {</p><p class="source-code">  router := gin.Default()</p><p class="source-code">  router.POST("/parse", ParserHandler)</p><p class="source-code">  router.Run(":5000")</p><p class="source-code">}</p></li>
				<li>Finally, run <a id="_idIndexMarker481"/>the application <a id="_idIndexMarker482"/>with the <strong class="source-inline">RABBITMQ_URI</strong> and <strong class="source-inline">RABBITMQ_QUEUE</strong> variables, as <a id="_idIndexMarker483"/>follows:<p class="source-code">RABBITMQ_URI="amqp://user:password@localhost:5672/" RABBITMQ_QUEUE=rss_urls go run main.go</p></li>
				<li>Then, execute a POST request on the <strong class="source-inline">/parse</strong> endpoint. You should receive a 200 <strong class="bold">success</strong> message, as shown here:<div id="_idContainer201" class="IMG---Figure"><img src="image/Figure_6.11_B17115.jpg" alt="Figure 6.11 – Publishing data in RabbitMQ&#13;&#10;"/></div><p class="figure-caption">Figure 6.11 – Publishing data in RabbitMQ</p></li>
				<li>Head <a id="_idIndexMarker484"/>back to the RabbitMQ <a id="_idIndexMarker485"/>dashboard, go to the <strong class="bold">Queues</strong> section, and click <a id="_idIndexMarker486"/>on the <strong class="bold">rss_urls</strong> queue. You should be redirected to the <strong class="bold">Queue metrics</strong> page. Here, you will notice a message in the queue:</li>
			</ol>
			<div>
				<div id="_idContainer202" class="IMG---Figure">
					<img src="image/B17115_06_12_v2.jpg" alt="Figure 6.12 – Queue metrics page &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.12 – Queue metrics page </p>
			<p>With the producer service up and running, you need to build the worker/consumer to consume the messages/URLs available in the RabbitMQ queue:</p>
			<ol>
				<li value="1">Create a <a id="_idIndexMarker487"/>new Go project <a id="_idIndexMarker488"/>called <strong class="source-inline">consumer</strong> and create a new file <a id="_idIndexMarker489"/>called <strong class="source-inline">main.go</strong>. Write the following code inside the file:<p class="source-code">func main() {</p><p class="source-code">   amqpConnection, err := amqp.Dial(os.Getenv(</p><p class="source-code">       "RABBITMQ_URI"))</p><p class="source-code">   if err != nil {</p><p class="source-code">       log.Fatal(err)</p><p class="source-code">   }</p><p class="source-code">   defer amqpConnection.Close()</p><p class="source-code">   channelAmqp, _ := amqpConnection.Channel()</p><p class="source-code">   defer channelAmqp.Close()</p><p class="source-code">   forever := make(chan bool)</p><p class="source-code">   msgs, err := channelAmqp.Consume(</p><p class="source-code">       os.Getenv("RABBITMQ_QUEUE"),</p><p class="source-code">       "",</p><p class="source-code">       true,</p><p class="source-code">       false,</p><p class="source-code">       false,</p><p class="source-code">       false,</p><p class="source-code">       nil,</p><p class="source-code">   )</p><p class="source-code">   go func() {</p><p class="source-code">       for d := range msgs {</p><p class="source-code">           log.Printf("Received a message: %s", d.Body)</p><p class="source-code">       }</p><p class="source-code">   }()</p><p class="source-code">   log.Printf(" [*] Waiting for messages. </p><p class="source-code">              To exit press CTRL+C")</p><p class="source-code">   &lt;-forever</p><p class="source-code">}</p><p>The code <a id="_idIndexMarker490"/>is straightforward: it <a id="_idIndexMarker491"/>sets up a connection to the RabbitMQ <a id="_idIndexMarker492"/>server and subscribes to the <strong class="source-inline">rss_urls</strong> queue. Then, it creates an infinite loop and fetches a message from the queue, after which it displays the message body to the console and waits for new messages. </p></li>
				<li>Run the consumer project by passing the RabbitMQ URI and queue name as environment variables:<p class="source-code">RABBITMQ_URI="amqp://user:password@localhost:5672/" RABBITMQ_QUEUE=rss_urls go run main.go</p><p>Once launched, the consumer will fetch the message that was pushed previously by the producer and display its content on the console. Then, it will delete the message from the queue:</p><div id="_idContainer203" class="IMG---Figure"><img src="image/B17115_06_13_v2.jpg" alt="Figure 6.13 – Subscribing and fetching a message from RabbitMQ&#13;&#10;"/></div><p class="figure-caption">Figure 6.13 – Subscribing and fetching a message from RabbitMQ</p></li>
				<li>Verify that the message has been deleted by refreshing the <strong class="bold">Queue metrics</strong> page. The <strong class="bold">Queued messages</strong> chart should confirm this deletion:</li>
			</ol>
			<div>
				<div id="_idContainer204" class="IMG---Figure">
					<img src="image/Figure_6.14_B17115.jpg" alt="Figure 6.14 – Deleting a message from the queue&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.14 – Deleting a message from the queue</p>
			<p>With that, your worker/consumer has been built! </p>
			<p>So far, you've <a id="_idIndexMarker493"/>seen that the <a id="_idIndexMarker494"/>consumer displays the message's content. Now, let's take <a id="_idIndexMarker495"/>this further and encode the message body in a <strong class="source-inline">Request</strong> struct and get the feed entries by calling the <strong class="source-inline">GetFeedEntries</strong> method, which we mentioned earlier. The entries will then be saved in the <strong class="source-inline">recipes</strong> collection in MongoDB: </p>
			<p class="source-code">go func() {</p>
			<p class="source-code">       for d := range msgs {</p>
			<p class="source-code">           log.Printf("Received a message: %s", d.Body)</p>
			<p class="source-code">           var request Request</p>
			<p class="source-code">           json.Unmarshal(d.Body, &amp;request)</p>
			<p class="source-code">           log.Println("RSS URL:", request.URL)</p>
			<p class="source-code">           entries, _ := GetFeedEntries(request.URL)</p>
			<p class="source-code">           collection := mongoClient.Database(os.Getenv(</p>
			<p class="source-code">              "MONGO_DATABASE")).Collection("recipes")</p>
			<p class="source-code">           for _, entry := range entries[2:] {</p>
			<p class="source-code">               collection.InsertOne(ctx, bson.M{</p>
			<p class="source-code">                   "title":     entry.Title,</p>
			<p class="source-code">                   "thumbnail": entry.Thumbnail.URL,</p>
			<p class="source-code">                   "url":       entry.Link.Href,</p>
			<p class="source-code">               })</p>
			<p class="source-code">           }</p>
			<p class="source-code">       }</p>
			<p class="source-code">}()</p>
			<p>Rerun the <a id="_idIndexMarker496"/>application, but this <a id="_idIndexMarker497"/>time, provide the MongoDB connection parameters, in <a id="_idIndexMarker498"/>addition to the RabbitMQ parameters:</p>
			<p class="source-code">RABBITMQ_URI="amqp://user:password@localhost:5672/" RABBITMQ_QUEUE=rss_urls MONGO_URI="mongodb://admin:password@localhost:27017/test?authSource=admin&amp;readPreference=primary&amp;appname=MongoDB%20Compass&amp;ssl=false" MONGO_DATABASE=demo go run main.go </p>
			<p>To test this out, issue a POST request to the producer server with an RSS feed URL in the request body. The producer will publish the URL in the RabbitMQ queue. From there, the consumer will fetch the message and get the XML response of the RSS URL, encode the response in an array of entries, and save the results in MongoDB:</p>
			<div>
				<div id="_idContainer205" class="IMG---Figure">
					<img src="image/B17115_06_15.jpg" alt="Figure 6.15 – Consumer server logs&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.15 – Consumer server logs</p>
			<p>You can issue multiple subreddit URLs to the producer server. This time, the consumer will fetch the URLs one by one, as follows:</p>
			<div>
				<div id="_idContainer206" class="IMG---Figure">
					<img src="image/B17115_06_16.jpg" alt="Figure 6.16 – Parsing multiple RSS URLs&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.16 – Parsing multiple RSS URLs</p>
			<p>To view the entries that have been saved in MongoDB, build a simple dashboard to list all the <a id="_idIndexMarker499"/>recipes in the <strong class="source-inline">recipes</strong> collection. You can create a new project from scratch or expose an additional route on <a id="_idIndexMarker500"/>the web application we built in the previous chapter <a id="_idIndexMarker501"/>to serve an HTML representation of the recipes:</p>
			<p class="source-code">router.GET("/dashboard", IndexHandler)</p>
			<p>Then, make sure that you update the <strong class="source-inline">Recipe</strong> struct fields to mirror the MongoDB document field's structure:</p>
			<p class="source-code">type Recipe struct {</p>
			<p class="source-code">   Title     string `json:"title" bson:"title"`</p>
			<p class="source-code">   Thumbnail string `json:"thumbnail" bson:"thumbnail"`</p>
			<p class="source-code">   URL       string `json:"url" bson:"url"`</p>
			<p class="source-code">} </p>
			<p>The route handler will simply call the <strong class="source-inline">Find</strong> operation on the <strong class="source-inline">recipes</strong> collection to return all the recipes. Then, it will encode the results in a <strong class="source-inline">recipes</strong> slice. Finally, it will pass the <strong class="source-inline">recipes</strong> variable into an HTML template to display the results:</p>
			<p class="source-code">func IndexHandler(c *gin.Context) {</p>
			<p class="source-code">   cur, err := collection.Find(ctx, bson.M{})</p>
			<p class="source-code">   if err != nil {</p>
			<p class="source-code">       c.JSON(http.StatusInternalServerError, </p>
			<p class="source-code">           gin.H{"error": err.Error()})</p>
			<p class="source-code">       return</p>
			<p class="source-code">   }</p>
			<p class="source-code">   defer cur.Close(ctx)</p>
			<p class="source-code">   recipes := make([]Recipe, 0)</p>
			<p class="source-code">   for cur.Next(ctx) {</p>
			<p class="source-code">       var recipe Recipe</p>
			<p class="source-code">       cur.Decode(&amp;recipe)</p>
			<p class="source-code">       recipes = append(recipes, recipe)</p>
			<p class="source-code">   }</p>
			<p class="source-code">   c.HTML(http.StatusOK, "index.tmpl", gin.H{</p>
			<p class="source-code">       "recipes": recipes,</p>
			<p class="source-code">   })</p>
			<p class="source-code">} </p>
			<p>The following <a id="_idIndexMarker502"/>is the HTML <a id="_idIndexMarker503"/>template's content. It uses the Bootstrap framework <a id="_idIndexMarker504"/>to build an appealing user interface. It also uses the <strong class="source-inline">range</strong> keyword to loop through each recipe within the <strong class="source-inline">recipes</strong> slice and displays its details (title, thumbnail image, and Reddit URL):</p>
			<p class="source-code">&lt;section class="container"&gt;</p>
			<p class="source-code">       &lt;div class="row"&gt;</p>
			<p class="source-code">           &lt;ul class="list-group"&gt;</p>
			<p class="source-code">               {{range .recipes}}</p>
			<p class="source-code">               &lt;li class="list-group-item"&gt;</p>
			<p class="source-code">                   &lt;div style="width: 100%;"&gt;</p>
			<p class="source-code">                       &lt;img src="{{ .Thumbnail }}" </p>
			<p class="source-code">                          class="card-img-top thumbnail"&gt;</p>
			<p class="source-code">                       &lt;span class="title"&gt;{{ .Title </p>
			<p class="source-code">                       }}&lt;/span&gt;</p>
			<p class="source-code">                       &lt;a href="{{ .URL }}" target="_blank"</p>
			<p class="source-code">                          class="btn btn-warning </p>
			<p class="source-code">                          btn-sm see_recipe"&gt;See recipe&lt;/a&gt;</p>
			<p class="source-code">                   &lt;/div&gt;</p>
			<p class="source-code">               &lt;/li&gt;</p>
			<p class="source-code">               {{end}}</p>
			<p class="source-code">           &lt;/ul&gt;</p>
			<p class="source-code">       &lt;/div&gt;</p>
			<p class="source-code">&lt;/section&gt; </p>
			<p>Configure <a id="_idIndexMarker505"/>the Gin server to run <a id="_idIndexMarker506"/>on port <strong class="source-inline">3000</strong> and execute the server with the <strong class="source-inline">go run main.go</strong> command <a id="_idIndexMarker507"/>with the <strong class="source-inline">MONGO_URI</strong> and <strong class="source-inline">MONGO_DATABASE</strong> variables. On your browser, head to Localhost:3000/dashboard Apart from, where a list of recipes should be returned, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer207" class="IMG---Figure">
					<img src="image/B17115_06_17.jpg" alt="Figure 6.17 – Trending Reddit recipes &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.17 – Trending Reddit recipes </p>
			<p class="callout-heading">Note</p>
			<p class="callout">The application layout and stylesheet can be found in this book's GitHub repository: <a href="https://github.com/PacktPublishing/Building-Distributed-Applications-in-Gin/blob/main/chapter06/dashboard/templates/index.tmpl">https://github.com/PacktPublishing/Building-Distributed-Applications-in-Gin/blob/main/chapter06/dashboard/templates/index.tmpl</a>.</p>
			<p>Awesome! You <a id="_idIndexMarker508"/>are now familiar <a id="_idIndexMarker509"/>with how to use a message broker such as RabbitMQ to <a id="_idIndexMarker510"/>scale your Gin distributed applications. In the next section, we will demonstrate another technique for scaling a Gin distributed application through Docker.</p>
			<h1 id="_idParaDest-102"><a id="_idTextAnchor108"/>Scaling horizontally with Docker replicas</h1>
			<p>So far, you have learned how to build a Producer/Consumer architecture with the Gin framework <a id="_idIndexMarker511"/>and RabbitMQ. In this section, we'll cover <a id="_idIndexMarker512"/>how to scale the consumer component so that we can split the incoming workload across multiple consumers.</p>
			<p>You can achieve this by building a Docker image of the consumer project and building multiple containers based on that image. The Docker image is immutable, which guarantees the same environment each time a container is based on the image that is run.</p>
			<p>The following schema illustrates how multiple consumers/workers are used:</p>
			<div>
				<div id="_idContainer208" class="IMG---Figure">
					<img src="image/B17115_06_18.jpg" alt="Figure 6.18 – Scaling multiple workers with Docker &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.18 – Scaling multiple workers with Docker </p>
			<p>To create a Docker image, we need to define a <strong class="source-inline">Dockerfile</strong> – a blueprint that contains all the instructions to run the consumer project. Create a <strong class="source-inline">Dockerfile</strong> in your worker/consumer directory with the following content:</p>
			<p class="source-code">FROM golang:1.16</p>
			<p class="source-code">WORKDIR /go/src/github.com/worker</p>
			<p class="source-code">COPY main.go go.mod go.sum ./</p>
			<p class="source-code">RUN go mod download</p>
			<p class="source-code">RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .</p>
			<p class="source-code">FROM alpine:latest </p>
			<p class="source-code">RUN apk --no-cache add ca-certificates</p>
			<p class="source-code">WORKDIR /root/</p>
			<p class="source-code">COPY --from=0 /go/src/github.com/worker/app .</p>
			<p class="source-code">CMD ["./app"]</p>
			<p>This <strong class="source-inline">Dockerfile</strong> uses <a id="_idIndexMarker513"/>the multi-stage build feature to build a lightweight Docker image. We will see how this works in the next section. </p>
			<h2 id="_idParaDest-103"><a id="_idTextAnchor109"/>Using Docker multi-stage builds</h2>
			<p><strong class="bold">Multi-stage builds</strong> were introduced in Docker Engine 1.17.05. It allows you to use multiple <strong class="source-inline">FROM</strong> statements <a id="_idIndexMarker514"/>in your <strong class="source-inline">Dockerfile</strong> and copy artifacts from one stage to another, leaving behind everything you don't need in the final image. </p>
			<p>In the <a id="_idIndexMarker515"/>previous example, you used <strong class="source-inline">golang:1.16</strong> as a base image to build a single binary. Then, the second <strong class="source-inline">FROM</strong> instruction started a new build stage with the Alpine image as its base. From here, you can copy the binary from the previous stage using the <strong class="source-inline">COPY –from=0</strong> instruction. As a result, you will end up with a small Docker image.</p>
			<p>To build the image, run the following command. The dot at the end is important as it points to the current directory:</p>
			<p class="source-code">docker build -t worker . </p>
			<p>The building process should take a few seconds to be completed. Then, you will find the following Docker build logs:</p>
			<div>
				<div id="_idContainer209" class="IMG---Figure">
					<img src="image/B17115_06_19.jpg" alt="Figure 6.19 – Docker build logs&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.19 – Docker build logs</p>
			<p>If you review the preceding output, you will see that Docker logged every instruction of building <a id="_idIndexMarker516"/>the worker image according to the steps in our <strong class="source-inline">Dockerfile</strong>. Once the image has been built, run the following command to list the available images in your machine:</p>
			<p class="source-code">docker image ls</p>
			<p>The worker/consumer image should be listed at the top of the list:</p>
			<div>
				<div id="_idContainer210" class="IMG---Figure">
					<img src="image/B17115_06_20.jpg" alt="Figure 6.20 – Worker Docker image&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.20 – Worker Docker image</p>
			<p>Run a container based on the image with the <strong class="source-inline">docker run</strong> command. You need to provide the MongoDB and RabbitMQ URIs as environment variables with the <strong class="source-inline">–e</strong> flag. The <strong class="source-inline">–link</strong> flag can be used to interact with MongoDB and RabbitMQ within the container:</p>
			<p class="source-code">docker run -d -e MONGO_URI="mongodb://admin:password@mongodb:27017/test?authSource=admin&amp;readPreference=primary&amp;appname=MongoDB%20Compass&amp;ssl=false" -e MONGO_DATABASE=demo2 -e RABBITMQ_URI="amqp://user:password@rabbitmq:5672/" -e RABBITMQ_QUEUE=rss_urls --link rabbitmq --link mongodb --name worker worker </p>
			<p>The <a id="_idIndexMarker517"/>container logs are as follows:</p>
			<div>
				<div id="_idContainer211" class="IMG---Figure">
					<img src="image/B17115_06_21.jpg" alt="Figure 6.21 – Worker's container logs&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.21 – Worker's container logs</p>
			<p>With that, you have dockerized the worker's service. Next, we will scale it with Docker Compose.</p>
			<h2 id="_idParaDest-104"><a id="_idTextAnchor110"/>Scaling services with Docker Compose</h2>
			<p><strong class="bold">Docker Compose</strong> is a <a id="_idIndexMarker518"/>container orchestration tool built on <a id="_idIndexMarker519"/>top of Docker Engine. It helps you manage an application stack or multiple containers with a single command line.</p>
			<p>Using Docker Compose is as simple as creating a Docker image: </p>
			<ol>
				<li value="1">Define a <strong class="source-inline">docker-compose.yml</strong> file in the root of your project and type in the following YAML code: <p class="source-code">version: "3.9"</p><p class="source-code">services:</p><p class="source-code"> worker:</p><p class="source-code">   image: worker</p><p class="source-code">   environment:</p><p class="source-code">     - MONGO_URI="mongodb://admin:password</p><p class="source-code">           @mongodb:27017/test?authSource=admin</p><p class="source-code">           &amp;readPreference=primary&amp;ssl=false"</p><p class="source-code">     - MONGO_DATABASE=demo2</p><p class="source-code">     - RABBITMQ_URI=amqp://user:password@rabbitmq:5672</p><p class="source-code">     - RABBITMQ_QUEUE=rss_urls</p><p class="source-code">   networks:</p><p class="source-code">     - app_network</p><p class="source-code">   external_links:</p><p class="source-code">     - mongodb</p><p class="source-code">     - rabbitmq</p><p class="source-code">networks:</p><p class="source-code"> app_network:</p><p class="source-code">   external: true</p><p>The configuration specifies the environment variables and network topology that the worker requires.</p></li>
				<li>Define <a id="_idIndexMarker520"/>an external network where the workers, MongoDB, and RabbitMQ services will be living. Execute the following command:<p class="source-code">docker network create app_network</p></li>
				<li>Redeploy the RabbitMQ and MongoDB containers but this time, deploy them within the <strong class="source-inline">app_network</strong> custom network by passing the <strong class="source-inline">–network</strong> flag: <p class="source-code">docker run -d --name rabbitmq -e RABBITMQ_DEFAULT_USER=user -e RABBITMQ_DEFAULT_PASS=password -p 8080:15672 -p 5672:5672 --network app_network rabbitmq:3-management</p></li>
				<li>With the containers being configured properly, issue the following command to deploy the worker:<p class="source-code">docker-compose up -d</p><p>The <strong class="source-inline">-d</strong> flag instructs Docker Compose to run the containers in the background (detached mode).</p></li>
				<li>Issue the following command to list the running services:<div id="_idContainer212" class="IMG---Figure"><img src="image/B17115_06_22.jpg" alt="Figure 6.22 – Docker Compose service&#13;&#10;"/></div><p class="figure-caption">Figure 6.22 – Docker Compose service</p></li>
				<li>To scale the worker, rerun the previous command with the <strong class="source-inline">–scale</strong> flag:<p class="source-code">docker-compose up -d --scale worker=5</p><p>The final <a id="_idIndexMarker521"/>output will look as follows:</p><div id="_idContainer213" class="IMG---Figure"><img src="image/B17115_06_23.jpg" alt="Figure 6.23 – Scaling five workers &#13;&#10;"/></div><p class="figure-caption">Figure 6.23 – Scaling five workers </p></li>
				<li>To test everything out, create a file called <strong class="source-inline">threads</strong> that contains a list of Reddit's best cooking and recipes subreddits. The following list has been cropped for brevity:<p class="source-code">https://www.reddit.com/r/recipes/.rss</p><p class="source-code">https://www.reddit.com/r/food/.rss</p><p class="source-code">https://www.reddit.com/r/Cooking/.rss</p><p class="source-code">https://www.reddit.com/r/IndianFood/.rss</p><p class="source-code">https://www.reddit.com/r/Baking/.rss</p><p class="source-code">https://www.reddit.com/r/vegan/.rss</p><p class="source-code">https://www.reddit.com/r/fastfood/.rss</p><p class="source-code">https://www.reddit.com/r/vegetarian/.rss</p><p class="source-code">https://www.reddit.com/r/cookingforbeginners/.rss</p><p class="source-code">https://www.reddit.com/r/MealPrepSunday/.rss</p><p class="source-code">https://www.reddit.com/r/EatCheapAndHealthy/.rss</p><p class="source-code">https://www.reddit.com/r/Cheap_Meals/.rss</p><p class="source-code">https://www.reddit.com/r/slowcooking/.rss</p><p class="source-code">https://www.reddit.com/r/AskCulinary/.rss</p><p class="source-code">https://www.reddit.com/r/fromscratch/.rss</p></li>
				<li>Then, write a <strong class="source-inline">bulk.sh</strong> shell script to read the <strong class="source-inline">threads</strong> file line by line and issue a POST request to the producer service:<p class="source-code">#!/bin/bash</p><p class="source-code">while IFS= read -r thread</p><p class="source-code">do</p><p class="source-code">   printf "\n$thread\n"</p><p class="source-code">   curl -X POST http://localhost:5000/parse -d </p><p class="source-code">     '{"url":"$thread"}' http://localhost:5000/parse</p><p class="source-code">done &lt; "threads" </p></li>
				<li>To run <a id="_idIndexMarker522"/>the script, add the execution permission and execute the file with the following command:<p class="source-code">chmod +x bulk.sh</p><p class="source-code">./bulk.sh </p><p class="callout-heading">Note</p><p class="callout">Make sure the producer service is running, otherwise the issued HTTP requests with <strong class="source-inline">curl</strong> command will timeout.</p><p>The script will read the <strong class="source-inline">threads</strong> file line by line and issue a POST request, as follows:</p><div id="_idContainer214" class="IMG---Figure"><img src="image/B17115_06_24.jpg" alt="Figure 6.24 – Shell script's output&#13;&#10;"/></div><p class="figure-caption">Figure 6.24 – Shell script's output</p></li>
				<li>Run the <strong class="source-inline">docker-compose logs -f</strong> command. This time, you should notice multiple <a id="_idIndexMarker523"/>workers are being used. Also, Docker Compose assigned colors to instances and each message is being fetched by a different worker:</li>
			</ol>
			<div>
				<div id="_idContainer215" class="IMG---Figure">
					<img src="image/B17115_06_25.jpg" alt="Figure 6.25 – Splitting the workload across multiple workers &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.25 – Splitting the workload across multiple workers </p>
			<p>With that, you <a id="_idIndexMarker524"/>have successfully split the workload across multiple workers. This approach is called <strong class="bold">horizontal scaling</strong>.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">In <a href="B17115_08_Final_JM_ePub.xhtml#_idTextAnchor131"><em class="italic">Chapter 8</em></a>, <em class="italic">Deploying the Application on AWS</em>, we will cover how to deploy the web application <a id="_idIndexMarker525"/>on AWS and how to use a <strong class="bold">Simple Queue Service</strong> (<strong class="bold">SQS</strong>) instead of RabbitMQ to scale the workers.</p>
			<h1 id="_idParaDest-105"><a id="_idTextAnchor111"/>Using the NGINX reverse proxy</h1>
			<p>In the previous section, you learned how to scale the workers responsible for parsing the subreddit URLs. In this section, you will explore how to scale the Recipes API we built in the <a id="_idIndexMarker526"/>previous chapters by serving it behind a reverse proxy. </p>
			<p>One of the <a id="_idIndexMarker527"/>most used reverse proxies is <strong class="bold">Nginx</strong>. It faces the client and receives the incoming HTTP(S) requests. It then redirects them to one of the API instances in a round-robin fashion. To deploy multiple instances of the Recipes API, you will be <a id="_idIndexMarker528"/>using Docker Compose to orchestrate <a id="_idIndexMarker529"/>the containers. The following schema illustrates the difference between a <strong class="bold">single instance architecture</strong> and a <strong class="bold">load balanced multi-instance architecture</strong> with Nginx:</p>
			<div>
				<div id="_idContainer216" class="IMG---Figure">
					<img src="image/Figure_6.26_B17115.jpg" alt="Figure 6.26 – Load balanced multi-instance architecture with Nginx &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.26 – Load balanced multi-instance architecture with Nginx </p>
			<p>Another solution <a id="_idIndexMarker530"/>for scaling the Recipes API is <strong class="bold">vertical scaling</strong>, which consists of increasing the CPU/RAM of the system where the service is running. However, this approach tends to have some limitations in the long run (not cost-effective). That's why, here, you will adopt the horizontal scaling approach and distribute the load across multiple API instances.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">An alternative to Nginx is Traefik (<a href="https://doc.traefik.io/traefik/">https://doc.traefik.io/traefik/</a>). It's an open source project built with scalability in mind.</p>
			<p>The following <a id="_idIndexMarker531"/>is a quick reminder of the Recipes API's output:</p>
			<div>
				<div id="_idContainer217" class="IMG---Figure">
					<img src="image/Figure_6.27_B17115.jpg" alt="Figure 6.27 – GET /recipes endpoint response&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.27 – GET /recipes endpoint response</p>
			<p>To deploy multiple instances of the Recipes API, follow these steps:</p>
			<ol>
				<li value="1">Build a Docker image and write a Dockerfile in the folder with your Recipes API implementation that contains the following content: <p class="source-code">FROM golang:1.16</p><p class="source-code">WORKDIR /go/src/github.com/api</p><p class="source-code">COPY . .</p><p class="source-code">RUN go mod download</p><p class="source-code">RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .</p><p class="source-code">FROM alpine:latest </p><p class="source-code">RUN apk --no-cache add ca-certificates</p><p class="source-code">WORKDIR /root/</p><p class="source-code">COPY --from=0 /go/src/github.com/api/app .</p><p class="source-code">CMD ["./app"]</p></li>
				<li>This <strong class="source-inline">Dockerfile</strong> uses <a id="_idIndexMarker532"/>the multi-stage feature to ship a lightweight image. The <strong class="source-inline">docker build -t recipes-api.</strong> Command's output is as follows:<div id="_idContainer218" class="IMG---Figure"><img src="image/Figure_6.28_B17115.jpg" alt="Figure 6.28 – Docker build logs&#13;&#10;"/></div><p class="figure-caption">Figure 6.28 – Docker build logs</p><p>With the image built, create a <strong class="source-inline">docker-compose.yml</strong> file and define three services:</p><p><strong class="bold">API</strong>: The Recipes <a id="_idIndexMarker533"/>API container</p><p><strong class="bold">Redis</strong>: The in-memory <a id="_idIndexMarker534"/>caching database</p><p><strong class="bold">MongoDB</strong>: The NoSQL <a id="_idIndexMarker535"/>database where the recipes are stored</p></li>
				<li>Then, add <a id="_idIndexMarker536"/>the following lines to the file:<p class="source-code">version: "3.9"</p><p class="source-code">services:</p><p class="source-code"> api:</p><p class="source-code">   image: recipes-api</p><p class="source-code">   environment:</p><p class="source-code">     - MONGO_URI=mongodb://admin:password</p><p class="source-code">          @mongodb:27017/test?authSource=admin</p><p class="source-code">          &amp;readPreference=primary&amp;ssl=false</p><p class="source-code">     - MONGO_DATABASE=demo</p><p class="source-code">     - REDIS_URI=redis:6379</p><p class="source-code">   networks:</p><p class="source-code">     - api_network</p><p class="source-code">   external_links:</p><p class="source-code">     - mongodb</p><p class="source-code">     - redis</p><p class="source-code"> redis:</p><p class="source-code">   image: redis</p><p class="source-code">   networks:</p><p class="source-code">     - api_network</p><p class="source-code"> mongodb:</p><p class="source-code">   image: mongo:4.4.3</p><p class="source-code">   networks:</p><p class="source-code">     - api_network</p><p class="source-code">   environment:</p><p class="source-code">     - MONGO_INITDB_ROOT_USERNAME=admin</p><p class="source-code">     - MONGO_INITDB_ROOT_PASSWORD=password</p><p class="source-code">networks:</p><p class="source-code">   api_network:</p></li>
				<li>Next, define a <a id="_idIndexMarker537"/>Nginx service with the following code block: <p class="source-code">nginx:</p><p class="source-code">   image: nginx</p><p class="source-code">   ports:</p><p class="source-code">     - 80:80</p><p class="source-code">   volumes:</p><p class="source-code">     - $PWD/nginx.conf:/etc/nginx/nginx.conf</p><p class="source-code">   depends_on:</p><p class="source-code">     - api</p><p class="source-code">   networks:</p><p class="source-code">     - api_network </p><p>This code maps a local <strong class="source-inline">nginx.conf</strong> file into <strong class="source-inline">/etc/nginx/nginx.conf</strong> inside the container. The file provides instructions to Nginx about how to handle the incoming HTTP requests. The following is a simplified version:</p><p class="source-code">events {</p><p class="source-code">   worker_connections 1024;</p><p class="source-code">}</p><p class="source-code">http {</p><p class="source-code"> server_tokens off;</p><p class="source-code"> server {</p><p class="source-code">   listen 80;</p><p class="source-code">   root  /var/www;</p><p class="source-code">   location /api/ {</p><p class="source-code">     proxy_set_header X-Forwarded-For $remote_addr;</p><p class="source-code">     proxy_set_header Host            $http_host;</p><p class="source-code">     proxy_pass http://api:8080/;</p><p class="source-code">   }</p><p class="source-code"> }</p><p class="source-code">} </p></li>
				<li>In <strong class="source-inline">location /api</strong>, set up a <a id="_idIndexMarker538"/>reverse proxy to forward the requests to the API running in port <strong class="source-inline">8080</strong> (internally). </li>
				<li>Deploy the entire stack with the <strong class="source-inline">docker-compose up –d</strong> command. Then, issue the following command to display the running services:<p class="source-code"><strong class="bold">docker-compose ps</strong></p><p>The command's output is as follows:</p><div id="_idContainer219" class="IMG---Figure"><img src="image/Figure_6.29_B17115.jpg" alt="Figure 6.29 – Application stack &#13;&#10;"/></div><p class="figure-caption">Figure 6.29 – Application stack </p></li>
				<li>The Nginx service is exposed on port <strong class="source-inline">80</strong>. Head to <strong class="source-inline">localhost/api/recipes</strong>; the server will <a id="_idIndexMarker539"/>call the Recipes API and forward the recipes list response, as follows:<div id="_idContainer220" class="IMG---Figure"><img src="image/Figure_6.30_B17115.jpg" alt="Figure 6.30 – Forwarding a HTTP response with Nginx&#13;&#10;"/></div><p class="figure-caption">Figure 6.30 – Forwarding a HTTP response with Nginx</p><p class="callout-heading">Note</p><p class="callout">For production usage, it's important that you secure your API endpoints with HTTPS. Luckily, you can use the "Let's Encrypt" add-on for Nginx to generate the TLS certificates automatically.</p></li>
				<li>To ensure the response is being forwarded from the Recipes API, check out the Nginx service logs with the following command:<p class="source-code">docker-compose logs –f nginx </p></li>
				<li> You <a id="_idIndexMarker540"/>should see something like this:<p class="source-code">/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration</p><p class="source-code">/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/</p><p class="source-code">/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh</p><p class="source-code">10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf</p><p class="source-code">10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf</p><p class="source-code">/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh</p><p class="source-code">/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh</p><p class="source-code">/docker-entrypoint.sh: Configuration complete; ready for start up</p><p class="source-code">172.21.0.1 - - [21/Mar/2021:18:11:02 +0000] "GET /api/recipes HTTP/1.1" 200 2 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.192 Safari/537.36"</p></li>
				<li>So far, one instance of the Recipes API container is running. To scale it out, use the <strong class="source-inline">–scale</strong> flag with the <strong class="source-inline">docker-compose up</strong> command or define the number of replicas in the <strong class="source-inline">docker-compose.yml</strong> file, as follows:<p class="source-code">api:</p><p class="source-code">   image: recipes-api</p><p class="source-code">   environment:</p><p class="source-code">     - MONGO_URI=mongodb://admin:password</p><p class="source-code">          @mongodb:27017/test?authSource=admin</p><p class="source-code">          &amp;readPreference=primary&amp;ssl=false</p><p class="source-code">     - MONGO_DATABASE=demo</p><p class="source-code">     - REDIS_URI=redis:6379</p><p class="source-code">   networks:</p><p class="source-code">     - api_network</p><p class="source-code">   external_links:</p><p class="source-code">     - mongodb</p><p class="source-code">     - redis</p><p class="source-code">   scale: 5</p></li>
				<li>Re-execute the <strong class="source-inline">docker-compose up</strong> command. Four additional services will be created based <a id="_idIndexMarker541"/>on the Recipes API Docker image. Following are the service logs:<div id="_idContainer221" class="IMG---Figure"><img src="image/Figure_6.31_B17115.jpg" alt="Figure 6.31 – Scaling the Recipes API&#13;&#10;"/></div><p class="figure-caption">Figure 6.31 – Scaling the Recipes API</p><p>Now, when the client sends a request, it will hit Nginx and then be forwarded to one of the API services in a round-robin fashion. This helps us evenly distribute the load.</p><p class="callout-heading">Note</p><p class="callout">In <a href="B17115_10_Final_JM_ePub.xhtml#_idTextAnchor160"><em class="italic">Chapter 10</em></a><em class="italic">, Capturing Gin Application Metrics</em>, we will learn how to set up a monitoring platform to trigger a scale-out event to increase the number of services when the demand increases.</p><p>The advantage of using a reverse proxy is that you can set up a single point of entry for your entire distributed web application. Both the backend and the web application <a id="_idIndexMarker542"/>will be located at the same URL. That way, you won't need to handle CORS on your API server. </p></li>
				<li>Similar to the Recipes API, create a Docker image for the <strong class="source-inline">react-ui</strong> service. The following is the content of our <strong class="source-inline">Dockerfile</strong>:<p class="source-code">FROM node:14.15.1</p><p class="source-code">COPY package-lock.json .</p><p class="source-code">COPY package.json .</p><p class="source-code">RUN npm install</p><p class="source-code">CMD npm start</p><p>As you can see, this is dead simple. Here, you are using a pre-built Node.js base image because the <strong class="source-inline">react-ui</strong> service is written in JavaScript.</p></li>
				<li>Build the Docker image with <strong class="source-inline">`docker build -t dashboard'</strong>. Then, update <strong class="source-inline">docker-compose.yml</strong> so that it runs a Docker service from the image with the following code block:<p class="source-code">dashboard:</p><p class="source-code">   image: dashboard</p><p class="source-code">   networks:</p><p class="source-code">     - api_network</p></li>
				<li>Next, update <strong class="source-inline">nginx.conf</strong> so that it forwards incoming requests at the root level of the <a id="_idIndexMarker543"/>URL to the dashboard service:<p class="source-code">events {</p><p class="source-code">   worker_connections 1024;</p><p class="source-code">}</p><p class="source-code">http {</p><p class="source-code"> server_tokens off;</p><p class="source-code"> server {</p><p class="source-code">   listen 80;</p><p class="source-code">   root  /var/www;</p><p class="source-code">   location / {</p><p class="source-code">     proxy_set_header X-Forwarded-For $remote_addr;</p><p class="source-code">     proxy_set_header Host            $http_host;</p><p class="source-code">     proxy_pass http://dashboard:3000/;</p><p class="source-code">   }</p><p class="source-code">   location /api/ {</p><p class="source-code">     proxy_set_header X-Forwarded-For $remote_addr;</p><p class="source-code">     proxy_set_header Host            $http_host;</p><p class="source-code">     proxy_pass http://api:8080/;</p><p class="source-code">   }</p><p class="source-code"> }</p><p class="source-code">}</p></li>
				<li>Rerun the <strong class="source-inline">docker-compose up</strong> <strong class="source-inline">-d</strong> command for the changes to take effect:<div id="_idContainer222" class="IMG---Figure"><img src="image/Figure_6.32_B17115.jpg" alt="Figure 6.32 – Serving the web dashboard from Nginx &#13;&#10;"/></div><p class="figure-caption">Figure 6.32 – Serving the web dashboard from Nginx </p></li>
				<li>Head to <strong class="source-inline">localhost/dashboard</strong>; you will be redirected to the web dashboard we wrote <a id="_idIndexMarker544"/>in the previous chapter:</li>
			</ol>
			<div>
				<div id="_idContainer223" class="IMG---Figure">
					<img src="image/Figure_6.33_B17115.jpg" alt="Figure 6.33 – Serving two backends from the same URL &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.33 – Serving two backends from the same URL </p>
			<p>Now, both the RESTful API and dashboard are being served from the same domain name.</p>
			<p>To take down your containers, you can use the following command:</p>
			<p class="source-code">docker-compose down</p>
			<p class="callout-heading">Note</p>
			<p class="callout">If you're using session-based authentication, you'll need to configure cookie stickiness on Nginx to keep a user's session on the server where it was started.</p>
			<p>You can also <a id="_idIndexMarker545"/>serve the subreddits application (built at the beginning of this chapter) from the Nginx server by replacing the dashboard location with another location section, to the <strong class="source-inline">nginx.conf</strong> file:</p>
			<p class="source-code">location /reddit/ {</p>
			<p class="source-code">     proxy_set_header X-Forwarded-For $remote_addr;</p>
			<p class="source-code">     proxy_set_header Host            $http_host;</p>
			<p class="source-code">     proxy_pass http://reddit-trending:3000/;</p>
			<p class="source-code">}</p>
			<p>Similar to <strong class="source-inline">react-ui</strong>, create a Docker image for the subreddits application. The following is the content of our <strong class="source-inline">Dockerfile</strong>:</p>
			<p class="source-code">FROM node:14.15.1</p>
			<p class="source-code">COPY . .</p>
			<p class="source-code">COPY package-lock.json .</p>
			<p class="source-code">COPY package.json .</p>
			<p class="source-code">RUN npm install</p>
			<p class="source-code">CMD npm start</p>
			<p>Here, you are using a pre-built Node.js base image because the dashboard service is written in JavaScript. Build the Docker image with <strong class="source-inline">"docker build -t dashboard"</strong>. </p>
			<p>Also, don't forget to add the application to the <strong class="source-inline">docker-compose.yml</strong> file:</p>
			<p class="source-code">  reddit-trending:</p>
			<p class="source-code">    image: web</p>
			<p class="source-code">    networks:</p>
			<p class="source-code">      - api_network </p>
			<p>Once you <a id="_idIndexMarker546"/>have redeployed the stack with <strong class="source-inline">docker-compose</strong>, head to <a href="http://localhost/reddit">localhost/reddit</a>; you will be redirected to the following UI:</p>
			<div>
				<div id="_idContainer224" class="IMG---Figure">
					<img src="image/Figure_6.34_B17115.jpg" alt="Figure 6.34 – Trending recipes application&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.34 – Trending recipes application</p>
			<p>The application layout is broken because the <strong class="source-inline">app.css</strong> file is being served from the wrong backend. You can confirm this by opening the debug console on Chrome:</p>
			<div>
				<div id="_idContainer225" class="IMG---Figure">
					<img src="image/Figure_6.35_B17115.jpg" alt="Figure 6.35 – Stylesheet location &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.35 – Stylesheet location </p>
			<p>You can <a id="_idIndexMarker547"/>force Nginx to serve the <strong class="source-inline">app.css</strong> file from the subreddit application container by adding the following code block to <strong class="source-inline">nginx.conf</strong>:</p>
			<p class="source-code">location /assets/css/app.css {</p>
			<p class="source-code">     proxy_set_header X-Forwarded-For $remote_addr;</p>
			<p class="source-code">     proxy_set_header Host            $http_host;</p>
			<p class="source-code">     proxy_pass http://reddit-trending:3000/assets</p>
			<p class="source-code">       /css/app.css;</p>
			<p class="source-code">}</p>
			<p>Now, refresh the web page; the application layout will be fixed:</p>
			<div>
				<div id="_idContainer226" class="IMG---Figure">
					<img src="image/Figure_6.36_B17115.jpg" alt="Figure 6.36 – Application layout &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.36 – Application layout </p>
			<p>As you can see, the dashboard displays the recipes thumbnails. These images are then served from <a id="_idIndexMarker548"/>the backend each time you refresh the page. To reduce the stress on the backend, you can configure Nginx to cache the static files. Insert the following code snippet before the <strong class="source-inline">server</strong> section in the Nginx config file:</p>
			<p class="source-code">map $sent_http_content_type $expires {</p>
			<p class="source-code">   default                    off;</p>
			<p class="source-code">   text/html                  epoch;</p>
			<p class="source-code">   text/css                   max;</p>
			<p class="source-code">   application/javascript     max;</p>
			<p class="source-code">   ~image/                    max;</p>
			<p class="source-code">}</p>
			<p>The <strong class="source-inline">~image</strong> keyword will handle all kinds of images (PNG, JPEG, GIF, SVG, and so on). Now, configure expiration with the <strong class="source-inline">expires</strong> instruction in the <strong class="source-inline">server</strong> section:</p>
			<p class="source-code">http {</p>
			<p class="source-code"> server {</p>
			<p class="source-code">   listen 80;</p>
			<p class="source-code">   expires $expires;</p>
			<p class="source-code">   ...</p>
			<p class="source-code"> }</p>
			<p class="source-code">}</p>
			<p>Then, redeploy <a id="_idIndexMarker549"/>the stack with the following command:</p>
			<p class="source-code">docker-compose up –d</p>
			<p>The images should now be cached, which reduces the number of requests hitting the backend. In the next section, we will cover how to get the same results in the backend with Gin. </p>
			<h1 id="_idParaDest-106"><a id="_idTextAnchor112"/>Caching assets with HTTP cache headers</h1>
			<p>You can <a id="_idIndexMarker550"/>also manage caching with the Gin <a id="_idIndexMarker551"/>framework. To illustrate this, write a simple web application to serve an image. The code is as follows:</p>
			<p class="source-code">func IllustrationHandler(c *gin.Context) {</p>
			<p class="source-code">   c.File("illustration.png")</p>
			<p class="source-code">}</p>
			<p class="source-code">func main() {</p>
			<p class="source-code">   router := gin.Default()</p>
			<p class="source-code">   router.GET("/illustration", IllustrationHandler)</p>
			<p class="source-code">   router.Run(":3000")</p>
			<p class="source-code">}</p>
			<p>The application should serve an image when the user hits the <strong class="source-inline">/illustration</strong> resource URL:</p>
			<div>
				<div id="_idContainer227" class="IMG---Figure">
					<img src="image/Figure_6.37_B17115.jpg" alt="Figure 6.37 – Serving an image with Gin&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.37 – Serving an image with Gin</p>
			<p>Because the <a id="_idIndexMarker552"/>same image is always delivered, we <a id="_idIndexMarker553"/>need to make sure that we're caching the image. That way, we can avoid having unnecessary traffic and have better web performance. Let's see how that is done. </p>
			<h2 id="_idParaDest-107"><a id="_idTextAnchor113"/>Setting HTTP caching headers</h2>
			<p>To cache this HTTP <a id="_idIndexMarker554"/>request, you can attach an <strong class="bold">entity tag</strong> (<strong class="bold">ETag</strong>) to the <a id="_idIndexMarker555"/>HTTP response header. When a user sends an HTTP request, the server will read the HTTP header and check if the <strong class="source-inline">If-None-Match</strong> field has an <strong class="source-inline">Etag</strong> key value. If there is a match between the <strong class="source-inline">If-None-Match</strong> field and the key that's generated, then a 304 status code will be returned:</p>
			<p class="source-code">func IllustrationHandler(c *gin.Context) {</p>
			<p class="source-code">   c.Header("Etag", "illustration")</p>
			<p class="source-code">   c.Header("Cache-Control", "max-age=2592000")</p>
			<p class="source-code">   if match := c.GetHeader("If-None-Match"); match != "" {</p>
			<p class="source-code">       if strings.Contains(match, "illustration") {</p>
			<p class="source-code">           c.Writer.WriteHeader(http.StatusNotModified)</p>
			<p class="source-code">           return</p>
			<p class="source-code">       }</p>
			<p class="source-code">   }</p>
			<p class="source-code">   c.File("illustration.png")</p>
			<p class="source-code">}</p>
			<p>Once you've updated the HTTP handler with the preceding code, test it out. The first time you <a id="_idIndexMarker556"/>ask for the <strong class="source-inline">/illustration</strong> resource, you should get a status of <strong class="source-inline">200 OK</strong>. However, for the second request, you should get a <strong class="source-inline">304 StatusNotModified</strong> response:</p>
			<div>
				<div id="_idContainer228" class="IMG---Figure">
					<img src="image/Figure_6.38_B17115.jpg" alt="Figure 6.38 – Response caching with Gin&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.38 – Response caching with Gin</p>
			<p>You may also notice that the latency of the second request is shorter than the first one. By keeping the number of queries to a minimum, you can mitigate the API's impact on your application's performance. </p>
			<h1 id="_idParaDest-108"><a id="_idTextAnchor114"/>Summary</h1>
			<p>In this chapter, you learned how to build a distributed web application using the Gin framework based on the Microservices architecture.</p>
			<p>You also have explored how to set up RabbitMQ as a message broker between the microservices and how to scale out those services with Docker. Along the way, you learned how to maintain the service image's size with Docker's multi-stage build feature, as well as how to improve the API's performance with Nginx and HTTP caching headers.</p>
			<p>In the next chapter, you will learn how to write unit and integration tests for a Gin web application.</p>
			<h1 id="_idParaDest-109"><a id="_idTextAnchor115"/>Further reading</h1>
			<ul>
				<li><em class="italic">RabbitMQ Essentials – Second Edition,</em> by Lovisa Johansson, Packt Publishing</li>
				<li><em class="italic">Docker for Developers,</em> by Richard Bullington-McGuire, Andrew K. Dennis, Michael Schwartz, Packt Publishing.</li>
			</ul>
		</div>
	</body></html>