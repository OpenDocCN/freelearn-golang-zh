- en: 'Chapter 6: Scaling a Gin Application'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will learn how to improve the performance and scalability
    of a distributed web application written with the Gin framework. This chapter
    will cover how to use caching mechanisms to alleviate performance bottlenecks.
    Along the way, you will learn how to scale a web app using a message broker solution
    such as RabbitMQ. Finally, you will learn how to **containerize** the application
    and scale it out with **Docker Compose**.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Scaling workloads with a message broker
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scaling horizontally with Docker replicas
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the Nginx reverse proxy
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Caching assets with HTTP cache headers
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will be able to build a highly available and
    distributed web application with the Gin framework, Docker, and RabbitMQ.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To follow the content in this chapter, you will need the following:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: A complete understanding of the previous chapter. This chapter is a follow-up
    to the previous one as it will use the same source code. Hence, some snippets
    won't be explained to avoid repetition.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An understanding of Docker and its architecture. Ideally, some previous experience
    with a message queue service such as RabbitMQ, ActiveMQ, Kafka, and so on would
    be beneficial.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code bundle for this chapter is hosted on GitHub at [https://github.com/PacktPublishing/Building-Distributed-Applications-in-Gin/tree/main/chapter06](https://github.com/PacktPublishing/Building-Distributed-Applications-in-Gin/tree/main/chapter06).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Scaling workloads with a message broker
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When developing a web application, one important aspect of the user experience
    that is often overlooked is the response time. Nothing can turn away a user more
    quickly than an application that is slow and sluggish. In the previous chapters,
    you learned how to reduce database queries with Redis for faster data access.
    In this chapter, you will take things further and cover how to scale a web application
    written with the Gin framework.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we get into why you need to scale the application workload, let''s add
    another block to the architecture. The new service will parse a Reddit RSS feed
    and insert feed entries into the MongoDB `recipes` collection. The following diagram
    illustrates how the new service integrates with the architecture:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1 – Parsing a Reddit RSS feed'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.1_B17115.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.1 – Parsing a Reddit RSS feed
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: 'The service will take a subreddit RSS URL as a parameter. We can create an
    RSS feed by adding `.rss` to the end of an existing subreddit URL:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.reddit.com/r/THREAD_NAME/.rss](https://www.reddit.com/r/THREAD_NAME/.rss)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, let''s have a look at the recipes subreddit shown in the following
    screenshot:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.2 – Recipes subreddit'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.2_B17115.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.2 – Recipes subreddit
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: 'This subreddit will have the following URL for the RSS feed:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.reddit.com/r/recipes/.rss](https://www.reddit.com/r/recipes/.rss)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.reddit.com/r/recipes/.rss](https://www.reddit.com/r/recipes/.rss)'
- en: 'If you visit the aforementioned URL, you should receive an XML response. The
    following is an example of the XML structure that''s returned by the recipes subreddit''s
    RSS URL:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您访问上述 URL，您应该收到一个 XML 响应。以下是由食谱 subreddits 的 RSS URL 返回的 XML 结构示例：
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To get started, follow these steps:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，请按照以下步骤操作：
- en: 'Create an `rss-parser` project, load it into the VSCode editor, and write a
    `main.go` file. Within the file, declare a `Feed` struct to mirror the XML structure:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 `rss-parser` 项目，将其加载到 VSCode 编辑器中，并编写一个 `main.go` 文件。在文件中，声明一个 `Feed` 结构体以反映
    XML 结构：
- en: '[PRE1]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Next, write a `GetFeedEntries` method, which takes the RSS URL as a parameter,
    and return a list of entries:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，编写一个 `GetFeedEntries` 方法，该方法接受 RSS URL 作为参数，并返回一个条目列表：
- en: '[PRE2]'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This method uses the HTTP client to issue a GET request into the URL given in
    the `GetFeedEntries` method parameter. Then, it encodes the response body into
    a `Feed` struct. Finally, it returns the `Entries` attribute.
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此方法使用 HTTP 客户端向 `GetFeedEntries` 方法参数中给出的 URL 发起 GET 请求。然后，将响应体编码到 `Feed` 结构体中。最后，它返回
    `Entries` 属性。
- en: 'Note the usage of the `User-Agent` request header to simulate a request being
    sent from the browser and avoiding being blocked by the Reddit servers:'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意使用 `User-Agent` 请求头模拟从浏览器发送的请求，以避免被 Reddit 服务器阻止：
- en: '[PRE3]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: 'A list of valid User-Agents can be found at the following URL (it''s updated
    regularly): [https://developers.whatismybrowser.com/useragents/explore/](https://developers.whatismybrowser.com/useragents/explore/).'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以在以下 URL 找到有效 User-Agent 列表（它定期更新）：[https://developers.whatismybrowser.com/useragents/explore/](https://developers.whatismybrowser.com/useragents/explore/)。
- en: 'Next, create a web server with the Gin router and expose a POST request on
    the `/parse` endpoint. Then, define a route handler called `ParserHandler`:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，使用 Gin 路由器创建一个 Web 服务器，并在 `/parse` 端点公开 POST 请求。然后，定义一个名为 `ParserHandler`
    的路由处理程序：
- en: '[PRE4]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '`ParserHandler` is self-explanatory: it marshals the request payload into a
    `Request` struct. Then, it calls the `GetFeedEntries` method with the `URL` attribute
    of the `Request` struct. Finally, based on the method''s response, it returns
    a 500 error code or a 200 status code, along with a list of feed entries:'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`ParserHandler` 的名称是自解释的：它将请求有效载荷序列化为 `Request` 结构体。然后，它使用 `Request` 结构体的 `URL`
    属性调用 `GetFeedEntries` 方法。最后，根据方法响应，它返回一个 500 错误代码或 200 状态代码，以及一个条目列表：'
- en: '[PRE5]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The `Request` struct has a `URL` attribute:'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`Request` 结构体有一个 `URL` 属性：'
- en: '[PRE6]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: To test it out, run the server on a different port (for example, `5000`) to
    avoid port conflicts with the recipes API (already running on port `8080`):![Figure
    6.3 – RSS parser logs
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了测试它，在不同的端口（例如，`5000`）上运行服务器，以避免与已运行在端口 `8080` 上的食谱 API 发生端口冲突：![图 6.3 – RSS
    解析日志
- en: '](img/Figure_6.3_B17115.jpg)'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_6.3_B17115.jpg)'
- en: Figure 6.3 – RSS parser logs
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.3 – RSS 解析日志
- en: On the Postman client, issue a POST request on the `/parse` endpoint with the
    URL of a subreddit in the request body. The server will parse the RSS feed and
    return a list of feed entries, as shown in the following screenshot:![Figure 6.4
    – RSS feed entries
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Postman 客户端，对 `/parse` 端点发起一个 POST 请求，请求体中包含 subreddits 的 URL。服务器将解析 RSS 源并返回一个条目列表，如下截图所示：![图
    6.4 – RSS 源条目
- en: '](img/Figure_6.4_B17115.jpg)'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_6.4_B17115.jpg)'
- en: Figure 6.4 – RSS feed entries
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.4 – RSS 源条目
- en: 'Now, insert the results into MongoDB by connecting to the MongoDB server deployed
    in previous chapters. Define the connection instructions on the `init()` method,
    as follows:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，通过连接到之前章节中部署的 MongoDB 服务器将结果插入 MongoDB。在 `init()` 方法中定义连接指令，如下所示：
- en: '[PRE7]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Then, update the HTTP handler to insert entries into the `recipes` collection
    with the `InsertOne` operation:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，更新 HTTP 处理器以使用 `InsertOne` 操作将条目插入到 `recipes` 集合中：
- en: '[PRE8]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Rerun the application, but this time, provide the `MONGO_URI` and `MONGO_DATABASE`
    environment variables, as follows:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新运行应用程序，但这次，提供 `MONGO_URI` 和 `MONGO_DATABASE` 环境变量，如下所示：
- en: '[PRE9]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Reissue a POST request with Postman or the `curl` command. Head back to MongoDB
    Compass and refresh the `recipes` collection. The RSS entries should have been
    successfully inserted, as follows:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Postman 或 `curl` 命令重新发起 POST 请求。回到 MongoDB Compass 并刷新 `recipes` 集合。RSS 条目应该已成功插入，如下所示：
- en: '![Figure 6.5 – Recipes collection'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.5 – 食谱集合'
- en: '](img/Figure_6.5_B17115.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_6.5_B17115.jpg)'
- en: Figure 6.5 – Recipes collection
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.5 – 食谱集合
- en: Note
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: If you're using the same database and collection that was shown in the previous
    chapters, you might need to drop existing documents before inserting new recipes.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在使用与之前章节中显示的相同数据库和集合，在插入新食谱之前，您可能需要删除现有文档。
- en: The `recipes` collection has now been initialized with a list of recipes.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '`recipes`集合现在已初始化为一系列食谱。'
- en: You can repeat the same steps to parse other subreddit RSS feeds. However, what
    if you want to parse thousands or millions of subreddits? Handling such a large
    number of workloads will take a lot of resources (CPU/RAM) and will be time-consuming.
    That's why we will separate the service logic into multiple loosely coupled services,
    and then scale them based on the incoming workload.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以重复相同的步骤来解析其他subreddit RSS源。然而，如果您想解析成千上万的subreddits，处理如此大量的工作负载将需要大量的资源（CPU/RAM），并且会耗费大量时间。这就是为什么我们将服务逻辑分割成多个松散耦合的服务，然后根据传入的工作负载进行扩展。
- en: Those services will need to communicate with each other, and the most effective
    communication approach is to use message brokers. That's where RabbitMQ comes
    into the picture.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这些服务需要相互通信，最有效的通信方式是使用消息代理。这就是RabbitMQ发挥作用的地方。
- en: Deploying RabbitMQ with Docker
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署RabbitMQ与Docker
- en: '**RabbitMQ** ([https://www.rabbitmq.com/#getstarted](https://www.rabbitmq.com/#getstarted))
    is a reliable, highly available message broker. The following schema describes
    how RabbitMQ will be used within the application architecture:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**RabbitMQ** ([https://www.rabbitmq.com/#getstarted](https://www.rabbitmq.com/#getstarted))是一个可靠且高度可用的消息代理。以下架构描述了RabbitMQ将在应用程序架构中的应用方式：'
- en: '![Figure 6.6 – Scaling with RabbitMQ'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.6 – 使用RabbitMQ进行扩展'
- en: '](img/Figure_6.6_B17115.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_6.6_B17115.jpg)'
- en: Figure 6.6 – Scaling with RabbitMQ
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.6 – 使用RabbitMQ进行扩展
- en: 'To deploy RabbitMQ with Docker, use the official RabbitMQ Docker image ([https://hub.docker.com/_/rabbitmq](https://hub.docker.com/_/rabbitmq))
    and implement the following steps:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用Docker部署RabbitMQ，使用官方的RabbitMQ Docker镜像([https://hub.docker.com/_/rabbitmq](https://hub.docker.com/_/rabbitmq))并执行以下步骤：
- en: 'Issue the following command to run a container from the RabbitMQ image:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下命令从RabbitMQ镜像运行容器：
- en: '[PRE10]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Once the container has been deployed, run the following command to display
    the server logs:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 容器部署完成后，运行以下命令以显示服务器日志：
- en: '[PRE11]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Here''s how the startup logs will be displayed:'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这就是启动日志的显示方式：
- en: '![Figure 6.7 – RabbitMQ startup logs'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图6.7 – RabbitMQ启动日志'
- en: '](img/Figure_6.7_B17115.jpg)'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_6.7_B17115.jpg)'
- en: Figure 6.7 – RabbitMQ startup logs
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.7 – RabbitMQ启动日志
- en: Once the server initialization has been completed, navigate to `localhost:8080`
    via your browser. A RabbitMQ login page will be displayed. Sign in with your user/password
    credentials. You will land on the dashboard:![Figure 6.8 – RabbitMQ dashboard
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦服务器初始化完成，通过浏览器导航到`localhost:8080`。将显示一个RabbitMQ登录页面。使用您的用户/密码凭据登录。您将进入仪表板：![图6.8
    – RabbitMQ仪表板
- en: '](img/B17115_06_08_v2.jpg)'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17115_06_08_v2.jpg)'
- en: Figure 6.8 – RabbitMQ dashboard
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.8 – RabbitMQ仪表板
- en: Now, create a messaging queue where the RSS URLs will be pushed to by the services.
    Click on **Queues** from the navigation bar and create a new queue by clicking
    on **Add a new queue**:![Figure 6.9 – Creating a new RabbitMQ queue
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，创建一个消息队列，服务将把RSS URL推送到该队列。点击导航栏中的**队列**，然后点击**添加新队列**来创建一个新的队列：![图6.9 –
    创建新的RabbitMQ队列
- en: '](img/B17115_06_09_v2.jpg)'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17115_06_09_v2.jpg)'
- en: Figure 6.9 – Creating a new RabbitMQ queue
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.9 – 创建新的RabbitMQ队列
- en: Make sure that you set the **Durability** field to **Durable** for the data
    to be persisted on disk if RabbitMQ ever goes down.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保将**持久性**字段设置为**持久**，以便在RabbitMQ断电时数据能够持久化到磁盘。
- en: With RabbitMQ up and running, we can move on and implement a producer service
    to push incoming RSS URLs to RabbitMQ, as well as a consumer service to consume
    the URLs from the queue.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在RabbitMQ运行起来后，我们可以继续实现一个生产者服务，将传入的RSS URL推送到RabbitMQ，以及一个消费者服务从队列中消费URL。
- en: Exploring the Producer/Consumer pattern
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索生产者/消费者模式
- en: 'Before we dig deeper into the implementation, we need to explore the Producer/Consumer
    pattern. The following schema illustrates these two concepts:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入实现之前，我们需要探索生产者/消费者模式。以下架构说明了这两个概念：
- en: '![Figure 6.10 – Producer/Consumer pattern'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.10 – 生产者/消费者模式'
- en: '](img/B17115_06_10_v2.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17115_06_10_v2.jpg)'
- en: Figure 6.10 – Producer/Consumer pattern
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.10 – 生产者/消费者模式
- en: 'Now that the main concepts are clear, let''s get started:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在主要概念已经清晰，让我们开始吧：
- en: 'Create a new Go project called `producer` and install the RabbitMQ SDK for
    Golang with the following command:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `producer` 的新 Go 项目，并使用以下命令安装 RabbitMQ SDK for Golang：
- en: '[PRE12]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Write a `main.go` file and set up a TCP connection to the RabbitMQ server with
    the following code snippet:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个 `main.go` 文件，并使用以下代码片段设置与 RabbitMQ 服务器的 TCP 连接：
- en: '[PRE13]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The AMQP connection string will be provided, along with the password, through
    the `RABBITMQ_URI` environment variable.
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: AMQP 连接字符串将通过 `RABBITMQ_URI` 环境变量提供，以及密码。
- en: 'Next, define an HTTP handler on the `/parse` endpoint. The handler will push
    the URL given in the request body into the RabbitMQ queue using the `Publish`
    method:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在 `/parse` 端点定义一个 HTTP 处理器。该处理器将请求体中给出的 URL 使用 `Publish` 方法推送到 RabbitMQ
    队列：
- en: '[PRE14]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Finally, run the application with the `RABBITMQ_URI` and `RABBITMQ_QUEUE` variables,
    as follows:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，使用 `RABBITMQ_URI` 和 `RABBITMQ_QUEUE` 变量运行应用程序，如下所示：
- en: '[PRE15]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Then, execute a POST request on the `/parse` endpoint. You should receive a
    200 **success** message, as shown here:![Figure 6.11 – Publishing data in RabbitMQ
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，在 `/parse` 端点执行 POST 请求。你应该会收到一个 200 **成功** 消息，如图所示：![Figure 6.11 – 在 RabbitMQ
    中发布数据
- en: '](img/Figure_6.11_B17115.jpg)'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/Figure_6.11_B17115.jpg]'
- en: Figure 6.11 – Publishing data in RabbitMQ
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.11 – 在 RabbitMQ 中发布数据
- en: 'Head back to the RabbitMQ dashboard, go to the **Queues** section, and click
    on the **rss_urls** queue. You should be redirected to the **Queue metrics** page.
    Here, you will notice a message in the queue:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回 RabbitMQ 仪表板，转到 **Queues** 部分，并点击 **rss_urls** 队列。你应该会被重定向到 **Queue metrics**
    页面。在这里，你会注意到队列中的一个消息：
- en: '![Figure 6.12 – Queue metrics page'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 6.12 – 队列指标页面'
- en: '](img/B17115_06_12_v2.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17115_06_12_v2.jpg]'
- en: Figure 6.12 – Queue metrics page
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.12 – 队列指标页面
- en: 'With the producer service up and running, you need to build the worker/consumer
    to consume the messages/URLs available in the RabbitMQ queue:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产者服务运行起来后，你需要构建工作/消费者以消费 RabbitMQ 队列中可用的消息/URL：
- en: 'Create a new Go project called `consumer` and create a new file called `main.go`.
    Write the following code inside the file:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `consumer` 的新 Go 项目，并创建一个名为 `main.go` 的新文件。在文件内编写以下代码：
- en: '[PRE16]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The code is straightforward: it sets up a connection to the RabbitMQ server
    and subscribes to the `rss_urls` queue. Then, it creates an infinite loop and
    fetches a message from the queue, after which it displays the message body to
    the console and waits for new messages.'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 代码很简单：它设置了一个到 RabbitMQ 服务器的连接，并订阅了 `rss_urls` 队列。然后，它创建了一个无限循环，并从队列中获取一个消息，之后在控制台上显示消息体，并等待新消息。
- en: 'Run the consumer project by passing the RabbitMQ URI and queue name as environment
    variables:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过传递 RabbitMQ URI 和队列名称作为环境变量来运行消费者项目：
- en: '[PRE17]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Once launched, the consumer will fetch the message that was pushed previously
    by the producer and display its content on the console. Then, it will delete the
    message from the queue:'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦启动，消费者将获取之前由生产者推送的消息，并在控制台上显示其内容。然后，它将从队列中删除该消息：
- en: '![Figure 6.13 – Subscribing and fetching a message from RabbitMQ'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![Figure 6.13 – 从 RabbitMQ 订阅和获取消息'
- en: '](img/B17115_06_13_v2.jpg)'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B17115_06_13_v2.jpg]'
- en: Figure 6.13 – Subscribing and fetching a message from RabbitMQ
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.13 – 从 RabbitMQ 订阅和获取消息
- en: 'Verify that the message has been deleted by refreshing the **Queue metrics**
    page. The **Queued messages** chart should confirm this deletion:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过刷新 **Queue metrics** 页面来验证消息已被删除。**Queued messages** 图表应确认此删除：
- en: '![Figure 6.14 – Deleting a message from the queue'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 6.14 – 从队列中删除消息'
- en: '](img/Figure_6.14_B17115.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/Figure_6.14_B17115.jpg]'
- en: Figure 6.14 – Deleting a message from the queue
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.14 – 从队列中删除消息
- en: With that, your worker/consumer has been built!
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，你的工作/消费者已经构建完成！
- en: 'So far, you''ve seen that the consumer displays the message''s content. Now,
    let''s take this further and encode the message body in a `Request` struct and
    get the feed entries by calling the `GetFeedEntries` method, which we mentioned
    earlier. The entries will then be saved in the `recipes` collection in MongoDB:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经看到消费者显示了消息的内容。现在，让我们更进一步，将消息体编码到 `Request` 结构体中，并通过调用我们之前提到的 `GetFeedEntries`
    方法获取内容条目。然后，这些条目将被保存在 MongoDB 的 `recipes` 集合中：
- en: '[PRE18]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Rerun the application, but this time, provide the MongoDB connection parameters,
    in addition to the RabbitMQ parameters:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 重新运行应用程序，但这次，除了 RabbitMQ 参数外，还需要提供 MongoDB 连接参数：
- en: '[PRE19]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'To test this out, issue a POST request to the producer server with an RSS feed
    URL in the request body. The producer will publish the URL in the RabbitMQ queue.
    From there, the consumer will fetch the message and get the XML response of the
    RSS URL, encode the response in an array of entries, and save the results in MongoDB:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试这一点，向生产服务器发送一个包含 RSS feed URL 的请求体中的 POST 请求。生产者将在 RabbitMQ 队列中发布该 URL。从那里，消费者将获取消息并获取
    RSS URL 的 XML 响应，将响应编码为条目数组，并将结果保存到 MongoDB 中：
- en: '![Figure 6.15 – Consumer server logs'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.15 – 消费者服务器日志'
- en: '](img/B17115_06_15.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17115_06_15.jpg](img/B17115_06_15.jpg)'
- en: Figure 6.15 – Consumer server logs
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.15 – 消费者服务器日志
- en: 'You can issue multiple subreddit URLs to the producer server. This time, the
    consumer will fetch the URLs one by one, as follows:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以向生产服务器发送多个 subreddit URL。这次，消费者将逐个获取 URL，如下所示：
- en: '![Figure 6.16 – Parsing multiple RSS URLs'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.16 – 解析多个 RSS URLs'
- en: '](img/B17115_06_16.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17115_06_16.jpg](img/B17115_06_16.jpg)'
- en: Figure 6.16 – Parsing multiple RSS URLs
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.16 – 解析多个 RSS URLs
- en: 'To view the entries that have been saved in MongoDB, build a simple dashboard
    to list all the recipes in the `recipes` collection. You can create a new project
    from scratch or expose an additional route on the web application we built in
    the previous chapter to serve an HTML representation of the recipes:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看已保存在 MongoDB 中的条目，构建一个简单的仪表板以列出 `recipes` 集合中的所有食谱。你可以从头创建一个新项目，或者在前一章中构建的
    Web 应用程序上暴露一个额外的路由以提供食谱的 HTML 表示形式：
- en: '[PRE20]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Then, make sure that you update the `Recipe` struct fields to mirror the MongoDB
    document field''s structure:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，确保你更新 `Recipe` 结构体字段以反映 MongoDB 文档字段的架构：
- en: '[PRE21]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The route handler will simply call the `Find` operation on the `recipes` collection
    to return all the recipes. Then, it will encode the results in a `recipes` slice.
    Finally, it will pass the `recipes` variable into an HTML template to display
    the results:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 路由处理程序将简单地调用 `recipes` 集合上的 `Find` 操作以返回所有食谱。然后，它将结果编码到 `recipes` 切片中。最后，它将
    `recipes` 变量传递给 HTML 模板以显示结果：
- en: '[PRE22]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The following is the HTML template''s content. It uses the Bootstrap framework
    to build an appealing user interface. It also uses the `range` keyword to loop
    through each recipe within the `recipes` slice and displays its details (title,
    thumbnail image, and Reddit URL):'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为 HTML 模板的内容。它使用 Bootstrap 框架构建一个吸引人的用户界面。它还使用 `range` 关键字遍历 `recipes` 切片中的每个食谱并显示其详细信息（标题、缩略图图像和
    Reddit URL）：
- en: '[PRE23]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Configure the Gin server to run on port `3000` and execute the server with
    the `go run main.go` command with the `MONGO_URI` and `MONGO_DATABASE` variables.
    On your browser, head to Localhost:3000/dashboard Apart from, where a list of
    recipes should be returned, as shown in the following screenshot:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 将 Gin 服务器配置为在端口 `3000` 上运行，并使用 `go run main.go` 命令以及 `MONGO_URI` 和 `MONGO_DATABASE`
    变量来执行服务器。在你的浏览器中，转到 Localhost:3000/dashboard，除了返回食谱列表的地方，如下面的截图所示：
- en: '![Figure 6.17 – Trending Reddit recipes'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.17 – Trending Reddit recipes'
- en: '](img/B17115_06_17.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17115_06_17.jpg](img/B17115_06_17.jpg)'
- en: Figure 6.17 – Trending Reddit recipes
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.17 – Trending Reddit recipes
- en: Note
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The application layout and stylesheet can be found in this book''s GitHub repository:
    [https://github.com/PacktPublishing/Building-Distributed-Applications-in-Gin/blob/main/chapter06/dashboard/templates/index.tmpl](https://github.com/PacktPublishing/Building-Distributed-Applications-in-Gin/blob/main/chapter06/dashboard/templates/index.tmpl).'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 应用布局和样式表可以在本书的 GitHub 仓库中找到：[https://github.com/PacktPublishing/Building-Distributed-Applications-in-Gin/blob/main/chapter06/dashboard/templates/index.tmpl](https://github.com/PacktPublishing/Building-Distributed-Applications-in-Gin/blob/main/chapter06/dashboard/templates/index.tmpl)。
- en: Awesome! You are now familiar with how to use a message broker such as RabbitMQ
    to scale your Gin distributed applications. In the next section, we will demonstrate
    another technique for scaling a Gin distributed application through Docker.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！你现在已经熟悉了如何使用像 RabbitMQ 这样的消息代理来扩展你的 Gin 分布式应用程序。在下一节中，我们将演示另一种通过 Docker
    扩展 Gin 分布式应用程序的技术。
- en: Scaling horizontally with Docker replicas
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Docker 副本来水平扩展
- en: So far, you have learned how to build a Producer/Consumer architecture with
    the Gin framework and RabbitMQ. In this section, we'll cover how to scale the
    consumer component so that we can split the incoming workload across multiple
    consumers.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经学会了如何使用 Gin 框架和 RabbitMQ 构建生产者/消费者架构。在本节中，我们将介绍如何扩展消费者组件，以便我们可以将传入的工作量分配给多个消费者。
- en: You can achieve this by building a Docker image of the consumer project and
    building multiple containers based on that image. The Docker image is immutable,
    which guarantees the same environment each time a container is based on the image
    that is run.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过构建消费者项目的 Docker 镜像并基于该镜像构建多个容器来实现这一点。Docker 镜像是不可变的，这保证了每次基于运行该镜像的镜像创建容器时，环境都是相同的。
- en: 'The following schema illustrates how multiple consumers/workers are used:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 以下架构图说明了如何使用多个消费者/工作者：
- en: '![Figure 6.18 – Scaling multiple workers with Docker'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.18 – 使用 Docker 规模化多个工作者'
- en: '](img/B17115_06_18.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17115_06_18.jpg)'
- en: Figure 6.18 – Scaling multiple workers with Docker
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.18 – 使用 Docker 规模化多个工作者
- en: 'To create a Docker image, we need to define a `Dockerfile` – a blueprint that
    contains all the instructions to run the consumer project. Create a `Dockerfile`
    in your worker/consumer directory with the following content:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建 Docker 镜像，我们需要定义一个 `Dockerfile` – 一个包含运行消费者项目所有指令的蓝图。在您的工作者/消费者目录中创建一个 `Dockerfile`，内容如下：
- en: '[PRE24]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This `Dockerfile` uses the multi-stage build feature to build a lightweight
    Docker image. We will see how this works in the next section.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 此 `Dockerfile` 使用多阶段构建功能构建一个轻量级 Docker 镜像。我们将在下一节中看到它是如何工作的。
- en: Using Docker multi-stage builds
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Docker 多阶段构建
- en: '`FROM` statements in your `Dockerfile` and copy artifacts from one stage to
    another, leaving behind everything you don''t need in the final image.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的 `Dockerfile` 中的 `FROM` 语句和从一阶段复制工件到另一阶段，留下您在最终镜像中不需要的所有内容。
- en: In the previous example, you used `golang:1.16` as a base image to build a single
    binary. Then, the second `FROM` instruction started a new build stage with the
    Alpine image as its base. From here, you can copy the binary from the previous
    stage using the `COPY –from=0` instruction. As a result, you will end up with
    a small Docker image.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，您使用了 `golang:1.16` 作为基础镜像来构建单个二进制文件。然后，第二个 `FROM` 指令以 Alpine 镜像作为其基础启动了新的构建阶段。从这里，您可以使用
    `COPY –from=0` 指令从上一个阶段复制二进制文件。结果，您将得到一个小的 Docker 镜像。
- en: 'To build the image, run the following command. The dot at the end is important
    as it points to the current directory:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建镜像，请运行以下命令。末尾的点很重要，因为它指向当前目录：
- en: '[PRE25]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The building process should take a few seconds to be completed. Then, you will
    find the following Docker build logs:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 构建过程应在几秒钟内完成。然后，您将找到以下 Docker 构建日志：
- en: '![Figure 6.19 – Docker build logs'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.19 – Docker 构建日志'
- en: '](img/B17115_06_19.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17115_06_19.jpg)'
- en: Figure 6.19 – Docker build logs
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.19 – Docker 构建日志
- en: 'If you review the preceding output, you will see that Docker logged every instruction
    of building the worker image according to the steps in our `Dockerfile`. Once
    the image has been built, run the following command to list the available images
    in your machine:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您回顾前面的输出，您将看到 Docker 根据我们 `Dockerfile` 中的步骤记录了构建工作者镜像的每条指令。一旦镜像构建完成，运行以下命令以列出您机器上的可用镜像：
- en: '[PRE26]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The worker/consumer image should be listed at the top of the list:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 工作者/消费者镜像应列在列表的顶部：
- en: '![Figure 6.20 – Worker Docker image'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.20 – 工作者 Docker 镜像'
- en: '](img/B17115_06_20.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17115_06_20.jpg)'
- en: Figure 6.20 – Worker Docker image
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.20 – 工作者 Docker 镜像
- en: 'Run a container based on the image with the `docker run` command. You need
    to provide the MongoDB and RabbitMQ URIs as environment variables with the `–e`
    flag. The `–link` flag can be used to interact with MongoDB and RabbitMQ within
    the container:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `docker run` 命令基于镜像运行容器。您需要使用 `–e` 标志提供 MongoDB 和 RabbitMQ 的 URI 作为环境变量。可以使用
    `–link` 标志在容器内与 MongoDB 和 RabbitMQ 交互：
- en: '[PRE27]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The container logs are as follows:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 容器日志如下：
- en: '![Figure 6.21 – Worker''s container logs'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.21 – 工作者的容器日志'
- en: '](img/B17115_06_21.jpg)'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17115_06_21.jpg)'
- en: Figure 6.21 – Worker's container logs
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.21 – 工作者的容器日志
- en: With that, you have dockerized the worker's service. Next, we will scale it
    with Docker Compose.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样，您已经将工作者服务容器化了。接下来，我们将使用 Docker Compose 进行扩展。
- en: Scaling services with Docker Compose
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Docker Compose 规模化服务
- en: '**Docker Compose** is a container orchestration tool built on top of Docker
    Engine. It helps you manage an application stack or multiple containers with a
    single command line.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '**Docker Compose** 是一个基于 Docker 引擎构建的容器编排工具。它可以帮助您通过单个命令行管理应用程序堆栈或多个容器。'
- en: 'Using Docker Compose is as simple as creating a Docker image:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Docker Compose 与创建 Docker 镜像一样简单：
- en: 'Define a `docker-compose.yml` file in the root of your project and type in
    the following YAML code:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您项目的根目录下定义一个 `docker-compose.yml` 文件，并输入以下 YAML 代码：
- en: '[PRE28]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The configuration specifies the environment variables and network topology that
    the worker requires.
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 配置指定了工作节点所需的环境变量和网络拓扑。
- en: 'Define an external network where the workers, MongoDB, and RabbitMQ services
    will be living. Execute the following command:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个外部网络，其中将运行工作节点、MongoDB和RabbitMQ服务。执行以下命令：
- en: '[PRE29]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Redeploy the RabbitMQ and MongoDB containers but this time, deploy them within
    the `app_network` custom network by passing the `–network` flag:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新部署RabbitMQ和MongoDB容器，但这次，通过传递`–network`标志在自定义网络`app_network`中部署它们：
- en: '[PRE30]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'With the containers being configured properly, issue the following command
    to deploy the worker:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 容器配置正确后，执行以下命令以部署工作节点：
- en: '[PRE31]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The `-d` flag instructs Docker Compose to run the containers in the background
    (detached mode).
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`-d`标志指示Docker Compose在后台（分离模式）运行容器。'
- en: Issue the following command to list the running services:![Figure 6.22 – Docker
    Compose service
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下命令以列出正在运行的服务：![图 6.22 – Docker Compose 服务
- en: '](img/B17115_06_22.jpg)'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B17115_06_22.jpg](img/B17115_06_22.jpg)'
- en: Figure 6.22 – Docker Compose service
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.22 – Docker Compose 服务
- en: 'To scale the worker, rerun the previous command with the `–scale` flag:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要扩展工作节点，重新运行之前的命令并带有`–scale`标志：
- en: '[PRE32]'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The final output will look as follows:'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最终输出将如下所示：
- en: '![Figure 6.23 – Scaling five workers'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.23 – 扩展五个工作节点'
- en: '](img/B17115_06_23.jpg)'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B17115_06_23.jpg](img/B17115_06_23.jpg)'
- en: Figure 6.23 – Scaling five workers
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.23 – 扩展五个工作节点
- en: 'To test everything out, create a file called `threads` that contains a list
    of Reddit''s best cooking and recipes subreddits. The following list has been
    cropped for brevity:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要测试一切，创建一个名为`threads`的文件，其中包含Reddit上最佳烹饪和食谱子版块的列表。以下列表因简洁而被裁剪：
- en: '[PRE33]'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Then, write a `bulk.sh` shell script to read the `threads` file line by line
    and issue a POST request to the producer service:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，编写一个`bulk.sh`shell脚本，逐行读取`threads`文件并发出对生产者服务的POST请求：
- en: '[PRE34]'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'To run the script, add the execution permission and execute the file with the
    following command:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要运行脚本，添加执行权限，并使用以下命令执行文件：
- en: '[PRE35]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Note
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Make sure the producer service is running, otherwise the issued HTTP requests
    with `curl` command will timeout.
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 确保生产者服务正在运行，否则使用`curl`命令发出的HTTP请求将超时。
- en: 'The script will read the `threads` file line by line and issue a POST request,
    as follows:'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 脚本将逐行读取`threads`文件并发出POST请求，如下所示：
- en: '![Figure 6.24 – Shell script''s output'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.24 – Shell 脚本输出'
- en: '](img/B17115_06_24.jpg)'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B17115_06_24.jpg](img/B17115_06_24.jpg)'
- en: Figure 6.24 – Shell script's output
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.24 – Shell 脚本输出
- en: 'Run the `docker-compose logs -f` command. This time, you should notice multiple
    workers are being used. Also, Docker Compose assigned colors to instances and
    each message is being fetched by a different worker:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行`docker-compose logs -f`命令。这次，你应该注意到正在使用多个工作节点。此外，Docker Compose为实例分配了颜色，并且每个消息都由不同的工作节点获取：
- en: '![Figure 6.25 – Splitting the workload across multiple workers'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.25 – 在多个工作节点间分配工作负载'
- en: '](img/B17115_06_25.jpg)'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17115_06_25.jpg](img/B17115_06_25.jpg)'
- en: Figure 6.25 – Splitting the workload across multiple workers
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.25 – 在多个工作节点间分配工作负载
- en: With that, you have successfully split the workload across multiple workers.
    This approach is called **horizontal scaling**.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，你已经成功地将工作负载分配到多个工作节点上。这种方法被称为**水平扩展**。
- en: Note
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: In [*Chapter 8*](B17115_08_Final_JM_ePub.xhtml#_idTextAnchor131), *Deploying
    the Application on AWS*, we will cover how to deploy the web application on AWS
    and how to use a **Simple Queue Service** (**SQS**) instead of RabbitMQ to scale
    the workers.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第8章*](B17115_08_Final_JM_ePub.xhtml#_idTextAnchor131)中，*在AWS上部署应用程序*，我们将介绍如何在AWS上部署Web应用程序以及如何使用**简单队列服务**（**SQS**）而不是RabbitMQ来扩展工作节点。
- en: Using the NGINX reverse proxy
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用NGINX反向代理
- en: In the previous section, you learned how to scale the workers responsible for
    parsing the subreddit URLs. In this section, you will explore how to scale the
    Recipes API we built in the previous chapters by serving it behind a reverse proxy.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，你学习了如何扩展负责解析子版块URL的工作节点。在本节中，你将探索如何通过在反向代理后面提供服务来扩展我们在上一章中构建的Recipes API。
- en: 'One of the most used reverse proxies is **Nginx**. It faces the client and
    receives the incoming HTTP(S) requests. It then redirects them to one of the API
    instances in a round-robin fashion. To deploy multiple instances of the Recipes
    API, you will be using Docker Compose to orchestrate the containers. The following
    schema illustrates the difference between a **single instance architecture** and
    a **load balanced multi-instance architecture** with Nginx:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 最常用的反向代理之一是 **Nginx**。它面向客户端并接收传入的HTTP(S)请求。然后，它以轮询的方式将它们重定向到 API 实例之一。要部署多个
    Recipes API 实例，你将使用 Docker Compose 来编排容器。以下架构图说明了 **单实例架构** 与使用 Nginx 的 **负载均衡多实例架构**
    之间的区别：
- en: '![Figure 6.26 – Load balanced multi-instance architecture with Nginx'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.26 – 使用 Nginx 的负载均衡多实例架构'
- en: '](img/Figure_6.26_B17115.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_6.26_B17115.jpg)'
- en: Figure 6.26 – Load balanced multi-instance architecture with Nginx
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.26 – 使用 Nginx 的负载均衡多实例架构
- en: Another solution for scaling the Recipes API is **vertical scaling**, which
    consists of increasing the CPU/RAM of the system where the service is running.
    However, this approach tends to have some limitations in the long run (not cost-effective).
    That's why, here, you will adopt the horizontal scaling approach and distribute
    the load across multiple API instances.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种扩展 Recipes API 的解决方案是**垂直扩展**，这包括增加服务运行系统的CPU/RAM。然而，这种方法在长期来看往往有一些限制（不经济）。这就是为什么在这里，你将采用水平扩展方法，并将负载分配到多个API实例。
- en: Note
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: An alternative to Nginx is Traefik ([https://doc.traefik.io/traefik/](https://doc.traefik.io/traefik/)).
    It's an open source project built with scalability in mind.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: Nginx 的替代方案是 Traefik ([https://doc.traefik.io/traefik/](https://doc.traefik.io/traefik/))。这是一个以可扩展性为设计理念的开放源代码项目。
- en: 'The following is a quick reminder of the Recipes API''s output:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是对 Recipes API 输出的快速回顾：
- en: '![Figure 6.27 – GET /recipes endpoint response'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.27 – GET /recipes 端点响应'
- en: '](img/Figure_6.27_B17115.jpg)'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_6.27_B17115.jpg)'
- en: Figure 6.27 – GET /recipes endpoint response
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.27 – GET /recipes 端点响应
- en: 'To deploy multiple instances of the Recipes API, follow these steps:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 要部署多个 Recipes API 实例，请按照以下步骤操作：
- en: 'Build a Docker image and write a Dockerfile in the folder with your Recipes
    API implementation that contains the following content:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在包含你的 Recipes API 实现的文件夹中构建 Docker 镜像并编写 Dockerfile，内容如下：
- en: '[PRE36]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: This `Dockerfile` uses the multi-stage feature to ship a lightweight image.
    The `docker build -t recipes-api.` Command's output is as follows:![Figure 6.28
    – Docker build logs
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个 `Dockerfile` 使用多阶段特性来传输一个轻量级镜像。`docker build -t recipes-api.` 命令的输出如下：![图
    6.28 – Docker 构建日志
- en: '](img/Figure_6.28_B17115.jpg)'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_6.28_B17115.jpg)'
- en: Figure 6.28 – Docker build logs
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.28 – Docker 构建日志
- en: 'With the image built, create a `docker-compose.yml` file and define three services:'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 构建镜像后，创建一个 `docker-compose.yml` 文件并定义三个服务：
- en: '**API**: The Recipes API container'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**API**：Recipes API 容器'
- en: '**Redis**: The in-memory caching database'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**Redis**：内存缓存数据库'
- en: '**MongoDB**: The NoSQL database where the recipes are stored'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**MongoDB**：存储食谱的非关系型数据库'
- en: 'Then, add the following lines to the file:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，将以下行添加到文件中：
- en: '[PRE37]'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Next, define a Nginx service with the following code block:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，定义一个 Nginx 服务，如下所示：
- en: '[PRE38]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'This code maps a local `nginx.conf` file into `/etc/nginx/nginx.conf` inside
    the container. The file provides instructions to Nginx about how to handle the
    incoming HTTP requests. The following is a simplified version:'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这段代码将本地的 `nginx.conf` 文件映射到容器内的 `/etc/nginx/nginx.conf`。该文件提供了Nginx如何处理传入的HTTP请求的指令。以下是一个简化版本：
- en: '[PRE39]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: In `location /api`, set up a reverse proxy to forward the requests to the API
    running in port `8080` (internally).
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `location /api` 中设置反向代理，将请求转发到运行在端口 `8080`（内部）的 API。
- en: 'Deploy the entire stack with the `docker-compose up –d` command. Then, issue
    the following command to display the running services:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `docker-compose up –d` 命令部署整个堆栈。然后，执行以下命令以显示正在运行的服务：
- en: '[PRE40]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The command''s output is as follows:'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 命令的输出如下：
- en: '![Figure 6.29 – Application stack'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.29 – 应用堆栈'
- en: '](img/Figure_6.29_B17115.jpg)'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_6.29_B17115.jpg)'
- en: Figure 6.29 – Application stack
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.29 – 应用堆栈
- en: The Nginx service is exposed on port `80`. Head to `localhost/api/recipes`;
    the server will call the Recipes API and forward the recipes list response, as
    follows:![Figure 6.30 – Forwarding a HTTP response with Nginx
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Nginx 服务在端口 `80` 上公开。访问 `localhost/api/recipes`；服务器将调用 Recipes API 并转发食谱列表响应，如下所示：![图
    6.30 – 使用 Nginx 转发 HTTP 响应
- en: '](img/Figure_6.30_B17115.jpg)'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_6.30_B17115.jpg)'
- en: Figure 6.30 – Forwarding a HTTP response with Nginx
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For production usage, it's important that you secure your API endpoints with
    HTTPS. Luckily, you can use the "Let's Encrypt" add-on for Nginx to generate the
    TLS certificates automatically.
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To ensure the response is being forwarded from the Recipes API, check out the
    Nginx service logs with the following command:'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'You should see something like this:'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'So far, one instance of the Recipes API container is running. To scale it out,
    use the `–scale` flag with the `docker-compose up` command or define the number
    of replicas in the `docker-compose.yml` file, as follows:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Re-execute the `docker-compose up` command. Four additional services will be
    created based on the Recipes API Docker image. Following are the service logs:![Figure
    6.31 – Scaling the Recipes API
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_6.31_B17115.jpg)'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.31 – Scaling the Recipes API
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now, when the client sends a request, it will hit Nginx and then be forwarded
    to one of the API services in a round-robin fashion. This helps us evenly distribute
    the load.
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In [*Chapter 10*](B17115_10_Final_JM_ePub.xhtml#_idTextAnchor160)*, Capturing
    Gin Application Metrics*, we will learn how to set up a monitoring platform to
    trigger a scale-out event to increase the number of services when the demand increases.
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The advantage of using a reverse proxy is that you can set up a single point
    of entry for your entire distributed web application. Both the backend and the
    web application will be located at the same URL. That way, you won't need to handle
    CORS on your API server.
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Similar to the Recipes API, create a Docker image for the `react-ui` service.
    The following is the content of our `Dockerfile`:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: As you can see, this is dead simple. Here, you are using a pre-built Node.js
    base image because the `react-ui` service is written in JavaScript.
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Build the Docker image with `` `docker build -t dashboard'' ``. Then, update
    `docker-compose.yml` so that it runs a Docker service from the image with the
    following code block:'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Next, update `nginx.conf` so that it forwards incoming requests at the root
    level of the URL to the dashboard service:'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Rerun the `docker-compose up` `-d` command for the changes to take effect:![Figure
    6.32 – Serving the web dashboard from Nginx
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_6.32_B17115.jpg)'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.32 – Serving the web dashboard from Nginx
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Head to `localhost/dashboard`; you will be redirected to the web dashboard
    we wrote in the previous chapter:'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.33 – Serving two backends from the same URL'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.33_B17115.jpg)'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.33 – Serving two backends from the same URL
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: Now, both the RESTful API and dashboard are being served from the same domain
    name.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: 'To take down your containers, you can use the following command:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Note
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: If you're using session-based authentication, you'll need to configure cookie
    stickiness on Nginx to keep a user's session on the server where it was started.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also serve the subreddits application (built at the beginning of this
    chapter) from the Nginx server by replacing the dashboard location with another
    location section, to the `nginx.conf` file:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Similar to `react-ui`, create a Docker image for the subreddits application.
    The following is the content of our `Dockerfile`:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Here, you are using a pre-built Node.js base image because the dashboard service
    is written in JavaScript. Build the Docker image with `"docker build -t dashboard"`.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, don''t forget to add the application to the `docker-compose.yml` file:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Once you have redeployed the stack with `docker-compose`, head to [localhost/reddit](http://localhost/reddit);
    you will be redirected to the following UI:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.34 – Trending recipes application'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.34_B17115.jpg)'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.34 – Trending recipes application
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: 'The application layout is broken because the `app.css` file is being served
    from the wrong backend. You can confirm this by opening the debug console on Chrome:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.35 – Stylesheet location'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.35_B17115.jpg)'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.35 – Stylesheet location
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: 'You can force Nginx to serve the `app.css` file from the subreddit application
    container by adding the following code block to `nginx.conf`:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Now, refresh the web page; the application layout will be fixed:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.36 – Application layout'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.36_B17115.jpg)'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.36 – Application layout
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, the dashboard displays the recipes thumbnails. These images
    are then served from the backend each time you refresh the page. To reduce the
    stress on the backend, you can configure Nginx to cache the static files. Insert
    the following code snippet before the `server` section in the Nginx config file:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The `~image` keyword will handle all kinds of images (PNG, JPEG, GIF, SVG,
    and so on). Now, configure expiration with the `expires` instruction in the `server`
    section:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Then, redeploy the stack with the following command:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: The images should now be cached, which reduces the number of requests hitting
    the backend. In the next section, we will cover how to get the same results in
    the backend with Gin.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: Caching assets with HTTP cache headers
  id: totrans-326
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can also manage caching with the Gin framework. To illustrate this, write
    a simple web application to serve an image. The code is as follows:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The application should serve an image when the user hits the `/illustration`
    resource URL:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.37 – Serving an image with Gin'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.37_B17115.jpg)'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.37 – Serving an image with Gin
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: Because the same image is always delivered, we need to make sure that we're
    caching the image. That way, we can avoid having unnecessary traffic and have
    better web performance. Let's see how that is done.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: Setting HTTP caching headers
  id: totrans-334
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To cache this HTTP request, you can attach an `If-None-Match` field has an
    `Etag` key value. If there is a match between the `If-None-Match` field and the
    key that''s generated, then a 304 status code will be returned:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Once you''ve updated the HTTP handler with the preceding code, test it out.
    The first time you ask for the `/illustration` resource, you should get a status
    of `200 OK`. However, for the second request, you should get a `304 StatusNotModified`
    response:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.38 – Response caching with Gin'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.38_B17115.jpg)'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.38 – Response caching with Gin
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: You may also notice that the latency of the second request is shorter than the
    first one. By keeping the number of queries to a minimum, you can mitigate the
    API's impact on your application's performance.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-342
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to build a distributed web application using
    the Gin framework based on the Microservices architecture.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: You also have explored how to set up RabbitMQ as a message broker between the
    microservices and how to scale out those services with Docker. Along the way,
    you learned how to maintain the service image's size with Docker's multi-stage
    build feature, as well as how to improve the API's performance with Nginx and
    HTTP caching headers.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn how to write unit and integration tests
    for a Gin web application.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-346
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*RabbitMQ Essentials – Second Edition,* by Lovisa Johansson, Packt Publishing'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Docker for Developers,* by Richard Bullington-McGuire, Andrew K. Dennis, Michael
    Schwartz, Packt Publishing.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
