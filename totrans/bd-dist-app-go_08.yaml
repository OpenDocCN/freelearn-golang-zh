- en: 'Chapter 6: Scaling a Gin Application'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will learn how to improve the performance and scalability
    of a distributed web application written with the Gin framework. This chapter
    will cover how to use caching mechanisms to alleviate performance bottlenecks.
    Along the way, you will learn how to scale a web app using a message broker solution
    such as RabbitMQ. Finally, you will learn how to **containerize** the application
    and scale it out with **Docker Compose**.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Scaling workloads with a message broker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scaling horizontally with Docker replicas
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the Nginx reverse proxy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Caching assets with HTTP cache headers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will be able to build a highly available and
    distributed web application with the Gin framework, Docker, and RabbitMQ.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To follow the content in this chapter, you will need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A complete understanding of the previous chapter. This chapter is a follow-up
    to the previous one as it will use the same source code. Hence, some snippets
    won't be explained to avoid repetition.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An understanding of Docker and its architecture. Ideally, some previous experience
    with a message queue service such as RabbitMQ, ActiveMQ, Kafka, and so on would
    be beneficial.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code bundle for this chapter is hosted on GitHub at [https://github.com/PacktPublishing/Building-Distributed-Applications-in-Gin/tree/main/chapter06](https://github.com/PacktPublishing/Building-Distributed-Applications-in-Gin/tree/main/chapter06).
  prefs: []
  type: TYPE_NORMAL
- en: Scaling workloads with a message broker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When developing a web application, one important aspect of the user experience
    that is often overlooked is the response time. Nothing can turn away a user more
    quickly than an application that is slow and sluggish. In the previous chapters,
    you learned how to reduce database queries with Redis for faster data access.
    In this chapter, you will take things further and cover how to scale a web application
    written with the Gin framework.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we get into why you need to scale the application workload, let''s add
    another block to the architecture. The new service will parse a Reddit RSS feed
    and insert feed entries into the MongoDB `recipes` collection. The following diagram
    illustrates how the new service integrates with the architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1 – Parsing a Reddit RSS feed'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.1_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.1 – Parsing a Reddit RSS feed
  prefs: []
  type: TYPE_NORMAL
- en: 'The service will take a subreddit RSS URL as a parameter. We can create an
    RSS feed by adding `.rss` to the end of an existing subreddit URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.reddit.com/r/THREAD_NAME/.rss](https://www.reddit.com/r/THREAD_NAME/.rss)'
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, let''s have a look at the recipes subreddit shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.2 – Recipes subreddit'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.2_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.2 – Recipes subreddit
  prefs: []
  type: TYPE_NORMAL
- en: 'This subreddit will have the following URL for the RSS feed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.reddit.com/r/recipes/.rss](https://www.reddit.com/r/recipes/.rss)'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you visit the aforementioned URL, you should receive an XML response. The
    following is an example of the XML structure that''s returned by the recipes subreddit''s
    RSS URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'To get started, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create an `rss-parser` project, load it into the VSCode editor, and write a
    `main.go` file. Within the file, declare a `Feed` struct to mirror the XML structure:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, write a `GetFeedEntries` method, which takes the RSS URL as a parameter,
    and return a list of entries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This method uses the HTTP client to issue a GET request into the URL given in
    the `GetFeedEntries` method parameter. Then, it encodes the response body into
    a `Feed` struct. Finally, it returns the `Entries` attribute.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Note the usage of the `User-Agent` request header to simulate a request being
    sent from the browser and avoiding being blocked by the Reddit servers:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'A list of valid User-Agents can be found at the following URL (it''s updated
    regularly): [https://developers.whatismybrowser.com/useragents/explore/](https://developers.whatismybrowser.com/useragents/explore/).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, create a web server with the Gin router and expose a POST request on
    the `/parse` endpoint. Then, define a route handler called `ParserHandler`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`ParserHandler` is self-explanatory: it marshals the request payload into a
    `Request` struct. Then, it calls the `GetFeedEntries` method with the `URL` attribute
    of the `Request` struct. Finally, based on the method''s response, it returns
    a 500 error code or a 200 status code, along with a list of feed entries:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `Request` struct has a `URL` attribute:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: To test it out, run the server on a different port (for example, `5000`) to
    avoid port conflicts with the recipes API (already running on port `8080`):![Figure
    6.3 – RSS parser logs
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_6.3_B17115.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.3 – RSS parser logs
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: On the Postman client, issue a POST request on the `/parse` endpoint with the
    URL of a subreddit in the request body. The server will parse the RSS feed and
    return a list of feed entries, as shown in the following screenshot:![Figure 6.4
    – RSS feed entries
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_6.4_B17115.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.4 – RSS feed entries
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, insert the results into MongoDB by connecting to the MongoDB server deployed
    in previous chapters. Define the connection instructions on the `init()` method,
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, update the HTTP handler to insert entries into the `recipes` collection
    with the `InsertOne` operation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Rerun the application, but this time, provide the `MONGO_URI` and `MONGO_DATABASE`
    environment variables, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Reissue a POST request with Postman or the `curl` command. Head back to MongoDB
    Compass and refresh the `recipes` collection. The RSS entries should have been
    successfully inserted, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.5 – Recipes collection'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.5_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.5 – Recipes collection
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: If you're using the same database and collection that was shown in the previous
    chapters, you might need to drop existing documents before inserting new recipes.
  prefs: []
  type: TYPE_NORMAL
- en: The `recipes` collection has now been initialized with a list of recipes.
  prefs: []
  type: TYPE_NORMAL
- en: You can repeat the same steps to parse other subreddit RSS feeds. However, what
    if you want to parse thousands or millions of subreddits? Handling such a large
    number of workloads will take a lot of resources (CPU/RAM) and will be time-consuming.
    That's why we will separate the service logic into multiple loosely coupled services,
    and then scale them based on the incoming workload.
  prefs: []
  type: TYPE_NORMAL
- en: Those services will need to communicate with each other, and the most effective
    communication approach is to use message brokers. That's where RabbitMQ comes
    into the picture.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying RabbitMQ with Docker
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**RabbitMQ** ([https://www.rabbitmq.com/#getstarted](https://www.rabbitmq.com/#getstarted))
    is a reliable, highly available message broker. The following schema describes
    how RabbitMQ will be used within the application architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.6 – Scaling with RabbitMQ'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.6_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.6 – Scaling with RabbitMQ
  prefs: []
  type: TYPE_NORMAL
- en: 'To deploy RabbitMQ with Docker, use the official RabbitMQ Docker image ([https://hub.docker.com/_/rabbitmq](https://hub.docker.com/_/rabbitmq))
    and implement the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Issue the following command to run a container from the RabbitMQ image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once the container has been deployed, run the following command to display
    the server logs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here''s how the startup logs will be displayed:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.7 – RabbitMQ startup logs'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/Figure_6.7_B17115.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.7 – RabbitMQ startup logs
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Once the server initialization has been completed, navigate to `localhost:8080`
    via your browser. A RabbitMQ login page will be displayed. Sign in with your user/password
    credentials. You will land on the dashboard:![Figure 6.8 – RabbitMQ dashboard
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17115_06_08_v2.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.8 – RabbitMQ dashboard
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now, create a messaging queue where the RSS URLs will be pushed to by the services.
    Click on **Queues** from the navigation bar and create a new queue by clicking
    on **Add a new queue**:![Figure 6.9 – Creating a new RabbitMQ queue
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17115_06_09_v2.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.9 – Creating a new RabbitMQ queue
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Make sure that you set the **Durability** field to **Durable** for the data
    to be persisted on disk if RabbitMQ ever goes down.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With RabbitMQ up and running, we can move on and implement a producer service
    to push incoming RSS URLs to RabbitMQ, as well as a consumer service to consume
    the URLs from the queue.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the Producer/Consumer pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we dig deeper into the implementation, we need to explore the Producer/Consumer
    pattern. The following schema illustrates these two concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.10 – Producer/Consumer pattern'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17115_06_10_v2.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.10 – Producer/Consumer pattern
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that the main concepts are clear, let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Go project called `producer` and install the RabbitMQ SDK for
    Golang with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Write a `main.go` file and set up a TCP connection to the RabbitMQ server with
    the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The AMQP connection string will be provided, along with the password, through
    the `RABBITMQ_URI` environment variable.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, define an HTTP handler on the `/parse` endpoint. The handler will push
    the URL given in the request body into the RabbitMQ queue using the `Publish`
    method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, run the application with the `RABBITMQ_URI` and `RABBITMQ_QUEUE` variables,
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Then, execute a POST request on the `/parse` endpoint. You should receive a
    200 **success** message, as shown here:![Figure 6.11 – Publishing data in RabbitMQ
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_6.11_B17115.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.11 – Publishing data in RabbitMQ
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Head back to the RabbitMQ dashboard, go to the **Queues** section, and click
    on the **rss_urls** queue. You should be redirected to the **Queue metrics** page.
    Here, you will notice a message in the queue:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.12 – Queue metrics page'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17115_06_12_v2.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.12 – Queue metrics page
  prefs: []
  type: TYPE_NORMAL
- en: 'With the producer service up and running, you need to build the worker/consumer
    to consume the messages/URLs available in the RabbitMQ queue:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Go project called `consumer` and create a new file called `main.go`.
    Write the following code inside the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The code is straightforward: it sets up a connection to the RabbitMQ server
    and subscribes to the `rss_urls` queue. Then, it creates an infinite loop and
    fetches a message from the queue, after which it displays the message body to
    the console and waits for new messages.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the consumer project by passing the RabbitMQ URI and queue name as environment
    variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once launched, the consumer will fetch the message that was pushed previously
    by the producer and display its content on the console. Then, it will delete the
    message from the queue:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.13 – Subscribing and fetching a message from RabbitMQ'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B17115_06_13_v2.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.13 – Subscribing and fetching a message from RabbitMQ
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Verify that the message has been deleted by refreshing the **Queue metrics**
    page. The **Queued messages** chart should confirm this deletion:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.14 – Deleting a message from the queue'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.14_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.14 – Deleting a message from the queue
  prefs: []
  type: TYPE_NORMAL
- en: With that, your worker/consumer has been built!
  prefs: []
  type: TYPE_NORMAL
- en: 'So far, you''ve seen that the consumer displays the message''s content. Now,
    let''s take this further and encode the message body in a `Request` struct and
    get the feed entries by calling the `GetFeedEntries` method, which we mentioned
    earlier. The entries will then be saved in the `recipes` collection in MongoDB:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Rerun the application, but this time, provide the MongoDB connection parameters,
    in addition to the RabbitMQ parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'To test this out, issue a POST request to the producer server with an RSS feed
    URL in the request body. The producer will publish the URL in the RabbitMQ queue.
    From there, the consumer will fetch the message and get the XML response of the
    RSS URL, encode the response in an array of entries, and save the results in MongoDB:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.15 – Consumer server logs'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17115_06_15.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.15 – Consumer server logs
  prefs: []
  type: TYPE_NORMAL
- en: 'You can issue multiple subreddit URLs to the producer server. This time, the
    consumer will fetch the URLs one by one, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.16 – Parsing multiple RSS URLs'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17115_06_16.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.16 – Parsing multiple RSS URLs
  prefs: []
  type: TYPE_NORMAL
- en: 'To view the entries that have been saved in MongoDB, build a simple dashboard
    to list all the recipes in the `recipes` collection. You can create a new project
    from scratch or expose an additional route on the web application we built in
    the previous chapter to serve an HTML representation of the recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, make sure that you update the `Recipe` struct fields to mirror the MongoDB
    document field''s structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The route handler will simply call the `Find` operation on the `recipes` collection
    to return all the recipes. Then, it will encode the results in a `recipes` slice.
    Finally, it will pass the `recipes` variable into an HTML template to display
    the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the HTML template''s content. It uses the Bootstrap framework
    to build an appealing user interface. It also uses the `range` keyword to loop
    through each recipe within the `recipes` slice and displays its details (title,
    thumbnail image, and Reddit URL):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Configure the Gin server to run on port `3000` and execute the server with
    the `go run main.go` command with the `MONGO_URI` and `MONGO_DATABASE` variables.
    On your browser, head to Localhost:3000/dashboard Apart from, where a list of
    recipes should be returned, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.17 – Trending Reddit recipes'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17115_06_17.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.17 – Trending Reddit recipes
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'The application layout and stylesheet can be found in this book''s GitHub repository:
    [https://github.com/PacktPublishing/Building-Distributed-Applications-in-Gin/blob/main/chapter06/dashboard/templates/index.tmpl](https://github.com/PacktPublishing/Building-Distributed-Applications-in-Gin/blob/main/chapter06/dashboard/templates/index.tmpl).'
  prefs: []
  type: TYPE_NORMAL
- en: Awesome! You are now familiar with how to use a message broker such as RabbitMQ
    to scale your Gin distributed applications. In the next section, we will demonstrate
    another technique for scaling a Gin distributed application through Docker.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling horizontally with Docker replicas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, you have learned how to build a Producer/Consumer architecture with
    the Gin framework and RabbitMQ. In this section, we'll cover how to scale the
    consumer component so that we can split the incoming workload across multiple
    consumers.
  prefs: []
  type: TYPE_NORMAL
- en: You can achieve this by building a Docker image of the consumer project and
    building multiple containers based on that image. The Docker image is immutable,
    which guarantees the same environment each time a container is based on the image
    that is run.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following schema illustrates how multiple consumers/workers are used:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.18 – Scaling multiple workers with Docker'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17115_06_18.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.18 – Scaling multiple workers with Docker
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a Docker image, we need to define a `Dockerfile` – a blueprint that
    contains all the instructions to run the consumer project. Create a `Dockerfile`
    in your worker/consumer directory with the following content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: This `Dockerfile` uses the multi-stage build feature to build a lightweight
    Docker image. We will see how this works in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Using Docker multi-stage builds
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`FROM` statements in your `Dockerfile` and copy artifacts from one stage to
    another, leaving behind everything you don''t need in the final image.'
  prefs: []
  type: TYPE_NORMAL
- en: In the previous example, you used `golang:1.16` as a base image to build a single
    binary. Then, the second `FROM` instruction started a new build stage with the
    Alpine image as its base. From here, you can copy the binary from the previous
    stage using the `COPY –from=0` instruction. As a result, you will end up with
    a small Docker image.
  prefs: []
  type: TYPE_NORMAL
- en: 'To build the image, run the following command. The dot at the end is important
    as it points to the current directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The building process should take a few seconds to be completed. Then, you will
    find the following Docker build logs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.19 – Docker build logs'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17115_06_19.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.19 – Docker build logs
  prefs: []
  type: TYPE_NORMAL
- en: 'If you review the preceding output, you will see that Docker logged every instruction
    of building the worker image according to the steps in our `Dockerfile`. Once
    the image has been built, run the following command to list the available images
    in your machine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The worker/consumer image should be listed at the top of the list:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.20 – Worker Docker image'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17115_06_20.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.20 – Worker Docker image
  prefs: []
  type: TYPE_NORMAL
- en: 'Run a container based on the image with the `docker run` command. You need
    to provide the MongoDB and RabbitMQ URIs as environment variables with the `–e`
    flag. The `–link` flag can be used to interact with MongoDB and RabbitMQ within
    the container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The container logs are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.21 – Worker''s container logs'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17115_06_21.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.21 – Worker's container logs
  prefs: []
  type: TYPE_NORMAL
- en: With that, you have dockerized the worker's service. Next, we will scale it
    with Docker Compose.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling services with Docker Compose
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Docker Compose** is a container orchestration tool built on top of Docker
    Engine. It helps you manage an application stack or multiple containers with a
    single command line.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using Docker Compose is as simple as creating a Docker image:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define a `docker-compose.yml` file in the root of your project and type in
    the following YAML code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The configuration specifies the environment variables and network topology that
    the worker requires.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Define an external network where the workers, MongoDB, and RabbitMQ services
    will be living. Execute the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Redeploy the RabbitMQ and MongoDB containers but this time, deploy them within
    the `app_network` custom network by passing the `–network` flag:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'With the containers being configured properly, issue the following command
    to deploy the worker:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `-d` flag instructs Docker Compose to run the containers in the background
    (detached mode).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Issue the following command to list the running services:![Figure 6.22 – Docker
    Compose service
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17115_06_22.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.22 – Docker Compose service
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To scale the worker, rerun the previous command with the `–scale` flag:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The final output will look as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.23 – Scaling five workers'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B17115_06_23.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.23 – Scaling five workers
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To test everything out, create a file called `threads` that contains a list
    of Reddit''s best cooking and recipes subreddits. The following list has been
    cropped for brevity:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, write a `bulk.sh` shell script to read the `threads` file line by line
    and issue a POST request to the producer service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To run the script, add the execution permission and execute the file with the
    following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Make sure the producer service is running, otherwise the issued HTTP requests
    with `curl` command will timeout.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The script will read the `threads` file line by line and issue a POST request,
    as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.24 – Shell script''s output'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B17115_06_24.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.24 – Shell script's output
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the `docker-compose logs -f` command. This time, you should notice multiple
    workers are being used. Also, Docker Compose assigned colors to instances and
    each message is being fetched by a different worker:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.25 – Splitting the workload across multiple workers'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17115_06_25.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.25 – Splitting the workload across multiple workers
  prefs: []
  type: TYPE_NORMAL
- en: With that, you have successfully split the workload across multiple workers.
    This approach is called **horizontal scaling**.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 8*](B17115_08_Final_JM_ePub.xhtml#_idTextAnchor131), *Deploying
    the Application on AWS*, we will cover how to deploy the web application on AWS
    and how to use a **Simple Queue Service** (**SQS**) instead of RabbitMQ to scale
    the workers.
  prefs: []
  type: TYPE_NORMAL
- en: Using the NGINX reverse proxy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, you learned how to scale the workers responsible for
    parsing the subreddit URLs. In this section, you will explore how to scale the
    Recipes API we built in the previous chapters by serving it behind a reverse proxy.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the most used reverse proxies is **Nginx**. It faces the client and
    receives the incoming HTTP(S) requests. It then redirects them to one of the API
    instances in a round-robin fashion. To deploy multiple instances of the Recipes
    API, you will be using Docker Compose to orchestrate the containers. The following
    schema illustrates the difference between a **single instance architecture** and
    a **load balanced multi-instance architecture** with Nginx:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.26 – Load balanced multi-instance architecture with Nginx'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.26_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.26 – Load balanced multi-instance architecture with Nginx
  prefs: []
  type: TYPE_NORMAL
- en: Another solution for scaling the Recipes API is **vertical scaling**, which
    consists of increasing the CPU/RAM of the system where the service is running.
    However, this approach tends to have some limitations in the long run (not cost-effective).
    That's why, here, you will adopt the horizontal scaling approach and distribute
    the load across multiple API instances.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: An alternative to Nginx is Traefik ([https://doc.traefik.io/traefik/](https://doc.traefik.io/traefik/)).
    It's an open source project built with scalability in mind.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a quick reminder of the Recipes API''s output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.27 – GET /recipes endpoint response'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.27_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.27 – GET /recipes endpoint response
  prefs: []
  type: TYPE_NORMAL
- en: 'To deploy multiple instances of the Recipes API, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Build a Docker image and write a Dockerfile in the folder with your Recipes
    API implementation that contains the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This `Dockerfile` uses the multi-stage feature to ship a lightweight image.
    The `docker build -t recipes-api.` Command's output is as follows:![Figure 6.28
    – Docker build logs
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_6.28_B17115.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.28 – Docker build logs
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'With the image built, create a `docker-compose.yml` file and define three services:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**API**: The Recipes API container'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Redis**: The in-memory caching database'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**MongoDB**: The NoSQL database where the recipes are stored'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Then, add the following lines to the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, define a Nginx service with the following code block:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This code maps a local `nginx.conf` file into `/etc/nginx/nginx.conf` inside
    the container. The file provides instructions to Nginx about how to handle the
    incoming HTTP requests. The following is a simplified version:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In `location /api`, set up a reverse proxy to forward the requests to the API
    running in port `8080` (internally).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Deploy the entire stack with the `docker-compose up –d` command. Then, issue
    the following command to display the running services:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The command''s output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.29 – Application stack'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/Figure_6.29_B17115.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.29 – Application stack
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The Nginx service is exposed on port `80`. Head to `localhost/api/recipes`;
    the server will call the Recipes API and forward the recipes list response, as
    follows:![Figure 6.30 – Forwarding a HTTP response with Nginx
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_6.30_B17115.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.30 – Forwarding a HTTP response with Nginx
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For production usage, it's important that you secure your API endpoints with
    HTTPS. Luckily, you can use the "Let's Encrypt" add-on for Nginx to generate the
    TLS certificates automatically.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To ensure the response is being forwarded from the Recipes API, check out the
    Nginx service logs with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should see something like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'So far, one instance of the Recipes API container is running. To scale it out,
    use the `–scale` flag with the `docker-compose up` command or define the number
    of replicas in the `docker-compose.yml` file, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Re-execute the `docker-compose up` command. Four additional services will be
    created based on the Recipes API Docker image. Following are the service logs:![Figure
    6.31 – Scaling the Recipes API
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_6.31_B17115.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.31 – Scaling the Recipes API
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now, when the client sends a request, it will hit Nginx and then be forwarded
    to one of the API services in a round-robin fashion. This helps us evenly distribute
    the load.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In [*Chapter 10*](B17115_10_Final_JM_ePub.xhtml#_idTextAnchor160)*, Capturing
    Gin Application Metrics*, we will learn how to set up a monitoring platform to
    trigger a scale-out event to increase the number of services when the demand increases.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The advantage of using a reverse proxy is that you can set up a single point
    of entry for your entire distributed web application. Both the backend and the
    web application will be located at the same URL. That way, you won't need to handle
    CORS on your API server.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Similar to the Recipes API, create a Docker image for the `react-ui` service.
    The following is the content of our `Dockerfile`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you can see, this is dead simple. Here, you are using a pre-built Node.js
    base image because the `react-ui` service is written in JavaScript.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Build the Docker image with `` `docker build -t dashboard'' ``. Then, update
    `docker-compose.yml` so that it runs a Docker service from the image with the
    following code block:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, update `nginx.conf` so that it forwards incoming requests at the root
    level of the URL to the dashboard service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Rerun the `docker-compose up` `-d` command for the changes to take effect:![Figure
    6.32 – Serving the web dashboard from Nginx
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_6.32_B17115.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.32 – Serving the web dashboard from Nginx
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Head to `localhost/dashboard`; you will be redirected to the web dashboard
    we wrote in the previous chapter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.33 – Serving two backends from the same URL'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.33_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.33 – Serving two backends from the same URL
  prefs: []
  type: TYPE_NORMAL
- en: Now, both the RESTful API and dashboard are being served from the same domain
    name.
  prefs: []
  type: TYPE_NORMAL
- en: 'To take down your containers, you can use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: If you're using session-based authentication, you'll need to configure cookie
    stickiness on Nginx to keep a user's session on the server where it was started.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also serve the subreddits application (built at the beginning of this
    chapter) from the Nginx server by replacing the dashboard location with another
    location section, to the `nginx.conf` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Similar to `react-ui`, create a Docker image for the subreddits application.
    The following is the content of our `Dockerfile`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Here, you are using a pre-built Node.js base image because the dashboard service
    is written in JavaScript. Build the Docker image with `"docker build -t dashboard"`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, don''t forget to add the application to the `docker-compose.yml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you have redeployed the stack with `docker-compose`, head to [localhost/reddit](http://localhost/reddit);
    you will be redirected to the following UI:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.34 – Trending recipes application'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.34_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.34 – Trending recipes application
  prefs: []
  type: TYPE_NORMAL
- en: 'The application layout is broken because the `app.css` file is being served
    from the wrong backend. You can confirm this by opening the debug console on Chrome:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.35 – Stylesheet location'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.35_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.35 – Stylesheet location
  prefs: []
  type: TYPE_NORMAL
- en: 'You can force Nginx to serve the `app.css` file from the subreddit application
    container by adding the following code block to `nginx.conf`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, refresh the web page; the application layout will be fixed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.36 – Application layout'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.36_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.36 – Application layout
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, the dashboard displays the recipes thumbnails. These images
    are then served from the backend each time you refresh the page. To reduce the
    stress on the backend, you can configure Nginx to cache the static files. Insert
    the following code snippet before the `server` section in the Nginx config file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The `~image` keyword will handle all kinds of images (PNG, JPEG, GIF, SVG,
    and so on). Now, configure expiration with the `expires` instruction in the `server`
    section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, redeploy the stack with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: The images should now be cached, which reduces the number of requests hitting
    the backend. In the next section, we will cover how to get the same results in
    the backend with Gin.
  prefs: []
  type: TYPE_NORMAL
- en: Caching assets with HTTP cache headers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can also manage caching with the Gin framework. To illustrate this, write
    a simple web application to serve an image. The code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'The application should serve an image when the user hits the `/illustration`
    resource URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.37 – Serving an image with Gin'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.37_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.37 – Serving an image with Gin
  prefs: []
  type: TYPE_NORMAL
- en: Because the same image is always delivered, we need to make sure that we're
    caching the image. That way, we can avoid having unnecessary traffic and have
    better web performance. Let's see how that is done.
  prefs: []
  type: TYPE_NORMAL
- en: Setting HTTP caching headers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To cache this HTTP request, you can attach an `If-None-Match` field has an
    `Etag` key value. If there is a match between the `If-None-Match` field and the
    key that''s generated, then a 304 status code will be returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you''ve updated the HTTP handler with the preceding code, test it out.
    The first time you ask for the `/illustration` resource, you should get a status
    of `200 OK`. However, for the second request, you should get a `304 StatusNotModified`
    response:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.38 – Response caching with Gin'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.38_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.38 – Response caching with Gin
  prefs: []
  type: TYPE_NORMAL
- en: You may also notice that the latency of the second request is shorter than the
    first one. By keeping the number of queries to a minimum, you can mitigate the
    API's impact on your application's performance.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to build a distributed web application using
    the Gin framework based on the Microservices architecture.
  prefs: []
  type: TYPE_NORMAL
- en: You also have explored how to set up RabbitMQ as a message broker between the
    microservices and how to scale out those services with Docker. Along the way,
    you learned how to maintain the service image's size with Docker's multi-stage
    build feature, as well as how to improve the API's performance with Nginx and
    HTTP caching headers.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn how to write unit and integration tests
    for a Gin web application.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*RabbitMQ Essentials – Second Edition,* by Lovisa Johansson, Packt Publishing'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Docker for Developers,* by Richard Bullington-McGuire, Andrew K. Dennis, Michael
    Schwartz, Packt Publishing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
