<html><head></head><body>
		<div id="_idContainer303">
			<h1 id="_idParaDest-125"><a id="_idTextAnchor131"/>Chapter <a id="_idTextAnchor132"/>8: Deploying the Application on AWS</h1>
			<p>This chapter will teach you how to deploy the <strong class="bold">API</strong> on <strong class="bold">Amazon Web Services</strong> (<strong class="bold">AWS</strong>). It also goes on to explain how to serve the application through <strong class="bold">HTTPS</strong> using a custom domain name, and scale the Gin-based API on Kubernetes and <strong class="bold">Amazon Elastic Container Service</strong> (<strong class="bold">Amazon ECS</strong>).</p>
			<p>As such, we will focus on the following topics:</p>
			<ul>
				<li>Deploying a Gin web application on an <strong class="bold">Amazon Elastic Compute Cloud</strong> (<strong class="bold">Amazon EC2</strong>) instance</li>
				<li>Deploying on Amazon <strong class="bold">ECS</strong> (<strong class="bold">Elastic Container Service</strong>)</li>
				<li>Deploying on Kubernetes with <strong class="bold">Amazon Elastic Kubernetes Service</strong> (<strong class="bold">Amazon EKS</strong>)</li>
			</ul>
			<h1 id="_idParaDest-126"><a id="_idTextAnchor133"/>Technical requirements</h1>
			<p>To follow the instructions in this chapter, you will need the following:</p>
			<ul>
				<li>A complete understanding of the previous chapter—this chapter is a follow-up to the previous one and it will use the same source code. Hence, some snippets won't be explained, to avoid repetition.</li>
				<li>Previous experience of using AWS is mandatory.</li>
				<li>A basic understanding of Kubernetes is required.</li>
			</ul>
			<p>The code bundle for this chapter is hosted on GitHub at <a href="https://github.com/PacktPublishing/Building-Distributed-Applications-in-Gin/tree/main/chapter08">https://github.com/PacktPublishing/Building-Distributed-Applications-in-Gin/tree/main/chapter08</a>.</p>
			<h1 id="_idParaDest-127"><a id="_idTextAnchor134"/>Deploying on EC2 instance</h1>
			<p>Throughout the course of the book, you have learned how to build a distributed web application <a id="_idIndexMarker637"/>using the Gin framework <a id="_idIndexMarker638"/>and how to scale the API for loading and testing it locally. In this section, we will cover how to deploy the following architecture on the cloud and serve it to external users. </p>
			<p>An overview of the application architecture can be seen here:</p>
			<div>
				<div id="_idContainer261" class="IMG---Figure">
					<img src="image/B17115_08_01_v2.jpg" alt="Figure 8.1 – Application architecture&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.1 – Application architecture</p>
			<p>AWS is the leader when it comes to cloud providers—it offers a huge range of infrastructure services such as load balancers, servers, databases, and network services.</p>
			<p>To get started, create an AWS account (<a href="https://aws.amazon.com">https://aws.amazon.com</a>). Most AWS services offer an abundance of Free Tier resources, so deploying your application will cost you little or nothing.</p>
			<h2 id="_idParaDest-128"><a id="_idTextAnchor135"/>Launching an EC2 instance</h2>
			<p>With the <a id="_idIndexMarker639"/>AWS account created, you are now ready to launch an EC2 instance. To do so, proceed as follows:</p>
			<ol>
				<li>Sign in to the <strong class="bold">AWS Management Console</strong> (<a href="https://console.aws.amazon.com">https://console.aws.amazon.com</a>) and search for <strong class="bold">EC2</strong>. In the <strong class="bold">EC2</strong> dashboard, click on the <strong class="bold">Launch Instance</strong> button to provision a new EC2 instance.</li>
				<li>Choose <strong class="bold">Amazon Linux 2 AMI</strong> as an <strong class="bold">Amazon Machine Image</strong> (<strong class="bold">AMI</strong>). This is the <strong class="bold">operating system</strong> (<strong class="bold">OS</strong>) that <a id="_idIndexMarker640"/>will run <a id="_idIndexMarker641"/>the EC2 instance. The following screenshot provides an overview of this:<div id="_idContainer262" class="IMG---Figure"><img src="image/B17115_08_02_v2.jpg" alt="Figure 8.2 – AMI&#13;&#10;"/></div><p class="figure-caption">Figure 8.2 – AMI</p></li>
				<li>Next, select an instance type. You can start with a <strong class="source-inline">t2.micro</strong> instance and upgrade later if needed. Then, click on <strong class="bold">Configure Instance Details</strong> and leave the settings at their defaults, as illustrated in the following screenshot:<div id="_idContainer263" class="IMG---Figure"><img src="image/B17115_08_03_v2.jpg" alt="Figure 8.3 – Instance configuration&#13;&#10;"/></div><p class="figure-caption">Figure 8.3 – Instance configuration</p></li>
				<li>Now, click <a id="_idIndexMarker642"/>on the <strong class="bold">Add Storage</strong> button and <a id="_idIndexMarker643"/>leave the <strong class="bold">Elastic Block Store</strong> (<strong class="bold">EBS</strong>) volume <a id="_idIndexMarker644"/>size as 8 <strong class="bold">gigabytes</strong> (<strong class="bold">GB</strong>). For <strong class="bold">Volume type</strong>, you might change it from <strong class="source-inline">GP2</strong> to <strong class="source-inline">GP3</strong> or provisioned IOPS.<p class="callout-heading">Note</p><p class="callout">MongoDB requires fast storage. Therefore, if you're planning to host a MongoDB container on EC2, an EBS-optimized <a id="_idIndexMarker645"/>type can improve the <strong class="bold">input/output</strong> (<strong class="bold">I/O</strong>) operations.</p></li>
				<li>Then, click on <strong class="bold">Add Tags</strong> and create a new one called <strong class="source-inline">Name=application-sg</strong>, as illustrated in the following screenshot. Leave the security group at its default setting (allow inbound traffic on port 22 for SSH). Then, click on <strong class="bold">Review and launch</strong>:<div id="_idContainer264" class="IMG---Figure"><img src="image/B17115_08_04_v2.jpg" alt="Figure 8.4 – Security group&#13;&#10;"/></div><p class="figure-caption">Figure 8.4 – Security group</p><p class="callout-heading">Note</p><p class="callout">As a best practice, you should <a id="_idIndexMarker646"/>always restrict <strong class="bold">Secure Shell</strong> (<strong class="bold">SSH</strong>) solely to <a id="_idIndexMarker647"/>known static <strong class="bold">Internet Protocol</strong> (<strong class="bold">IP</strong>) addresses or networks.</p></li>
				<li>Click on <strong class="bold">Launch</strong> and assign <a id="_idIndexMarker648"/>a key pair or create a new SSH key pair. Then, click on <strong class="bold">Create instance</strong>.</li>
				<li>Head back to the <strong class="bold">Instances</strong> dashboard by clicking on the <strong class="bold">View instances</strong> button—it will take a few seconds for the instance to be up and running but you should then see it on the screen, as per the following screenshot:<div id="_idContainer265" class="IMG---Figure"><img src="image/Figure_8.5_B17115.jpg" alt="Figure 8.5 – EC2 dashboard&#13;&#10;"/></div><p class="figure-caption">Figure 8.5 – EC2 dashboard</p></li>
				<li>Once the instance is ready, open your terminal session and SSH to the instance using <a id="_idIndexMarker649"/>the public <strong class="bold">IP version 4</strong> (<strong class="bold">IPv4</strong>) address. Replace <strong class="source-inline">key.pem</strong> with your SSH key pair, as illustrated here:<p class="source-code"><strong class="bold">ssh ec2-user@IP –I key.pem</strong></p></li>
				<li>A confirmation <a id="_idIndexMarker650"/>message will appear—enter <strong class="source-inline">Yes</strong>. Then, issue <a id="_idIndexMarker651"/>the following commands to install Git, <strong class="bold">Docker Community Edition</strong> (<strong class="bold">Docker CE</strong>), and Docker Compose:<p class="source-code"><strong class="bold">sudo su</strong></p><p class="source-code"><strong class="bold">yum update -y</strong></p><p class="source-code"><strong class="bold">yum install -y docker git</strong></p><p class="source-code"><strong class="bold">usermod –a -G docker ec2-user</strong></p><p class="source-code"><strong class="bold">service docker restart</strong></p><p class="source-code"><strong class="bold">curl -L "https://github.com/docker/compose/releases/download/1.29.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/bin/docker-compose</strong></p><p class="source-code"><strong class="bold">chmod +x /usr/bin/docker-compose</strong></p><p class="callout-heading">Note</p><p class="callout">The <strong class="source-inline">sudo su</strong> command is used to provide the privileges at the root level.</p><p>Here, we are using the Docker <strong class="source-inline">19.03.13-ce</strong> and Docker Compose <strong class="source-inline">1.29.0</strong> versions:</p></li>
			</ol>
			<div>
				<div id="_idContainer266" class="IMG---Figure">
					<img src="image/Figure_8.6_B17115.jpg" alt="Figure 8.6 – Docker version&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.6 – Docker version</p>
			<p>You have successfully provisioned and launched an EC2 instance. </p>
			<p>With the EC2 instance up and running, you can deploy your <strong class="bold">Docker Compose</strong> stack covered in <a href="B17115_06_Final_JM_ePub.xhtml#_idTextAnchor103"><em class="italic">Chapter 6</em></a>, <em class="italic">Scaling a Gin Application</em>. To do so, perform the following steps:</p>
			<ol>
				<li value="1">Clone the <a id="_idIndexMarker652"/>following GitHub repository, which includes the components and files for the distributed Gin web application:<p class="source-code"><strong class="bold">git clone https://github.com/PacktPublishing/Building-Distributed-Applications-in-Gin.git</strong></p><p class="source-code"><strong class="bold">cd Building-Distributed-Applications-in-Gin/chapter06</strong></p><p>Here is <a id="_idIndexMarker653"/>the content of the <strong class="source-inline">chapter06/docker-compose.yml</strong> file:</p><p class="source-code">version: "3.9"</p><p class="source-code">services:</p><p class="source-code"> api:</p><p class="source-code">   image: api</p><p class="source-code">   environment:</p><p class="source-code">     - MONGO_URI=mongodb://admin:password</p><p class="source-code">           @mongodb:27017/test?authSource=admin</p><p class="source-code">           &amp;readPreference=primary&amp;ssl=false</p><p class="source-code">     - MONGO_DATABASE=demo</p><p class="source-code">     - REDIS_URI=redis:6379</p><p class="source-code">   external_links:</p><p class="source-code">     - mongodb</p><p class="source-code">     - redis</p><p class="source-code">   scale: 5</p><p class="source-code"> dashboard:</p><p class="source-code">   image: dashboard</p><p class="source-code"> redis:</p><p class="source-code">   image: redis</p><p class="source-code"> mongodb:</p><p class="source-code">   image: mongo:4.4.3</p><p class="source-code">   environment:</p><p class="source-code">     - MONGO_INITDB_ROOT_USERNAME=admin</p><p class="source-code">     - MONGO_INITDB_ROOT_PASSWORD=password</p><p class="source-code"> nginx:</p><p class="source-code">   image: nginx</p><p class="source-code">   ports:</p><p class="source-code">     - 80:80</p><p class="source-code">   volumes:</p><p class="source-code">     - $PWD/nginx.conf:/etc/nginx/nginx.conf</p><p class="source-code">   depends_on:</p><p class="source-code">     - api</p><p class="source-code">     - dashboard</p><p>The stack <a id="_idIndexMarker654"/>consists of the following services:</p><p>a. RESTful <a id="_idIndexMarker655"/>API written with Go and the Gin framework</p><p>b. A dashboard written with JavaScript and the React framework</p><p>c. MongoDB for data storage</p><p>d. Redis for in-memory storage and API caching</p><p>e. Nginx as a reverse proxy</p></li>
				<li>Before deploying the stack, build the Docker images for the RESTful API and the web dashboard. Head <a id="_idIndexMarker656"/>to the corresponding folder of each service and run the <strong class="source-inline">docker build</strong> command. For instance, the following commands are used to build the Docker image for the RESTful API:<p class="source-code"><strong class="bold">cd api</strong></p><p class="source-code"><strong class="bold">docker build -t api .</strong></p><p>The command output is shown here:</p><div id="_idContainer267" class="IMG---Figure"><img src="image/Figure_8.7_B17115.jpg" alt="Figure 8.7 – Docker build logs&#13;&#10;"/></div><p class="figure-caption">Figure 8.7 – Docker build logs</p></li>
				<li>After building the images, issue the following command:<p class="source-code"><strong class="bold">cd ..</strong></p><p class="source-code"><strong class="bold">docker-compose up –d</strong></p><p>The services <a id="_idIndexMarker657"/>will be deployed, and five instances of the API will be created, as illustrated in the following screenshot:</p></li>
			</ol>
			<div>
				<div id="_idContainer268" class="IMG---Figure">
					<img src="image/Figure_8.8_B17115.jpg" alt="Figure 8.8 – Docker application&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.8 – Docker application</p>
			<p>With the application up and running, go to the web browser and paste the IP address that is used to connect to your EC2 instance. You should then see the following error message:</p>
			<div>
				<div id="_idContainer269" class="IMG---Figure">
					<img src="image/Figure_8.9_B17115.jpg" alt="Figure 8.9 – Request timeout&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.9 – Request timeout</p>
			<p>To fix that, you need <a id="_idIndexMarker658"/>to allow inbound traffic on port 80, which is the port the nginx proxy is exposed to. Head to <strong class="bold">Security Groups</strong> from the EC2 dashboard and search for the security group assigned to the EC2 instance in which the application is running. Once found, add an inbound rule, as follows:</p>
			<div>
				<div id="_idContainer270" class="IMG---Figure">
					<img src="image/Figure_8.10_B17115.jpg" alt="Figure 8.10 – Inbound rule on port 80&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.10 – Inbound rule on port 80</p>
			<p>Head back to <a id="_idIndexMarker659"/>your web browser and issue an HTTP request to the instance IP. This time, the nginx proxy will be hit and a response will be returned. If you issue a request to the <strong class="source-inline">/api/recipes</strong> endpoint, an empty array should be returned, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer271" class="IMG---Figure">
					<img src="image/Figure_8.11_B17115.jpg" alt="Figure 8.11 – RESTful API response&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.11 – RESTful API response</p>
			<p>The MongoDB <strong class="source-inline">recipes</strong> collection is empty. So, create a new recipe by issuing a <strong class="source-inline">POST </strong>request <a id="_idIndexMarker660"/>on the <strong class="source-inline">/api/recipes</strong> endpoint with the following JSON payload:</p>
			<div>
				<div id="_idContainer272" class="IMG---Figure">
					<img src="image/Figure_8.12_B17115.jpg" alt="Figure 8.12 – A POST request to create a new recipe&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.12 – A POST request to create a new recipe</p>
			<p>Make sure to include an <strong class="source-inline">Authorization</strong> header in the <strong class="source-inline">POST</strong> request. Refresh the web browser page <a id="_idIndexMarker661"/>and a recipe should then be returned on the web dashboard, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer273" class="IMG---Figure">
					<img src="image/Figure_8.13_B17115.jpg" alt="Figure 8.13 – New recipe&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.13 – New recipe</p>
			<p>Now, click on the <strong class="bold">Login</strong> button, and you should have an unsecure origin error, as follows:</p>
			<div>
				<div id="_idContainer274" class="IMG---Figure">
					<img src="image/Figure_8.14_B17115.jpg" alt="Figure 8.14 – Auth0 requires the client to be run though HTTPS&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.14 – Auth0 requires the client to be run though HTTPS</p>
			<p>The error is <a id="_idIndexMarker662"/>due to Auth0 needing to be run on a web application served through the HTTPS protocol. You can serve the application through HTTPS by <a id="_idIndexMarker663"/>setting up a <strong class="bold">load balancer</strong> on top of the EC2 instance.</p>
			<h2 id="_idParaDest-129"><a id="_idTextAnchor136"/>SSL offloading with an application load balancer</h2>
			<p>To run the API <a id="_idIndexMarker664"/>through HTTPS, we need a <strong class="bold">Secure Sockets Layer</strong> (<strong class="bold">SSL</strong>) certificate. You <a id="_idIndexMarker665"/>can easily get an SSL certificate with <strong class="bold">AWS Certificate Manager</strong> (<strong class="bold">ACM</strong>). This service makes it <a id="_idIndexMarker666"/>easy to provision, manage, and deploy SSL/<strong class="bold">Transport Layer Security</strong> (<strong class="bold">TLS</strong>) certificates on AWS-managed resources. To generate <a id="_idIndexMarker667"/>an SSL certificate, proceed as follows:</p>
			<ol>
				<li value="1">Head <a id="_idIndexMarker668"/>to the ACM dashboard and request a free SSL certificate for your domain name <a id="_idIndexMarker669"/>by clicking on the <strong class="bold">Request a certificate</strong> button and choosing <strong class="bold">Request a public certificate</strong>. </li>
				<li>On <a id="_idIndexMarker670"/>the <strong class="bold">Add domain names</strong> page, enter a <strong class="bold">fully qualified domain name</strong> (<strong class="bold">FQDN</strong>), such as <strong class="source-inline">domain.com</strong>.<p class="callout-heading">Note</p><p class="callout">The <strong class="source-inline">domain.com</strong> domain name can have multiple subdomains, such as <strong class="source-inline">sandbox.domain.com</strong>, <strong class="source-inline">production.domain.com</strong>, and <strong class="source-inline">api.domain.com</strong>.</p></li>
				<li>On the <strong class="bold">Select validation method</strong> page, choose <strong class="bold">DNS validation</strong> and add a <strong class="bold">Canonical Name</strong> (<strong class="bold">CNAME</strong>) record <a id="_idIndexMarker671"/>provided by ACM to your <strong class="bold">Domain Name System</strong> (<strong class="bold">DNS</strong>) configuration. Issuing public certificates <a id="_idIndexMarker672"/>might take a few minutes, but once the <a id="_idIndexMarker673"/>domain name is validated, the <a id="_idIndexMarker674"/>certificate will be issued and will appear in the ACM dashboard with the status set to <strong class="bold">Issued</strong>, as illustrated in the following screenshot:<div id="_idContainer275" class="IMG---Figure"><img src="image/Figure_8.15_B17115.jpg" alt="Figure 8.15 – Requesting a public certificate with ACM&#13;&#10;"/></div><p class="figure-caption">Figure 8.15 – Requesting a public certificate with ACM</p></li>
				<li>Next, create an application load balancer from the <strong class="bold">Load Balancers</strong> section within the EC2 dashboard, as illustrated in the following screenshot:<div id="_idContainer276" class="IMG---Figure"><img src="image/Figure_8.16_B17115.jpg" alt="Figure 8.16 – Application load balancer&#13;&#10;"/></div><p class="figure-caption">Figure 8.16 – Application load balancer</p></li>
				<li>On the subsequent page, enter a name for the load balancer and specify the scheme as <strong class="bold">Internet facing</strong> from the drop-down list. In the <strong class="bold">Availability Zones</strong> section, select a <a id="_idIndexMarker675"/>subnet from each <strong class="bold">availability zone</strong> (<strong class="bold">AZ</strong>) for resiliency. Then, under the <strong class="bold">Listeners</strong> section, add an HTTPS <a id="_idIndexMarker676"/>listener and an HTTP <a id="_idIndexMarker677"/>listener on ports 443 and 80, respectively, as illustrated in the following screenshot:<div id="_idContainer277" class="IMG---Figure"><img src="image/B17115_08_17_v2.jpg" alt="Figure 8.17 – HTTP and HTTPS listeners&#13;&#10;"/></div><p class="figure-caption">Figure 8.17 – HTTP and HTTPS listeners</p></li>
				<li>Click on the <strong class="bold">Configure Security Settings</strong> button to proceed and select the certificate created in ACM from the drop-down list, as illustrated in the following screenshot:<div id="_idContainer278" class="IMG---Figure"><img src="image/B17115_08_18_v2.jpg" alt="Figure 8.18 – Certificate configuration&#13;&#10;"/></div><p class="figure-caption">Figure 8.18 – Certificate configuration</p></li>
				<li>Now, click on <strong class="bold">Configure Routing</strong> and create a new target group called <strong class="bold">application</strong>. Ensure the protocol is set to HTTP and the port to 80 because the nginx proxy <a id="_idIndexMarker678"/>is listening on <a id="_idIndexMarker679"/>port 80. With this configuration, traffic between the load balancer and the instance will be transmitted using HTTP, even for HTTPS requests made by the client to the load balancer. You can see the configuration in the following screenshot:<div id="_idContainer279" class="IMG---Figure"><img src="image/B17115_08_19_v2.jpg" alt="Figure 8.19 – Configuring a target group&#13;&#10;"/></div><p class="figure-caption">Figure 8.19 – Configuring a target group</p></li>
				<li>In <a id="_idIndexMarker680"/>the <strong class="bold">Health checks</strong> section, define <a id="_idIndexMarker681"/>the protocol as <strong class="source-inline">HTTP</strong> and the path as <strong class="source-inline">/api/recipes</strong>. </li>
				<li>Click on <strong class="bold">Register Targets</strong>, select the EC2 instance on which the application is running, and click on <strong class="bold">Add to registered</strong>, as follows:<div id="_idContainer280" class="IMG---Figure"><img src="image/Figure_8.20_B17115.jpg" alt="Figure 8.20 – Registering an EC2 instance&#13;&#10;"/></div><p class="figure-caption">Figure 8.20 – Registering an EC2 instance</p></li>
				<li>When <a id="_idIndexMarker682"/>you have finished selecting instances, choose <strong class="bold">Next: Review</strong>. Review the settings <a id="_idIndexMarker683"/>that you selected and click on the <strong class="bold">Create</strong> button. The provisioning process should take a few minutes, but you should then see a screen like this:<div id="_idContainer281" class="IMG---Figure"><img src="image/Figure_8.21_B17115.jpg" alt="Figure 8.21 – Load balancer DNS name&#13;&#10;"/></div><p class="figure-caption">Figure 8.21 – Load balancer DNS name</p></li>
				<li>Once the state is <strong class="bold">active</strong>, copy the load balancer DNS name and create an <strong class="source-inline">A</strong> record that points to the public DNS name of the load balancer in Route 53 (<a href="https://aws.amazon.com/route53/">https://aws.amazon.com/route53/</a>) or in your DNS registrar, as illustrated in the following screenshot:</li>
			</ol>
			<div>
				<div id="_idContainer282" class="IMG---Figure">
					<img src="image/Figure_8.22_B17115.jpg" alt="Figure 8.22 – Route 53 new A record&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.22 – Route 53 new A record</p>
			<p>Once <a id="_idIndexMarker684"/>you make the <a id="_idIndexMarker685"/>necessary changes, it can take up to 48 hours for the change to propagate across other DNS servers.</p>
			<p>Verify that the changes to your domain name record have propagated by browsing to <a href="HTTPS://recipes.domain.com">HTTPS://recipes.domain.com</a>. This should result in the load balancer displaying the secure web dashboard of the application. Click on the <em class="italic">padlock</em> icon in the browser address bar and it should display the details of the domain and the SSL certificate, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer283" class="IMG---Figure">
					<img src="image/Figure_8.23_B17115.jpg" alt="Figure 8.23 – Serving through HTTPS&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.23 – Serving through HTTPS</p>
			<p>Your application load balancer has now been configured with an SSL certificate for your Gin application running on AWS. You can use the Auth0 service to sign in and add new recipes from the web dashboard.</p>
			<h1 id="_idParaDest-130"><a id="_idTextAnchor137"/>Deploying on Amazon ECS</h1>
			<p>In the previous section, we learned how to deploy an EC2 instance and configure it to run our Gin <a id="_idIndexMarker686"/>application on it. In this section, we will learn how to <a id="_idIndexMarker687"/>get the same results without managing <a id="_idIndexMarker688"/>an EC2 instance. AWS proposes two container orchestration services: <strong class="bold">ECS</strong> and <strong class="bold">EKS</strong>. </p>
			<p>In this section, you will learn about ECS, which is a fully managed container orchestration service. Before deploying our application to ECS, we need to store the application <a id="_idIndexMarker689"/>Docker images in a remote repository. That's where an <strong class="bold">Elastic Container Registry</strong> (<strong class="bold">ECR</strong>) repository comes into play.</p>
			<h2 id="_idParaDest-131"><a id="_idTextAnchor138"/>Storing images in a private repository</h2>
			<p>ECR is a <a id="_idIndexMarker690"/>widely used private Docker <a id="_idIndexMarker691"/>registry. To store images in a private repository, you <a id="_idIndexMarker692"/>need to create a repository in ECR first. To achieve that, follow these steps:</p>
			<ol>
				<li value="1">Jump to the ECR dashboard from the <strong class="bold">AWS Management Console</strong>, click on the <strong class="bold">Create repository</strong> button, and choose <strong class="source-inline">mlabouardy/recipes-api</strong> as a name for your Gin RESTful API repository, as illustrated in the following screenshot: <div id="_idContainer284" class="IMG---Figure"><img src="image/Figure_8.24_B17115.jpg" alt="Figure 8.24 – New ECR repository&#13;&#10;"/></div><p class="figure-caption">Figure 8.24 – New ECR repository</p><p class="callout-heading">Note</p><p class="callout">You can host your Docker images in Docker Hub. If you go with this approach, you can skip this part.</p></li>
				<li>Click <a id="_idIndexMarker693"/>on the <strong class="bold">Create repository</strong> button, and then <a id="_idIndexMarker694"/>select the repository <a id="_idIndexMarker695"/>and click on <strong class="bold">View push commands</strong>. Copy the commands to authenticate and push the API image to the repository, as illustrated in the following screenshot:<div id="_idContainer285" class="IMG---Figure"><img src="image/Figure_8.25_B17115.jpg" alt="Figure 8.25 – ECR login and push commands&#13;&#10;"/></div><p class="figure-caption">Figure 8.25 – ECR login and push commands</p><p class="callout-heading">Note</p><p class="callout">For a <a id="_idIndexMarker696"/>step-by-step <a id="_idIndexMarker697"/>guide on how to install the AWS <strong class="bold">command-line interface</strong> (<strong class="bold">CLI</strong>), refer to the official <a id="_idIndexMarker698"/>documentation at <a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html">https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html</a>.</p></li>
				<li>Follow <a id="_idIndexMarker699"/>the commands shown in <em class="italic">Figure 8.25</em> to authenticate with ECR. Tag the image and push it to the remote repository, as follows (substitute the <strong class="source-inline">ID</strong>, <strong class="source-inline">REGION</strong>, and <strong class="source-inline">USER</strong> variables with your own values):</li>
			</ol>
			<p class="source-code">aws ecr get-login-password --region REGION | docker login --username AWS --password-stdin ID.dkr.ecr.REGION.amazonaws.com</p>
			<p class="source-code">docker tag api ID.dkr.ecr.REGION.amazonaws.com/USER/recipes-api:latest</p>
			<p class="source-code">docker push ID.dkr.ecr.REGION.amazonaws.com/USER/recipes-api:latest</p>
			<p>The command logs are shown here:</p>
			<div>
				<div id="_idContainer286" class="IMG---Figure">
					<img src="image/Figure_8.26_B17115.jpg" alt="Figure 8.26 – Pushing an image to ECR&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.26 – Pushing an image to ECR</p>
			<p>The <a id="_idIndexMarker700"/>image will now be available <a id="_idIndexMarker701"/>on ECR, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer287" class="IMG---Figure">
					<img src="image/Figure_8.27_B17115.jpg" alt="Figure 8.27 – Image stored on ECR&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.27 – Image stored on ECR</p>
			<p>With the <a id="_idIndexMarker702"/>Docker image stored in ECR, you can go ahead and deploy the application in ECS.</p>
			<p>Now, update <a id="_idIndexMarker703"/>the <strong class="source-inline">docker-compose.yml</strong> file to reference the ECR repository URI in the <strong class="source-inline">image</strong> section, as follows:</p>
			<p class="source-code">version: "3.9"</p>
			<p class="source-code">services:</p>
			<p class="source-code"> api:</p>
			<p class="source-code">   image: ACCOUNT_ID.dkr.ecr.eu-central-1.amazonaws.com/</p>
			<p class="source-code">      mlabouardy/recipes-api:latest</p>
			<p class="source-code">   environment:</p>
			<p class="source-code">     - MONGO_URI=mongodb://admin:password@mongodb:27017/</p>
			<p class="source-code">           test?authSource=admin&amp;readPreference=</p>
			<p class="source-code">           primary&amp;ssl=false</p>
			<p class="source-code">     - MONGO_DATABASE=demo</p>
			<p class="source-code">     - REDIS_URI=redis:6379</p>
			<p class="source-code">   external_links:</p>
			<p class="source-code">     - mongodb</p>
			<p class="source-code">     - redis</p>
			<p class="source-code">   scale: 5</p>
			<p class="source-code"> dashboard:</p>
			<p class="source-code">   image: ACCOUNT_ID.dkr.ecr.eu-central-1.amazonaws.com/</p>
			<p class="source-code">       mlabouardy/dashboard:latest</p>
			<h2 id="_idParaDest-132"><a id="_idTextAnchor139"/>Creating an ECS cluster</h2>
			<p>Our <strong class="source-inline">docker-compose.yml</strong> file now references the images stored in ECR. We're ready to spin up <a id="_idIndexMarker704"/>the ECS cluster and deploy the application on it.</p>
			<p>You can deploy an ECS cluster either manually from the <strong class="bold">AWS Management Console</strong> or through the AWS ECS CLI. Follow the official instructions to install the Amazon ECS CLI based on your OS from <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ECS_CLI_installation.htm">https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ECS_CLI_installation.htm</a>.</p>
			<p>Once installed, configure the Amazon ECS CLI by providing the AWS credentials and the AWS region in which to create the cluster, as follows:</p>
			<p class="source-code">ecs-cli configure profile --profile-name default --access-key KEY --secret-key SECRET</p>
			<p>Before provisioning an ECS cluster, define a task execution <strong class="source-inline">IAM</strong> role to allow the Amazon ECS container <a id="_idIndexMarker705"/>agent to make AWS API calls on our behalf. Create a file named <strong class="source-inline">task-execution-assule-role.json</strong> with the following content:</p>
			<p class="source-code">{</p>
			<p class="source-code">   "Version": "2012-10-17",</p>
			<p class="source-code">   "Statement": [</p>
			<p class="source-code">       {</p>
			<p class="source-code">           "Sid": "",</p>
			<p class="source-code">           "Effect": "Allow",</p>
			<p class="source-code">           "Principal": {</p>
			<p class="source-code">               "Service": "ecs-tasks.amazonaws.com"</p>
			<p class="source-code">           },</p>
			<p class="source-code">           "Action": "sts:AssumeRole"</p>
			<p class="source-code">       }</p>
			<p class="source-code">   ]</p>
			<p class="source-code">}</p>
			<p>Create a task execution role using the JSON file, and attach the <strong class="source-inline">AmazonECSTaskExecutionRolePolicy</strong> task execution role policy to it, as follows:</p>
			<p class="source-code">aws iam --region REGION create-role --role-name ecsTaskExecutionRole --assume-role-policy-document file://task-execution-assume-role.json</p>
			<p class="source-code">aws iam --region REGION attach-role-policy --role-name ecsTaskExecutionRole --policy-arn arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy</p>
			<p>Complete the configuration with the following command, the default cluster name, and launch type. Then, create an Amazon ECS cluster with the <strong class="source-inline">ecs-cli</strong> <strong class="source-inline">up</strong> command:</p>
			<p class="source-code">ecs-cli configure --cluster sandbox --default-launch-type FARGATE --config-name sandbox --region REGION</p>
			<p class="source-code">ecs-cli up --cluster-config sandbox --aws-profile default</p>
			<p>This command may <a id="_idIndexMarker706"/>take a few minutes to complete as your resources (EC2 instances, load balancers, security groups, and so on) are created. The output of this command is shown here:</p>
			<div>
				<div id="_idContainer288" class="IMG---Figure">
					<img src="image/Figure_8.28_B17115.jpg" alt="Figure 8.28 – Creating an ECS cluster&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.28 – Creating an ECS cluster</p>
			<p>Jump to the ECS dashboard—the sandbox cluster should be up and running, as it is in the following screenshot:</p>
			<div>
				<div id="_idContainer289" class="IMG---Figure">
					<img src="image/Figure_8.29_B17115.jpg" alt="Figure 8.29 – Sandbox cluster&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.29 – Sandbox cluster</p>
			<p>To deploy the application, you can use the <strong class="source-inline">docker-compose</strong> file provided in the previous section. In addition to that, there are certain parameters specific to Amazon ECS that you need to provide in the config file, such as the following: </p>
			<ul>
				<li><strong class="bold">Subnets</strong>: To be replaced with a list of public subnets where the EC2 instances should be deployed</li>
				<li><strong class="bold">Security group and resource usage</strong>: <strong class="bold">Central processing unit</strong> (<strong class="bold">CPU</strong>) and <a id="_idIndexMarker707"/>memory</li>
			</ul>
			<p>Create <a id="_idIndexMarker708"/>an <strong class="source-inline">ecs-params.yml</strong> file with the following content:</p>
			<p class="source-code">version: 1</p>
			<p class="source-code">task_definition:</p>
			<p class="source-code"> task_execution_role: ecsTaskExecutionRole</p>
			<p class="source-code"> ecs_network_mode: awsvpc</p>
			<p class="source-code"> task_size:</p>
			<p class="source-code">   mem_limit: 2GB</p>
			<p class="source-code">   cpu_limit: 256</p>
			<p class="source-code">run_params:</p>
			<p class="source-code"> network_configuration:</p>
			<p class="source-code">   awsvpc_configuration:</p>
			<p class="source-code">     subnets:</p>
			<p class="source-code">       - "subnet-e0493c88"</p>
			<p class="source-code">       - "subnet-7472493e"</p>
			<p class="source-code">     security_groups:</p>
			<p class="source-code">       - "sg-d84cb3b3"</p>
			<p class="source-code">     assign_public_ip: ENABLED</p>
			<p>Next, deploy the <strong class="source-inline">docker compose</strong> file to the cluster with the following command. The <strong class="source-inline">--create-log-groups</strong> option creates the CloudWatch log groups for the container logs:</p>
			<p class="source-code">ecs-cli compose --project-name application -f </p>
			<p class="source-code">docker-compose.ecs.yml up --cluster sandbox </p>
			<p class="source-code">--create-log-groups</p>
			<p>The deployment logs are shown here:</p>
			<div>
				<div id="_idContainer290" class="IMG---Figure">
					<img src="image/Figure_8.30_B17115.jpg" alt="Figure 8.30 – Task deployment&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.30 – Task deployment</p>
			<p>An <strong class="source-inline">application</strong> task <a id="_idIndexMarker709"/>will be created. A <strong class="bold">task</strong> is a set of metadata (memory, CPU, port mapping, environment variables) that describes how a container should be deployed. You can see an overview of this here:</p>
			<div>
				<div id="_idContainer291" class="IMG---Figure">
					<img src="image/Figure_8.31_B17115.jpg" alt="Figure 8.31 – Task definition&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.31 – Task definition</p>
			<p>Using the AWS CLI, add a security group rule to allow inbound traffic on port 80, as follows:</p>
			<p class="source-code">aws ec2 authorize-security-group-ingress --group-id SG_ID --protocol tcp --port 80 --cidr 0.0.0.0/0 --region REGION</p>
			<p>Issue the following command to view the containers that are running in ECS:</p>
			<p class="source-code">ecs-cli compose --project-name application service ps –cluster--config sandbox --ecs-profile default</p>
			<p>The command will list the containers running and also the IP address and port of the nginx service. If you point your web browser at that address, you should see the web dashboard.</p>
			<p>Great! You now have a running ECS cluster with the Dockerized Gin application.</p>
			<h1 id="_idParaDest-133"><a id="_idTextAnchor140"/>Deploying on Kubernetes with Amazon EKS</h1>
			<p>ECS might be a good solution for beginners and small workloads. However, for large deployment <a id="_idIndexMarker710"/>and at a certain scale, you might <a id="_idIndexMarker711"/>want to consider shifting to Kubernetes (also known as <strong class="bold">K8s</strong>). For <a id="_idIndexMarker712"/>those of you who are AWS power users, Amazon EKS is a natural fit.</p>
			<p>AWS offers a managed Kubernetes solution under the EKS service. </p>
			<p>To get started, we need to deploy an EKS cluster, as follows:</p>
			<ol>
				<li value="1">Jump to the EKS dashboard and create a new cluster with the following parameters:<div id="_idContainer292" class="IMG---Figure"><img src="image/Figure_8.32_B17115.jpg" alt="Figure 8.32 – EKS cluster creation&#13;&#10;"/></div><p class="figure-caption">Figure 8.32 – EKS cluster creation</p><p>The cluster <strong class="source-inline">IAM</strong> role <a id="_idIndexMarker713"/>should include the following <strong class="bold">Identity and Access Management</strong> (<strong class="bold">IAM</strong>) policies: <strong class="source-inline">AmazonEKSWorkerNodePolicy</strong>, <strong class="source-inline">AmazonEKS_CNI_Policy</strong>, and <strong class="source-inline">AmazonEC2ContainerRegistryReadOnly</strong>.</p></li>
				<li>On the <strong class="bold">Specify networking</strong> page, select an existing <strong class="bold">virtual private cloud</strong> (<strong class="bold">VPC</strong>) to use <a id="_idIndexMarker714"/>for the cluster and subnets, as illustrated in the following screenshot. Leave the rest at their default settings:<div id="_idContainer293" class="IMG---Figure"><img src="image/Figure_8.33_B17115.jpg" alt="Figure 8.33 – EKS network configuration&#13;&#10;"/></div><p class="figure-caption">Figure 8.33 – EKS network configuration</p></li>
				<li>For <a id="_idIndexMarker715"/>cluster endpoint access, enable <a id="_idIndexMarker716"/>public access for <a id="_idIndexMarker717"/>simplicity. For a production usage, restrict access to your network <strong class="bold">Classless Inter-Domain Routing</strong> (<strong class="bold">CIDR</strong>) or enable only private access to the cluster API. </li>
				<li>Then, on the <strong class="bold">Configure Logging</strong> page, enable all log types to be able to troubleshoot or debug network issues from the CloudWatch console easily.</li>
				<li>Review the information and click on <strong class="bold">Create</strong>. The status file will show <strong class="bold">Creating</strong> while the cluster provisioning process is running. Once completed, the status will become <strong class="bold">Active</strong>, as illustrated in the following screenshot:<div id="_idContainer294" class="IMG---Figure"><img src="image/Figure_8.34_B17115.jpg" alt="Figure 8.34 – New EKS cluster&#13;&#10;"/></div><p class="figure-caption">Figure 8.34 – New EKS cluster</p><p>Optionally, create <a id="_idIndexMarker718"/>an EKS cluster <a id="_idIndexMarker719"/>with the EKS CLI through a single command, as follows:</p><p class="source-code">eksctl create cluster --name sandbox --version 1.19 --with-oidc --region REGION</p><p class="callout-heading">Note</p><p class="callout">For a step-by-step guide on how to provision EKS with <strong class="source-inline">eksctl</strong>, head over to the official guide at <a href="https://docs.aws.amazon.com/eks/latest/userguide/create-cluster.html">https://docs.aws.amazon.com/eks/latest/userguide/create-cluster.html</a>.</p></li>
				<li>Once the cluster is in an <strong class="bold">Active</strong> state, create a managed Node Group on which the containers will be running. </li>
				<li>Click on the cluster name and select the <strong class="bold">Configuration</strong> tab. On the <strong class="bold">Compute</strong> tab, click on <strong class="bold">Add Node Group</strong>. Set the group name to <strong class="source-inline">workers</strong> and create a Node IAM role, as illustrated in the following screenshot:<div id="_idContainer295" class="IMG---Figure"><img src="image/Figure_8.35_B17115.jpg" alt="Figure 8.35 – EKS Node Group&#13;&#10;"/></div><p class="figure-caption">Figure 8.35 – EKS Node Group</p><p class="callout-heading">Note</p><p class="callout">For more <a id="_idIndexMarker720"/>information on how to <a id="_idIndexMarker721"/>configure a Node Group, refer to the <a id="_idIndexMarker722"/>official documentation at <a href="https://docs.aws.amazon.com/eks/latest/userguide/create-node-role.html#create-worker-node-role">https://docs.aws.amazon.com/eks/latest/userguide/create-node-role.html#create-worker-node-role</a>.</p></li>
				<li>On the subsequent page, choose <strong class="source-inline">Amazon Linux 2</strong> as an AMI and select <strong class="source-inline">t3.medium</strong> <strong class="source-inline">On-Demand</strong> instances, as illustrated in the following screenshot:<div id="_idContainer296" class="IMG---Figure"><img src="image/Figure_8.36_B17115.jpg" alt="Figure 8.36 – Workers configuration&#13;&#10;"/></div><p class="figure-caption">Figure 8.36 – Workers configuration</p><p class="callout-heading">Note</p><p class="callout">For a <a id="_idIndexMarker723"/>production usage, you might <a id="_idIndexMarker724"/>use <strong class="source-inline">Spot-Instances</strong> instead of <strong class="source-inline">On-Demand</strong>. <strong class="source-inline">Spot-Instances</strong> usually comes with a good discount in price because of possibile spontaneous interruptions. Those interruptions can be gracefully handled by Kubernetes, leaving you with extra money.</p><p>The following figure shows how configuration is scaled:</p><div id="_idContainer297" class="IMG---Figure"><img src="image/Figure_8.37_B17115.jpg" alt="Figure 8.37 – Scaling configuration&#13;&#10;"/></div><p class="figure-caption">Figure 8.37 – Scaling configuration</p></li>
				<li>Finally, specify <a id="_idIndexMarker725"/>the subnets <a id="_idIndexMarker726"/>where the two nodes will be deployed. On the <strong class="bold">Review and create</strong> page, review your managed Node Group configuration and click on <strong class="bold">Create</strong>.</li>
			</ol>
			<p>Now that you've provisioned your EKS cluster, you need to configure <strong class="source-inline">kubectl</strong>.</p>
			<h2 id="_idParaDest-134"><a id="_idTextAnchor141"/>Configuring kubectl</h2>
			<p><strong class="source-inline">kubectl</strong> is a <a id="_idIndexMarker727"/>command-line utility for communicating <a id="_idIndexMarker728"/>with the cluster API server. To install the utility, execute the following commands:</p>
			<p class="source-code">curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/amd64/kubectl </p>
			<p class="source-code">chmod +x ./kubectl</p>
			<p class="source-code">mv kubectl /usr/local/bin/</p>
			<p>In this book, we are using the latest version of <strong class="source-inline">kubectl</strong>, which is 1.21.0, as you can see here: </p>
			<p class="source-code">Client Version: version.Info{Major:"1", Minor:"21", GitVersion:"v1.21.0", GitCommit:"cb303e613a121a29364f75cc67d3d580833a7479", GitTreeState:"clean", BuildDate:"2021-04-08T16:31:21Z", GoVersion:"go1.16.1", Compiler:"gc", Platform:"darwin/amd64"}</p>
			<p>Next, generate a <strong class="source-inline">kubeconfig</strong> file with the needed credentials for <strong class="source-inline">kubectl</strong> to interact with the EKS cluster, as follows:</p>
			<p class="source-code">aws eks update-kubeconfig --name sandbox --region eu-central-1</p>
			<p>You can now <a id="_idIndexMarker729"/>test the credentials by listing the nodes of <a id="_idIndexMarker730"/>the cluster with the following command:</p>
			<p class="source-code">kubectl get nodes</p>
			<p>The command will list two nodes as expected, as we can see here:</p>
			<div>
				<div id="_idContainer298" class="IMG---Figure">
					<img src="image/Figure_8.38_B17115.jpg" alt="Figure 8.38 – EKS nodes&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.38 – EKS nodes</p>
			<p>Awesome! You have successfully configured <strong class="source-inline">kubectl</strong>.</p>
			<p>Now that you've set up your EKS cluster, to run services on Kubernetes, you will need to translate your <strong class="source-inline">compose service</strong> definition to Kubernetes objects. <strong class="bold">Kompose</strong> is an open source <a id="_idIndexMarker731"/>tool that can speed up the translation process.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Instead <a id="_idIndexMarker732"/>of writing multiple Kubernetes <strong class="bold">YAML Ain't Markup Language</strong> (<strong class="bold">YAML</strong>) files, you can package your whole application in a Helm chart (<a href="https://docs.helm.sh/">https://docs.helm.sh/</a>) and store it in a remote registry for distribution.</p>
			<h2 id="_idParaDest-135"><a id="_idTextAnchor142"/>Migrating a Docker Compose workflow to Kubernetes</h2>
			<p>Kompose is <a id="_idIndexMarker733"/>an open source <a id="_idIndexMarker734"/>tool that converts <strong class="source-inline">docker-compose.yml</strong> files into Kubernetes deployment files. To get started with Kompose, proceed as follows:  </p>
			<ol>
				<li value="1">Navigate to the project's GitHub release page (<a href="https://github.com/kubernetes/kompose/releases">https://github.com/kubernetes/kompose/releases</a>) and download the binary based on your OS. Here, version 1.22.0 is used:<p class="source-code"><strong class="bold">curl -L</strong> <strong class="bold">https://github.com/kubernetes/kompose/releases/download/v1.22.0/kompose-darwin-amd64 -o kompose</strong></p><p class="source-code"><strong class="bold">chmod +x kompose</strong></p><p class="source-code"><strong class="bold">sudo mv ./kompose /usr/local/bin/kompose</strong></p></li>
				<li>With <a id="_idIndexMarker735"/>Kompose installed, convert <a id="_idIndexMarker736"/>your service definitions with the following command:<p class="source-code"><strong class="bold">kompose convert -o deploy</strong></p></li>
				<li>After running this command, Kompose will output information about the files it has created, as follows:<div id="_idContainer299" class="IMG---Figure"><img src="image/Figure_8.39_B17115.jpg" alt="Figure 8.39 – Translating Docker Compose to Kubernetes resources with Kompose&#13;&#10;"/></div><p class="figure-caption">Figure 8.39 – Translating Docker Compose to Kubernetes resources with Kompose</p><p>Here is an example of a generated <strong class="source-inline">Deployment</strong> file:</p><p class="source-code"><strong class="bold">apiVersion: apps/v1</strong></p><p class="source-code"><strong class="bold">kind: Deployment</strong></p><p class="source-code"><strong class="bold">metadata:</strong></p><p class="source-code"><strong class="bold"> annotations:</strong></p><p class="source-code"><strong class="bold">   kompose.cmd: kompose convert</strong></p><p class="source-code"><strong class="bold">   kompose.version: 1.22.0 (955b78124)</strong></p><p class="source-code"><strong class="bold"> creationTimestamp: null</strong></p><p class="source-code"><strong class="bold"> labels:</strong></p><p class="source-code"><strong class="bold">   io.kompose.service: api</strong></p><p class="source-code"><strong class="bold"> name: api</strong></p><p class="source-code"><strong class="bold">spec:</strong></p><p class="source-code"><strong class="bold"> replicas: 1</strong></p><p class="source-code"><strong class="bold"> selector:</strong></p><p class="source-code"><strong class="bold">   matchLabels:</strong></p><p class="source-code"><strong class="bold">     io.kompose.service: api</strong></p><p class="source-code"><strong class="bold"> strategy: {}</strong></p><p class="source-code"><strong class="bold"> template:</strong></p><p class="source-code"><strong class="bold">   metadata:</strong></p><p class="source-code"><strong class="bold">     annotations:</strong></p><p class="source-code"><strong class="bold">       kompose.cmd: kompose convert</strong></p><p class="source-code"><strong class="bold">       kompose.version: 1.22.0 (955b78124)</strong></p><p class="source-code"><strong class="bold">     creationTimestamp: null</strong></p><p class="source-code"><strong class="bold">     labels:</strong></p><p class="source-code"><strong class="bold">       io.kompose.network/api_network: "true"</strong></p><p class="source-code"><strong class="bold">       io.kompose.service: api</strong></p><p class="source-code"><strong class="bold">   spec:</strong></p><p class="source-code"><strong class="bold">     containers:</strong></p><p class="source-code"><strong class="bold">       - env:</strong></p><p class="source-code"><strong class="bold">           - name: MONGO_DATABASE</strong></p><p class="source-code"><strong class="bold">             value: demo</strong></p><p class="source-code"><strong class="bold">           - name: MONGO_URI</strong></p><p class="source-code"><strong class="bold">             value: mongodb://admin:password</strong></p><p class="source-code"><strong class="bold">                 @mongodb:27017/test?authSource=admin</strong></p><p class="source-code"><strong class="bold">                 &amp;readPreference=primary&amp;ssl=false</strong></p><p class="source-code"><strong class="bold">           - name: REDIS_URI</strong></p><p class="source-code"><strong class="bold">             value: redis:6379</strong></p><p class="source-code"><strong class="bold">         image: ID.dkr.ecr.REGION.amazonaws.com/USER</strong></p><p class="source-code"><strong class="bold">             /recipes-api:latest</strong></p><p class="source-code"><strong class="bold">         name: api</strong></p><p class="source-code"><strong class="bold">         resources: {}</strong></p><p class="source-code"><strong class="bold">     restartPolicy: Always</strong></p><p class="source-code"><strong class="bold">status: {}</strong></p></li>
				<li>Now, create <a id="_idIndexMarker737"/>Kubernetes objects and test whether your application is working as expected by <a id="_idIndexMarker738"/>issuing the following command:<p class="source-code"><strong class="bold">kubectl apply -f .</strong></p><p>You will see the following output, indicating that the objects have been created:</p><div id="_idContainer300" class="IMG---Figure"><img src="image/Figure_8.40_B17115.jpg" alt="Figure 8.40 – Deployments and services&#13;&#10;"/></div><p class="figure-caption">Figure 8.40 – Deployments and services</p></li>
				<li>To check that your Pods are running, deploy the Kubernetes dashboard with the following command:<p class="source-code"><strong class="bold">kubectl apply -f </strong>https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.5/aio/deploy/recommended.yaml</p></li>
				<li>Next, create an <strong class="source-inline">eks-admin</strong> service account and cluster role binding that you can use <a id="_idIndexMarker739"/>to securely <a id="_idIndexMarker740"/>connect to the dashboard with admin-level permissions, as follows:<p class="source-code">apiVersion: v1</p><p class="source-code">kind: ServiceAccount</p><p class="source-code">metadata:</p><p class="source-code">  name: eks-admin</p><p class="source-code">  namespace: kube-system</p><p class="source-code">---</p><p class="source-code">apiVersion: rbac.authorization.k8s.io/v1beta1</p><p class="source-code">kind: ClusterRoleBinding</p><p class="source-code">metadata:</p><p class="source-code">  name: eks-admin</p><p class="source-code">roleRef:</p><p class="source-code">  apiGroup: rbac.authorization.k8s.io</p><p class="source-code">  kind: ClusterRole</p><p class="source-code">  name: cluster-admin</p><p class="source-code">subjects:</p><p class="source-code">- kind: ServiceAccount</p><p class="source-code">  name: eks-admin</p><p class="source-code">  namespace: kube-system</p></li>
				<li>Save the content in an <strong class="source-inline">eks-admin-service-account.yml</strong> file and apply the service account to your cluster with the following command:<p class="source-code"><strong class="bold">kubectl apply -f eks-admin-service-account.yml</strong></p></li>
				<li>Before <a id="_idIndexMarker741"/>connecting to the dashboard, retrieve an authentication token with the following command:<p class="source-code"><strong class="bold">kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep eks-admin | awk '{print $1}')</strong></p><p>Here's how the Kubernetes dashboard token looks like:</p><div id="_idContainer301" class="IMG---Figure"><img src="image/Figure_8.41_B17115.jpg" alt="Figure 8.41 – Kubernetes dashboard token&#13;&#10;"/></div><p class="figure-caption">Figure 8.41 – Kubernetes dashboard token</p></li>
				<li>Run <a id="_idIndexMarker742"/>the proxy locally with the following command:<p class="source-code"><strong class="bold">kubectl proxy</strong></p></li>
				<li>Go to <strong class="source-inline">http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/#!/login</strong> and paste the authentication token. </li>
			</ol>
			<p>You should be redirected to the dashboard where you can view the distributed application containers, as well as their metrics and status, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer302" class="IMG---Figure">
					<img src="image/Figure_8.42_B17115.jpg" alt="Figure 8.42 – Kubernetes dashboard&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.42 – Kubernetes dashboard</p>
			<p>You can <a id="_idIndexMarker743"/>monitor your application <a id="_idIndexMarker744"/>running in EKS easily and scale the API Pods if needed.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">When you're done experimenting with EKS, it's a good idea to remove all the resources you created so that AWS doesn't charge you for them.</p>
			<h1 id="_idParaDest-136"><a id="_idTextAnchor143"/>Summary</h1>
			<p>In this chapter, you learned how to run a Gin web application on AWS using the Amazon EC2 service and how to serve it though HTTPS with an application load balancer and ACM.</p>
			<p>You have also explored how to deploy the application to a managed cluster with ECS without managing the underlying EC2 nodes. Along the way, you covered how to store the Docker images in a remote registry with ECR, and how to deploy the application for scale with Amazon EKS.</p>
			<p>In the next chapter, you will see how to automate the deployment of your Gin application on AWS with a <strong class="bold">continuous integration/continuous deployment</strong> (<strong class="bold">CI/CD</strong>) pipeline.</p>
			<h1 id="_idParaDest-137"><a id="_idTextAnchor144"/>Questions</h1>
			<ol>
				<li value="1">How will you configure a persistent volume for MongoDB container data?</li>
				<li>Deploy RabbitMQ on AWS EC2.</li>
				<li>Create MongoDB credentials with Kubernetes Secrets.</li>
				<li>Scale the API pods with <strong class="source-inline">kubectl</strong> to five instances.</li>
			</ol>
			<h1 id="_idParaDest-138"><a id="_idTextAnchor145"/>Further reading</h1>
			<ul>
				<li><em class="italic">Docker for Developers,</em> by Richard Bullington-McGuire, Andrew K. Dennis, and Michael Schwartz. Packt Publishing</li>
				<li><em class="italic">Mastering Kubernetes – Third Edition,</em> by Gigi Sayfan. Packt Publishing</li>
				<li><em class="italic">Docker on Amazon Web Services,</em> by Justin Menga. Packt Publishing</li>
			</ul>
		</div>
	</body></html>