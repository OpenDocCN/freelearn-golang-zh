- en: 'Chapter 10: Capturing Gin Application Metrics'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this final chapter, you will learn how to debug, troubleshoot, and monitor
    the RESTful API in near-real time. You will also learn how to collect Gin application
    metrics to measure the of the Gin application and to profile for abnormal behavior.
    Besides that, you will also explore how to stream Gin debug logs to a centralized
    logging platform using the ELK stack.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: 'As such, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Exposing Gin application metrics with Prometheus
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring server-side metrics
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Streaming Gin logs to the ELK platform
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will be able to instrument and monitor a Dockerized
    Gin web application running in production and debug its logs with ease.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To follow the content in this chapter, you will need the following:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: A complete understanding of the previous chapter. This chapter is a follow-up
    to the previous one as it will use the same source code. Hence, some snippets
    won't be explained to avoid repetition.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is assumed that you already have knowledge of Docker and containerization.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code bundle for this chapter is hosted on GitHub at [https://github.com/PacktPublishing/Building-Distributed-Applications-in-Gin/tree/main/chapter10](https://github.com/PacktPublishing/Building-Distributed-Applications-in-Gin/tree/main/chapter10).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Exposing Gin metrics with Prometheus
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, you learned how to automate the deployment process
    for a Gin application. However, no app is immune from downtime or external attacks
    (**DDoS**). That's why you need to set up the right tools to constantly monitor
    the performance of your application. **Prometheus** ([https://prometheus.io](https://prometheus.io))
    is a common open source tool for monitoring applications.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: 'You can install the Go client by running the following command from your terminal
    session:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, update the `main.go` file so that it exposes an HTTP route on the `/prometheus`
    path. The route handler will call the Prometheus HTTP handler, which will return
    a list of runtime and application metrics:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Then, import the following package to use the `promhttp` struct:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Next, redeploy the application. If you navigate to [http://localhost:8080/prometheus](http://localhost:8080/prometheus),
    you should see the following metrics:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1 – Prometheus default metrics'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.1_B17115.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.1 – Prometheus default metrics
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: This application only exposes the default metrics. You can also expose your
    own custom metrics by instrumenting the Gin application code. Let's learn how
    to do that.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Instrumenting a Gin application
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Instrumentation is the ability to monitor and measure performance, detect errors,
    and get trace information that represents the application's state. Prometheus
    allows us to inject code to monitor a Gin application up close.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: 'To add a custom metric, such as counting the number of incoming requests, follow
    these steps:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to create a piece of middleware to intercept incoming HTTP requests
    and increment the counter:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Then, we must define a piece of Gin middleware with the following code block:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Next, register the `totalRequests` counter within the `init()` method''s body:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Then, pass the `PrometheusMiddleware` middleware to the Gin router:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Restart the application and then refresh the `/prometheus` URL.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the response, you''ll see the number of requests per path:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.2 – Instrumenting Gin code'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.2_B17115.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.2 – Instrumenting Gin code
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: Your output might not display as much data as mine since you have not accessed
    the application that often. The best way to get more data is to issue multiple
    HTTP requests to the Recipes API.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: 'Another useful metric you can expose is the number of HTTP requests that have
    been received per HTTP method. Similarly, define a global counter and increment
    the counter for the corresponding HTTP method:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Register the `totalHTTPMethods` counter within the `init()` method body and
    restart the application.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the application has been restarted, in the response payload, you should
    see the number of requests partitioned by the HTTP method:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.3 – Number of requests per HTTP method'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.3_B17115.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.3 – Number of requests per HTTP method
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also record the HTTP request latencies in seconds with the following
    code block. We''re using `Histogram` instead of `Counter` to count individual
    observations from incoming HTTP requests:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'As a result, you should have something similar to the following:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.4 – Duration of the HTTP requests'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.4_B17115.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.4 – Duration of the HTTP requests
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: Now that the metrics have been exposed, you can store them in a time-series
    database and build an interactive dashboard on top of that. Getting regular insights
    into how the app works can help you identify ways to optimize its performance.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: 'Another alternative is to use the following Go library, written by the open
    source community: [https://github.com/zsais/go-gin-prometheus](https://github.com/zsais/go-gin-prometheus).
    It comes with a generic set of metrics.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: 'To get started, follow these steps:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: 'Deploy Prometheus by using the official Docker image with the following `docker-compose.yml`
    file:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The Prometheus container uses a `prometheus.yml` configuration file, which
    defines a background job to scrape the Golang Prometheus metrics endpoint:'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Redeploy the application stack with the following command:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The stack logs should look similar to this:'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.5 – Docker stack logs'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/Figure_10.5_B17115.jpg)'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.5 – Docker stack logs
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Navigate to the Prometheus dashboard by visiting `localhost:9090` in your favorite
    browser. You can explore the available metrics by using the search bar and writing
    queries using the **Prometheus Query Language** (**PromQL**). Prometheus collects
    metrics by polling (scraping) instrumented Gin code:![Figure 10.6 – Exploring
    metrics from the Prometheus dashboard
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_10.6_B17115.jpg)'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.6 – Exploring metrics from the Prometheus dashboard
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Turn the metrics into a chart by clicking on the **Graph** tab:![Figure 10.7
    – Using the built-in graph feature of Prometheus
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17115_10_07_v2.jpg)'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.7 – Using the built-in graph feature of Prometheus
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You can build advanced charts by using a visualization platform such as Grafana.
    It summarizes and visualizes data stored in Prometheus and provides a wide range
    of UI components to build user-friendly dashboards. The monitoring workflow is
    illustrated in the following schema:'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.8 – Collecting Gin metrics with Prometheus and Grafana'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/Figure_10.8_B17115.jpg)'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.8 – Collecting Gin metrics with Prometheus and Grafana
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Deploy Grafana inside a Docker container with the following code snippet:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Spin up the container using the following command:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Head to `localhost:3000`; you'll be asked to enter some user credentials. The
    defaults are admin for both the username and password:![Figure 10.9 – Grafana
    login page
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_10.9_B17115.jpg)'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.9 – Grafana login page
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Next, connect to Prometheus by creating a data source. Click on **Configuration**
    from the sidebar. Within the **Data Sources** tab, click on the **Add data source**
    button:![Figure 10.10 – Adding a new data source
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_10.10_B17115.jpg)'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.10 – Adding a new data source
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'After that, select **Prometheus** and then fill in the fields, as shown in
    the following screenshot. Then, click on the **Save & Test** button at the bottom
    of the page:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.11 – Configuring a Prometheus data source'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.11_B17115.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.11 – Configuring a Prometheus data source
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: You're now ready to create your first Grafana dashboard!
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: You can start by clicking on `http_requests_total` expression into the query
    field while using the `{{path}}` keyword in the `legend` field.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: 'You should now have the following graph configuration, which represents the
    total number of HTTP requests over time per path:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.12 – Total number of HTTP requests'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17115_10_12_v2.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.12 – Total number of HTTP requests
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: 'Save the panel and create a new one to display the response time of the served
    HTTP requests over time by using the `http_response_time_seconds_sum` expression:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.13 – HTTP response time'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17115_10_13_v2.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.13 – HTTP response time
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also create a single stat counter to display the total number of requests
    per HTTP method using the following configuration:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.14 – Using Grafana''s single stat component'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17115_10_14_v2.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.14 – Using Grafana's single stat component
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.14 – 使用Grafana的单个统计组件
- en: 'You can experiment with the dashboard by adding other panels with metrics and
    customize it to your liking:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过添加其他带有指标的面板并按您的喜好自定义来实验仪表板：
- en: '![Figure 10.15 – Interactive and dynamic Grafana dashboard'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.15 – 交互式和动态的Grafana仪表板'
- en: '](img/B17115_10_15_v2.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17115_10_15_v2.jpg)'
- en: Figure 10.15 – Interactive and dynamic Grafana dashboard
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.15 – 交互式和动态的Grafana仪表板
- en: Note
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You can download `dashboard.json`, which contains the Grafana configuration
    for the preceding dashboard, from the GitHub repository under the `chapter10`
    folder.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从GitHub仓库下的`chapter10`文件夹中下载`dashboard.json`，它包含前面仪表板的Grafana配置。
- en: Monitoring server-side metrics
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控服务器端指标
- en: So far, you have learned how to monitor application-side metrics by instrumenting
    the Gin application code. In this section, you will learn how to expose server-side
    metrics and monitor the overall health of the containers running on the Gin distributed
    web application.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您已经学习了如何通过为Gin应用程序代码添加工具来监控应用侧的指标。在本节中，您将学习如何暴露服务器端指标并监控运行在Gin分布式Web应用程序上的容器的整体健康状况。
- en: 'To collect server-side metrics, you can use an open source solution called
    **Telegraf** ([https://github.com/influxdata/telegraf](https://github.com/influxdata/telegraf)),
    a **data collection agent** (**DCA**) that can collect metrics from multiple inputs
    and forward them to different sources:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 要收集服务器端指标，您可以使用一个名为**Telegraf** ([https://github.com/influxdata/telegraf](https://github.com/influxdata/telegraf))的开源解决方案，这是一个**数据收集代理**（**DCA**），可以从多个输入收集指标并将它们转发到不同的来源：
- en: '![Figure 10.16 – Collecting server-side metrics with the Telegraf agent'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.16 – 使用Telegraf代理收集服务器端指标'
- en: '](img/Figure_10.16_B17115.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/Figure_10.16_B17115.jpg)'
- en: Figure 10.16 – Collecting server-side metrics with the Telegraf agent
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.16 – 使用Telegraf代理收集服务器端指标
- en: 'Telegraf can be easily deployed using Docker. Add the following code block
    to `docker-compose.yml`:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: Telegraf可以很容易地使用Docker部署。将以下代码块添加到`docker-compose.yml`中：
- en: '[PRE14]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '`telegraf.conf` contains a list of data sources (**inputs**) where Telegraf
    will fetch data from. It also contains a list of destinations (**outputs**) where
    the data will be forwarded to. In the following configuration file, Telegraf will
    collect the metrics about the server resources (memory, CPU, disk, and network
    traffic) and Docker daemon (usage of resources per container), and then forward
    these metrics to the Prometheus server:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`telegraf.conf`包含Telegraf将从其中获取数据的数据源（**输入**）列表。它还包含数据将被转发到的目的地（**输出**）列表。在以下配置文件中，Telegraf将收集关于服务器资源（内存、CPU、磁盘和网络流量）和Docker守护进程（每个容器的资源使用情况）的指标，然后将这些指标转发到Prometheus服务器：'
- en: '[PRE15]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Note
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You can also forward these metrics to InfluxDB ([https://github.com/influxdata/influxdb](https://github.com/influxdata/influxdb)),
    a scalable time-series database, and connect it to Grafana.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以将这些指标转发到InfluxDB ([https://github.com/influxdata/influxdb](https://github.com/influxdata/influxdb))，一个可扩展的时间序列数据库，并将其连接到Grafana。
- en: 'Next, define a new job in `prometheus.yml` to scrape the metrics that have
    been exposed by the Telegraf container:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在`prometheus.yml`中定义一个新的作业以抓取Telegraf容器暴露的指标：
- en: '[PRE16]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'With that done, restart the stack with the following command:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些后，使用以下命令重新启动堆栈：
- en: '[PRE17]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Then, head back to the Prometheus dashboard and navigate to **Targets** from
    the **Status** dropdown list. A Telegraf target should have been added to the
    list:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，返回到Prometheus仪表板，并从**状态**下拉列表中选择**目标**。应该已经添加了一个Telegraf目标到列表中：
- en: '![Figure 10.17 – Telegraf job up and running'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.17 – Telegraf作业正在运行'
- en: '](img/Figure_10.17_B17115.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/Figure_10.17_B17115.jpg)'
- en: Figure 10.17 – Telegraf job up and running
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.17 – Telegraf作业正在运行
- en: With the server-side metrics now available in Prometheus, you can create additional
    panels in Grafana.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在服务器端指标已在Prometheus中可用，您可以在Grafana中创建额外的面板。
- en: 'For instance, you can select the `docker_container_mem_usage_percent` expression
    from the **Metrics** dropdown to monitor the memory usage per container over time:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，您可以从**指标**下拉菜单中选择`docker_container_mem_usage_percent`表达式来监控每个容器随时间变化的内存使用情况：
- en: '![Figure 10.18 – Memory usage per container'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.18 – 每个容器的内存使用情况'
- en: '](img/B17115_10_18_v2.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17115_10_18_v2.jpg)'
- en: Figure 10.18 – Memory usage per container
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.18 – 每个容器的内存使用情况
- en: 'Add additional metrics so that you can monitor the CPU, disk usage, or the
    overall health metrics of the running containers:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 添加额外的指标，以便您可以监控CPU、磁盘使用情况或运行容器的整体健康指标：
- en: '![Figure 10.19 – Server-side and application-side metrics'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.19 – 服务器端和应用端指标'
- en: '](img/B17115_10_19_v2.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.19 – Server-side and application-side metrics
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: Well done! Now, you have a pretty interactive dashboard for a minimum amount
    of time.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Grafana notification channel
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous chapter, you learned how to use Slack to raise awareness about
    the CI/CD status for teams to take immediate actions. You can use the same approach
    while monitoring Gin applications by configuring a Slack alert on your **Grafana**
    dashboard when a certain threshold is reached.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: 'From the Grafana dashboard, click on the **Alerting** icon and click on **Notification
    channels**. Click on the **Add Channel** button and change the type to **Slack**.
    Then, input a Webhook URL:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.20 – Configuring a Slack notification channel'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.20_B17115.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.20 – Configuring a Slack notification channel
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: For a step-by-step guide on how to create a Slack application and generate a
    Webhook URL, check out [*Chapter 9*](B17115_09_Final_JM_ePub.xhtml#_idTextAnchor146),
    *Implementing a CI/CD Pipeline.*
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: 'To test out the configuration, click on the **Test** button. You should get
    a message similar to the following in your configured Slack channel:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.21 – Slack test message from Grafana'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.21_B17115.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.21 – Slack test message from Grafana
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that you have a notification channel, you can create an alerting rule on
    the dashboard panel. For instance, create an alert rule on the **HTTP Requests**
    graph that you created earlier and select the notification channel in the **Notifications**
    section. The rule will look as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.22 – Creating an alert rule in Grafana'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.22_B17115.jpg)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.22 – Creating an alert rule in Grafana
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: Every 30 seconds, Grafana will evaluate if the average number of HTTP requests
    is over 1,000 requests. If the metrics violate this rule, Grafana will wait for
    2 minutes. If, after 2 minutes, the metrics have not been recovered, Grafana will
    trigger an alert and a Slack notification will be sent.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: 'To test out the alert rule, you need to generate a workload. You can use **Apache
    Benchmark** to send 1,500 requests in parallel to the Recipes API with the following
    command:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Here, the number of requests for the `/recipes` endpoint will cross the 1,000
    threshold, as shown in the following graph:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.23 – Reaching the 1,000 requests limit'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.23_B17115.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.23 – Reaching the 1,000 requests limit
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: 'After 2 minutes, the alert will be triggered, and you will see the following
    message on your Slack channel:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.24 – Slack alert from Grafana'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.24_B17115.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.24 – Slack alert from Grafana
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: Another option for setting up metrics alerts is using Prometheus Alertmanager
    ([https://prometheus.io/docs/alerting/latest/alertmanager](https://prometheus.io/docs/alerting/latest/alertmanager)).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Having Slack notifications can help you take immediate action before things
    go horribly wrong in your production environment.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: Streaming Gin logs to the ELK platform
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another beneficial aspect to keep an eye on while deploying a Gin web application
    in production is **logs**. Logs can help you find the root cause of bad application
    performance or crashes.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: 'However, logs can be verbose and spammy – that''s why you''ll need a centralized
    platform to be able to apply filters and keep an eye on important events. That''s
    where a solution such as **Elasticsearch**, **Logstash**, and **Kibana** (**ELK**)
    is needed. The following schema illustrates how such a solution can be implemented:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.25 – Streaming Gin logs to ELK'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.25_B17115.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.25 – Streaming Gin logs to ELK
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: Gin application logs will be shipped to Logstash using the Docker GELF driver
    ([https://docs.docker.com/config/containers/logging/gelf/](https://docs.docker.com/config/containers/logging/gelf/)).
    From there, Logstash will process the incoming logs and store them in Elasticsearch.
    Finally, the logs can be visualized in Kibana through interactive dashboards.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the ELK stack with Docker
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By now, you should be familiar with Docker and be able to use it to deploy
    a Dockerized ELK stack using Docker Compose. To do so, follow these steps:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: 'Start with `docker-compose.yml`. The container uses the latest Docker image
    v7.12.1 (at the time of writing this chapter):'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The container uses a `logstash.conf` with the following content:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Next, deploy the second component responsible for storing and indexing incoming
    logs. Elasticsearch can be deployed in a single-node mode with the following configuration:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Note
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For production usage, it's highly recommended deploying Elasticsearch in a cluster
    mode with multiple data nodes to achieve high availability and resiliency.
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Then, deploy the third component to visualize the incoming Gin logs in an interactive
    way. The following YAML block is responsible for deploying Kibana:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Your ELK stack is now configured!
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: 'With the ELK stack configured, you need to stream the Gin application logs
    to Logstash. Luckily, Docker has a built-in `GELF` driver that supports Logstash.
    To stream the Gin application logs to Logstash, apply the following steps:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the following `logging` section to the Recipes API YAML block:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Redeploy the entire stack with `docker-compose up –d`. You can check whether
    all the services are up and running by running the `docker-compose ps` command:![Figure
    10.26 – List of running Docker services
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_10.26_B17115.jpg)'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.26 – List of running Docker services
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Make sure Docker Engine is allotted at least 4 GiB of memory. In Docker Desktop,
    you can configure resource usage of the **Advanced** tab in **Preferences**.
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Then, point your browser to `localhost:5601`. You should be welcomed with the
    Kibana dashboard:![Figure 10.27 – Kibana welcome page
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_10.27_B17115.jpg)'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.27 – Kibana welcome page
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Next, click on **Add data** and select **Elasticsearch logs** as a data source:![Figure
    10.28 – Adding data from Elasticsearch
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17115_10_28_v2.jpg)'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.28 – Adding data from Elasticsearch
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click on `containers-*` in the **Index pattern name** field. The *asterix* is
    used to include all the logs coming from Logstash. Then, click on the **Next step**
    button:![Figure 10.29 – Creating an index pattern
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_10.29_B17115.jpg)'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.29 – Creating an index pattern
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Select `@timestamp` as the primary time field to use with the global time filter.
    Then, click on `containers` index:![Figure 10.31 – List of available fields in
    the containers index
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17115_10_31_v2.jpg)'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.31 – List of available fields in the containers index
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: With Elasticsearch being connected with Kibana, click on **Discover** from the
    sidebar in the **Analytics** section. You should see a stream of logs coming from
    the Gin RESTful API:![Figure 10.32 – Gin logs in Kibana
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17115_10_32_v2.jpg)'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.32 – Gin logs in Kibana
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For production usage, you can use the curator tool ([https://www.elastic.co/guide/en/elasticsearch/client/curator/index.html](https://www.elastic.co/guide/en/elasticsearch/client/curator/index.html))
    to remove indices that are older than X days from Elasticsearch.
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Expand a row from the list of logs.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You should see that the Gin application log is stored in a field called `message`:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.33 – Message field content'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17115_10_33_v2.jpg)'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.33 – Message field content
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: Now, you have a working pipeline that reads Gin logs. However, you'll notice
    that the format of the log messages is not ideal. You can parse this field and
    split the important information into multiple fields using Grok expressions.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: Writing Grok expressions
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Grok expressions work by parsing text patterns by using regular expressions
    and assigning them to an identifier. The syntax is `%{PATTERN:IDENTIFIER}`. We
    can write a sequence of Grok patterns and assign various pieces of the following
    log message to various identifiers:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The Grok pattern is as follows:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Note
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: Grok comes with its own dictionary of patterns that you can use out of the box.
    However, you can always define your own custom pattern.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: You can test the pattern using the **Grok Debugger** feature on the **Dev Tools**
    page. In the **Sample Data** field, enter the previous message and in **Grok Pattern**,
    enter the Grok pattern.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, click on **Simulate**; you''ll see the simulated event that results from
    applying the Grok pattern:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.34 – Applying a Grok pattern to sample data'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17115_10_34_v2.jpg)'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.34 – Applying a Grok pattern to sample data
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: If an error occurs, you can continue iterating over the custom pattern until
    the output matches the event that you expect.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that you have a working Grok pattern, you can apply parsing at the Logstash
    level. To do this, update the `logstash.conf` file so that it includes a filter
    section, as follows:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now, if you restart the Logstash container, the incoming logs should be parsed
    and split into multiple fields:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.35 – Message field split into multiple fields'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.35_B17115.jpg)'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.35 – Message field split into multiple fields
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new dashboard and click on **Create panel** to create a new chart:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.36 – Creating a new Kibana dashboard'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.36_B17115.jpg)'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.36 – Creating a new Kibana dashboard
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: 'Drag the `status.keyword` field and drop it into the panel. Then, select a
    **Stacked bar** chart. You should get the following chart, which represents the
    number of requests per HTTP status code:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.37 – Building a chart with the Kibana chart builder'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17115_10_37_v2.jpg)'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.37 – Building a chart with the Kibana chart builder
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: You can save the stacked bar chart as a widget and import it into a dashboard.
    With a dashboard, you can combine multiple visualizations onto a single page,
    then filter them by providing a search query or by selecting filters by clicking
    elements in the visualization. Dashboards are useful when you want to get an overview
    of your Gin application logs and make correlations among various visualizations
    and logs.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: Updating the Gin logging format
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By default, Gin records every request field to **standard output** (**stdout**),
    which is awesome for troubleshooting and debugging HTTP request errors. However,
    this can be too verbose for other developers and they can get lost easily and
    miss the important events. Luckily, you can override this default behavior by
    creating a custom log formatter.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a custom log format with Gin, start with the following code block:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The code will log the request timestamp, HTTP method, path, status code, and
    duration:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.38 – Gin custom log format'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.38_B17115.jpg)'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.38 – Gin custom log format
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, Gin will output all logs to `stdout`, but you can disable them
    by setting `GIN_MODE` to release mode with the following command:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '![Figure 10.39 – Running Gin in release mode'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.39_B17115.jpg)'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.39 – Running Gin in release mode
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also override the log destination so that it''s a file instead of `stdout`
    with the following code block:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'As a result, a new file called `debug.log` should be created alongside the
    application logs:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.40 – Streaming logs to a file'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.40_B17115.jpg)'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.40 – Streaming logs to a file
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: 'You can stream the file''s content to Elasticsearch with Filebeat. **Filebeat**
    can be used as a replacement for Logstash:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.41 – Shipping log files with Filebeat to ELK'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.41_B17115.jpg)'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.41 – Shipping log files with Filebeat to ELK
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the following YAML block to `docker-compose.yml` to deploy a container
    based on the Filebeat v7.12.1 image:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The container will look in `/usr/share/filebeat` for the configuration file.
    The configuration file is provided through bind mounts (see the *volumes* section).
    The file''s content is as follows. It will listen for logs coming from `/var/log/api/debug.log`
    and echo any that are received by Elasticsearch:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Restart the stack with the `docker-compose up –d` command. The list of running
    Docker services is as follows:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.42 – Filebeat running as a Docker container'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.42_B17115.jpg)'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.42 – Filebeat running as a Docker container
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: 'Issue a few requests to the Recipes API. At this point, Gin will forward the
    logs to `debug.log` and Filebeat will stream them into Elasticsearch. From there,
    you can visualize them in real time in Kibana:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.43 – Visualizing logs coming from Filebeat'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.43_B17115.jpg)'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.43 – Visualizing logs coming from Filebeat
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: Great! You can now use the Kibana dashboard to analyze Gin logs in real time.
    Analyzing those logs can provide a lot of information that helps with troubleshooting
    the root cause of Gin application failure.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to instrument Gin application code to expose
    application-side metrics using Prometheus. You saw how to build a dynamic dashboard
    with Grafana to monitor the overall health of a Gin application in near-real time,
    as well as how to trigger a Slack alert when certain thresholds are crossed.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: Then, you learned how to stream Gin logs to a centralized logging platform built
    using open source tools such as Logstash, Elasticsearch, and Kibana. Along the
    way, you learned how to parse Gin logs with Grok patterns and how to build charts
    on top of these parsed fields.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! Now, you can design, build, and deploy a distributed Gin application
    from scratch. You also have a solid foundation regarding how to automate the deployment
    workflow and monitor a running Gin application in production.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Learn Grafana 7.0* by Eric Salituro, Packt publishing'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Hands-On Infrastructure Monitoring with Prometheus* by Joel Bastos and Pedro
    Arajo, Packt publishing'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We're at the end of our journey through this book! You've made it to the very
    end. I hope that you're proud of the journey you've taken. You've learned the
    ins and outs of the Gin framework and put together a fully functional distributed
    Gin application.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: By now, you should know all you need to know to build a scalable Dockerized
    Gin application, from handling multiple Git branches with GitFlow to automating
    the build on AWS with a CI/CD pipeline, troubleshooting and monitoring in near-real-time,
    and generating API documentation with OpenAPI.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: There's a lot to absorb and learn in this book, especially if this is your first
    exposure to the Gin framework. I find that the best way to learn is by doing,
    so take the RESTful API you've built and add new features to it. And if you do
    build something, reach out to me and tell me what you've done.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
