- en: 'Chapter 10: Capturing Gin Application Metrics'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this final chapter, you will learn how to debug, troubleshoot, and monitor
    the RESTful API in near-real time. You will also learn how to collect Gin application
    metrics to measure the of the Gin application and to profile for abnormal behavior.
    Besides that, you will also explore how to stream Gin debug logs to a centralized
    logging platform using the ELK stack.
  prefs: []
  type: TYPE_NORMAL
- en: 'As such, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Exposing Gin application metrics with Prometheus
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring server-side metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Streaming Gin logs to the ELK platform
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will be able to instrument and monitor a Dockerized
    Gin web application running in production and debug its logs with ease.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To follow the content in this chapter, you will need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A complete understanding of the previous chapter. This chapter is a follow-up
    to the previous one as it will use the same source code. Hence, some snippets
    won't be explained to avoid repetition.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is assumed that you already have knowledge of Docker and containerization.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code bundle for this chapter is hosted on GitHub at [https://github.com/PacktPublishing/Building-Distributed-Applications-in-Gin/tree/main/chapter10](https://github.com/PacktPublishing/Building-Distributed-Applications-in-Gin/tree/main/chapter10).
  prefs: []
  type: TYPE_NORMAL
- en: Exposing Gin metrics with Prometheus
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, you learned how to automate the deployment process
    for a Gin application. However, no app is immune from downtime or external attacks
    (**DDoS**). That's why you need to set up the right tools to constantly monitor
    the performance of your application. **Prometheus** ([https://prometheus.io](https://prometheus.io))
    is a common open source tool for monitoring applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can install the Go client by running the following command from your terminal
    session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, update the `main.go` file so that it exposes an HTTP route on the `/prometheus`
    path. The route handler will call the Prometheus HTTP handler, which will return
    a list of runtime and application metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, import the following package to use the `promhttp` struct:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, redeploy the application. If you navigate to [http://localhost:8080/prometheus](http://localhost:8080/prometheus),
    you should see the following metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1 – Prometheus default metrics'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.1_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.1 – Prometheus default metrics
  prefs: []
  type: TYPE_NORMAL
- en: This application only exposes the default metrics. You can also expose your
    own custom metrics by instrumenting the Gin application code. Let's learn how
    to do that.
  prefs: []
  type: TYPE_NORMAL
- en: Instrumenting a Gin application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Instrumentation is the ability to monitor and measure performance, detect errors,
    and get trace information that represents the application's state. Prometheus
    allows us to inject code to monitor a Gin application up close.
  prefs: []
  type: TYPE_NORMAL
- en: 'To add a custom metric, such as counting the number of incoming requests, follow
    these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to create a piece of middleware to intercept incoming HTTP requests
    and increment the counter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, we must define a piece of Gin middleware with the following code block:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, register the `totalRequests` counter within the `init()` method''s body:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, pass the `PrometheusMiddleware` middleware to the Gin router:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Restart the application and then refresh the `/prometheus` URL.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the response, you''ll see the number of requests per path:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.2 – Instrumenting Gin code'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.2_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.2 – Instrumenting Gin code
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Your output might not display as much data as mine since you have not accessed
    the application that often. The best way to get more data is to issue multiple
    HTTP requests to the Recipes API.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another useful metric you can expose is the number of HTTP requests that have
    been received per HTTP method. Similarly, define a global counter and increment
    the counter for the corresponding HTTP method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Register the `totalHTTPMethods` counter within the `init()` method body and
    restart the application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the application has been restarted, in the response payload, you should
    see the number of requests partitioned by the HTTP method:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.3 – Number of requests per HTTP method'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.3_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.3 – Number of requests per HTTP method
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also record the HTTP request latencies in seconds with the following
    code block. We''re using `Histogram` instead of `Counter` to count individual
    observations from incoming HTTP requests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'As a result, you should have something similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.4 – Duration of the HTTP requests'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.4_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.4 – Duration of the HTTP requests
  prefs: []
  type: TYPE_NORMAL
- en: Now that the metrics have been exposed, you can store them in a time-series
    database and build an interactive dashboard on top of that. Getting regular insights
    into how the app works can help you identify ways to optimize its performance.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'Another alternative is to use the following Go library, written by the open
    source community: [https://github.com/zsais/go-gin-prometheus](https://github.com/zsais/go-gin-prometheus).
    It comes with a generic set of metrics.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To get started, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Deploy Prometheus by using the official Docker image with the following `docker-compose.yml`
    file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The Prometheus container uses a `prometheus.yml` configuration file, which
    defines a background job to scrape the Golang Prometheus metrics endpoint:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Redeploy the application stack with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The stack logs should look similar to this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.5 – Docker stack logs'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/Figure_10.5_B17115.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.5 – Docker stack logs
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Navigate to the Prometheus dashboard by visiting `localhost:9090` in your favorite
    browser. You can explore the available metrics by using the search bar and writing
    queries using the **Prometheus Query Language** (**PromQL**). Prometheus collects
    metrics by polling (scraping) instrumented Gin code:![Figure 10.6 – Exploring
    metrics from the Prometheus dashboard
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_10.6_B17115.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.6 – Exploring metrics from the Prometheus dashboard
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Turn the metrics into a chart by clicking on the **Graph** tab:![Figure 10.7
    – Using the built-in graph feature of Prometheus
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17115_10_07_v2.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.7 – Using the built-in graph feature of Prometheus
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You can build advanced charts by using a visualization platform such as Grafana.
    It summarizes and visualizes data stored in Prometheus and provides a wide range
    of UI components to build user-friendly dashboards. The monitoring workflow is
    illustrated in the following schema:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.8 – Collecting Gin metrics with Prometheus and Grafana'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/Figure_10.8_B17115.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.8 – Collecting Gin metrics with Prometheus and Grafana
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Deploy Grafana inside a Docker container with the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Spin up the container using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Head to `localhost:3000`; you'll be asked to enter some user credentials. The
    defaults are admin for both the username and password:![Figure 10.9 – Grafana
    login page
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_10.9_B17115.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.9 – Grafana login page
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Next, connect to Prometheus by creating a data source. Click on **Configuration**
    from the sidebar. Within the **Data Sources** tab, click on the **Add data source**
    button:![Figure 10.10 – Adding a new data source
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_10.10_B17115.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.10 – Adding a new data source
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'After that, select **Prometheus** and then fill in the fields, as shown in
    the following screenshot. Then, click on the **Save & Test** button at the bottom
    of the page:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.11 – Configuring a Prometheus data source'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.11_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.11 – Configuring a Prometheus data source
  prefs: []
  type: TYPE_NORMAL
- en: You're now ready to create your first Grafana dashboard!
  prefs: []
  type: TYPE_NORMAL
- en: You can start by clicking on `http_requests_total` expression into the query
    field while using the `{{path}}` keyword in the `legend` field.
  prefs: []
  type: TYPE_NORMAL
- en: 'You should now have the following graph configuration, which represents the
    total number of HTTP requests over time per path:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.12 – Total number of HTTP requests'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17115_10_12_v2.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.12 – Total number of HTTP requests
  prefs: []
  type: TYPE_NORMAL
- en: 'Save the panel and create a new one to display the response time of the served
    HTTP requests over time by using the `http_response_time_seconds_sum` expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.13 – HTTP response time'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17115_10_13_v2.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.13 – HTTP response time
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also create a single stat counter to display the total number of requests
    per HTTP method using the following configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.14 – Using Grafana''s single stat component'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17115_10_14_v2.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.14 – Using Grafana's single stat component
  prefs: []
  type: TYPE_NORMAL
- en: 'You can experiment with the dashboard by adding other panels with metrics and
    customize it to your liking:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.15 – Interactive and dynamic Grafana dashboard'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17115_10_15_v2.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.15 – Interactive and dynamic Grafana dashboard
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: You can download `dashboard.json`, which contains the Grafana configuration
    for the preceding dashboard, from the GitHub repository under the `chapter10`
    folder.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring server-side metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, you have learned how to monitor application-side metrics by instrumenting
    the Gin application code. In this section, you will learn how to expose server-side
    metrics and monitor the overall health of the containers running on the Gin distributed
    web application.
  prefs: []
  type: TYPE_NORMAL
- en: 'To collect server-side metrics, you can use an open source solution called
    **Telegraf** ([https://github.com/influxdata/telegraf](https://github.com/influxdata/telegraf)),
    a **data collection agent** (**DCA**) that can collect metrics from multiple inputs
    and forward them to different sources:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.16 – Collecting server-side metrics with the Telegraf agent'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.16_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.16 – Collecting server-side metrics with the Telegraf agent
  prefs: []
  type: TYPE_NORMAL
- en: 'Telegraf can be easily deployed using Docker. Add the following code block
    to `docker-compose.yml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '`telegraf.conf` contains a list of data sources (**inputs**) where Telegraf
    will fetch data from. It also contains a list of destinations (**outputs**) where
    the data will be forwarded to. In the following configuration file, Telegraf will
    collect the metrics about the server resources (memory, CPU, disk, and network
    traffic) and Docker daemon (usage of resources per container), and then forward
    these metrics to the Prometheus server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: You can also forward these metrics to InfluxDB ([https://github.com/influxdata/influxdb](https://github.com/influxdata/influxdb)),
    a scalable time-series database, and connect it to Grafana.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, define a new job in `prometheus.yml` to scrape the metrics that have
    been exposed by the Telegraf container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'With that done, restart the stack with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, head back to the Prometheus dashboard and navigate to **Targets** from
    the **Status** dropdown list. A Telegraf target should have been added to the
    list:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.17 – Telegraf job up and running'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.17_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.17 – Telegraf job up and running
  prefs: []
  type: TYPE_NORMAL
- en: With the server-side metrics now available in Prometheus, you can create additional
    panels in Grafana.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, you can select the `docker_container_mem_usage_percent` expression
    from the **Metrics** dropdown to monitor the memory usage per container over time:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.18 – Memory usage per container'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17115_10_18_v2.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.18 – Memory usage per container
  prefs: []
  type: TYPE_NORMAL
- en: 'Add additional metrics so that you can monitor the CPU, disk usage, or the
    overall health metrics of the running containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.19 – Server-side and application-side metrics'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17115_10_19_v2.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.19 – Server-side and application-side metrics
  prefs: []
  type: TYPE_NORMAL
- en: Well done! Now, you have a pretty interactive dashboard for a minimum amount
    of time.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Grafana notification channel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous chapter, you learned how to use Slack to raise awareness about
    the CI/CD status for teams to take immediate actions. You can use the same approach
    while monitoring Gin applications by configuring a Slack alert on your **Grafana**
    dashboard when a certain threshold is reached.
  prefs: []
  type: TYPE_NORMAL
- en: 'From the Grafana dashboard, click on the **Alerting** icon and click on **Notification
    channels**. Click on the **Add Channel** button and change the type to **Slack**.
    Then, input a Webhook URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.20 – Configuring a Slack notification channel'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.20_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.20 – Configuring a Slack notification channel
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: For a step-by-step guide on how to create a Slack application and generate a
    Webhook URL, check out [*Chapter 9*](B17115_09_Final_JM_ePub.xhtml#_idTextAnchor146),
    *Implementing a CI/CD Pipeline.*
  prefs: []
  type: TYPE_NORMAL
- en: 'To test out the configuration, click on the **Test** button. You should get
    a message similar to the following in your configured Slack channel:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.21 – Slack test message from Grafana'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.21_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.21 – Slack test message from Grafana
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that you have a notification channel, you can create an alerting rule on
    the dashboard panel. For instance, create an alert rule on the **HTTP Requests**
    graph that you created earlier and select the notification channel in the **Notifications**
    section. The rule will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.22 – Creating an alert rule in Grafana'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.22_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.22 – Creating an alert rule in Grafana
  prefs: []
  type: TYPE_NORMAL
- en: Every 30 seconds, Grafana will evaluate if the average number of HTTP requests
    is over 1,000 requests. If the metrics violate this rule, Grafana will wait for
    2 minutes. If, after 2 minutes, the metrics have not been recovered, Grafana will
    trigger an alert and a Slack notification will be sent.
  prefs: []
  type: TYPE_NORMAL
- en: 'To test out the alert rule, you need to generate a workload. You can use **Apache
    Benchmark** to send 1,500 requests in parallel to the Recipes API with the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, the number of requests for the `/recipes` endpoint will cross the 1,000
    threshold, as shown in the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.23 – Reaching the 1,000 requests limit'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.23_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.23 – Reaching the 1,000 requests limit
  prefs: []
  type: TYPE_NORMAL
- en: 'After 2 minutes, the alert will be triggered, and you will see the following
    message on your Slack channel:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.24 – Slack alert from Grafana'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.24_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.24 – Slack alert from Grafana
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Another option for setting up metrics alerts is using Prometheus Alertmanager
    ([https://prometheus.io/docs/alerting/latest/alertmanager](https://prometheus.io/docs/alerting/latest/alertmanager)).
  prefs: []
  type: TYPE_NORMAL
- en: Having Slack notifications can help you take immediate action before things
    go horribly wrong in your production environment.
  prefs: []
  type: TYPE_NORMAL
- en: Streaming Gin logs to the ELK platform
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another beneficial aspect to keep an eye on while deploying a Gin web application
    in production is **logs**. Logs can help you find the root cause of bad application
    performance or crashes.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, logs can be verbose and spammy – that''s why you''ll need a centralized
    platform to be able to apply filters and keep an eye on important events. That''s
    where a solution such as **Elasticsearch**, **Logstash**, and **Kibana** (**ELK**)
    is needed. The following schema illustrates how such a solution can be implemented:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.25 – Streaming Gin logs to ELK'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.25_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.25 – Streaming Gin logs to ELK
  prefs: []
  type: TYPE_NORMAL
- en: Gin application logs will be shipped to Logstash using the Docker GELF driver
    ([https://docs.docker.com/config/containers/logging/gelf/](https://docs.docker.com/config/containers/logging/gelf/)).
    From there, Logstash will process the incoming logs and store them in Elasticsearch.
    Finally, the logs can be visualized in Kibana through interactive dashboards.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the ELK stack with Docker
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By now, you should be familiar with Docker and be able to use it to deploy
    a Dockerized ELK stack using Docker Compose. To do so, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start with `docker-compose.yml`. The container uses the latest Docker image
    v7.12.1 (at the time of writing this chapter):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The container uses a `logstash.conf` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, deploy the second component responsible for storing and indexing incoming
    logs. Elasticsearch can be deployed in a single-node mode with the following configuration:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For production usage, it's highly recommended deploying Elasticsearch in a cluster
    mode with multiple data nodes to achieve high availability and resiliency.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Then, deploy the third component to visualize the incoming Gin logs in an interactive
    way. The following YAML block is responsible for deploying Kibana:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Your ELK stack is now configured!
  prefs: []
  type: TYPE_NORMAL
- en: 'With the ELK stack configured, you need to stream the Gin application logs
    to Logstash. Luckily, Docker has a built-in `GELF` driver that supports Logstash.
    To stream the Gin application logs to Logstash, apply the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the following `logging` section to the Recipes API YAML block:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Redeploy the entire stack with `docker-compose up –d`. You can check whether
    all the services are up and running by running the `docker-compose ps` command:![Figure
    10.26 – List of running Docker services
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_10.26_B17115.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.26 – List of running Docker services
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Make sure Docker Engine is allotted at least 4 GiB of memory. In Docker Desktop,
    you can configure resource usage of the **Advanced** tab in **Preferences**.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Then, point your browser to `localhost:5601`. You should be welcomed with the
    Kibana dashboard:![Figure 10.27 – Kibana welcome page
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_10.27_B17115.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.27 – Kibana welcome page
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Next, click on **Add data** and select **Elasticsearch logs** as a data source:![Figure
    10.28 – Adding data from Elasticsearch
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17115_10_28_v2.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.28 – Adding data from Elasticsearch
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click on `containers-*` in the **Index pattern name** field. The *asterix* is
    used to include all the logs coming from Logstash. Then, click on the **Next step**
    button:![Figure 10.29 – Creating an index pattern
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_10.29_B17115.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.29 – Creating an index pattern
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Select `@timestamp` as the primary time field to use with the global time filter.
    Then, click on `containers` index:![Figure 10.31 – List of available fields in
    the containers index
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17115_10_31_v2.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.31 – List of available fields in the containers index
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: With Elasticsearch being connected with Kibana, click on **Discover** from the
    sidebar in the **Analytics** section. You should see a stream of logs coming from
    the Gin RESTful API:![Figure 10.32 – Gin logs in Kibana
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17115_10_32_v2.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.32 – Gin logs in Kibana
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For production usage, you can use the curator tool ([https://www.elastic.co/guide/en/elasticsearch/client/curator/index.html](https://www.elastic.co/guide/en/elasticsearch/client/curator/index.html))
    to remove indices that are older than X days from Elasticsearch.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Expand a row from the list of logs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You should see that the Gin application log is stored in a field called `message`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.33 – Message field content'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17115_10_33_v2.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.33 – Message field content
  prefs: []
  type: TYPE_NORMAL
- en: Now, you have a working pipeline that reads Gin logs. However, you'll notice
    that the format of the log messages is not ideal. You can parse this field and
    split the important information into multiple fields using Grok expressions.
  prefs: []
  type: TYPE_NORMAL
- en: Writing Grok expressions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Grok expressions work by parsing text patterns by using regular expressions
    and assigning them to an identifier. The syntax is `%{PATTERN:IDENTIFIER}`. We
    can write a sequence of Grok patterns and assign various pieces of the following
    log message to various identifiers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The Grok pattern is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Grok comes with its own dictionary of patterns that you can use out of the box.
    However, you can always define your own custom pattern.
  prefs: []
  type: TYPE_NORMAL
- en: You can test the pattern using the **Grok Debugger** feature on the **Dev Tools**
    page. In the **Sample Data** field, enter the previous message and in **Grok Pattern**,
    enter the Grok pattern.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, click on **Simulate**; you''ll see the simulated event that results from
    applying the Grok pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.34 – Applying a Grok pattern to sample data'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17115_10_34_v2.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.34 – Applying a Grok pattern to sample data
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: If an error occurs, you can continue iterating over the custom pattern until
    the output matches the event that you expect.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that you have a working Grok pattern, you can apply parsing at the Logstash
    level. To do this, update the `logstash.conf` file so that it includes a filter
    section, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, if you restart the Logstash container, the incoming logs should be parsed
    and split into multiple fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.35 – Message field split into multiple fields'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.35_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.35 – Message field split into multiple fields
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new dashboard and click on **Create panel** to create a new chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.36 – Creating a new Kibana dashboard'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.36_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.36 – Creating a new Kibana dashboard
  prefs: []
  type: TYPE_NORMAL
- en: 'Drag the `status.keyword` field and drop it into the panel. Then, select a
    **Stacked bar** chart. You should get the following chart, which represents the
    number of requests per HTTP status code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.37 – Building a chart with the Kibana chart builder'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17115_10_37_v2.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.37 – Building a chart with the Kibana chart builder
  prefs: []
  type: TYPE_NORMAL
- en: You can save the stacked bar chart as a widget and import it into a dashboard.
    With a dashboard, you can combine multiple visualizations onto a single page,
    then filter them by providing a search query or by selecting filters by clicking
    elements in the visualization. Dashboards are useful when you want to get an overview
    of your Gin application logs and make correlations among various visualizations
    and logs.
  prefs: []
  type: TYPE_NORMAL
- en: Updating the Gin logging format
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By default, Gin records every request field to **standard output** (**stdout**),
    which is awesome for troubleshooting and debugging HTTP request errors. However,
    this can be too verbose for other developers and they can get lost easily and
    miss the important events. Luckily, you can override this default behavior by
    creating a custom log formatter.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a custom log format with Gin, start with the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The code will log the request timestamp, HTTP method, path, status code, and
    duration:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.38 – Gin custom log format'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.38_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.38 – Gin custom log format
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, Gin will output all logs to `stdout`, but you can disable them
    by setting `GIN_MODE` to release mode with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 10.39 – Running Gin in release mode'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.39_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.39 – Running Gin in release mode
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also override the log destination so that it''s a file instead of `stdout`
    with the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'As a result, a new file called `debug.log` should be created alongside the
    application logs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.40 – Streaming logs to a file'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.40_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.40 – Streaming logs to a file
  prefs: []
  type: TYPE_NORMAL
- en: 'You can stream the file''s content to Elasticsearch with Filebeat. **Filebeat**
    can be used as a replacement for Logstash:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.41 – Shipping log files with Filebeat to ELK'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.41_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.41 – Shipping log files with Filebeat to ELK
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the following YAML block to `docker-compose.yml` to deploy a container
    based on the Filebeat v7.12.1 image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The container will look in `/usr/share/filebeat` for the configuration file.
    The configuration file is provided through bind mounts (see the *volumes* section).
    The file''s content is as follows. It will listen for logs coming from `/var/log/api/debug.log`
    and echo any that are received by Elasticsearch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Restart the stack with the `docker-compose up –d` command. The list of running
    Docker services is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.42 – Filebeat running as a Docker container'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.42_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.42 – Filebeat running as a Docker container
  prefs: []
  type: TYPE_NORMAL
- en: 'Issue a few requests to the Recipes API. At this point, Gin will forward the
    logs to `debug.log` and Filebeat will stream them into Elasticsearch. From there,
    you can visualize them in real time in Kibana:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.43 – Visualizing logs coming from Filebeat'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.43_B17115.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.43 – Visualizing logs coming from Filebeat
  prefs: []
  type: TYPE_NORMAL
- en: Great! You can now use the Kibana dashboard to analyze Gin logs in real time.
    Analyzing those logs can provide a lot of information that helps with troubleshooting
    the root cause of Gin application failure.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to instrument Gin application code to expose
    application-side metrics using Prometheus. You saw how to build a dynamic dashboard
    with Grafana to monitor the overall health of a Gin application in near-real time,
    as well as how to trigger a Slack alert when certain thresholds are crossed.
  prefs: []
  type: TYPE_NORMAL
- en: Then, you learned how to stream Gin logs to a centralized logging platform built
    using open source tools such as Logstash, Elasticsearch, and Kibana. Along the
    way, you learned how to parse Gin logs with Grok patterns and how to build charts
    on top of these parsed fields.
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! Now, you can design, build, and deploy a distributed Gin application
    from scratch. You also have a solid foundation regarding how to automate the deployment
    workflow and monitor a running Gin application in production.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Learn Grafana 7.0* by Eric Salituro, Packt publishing'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Hands-On Infrastructure Monitoring with Prometheus* by Joel Bastos and Pedro
    Arajo, Packt publishing'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We're at the end of our journey through this book! You've made it to the very
    end. I hope that you're proud of the journey you've taken. You've learned the
    ins and outs of the Gin framework and put together a fully functional distributed
    Gin application.
  prefs: []
  type: TYPE_NORMAL
- en: By now, you should know all you need to know to build a scalable Dockerized
    Gin application, from handling multiple Git branches with GitFlow to automating
    the build on AWS with a CI/CD pipeline, troubleshooting and monitoring in near-real-time,
    and generating API documentation with OpenAPI.
  prefs: []
  type: TYPE_NORMAL
- en: There's a lot to absorb and learn in this book, especially if this is your first
    exposure to the Gin framework. I find that the best way to learn is by doing,
    so take the RESTful API you've built and add new features to it. And if you do
    build something, reach out to me and tell me what you've done.
  prefs: []
  type: TYPE_NORMAL
