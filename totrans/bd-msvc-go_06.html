<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Microservice Frameworks</h1>
                </header>
            
            <article>
                
<p>In this chapter, we are going to look at some of the most popular frameworks for building microservices and look at an example project to see the implementation. We will examine both RESTful and RPC based microservices and, to throw a curve ball in, we are also going to look at a commercial framework which provides much of the glue needed when building a highly distributed system.</p>
<p>The source code to accompany this chapter can be found at <a href="https://github.com/building-microservices-with-go/chapter6">https://github.com/building-microservices-with-go/chapter6</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What makes a good microservice framework?</h1>
                </header>
            
            <article>
                
<p>What makes a microservice framework is an incredibly good question and one which is open to a lot of opinions. In an attempt to remove the subjectivity, we will break down the features of a good framework and try to allocate a score for each of these functions in a consistent way. The following diagram is a hierarchical mind map of the features which I deem necessary. When you are assessing the framework which is the best for you and your project, you can use this framework, adding or removing any of the attributes which may be relevant:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class="image-border" src="assets/e168c43e-07e3-42d4-abcd-8e6b49abfe59.png"/></div>
<p>Here are some of the features you need to keep in mind while choosing a good framework:</p>
<ul>
<li><strong>Ability to interface with other frameworks</strong>: It must be possible to interact with any service built with the framework by clients who are not built using the same framework.
<ul>
<li><strong>Implement standards</strong>: A standard message protocol should be used to maximize interaction, for example:
<ul>
<li>JSON-RPC</li>
<li>Thrift</li>
<li>Protocol Buffers</li>
<li>JSON</li>
</ul>
</li>
<li><strong>Open</strong>: The framework should be open in both the source code and the roadmap.</li>
</ul>
</li>
<li><strong>Patterns:</strong> The framework must implement the standard patterns of microservice architecture:
<ul>
<li><strong>Circuit breaking</strong>: Client calls to downstream services must implement circuit breaking.</li>
<li><strong>Service discovery</strong>: It must be capable of registering with a dynamic service registry and capable of querying the same registry to locate connected services</li>
<li><strong>Proprietary</strong>: Proprietary service registries must be open and usable from other clients who do not implement the framework or its SDKs.</li>
<li><strong>Timeouts</strong>: Downstream client calls should be configurable with a user determined timeout.</li>
<li><strong>Health checks</strong>: The framework must create an automatic health check endpoint.</li>
<li><strong>Routing</strong>: The framework must support multiple routes with an easy to use pattern based matching.</li>
<li><strong>Middleware</strong>: The framework must support middleware to allow the user to create shared code for handlers.</li>
<li><strong>Load balancing</strong>: Downstream client connections should be capable of load balancing.</li>
<li><strong>Language independence</strong>: The framework needs to be language independent to enable cross-team polyglot workflow. At a minimum, it should be possible to create client SDKs in multiple languages.</li>
</ul>
</li>
<li><strong>Communication Protocols:</strong> The service should support good standards in one of the following communication protocols:
<ul>
<li><strong>REST:</strong> If the framework implements REST, it must take full advantage of semantic API design with appropriate use of HTTP verbs and status codes.</li>
<li><strong>RPC:</strong> If the framework is RPC-based, it must use a standard and open messaging protocol.</li>
</ul>
</li>
<li><strong>Maintainable:</strong> The framework must be maintainable with the minimum effort:
<ul>
<li><strong>Easy to update</strong>: It must be easy to update with the minimum amount of code changes.</li>
<li><strong>Well versioned</strong>: The framework must be well versioned with breaking changes to the API mainly restricted to major version updates.</li>
</ul>
</li>
<li><strong>Tooling</strong>: There must be adequate tooling to fit with modern development practices:
<ul>
<li><strong>CI/CD</strong>: It must integrate and work well with continuous integration and continuous deployment pipelines; the tooling must be scriptable.</li>
<li><strong>Cross-platform</strong>: The tools must work cross-platform, with OSX, and Linux as a bare minimum.</li>
</ul>
</li>
<li><strong>Code generation</strong>: It should support code generation templates to scaffold a service and possibly extend the service.</li>
<li><strong>Fast set up</strong>: The framework should be fast to set up and with the minimum number of steps and dependencies.</li>
<li><strong>Ease of use</strong>: Any good framework should be easy to use; you will not thank yourself for choosing a framework which is a pain to work with. This category has been broken down into the following subcategories:</li>
<li><strong>Extensible</strong>: When required, the user should be able to extend the framework through:
<ul>
<li><strong>Plugins</strong>: A pluggable software architecture to be able to create generators and templates.</li>
<li><strong>Middleware</strong>: Extension through handler middleware.</li>
</ul>
</li>
<li><strong>Support</strong>: A good support network is incredibly important throughout the life cycle of the service.
<ul>
<li><strong>Maintained</strong>: The framework must be well maintained with:
<ul>
<li><strong>Regular updates</strong>: The framework is regularly updated and released.</li>
<li><strong>Accepts pull requests</strong>: The author accepts pull requests from community contributors.</li>
<li><strong>Corporate sponsor</strong>: While this option is not essential, a corporate sponsor can extend the life cycle of a framework as there is less likelihood of a leftpad situation. (<a href="http://www.theregister.co.uk/2016/03/23/npm_left_pad_chaos/">http://www.theregister.co.uk/2016/03/23/npm_left_pad_chaos/</a>).</li>
</ul>
</li>
<li><strong>Documentation</strong>: The framework should be well documented with clear and concise examples and comprehensive API documentation.
<ul>
<li><strong>Easy to follow</strong>: Documentation should be accessible and easy to read.</li>
<li><strong>Code samples</strong>: Adequate code examples should be provided to support a developer using the framework.</li>
</ul>
</li>
<li><strong>Tutorials</strong>: The framework will ideally have community contributed tutorials in both blog and video formats.</li>
<li><strong>Community</strong>: There should be a healthy community using and supporting the framework with at least one of the following channels of communication:
<ul>
<li>Slack</li>
<li>Gitter</li>
<li>Github</li>
<li>Mailing list</li>
<li>Stack Overflow</li>
</ul>
</li>
</ul>
</li>
<li><strong>Secure</strong>: The framework should be secure and implement the latest industry standards:
<ul>
<li><strong>TLS</strong>: Securing the endpoints of the framework using TLS should be possible.</li>
<li><strong>OWASP</strong>: The framework should implement OWASP advisory.</li>
<li><strong>Validation</strong>: Requests should be automatically validated based on rules implemented by message annotation.</li>
<li><strong>Well patched</strong>: Security vulnerabilities should be regularly assessed and patched.</li>
<li><strong>Authentication / Authorization</strong>: The framework should implement a method of authentication and authorization such as the OAuth standard.</li>
</ul>
</li>
<li><strong>Open source</strong>: The framework should be open sourced and released under a license which allows forking and modification:
<ul>
<li><strong>Community</strong>: There should be a good open source community following and contribution for the project.</li>
<li><strong>Popular</strong>: The framework should be popular and commercially used.</li>
</ul>
</li>
<li><strong>Quality</strong>: The code quality of the framework should be visible and of a high standard. Community contributions should follow a published process and standard.
<ul>
<li><strong>High test coverage</strong>: Test coverage should be high and monitored; pull requests should ensure adherence to coding standards.
<ul>
<li><strong>Unit tests</strong>: High fast running unit tests are essential.</li>
<li><strong>Behavioral/functional</strong>: Ideally, the framework should implement behavioral and functional tests regarding the generated code and the build process:</li>
</ul>
</li>
<li><strong>Automated builds</strong>: Automated builds of the source code should be present and visible. Pull requests should run an automated build, and the state reported on the request.</li>
<li><strong>Code quality</strong>: Automated code quality tools should be used and the results visible, for example:
<ul>
<li>Coveralls (<a href="https://coveralls.io/">https://coveralls.io/</a>)</li>
<li>Code Climate (<a href="https://codeclimate.com/">https://codeclimate.com/</a>)</li>
<li>Sonar (<a href="https://www.sonarqube.org/">https://www.sonarqube.org/</a>)</li>
</ul>
</li>
<li><strong>Standard language patterns</strong>: A standard method of writing the code taking account of the language level idioms is essential.</li>
<li><strong>Efficient</strong>: The framework must produce code which is efficient when run.</li>
<li><strong>Fast</strong>: The code must execute quickly and be designed for performance.</li>
<li><strong>Low latency</strong>: Requests should be low latency.</li>
<li><strong>Low memory</strong>: The service should be memory efficient.</li>
<li><strong>Supports a large number of connections</strong>: It should support a significant number of concurrent connections.</li>
</ul>
</li>
</ul>
<p>It's hard to compare the various frameworks on a like-for-like basis as each framework provides a different set of features and all of these features will affect the performance. I think it is useful, however, to try and run some performance tests against each of the frameworks. To do this, we will be running our example service in Docker on a small Digital Ocean host with two CPU cores and 2 GB of RAM. We will then use another server of the same size to execute the benchmarking application.</p>
<p>Our strategy is to run a 5-minute test with 400 connections and a 5-second timeout. The connections will be ramped up over a 90-second interval.</p>
<p>The process is not a scientific test, but it will give us an indication of the response time and to identify if the server can cope with a reasonable number of concurrent connections.</p>
<p>As a benchmark, I have created a vanilla HTTP server using JSON as a message protocol. The results can be seen for this service are outlined in following the sections and compared to other frameworks to form a base line efficiency.</p>
<p>It should be noted, however, that some frameworks have advanced capabilities such as request validation, circuit breaking out of the box. The number of these features present will influence the latency of the service, so it will not be possible to do a true like for like comparison.</p>
<p><strong>Results:</strong></p>
<table class="table">
<tbody>
<tr>
<td>
<p>Threads</p>
</td>
<td>
<p>400</p>
</td>
</tr>
<tr>
<td>
<p>Total Requests:</p>
</td>
<td>
<p>1546084</p>
</td>
</tr>
<tr>
<td>
<p>Avg. Request Time</p>
</td>
<td>
<p>51.50ms</p>
</td>
</tr>
<tr>
<td>
<p>Total Success</p>
</td>
<td>
<p>1546049</p>
</td>
</tr>
<tr>
<td>
<p>Total Timeouts</p>
</td>
<td>
<p>35</p>
</td>
</tr>
<tr>
<td>
<p>Total Failures</p>
</td>
<td>
<p>35</p>
</td>
</tr>
</tbody>
</table>
<div><strong>Requests over time:</strong></div>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="263" width="673" class="image-border" src="assets/860ca5ff-2248-4be8-bc69-105a99a80c3d.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Micro</h1>
                </header>
            
            <article>
                
<p>The first framework we are going to look at is Micro by Asim Aslam. It has been under active development over the last couple of years and has production credentials with its use at the car rental firm, Sixt. Micro is a pluggable RPC microservices framework supporting service discovery, load-balancing, synchronous and asynchronous communication and multiple message encoding formats. For a more in-depth overview of Micro's features and to check out the source code it is hosted on GitHub at the following location: <a href="https://github.com/micro/go-micro"><span class="URLPACKT">https://github.com/micro/go-micro</span></a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Setup</h1>
                </header>
            
            <article>
                
<p>Installation for Micro is easy; well, it is Go so it would be. You do need to install <kbd>protoc</kbd>, the application for generating source code which is part of Google's <kbd>Protocol Buffers</kbd> package. As a messaging protocol, <kbd>protobufs</kbd> are taking off big time and you will find this messaging protocol used in quite a few frameworks we are going to look at in this chapter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Code generation</h1>
                </header>
            
            <article>
                
<p>The <kbd>protoc</kbd> application is used for code generating our Go code from the proto file definition. In fact, the beautiful thing about <kbd>protoc</kbd> is that it can generate code in about 10 different languages. Micro also has the capability to use a <kbd>protoc</kbd> plugin to generate your clients and server code automatically. This is a nice feature and can indeed save a few keystrokes.</p>
<p>Let's take a look at how we can generate our Go code, which defines our message protocol, using <kbd>protoc</kbd>.</p>
<p><kbd>gomicro/proto/kittens.proto</kbd></p>
<pre>
  1 syntax = "proto3"; <br/>  2 <br/>  3 package bmigo.micro; <br/>  4 <br/>  5 message RequestEnvelope { <br/>  6     string service_method = 1; <br/>  7     fixed64 seq = 2; <br/>  8 } <br/>  9 <br/> 10 message ResponseEnvelope { <br/> 11     string service_method = 1; <br/> 12     fixed64 seq = 2; <br/> 13     string error = 3; <br/> 14 } <br/> 15 <br/> 16 message Request { <br/> 17     string name = 1; <br/> 18 } <br/> 19 <br/> 20 message Response { <br/> 21     string msg = 1; <br/> 22 } <br/> 23 <br/> 24 service Kittens { <br/> 25     rpc Hello(Request) returns (Response) {} <br/> 26 } 
</pre>
<p>When you run the <kbd>protoc</kbd> command, it processes the proto DSL file and outputs native language source files. In our example, a snippet of that code looks like the following:</p>
<p><kbd>gomicro/proto/kittens.pb.go</kbd></p>
<pre>
 32 type Request struct { <br/> 33   Name string `protobuf:"bytes,1,opt,name=name" <br/>      json:"name,omitempty"` <br/> 34 } <br/> 35 <br/> 36 func (m *Request) Reset()                    { *m = Request{} } <br/> 37 func (m *Request) String() string            { return <br/>    proto.CompactTextString(m) } <br/> 38 func (*Request) ProtoMessage()               {} <br/> 39 func (*Request) Descriptor() ([]byte, []int) { return <br/>    fileDescriptor0, []int{0} } 
</pre>
<p>We never edit this file by hand, so it does not matter what the code looks like. All this is doing is allowing a struct to be serialized using the binary standard set out by Protocol Buffers.</p>
<p>To use this with Micro, we do not have to do very much at all. Let's take a look at the main function and see how easy it is to set up:</p>
<p><kbd>gomicro/server/main.go</kbd></p>
<pre>
 20 func main() { <br/> 21   cmd.Init() <br/> 22 <br/> 23   server.Init( <br/> 24     server.Name("bmigo.micro.Kittens"), <br/> 25     server.Version("1.0.0"), <br/> 26     server.Address(":8091"), <br/> 27   ) <br/> 28 <br/> 29   // Register Handlers <br/> 30   server.Handle( <br/> 31     server.NewHandler( <br/> 32       new(Kittens), <br/> 33     ), <br/> 34   ) <br/> 35 <br/> 36   // Run server <br/> 37   if err := server.Run(); err != nil { <br/> 38     log.Fatal(err) <br/> 39   } <br/> 40 } 
</pre>
<p>In line <strong>24</strong>, we are initializing the micro server, passing it some options. In the same way that we could pass our basic HTTP server an address to configure what the IP and port the server would bind to, we are doing the same thing in line <strong>27</strong>.</p>
<p>The handlers section from line <strong>31</strong> should look familiar to you too; Micro uses exactly the same signature which is present in the <kbd>net/rpc</kbd> package. Creating a handler is as simple as defining a <kbd>struct</kbd> and adding methods to it. Micro will automatically register these as routes on your service:</p>
<pre>
 12 type Kittens struct{} <br/> 13 <br/> 14 func (s *Kittens) Hello(ctx context.Context, req *kittens.Request, <br/>    rsp *kittens.Response) error { <br/> 15   rsp.Msg = server.DefaultId + ": Hello " + req.Name <br/> 16 <br/> 17   return nil <br/> 18 } 
</pre>
<p>The form of the handler looks very similar to the one from the <kbd>net/http</kbd> package; we can see the same context object we looked at in the first chapter. If you remember from that chapter the Context is a safe method for accessing request scoped data which can be accessed from multiple Goroutines. The request and the response objects are those which we defined in our proto file. Instead of writing our response to a <kbd>ResponseWriter</kbd> in this handler, we set the values we wish to return to the reference of the response which is passed to the function. Regarding returning, we have the option to return an error if something went wrong and we wish to notify the caller.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Tooling (CI/CD, cross platform)</h1>
                </header>
            
            <article>
                
<p>Because Micro is written in pure Go, with the only external dependency being <kbd>protoc</kbd>, it creates a very lightweight framework which would be possible to use on Linux, Mac, and Windows with ease. It would also be easy to set up onto a CI server; the main complexity is the installation of <kbd>protoc</kbd>, but this application is incredibly well supported by Google and is available for all the main operating systems and architectures.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Maintainable</h1>
                </header>
            
            <article>
                
<p>The way that Micro has been built is incredibly sympathetic towards modern enterprise problems of updating and maintaining microservices. Versioning is incorporated into the framework, and in our example, we are setting the version in the <kbd>server.Init</kbd> method. It is possible for multiple services to co-exist differentiated by their version number. When requesting the service, it is possible to filter by a version which allows new versions of a service to be deployed without causing disruption to the rest of the estate.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Format (REST/RPC)</h1>
                </header>
            
            <article>
                
<p>At its heart, Micro uses Google's Protocol Buffers as its core messaging protocol. This, however, is not the only method by which you can communicate with the services. Micro also implements the sidecar pattern which is an RPC proxy. This gives a really simple way of integrating any application into the Micro ecosystem. The sidecar can be used as an API gateway, which is a single point of entry for multiple downstream services. In Micro's case, the gateway handles HTTP requests and converts them to RPC; it is also capable of providing reverse-proxy functionality. This is a very versatile pattern, and the sidecar can be scaled differently to the primary services, allowing you to expose this as a public facing endpoint for non-Micro consumers.</p>
<p>More information on the architecture of Micro can be found on the Micro website at <a href="https://blog.micro.mu/2016/03/20/micro.html"><span class="URLPACKT">https://blog.micro.mu/2016/03/20/micro.html</span></a> and <a href="https://blog.micro.mu/2016/04/18/micro-architecture.html"><span class="URLPACKT">https://blog.micro.mu/2016/04/18/micro-architecture.html</span></a>. I thoroughly recommend anyone who is thinking about using Micro to read these articles as they give an excellent overview of just what it is capable of and the fantastic array of patterns that it uses.</p>
<p>Micro also implements a codec interface for encoding and decoding messages so while, by default, this supports <kbd>proto-rpc</kbd> and <kbd>json-rpc</kbd>, it would be incredibly easy to apply the messaging protocol of your choice.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Patterns</h1>
                </header>
            
            <article>
                
<p>In general, Micro has been very well architected and built with production use in mind. Asim, who created Micro and is the primary maintainer, has an incredible pedigree as a software architect and software engineer. Most of the common patterns that we will discuss in this chapter have been implemented in Micro and many more are available as community plugins. Full PubSub support is included and again supports a vast array of backend servers including Redis and NATS. Due to the architectural model, it is comparatively easy to write your own plugins should your backend of choice not be supported as part of the standard package.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Language independence</h1>
                </header>
            
            <article>
                
<p>Thanks to two nice design choices with the use of Protocol Buffers as a messaging format and the ability of the sidecar, it is possible to interface with microservices from just about any language that can support an HTTP transport.</p>
<p>Let's take a quick look at how we could send and receive messages using Ruby. This example is probably a little more complicated than just making a simple REST call, and most people who use Micro would probably opt to use JSON-RPC from the sidecar. However, it is interesting to see how we can interface using the RPC interface. While there may seem to be far more boilerplate than what you would find if you were making a call using the Go client for Micro, this could be wrapped up into a library and distributed as a gem; this code is only to illustrate the possibilities:</p>
<p><kbd>gomicro/client/client.rb</kbd></p>
<pre>
 82 def main() <br/> 83 <br/> 84   puts "Connecting to Kittenserver" <br/> 85 <br/> 86   request = Bmigo::Micro::Request.new(name: 'Nic') <br/> 87   body = send_request('kittenserver_kittenserver_1', '8091', <br/>      'Kittens.Hello', request).body <br/> 88   envelope, message = read_response(body, Bmigo::Micro::Response) <br/> 89 <br/> 90   puts envelope.inspect <br/> 91   puts message.inspect <br/> 92 end 
</pre>
<p>In the same way that we generated some native Go code from the proto file, we can do the same for Ruby. This makes it possible to share these service definitions and save the consumer the trouble of having to write them by hand. In line <strong>86</strong>, we are creating our request which is sent to the Micro service. Even though Micro is an RPC service, it still uses HTTP as the transport which makes it easy to make a request using Ruby's standard <kbd>NET::HTTP</kbd> library. Before we can do this, however, we need to understand how the message protocol for Micro works. Following is the Micro message format:</p>
<table class="table">
<tbody>
<tr>
<td>
<p>Envelope Size</p>
<p>(4 bytes)</p>
</td>
<td>
<p>Envelope</p>
<p>(n bytes)</p>
</td>
<td>
<p>Message Size</p>
<p>(4 bytes)</p>
</td>
<td>
<p>Message</p>
<p>(n bytes)</p>
</td>
</tr>
</tbody>
</table>
<p>Â </p>
<p>The first 4 bytes in the body are the length of the envelope. The envelope itself is the method by which Micro determines where the message is sent to; it is similar to the way you would use a URI in a RESTful API. The envelope is written to the body using Protocol Buffer's binary serialization using the encode method. Thankfully, all this work is done for us by the <kbd>protobuf</kbd> package. We then write the message size again using exactly 4 bytes and following that the message, which again is encoded into a binary representation using the Protocol Buffers package.</p>
<p>The message can then be sent as an HTTP post. To let Micro know we are sending a binary message and not JSON-RPC, we have to specify the <kbd>Content-Type</kbd> header and set this to <kbd>application/octet-stream</kbd>.</p>
<p>The response which is returned by Micro will be in the same format as the request.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Ability to interface with other frameworks</h1>
                </header>
            
            <article>
                
<p>Because of its language-agnostic interface, it is possible to integrate Micro with many different frameworks. Theoretically, you could even write your Micro compatible service which takes advantage of all the service discovery and registration in a language which is not Go. Why would we want to do that though? After all, Go is fantastic.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Efficiency</h1>
                </header>
            
            <article>
                
<p>Micro performs admirably, managing to hold 400 connections with roughly a 125 ms response. The response time gives us nearly 3,000 requests per second. While this is not a direct reflection on how your server will perform in production, we will be using the same setup to test all the frameworks in this chapter. When load testing Micro, the memory consumption was efficient, only consuming approximately 10% of the available memory on the server. CPU loads, like all tests, were running at maximum but this is to be expected when the system is handling so many concurrent requests for such a small setup.</p>
<p><strong>Results:</strong></p>
<table class="table">
<tbody>
<tr>
<td>
<p>Threads</p>
</td>
<td>
<p>400</p>
</td>
</tr>
<tr>
<td>
<p>Total Requests:</p>
</td>
<td>
<p>806011</p>
</td>
</tr>
<tr>
<td>
<p>Avg. Request Time</p>
</td>
<td>
<p>125.58ms</p>
</td>
</tr>
<tr>
<td>
<p>Total Success</p>
</td>
<td>
<p>806011</p>
</td>
</tr>
<tr>
<td>
<p>Total Timeouts</p>
</td>
<td>
<p>0</p>
</td>
</tr>
<tr>
<td>
<p>Total Failures</p>
</td>
<td>
<p>0</p>
</td>
</tr>
</tbody>
</table>
<div><strong>Requests over time:</strong></div>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="275" width="704" class="image-border" src="assets/cbe35ccd-4cd5-439a-9e4b-f0b5096f00d1.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Quality</h1>
                </header>
            
            <article>
                
<p>The quality of the Micro framework is very high with automated builds, and decent code coverage where needed, and it should be straightforward to navigate implementing many of the standard Go idioms.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Open source</h1>
                </header>
            
            <article>
                
<p>The framework is open source using the Apache license. Regarding popularity, Micro has over 2,000 stars on GitHub and accepts contributions from the community.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Security</h1>
                </header>
            
            <article>
                
<p>Out of the box, Micro does not have an explicit authentication or authorization layer, and I believe this is a good thing. It would be relatively trivial to implement your authentication into the service framework using JWT or if you really must, your proprietary format. Request validation is handled in part by the Protocol Buffers. However, to do more complex validation would possible using something like <kbd>govalidator</kbd> (<a href="https://github.com/asaskevich/govalidator"><span class="URLPACKT">https://github.com/asaskevich/govalidator</span></a>). However, since you cannot directly modify the request objects to add the fields tags required, you may have to jump through a few hoops here. The issue with validation, however, is more to do with the Protocol Buffers framework, not Micro.</p>
<p>From a secure communication perspective, Micro uses <kbd>net/http</kbd> as the base transport, so it will be a trivial matter to introduce TLS encryption, not just for the public facing services, but also for private services. You will see why this is important when we take a more in-depth look at security.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Support</h1>
                </header>
            
            <article>
                
<p>Support for using the framework is pretty excellent; there are plenty of code examples, and there is a Slack group which is well used, so any questions you may have can be answered either by other users or by Asim himself, who is very active in the group in providing support.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Extensibility</h1>
                </header>
            
            <article>
                
<p>One of the nice features of Micro is the way that it has been architected for extensibility. All of the standard dependencies for service discovery, messaging, and transport follow an interface-driven abstraction. Should you need to implement a particular use case or for upgrades when a breaking change may be introduced by the likes of an etcd version update, it will be no problem to write a plugin specific to this and use this within your services. As expected of a framework of this quality, middleware is supported on both the client and the server interfaces, which would enable a vast array of functionality from authentication and authorization to request validation.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What we learned about Micro</h1>
                </header>
            
            <article>
                
<p>In general, Micro is a nice framework which covers nearly all of your needs when building a highly scalable distributed system. Asim has done an excellent job, both in creating this and maintaining it, and his skill and experience shine through in the patterns he has implemented.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Kite</h1>
                </header>
            
            <article>
                
<p>Kite is a framework that is developed by the team responsible for Koding, the browser-based IDE. The framework is used by the Koding team and was open sourced as they believed that it would be useful for other microservice practitioners, having faced many of the problems themselves.</p>
<p>The concept behind the framework is that everything is a Kite, both servers, and clients and that they communicate in a bi-directional manner using web sockets and an RPC based protocol. Web sockets make inter-service communication incredibly efficient as it removes the overhead of constantly having to handshake a connection which can take as much time as the message passing itself. Kite also has a built in service discovery feature which allows you to make a call to a Kite without knowing the specific endpoint.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Setup</h1>
                </header>
            
            <article>
                
<p>The installation of Kite is relatively simple; there are a few dependencies for service discovery, such as <kbd>etcd</kbd>, but all the code you need to create a Kite is found in the Go package. If we install this package using the <kbd>go get</kbd> command we can go ahead and start writing our first Kite.</p>
<pre>
<strong>go get github.com/koding/kite</strong>  
</pre>
<p>The way Kite works is that there is a service which runs along with your application Kites called <strong>kontrol</strong>. This handles service discovery, and all of your application services register with this service so that the clients can query the service catalog to obtain the service endpoint. The kontrol Kite comes bundled within the main package, and for convenience, I have created a Docker Compose file, which starts this along with <kbd>etcd</kbd>, which is used as the service registry.</p>
<p>If we take a look at our server implementation, we can see the various steps we need to add to register our new service:</p>
<p><kbd>kite/server/main.go</kbd></p>
<pre>
 13 func main() { <br/> 14 <br/> 15   k := kite.New("math", "1.0.0") <br/> 16   c := config.MustGet() <br/> 17   k.Config = c <br/> 18   k.Config.KontrolURL = "http://kontrol:6000/kite" <br/> 19 <br/> 20   k.RegisterForever(&amp;url.URL{Scheme: "http", Host: "127.0.0.1:8091", Path: "/kite"}) <br/> 21 <br/> 22   // Add our handler method with the name "square" <br/> 23   k.HandleFunc("Hello", func(r *kite.Request) (interface{}, error) { <br/> 24     name, _ := r.Args.One().String() <br/> 25 <br/> 26     return fmt.Sprintf("Hello %v", name), nil <br/> 27   }).DisableAuthentication() <br/> 28 <br/> 29   // Attach to a server with port8091 and run it <br/> 30   k.Config.Port = 8091 <br/> 31   k.Run() <br/> 32 <br/> 33 } 
</pre>
<p>In line <strong>15</strong>, we are creating our new Kite. We pass two arguments to the <kbd>New</kbd> method: the name of our Kite and the service version. We then obtain a reference to the configuration and set this to our Kite. To be able to register our kite with the service discovery, we have to set the <kbd>KontrolURL</kbd> with the correct URI for our kontrol server:</p>
<pre>
k.Config.KontrolURL = "http://kontrol:6000/kite 
</pre>
<p>If you look at the URL we are passing it; we are using the name that is supplied by Docker when we link together some containers.</p>
<p>In the next line, we are registering our container with the kontrol server. We need to pass the URL scheme we are using. In this instance, HTTP is the hostname; this needs to the accessible name for the application. We are cheating a little bit with this host as we are exposing the ports to the Docker host; we could have passed the internal name had our client application had been linked to this one.</p>
<p>Now the interesting stuff starts, and we define the methods that our Kite will have available to it. If we take a look at line <strong>25</strong>, we will see a pattern that should look quite familiar:</p>
<pre>
HandleFunc(route string, function func(*kite.Request) (interface{}, error)) 
</pre>
<p>The signature for <kbd>HandleFunc</kbd> is very similar to that of the standard HTTP library; we set up a route and pass a function which would be responsible for executing that request. You will see that both the request and the response are not typed. Well, that is not exactly correct for the <kbd>Request</kbd> method, but certainly, there is no explicitly defined contract.</p>
<p>To get the arguments which are passed with the <kbd>Request</kbd> method, we use the <kbd>Args</kbd> object, which is a <kbd>dnode</kbd> message. Unlike the other frameworks we have looked at, a <kbd>dnode</kbd> message does not have a contract which can be shared between consumers and producers of this message, so each must implement their interpretation. The <kbd>dnode</kbd> message itself is a newline terminated JSON message and is heavily abstracted by the kite framework, for the curious, the protocol definition can be found in the following document: <a href="https://github.com/substack/dnode-protocol/blob/master/doc/protocol.markdown#the-protocol">https://github.com/substack/dnode-protocol/blob/master/doc/protocol.markdown#the-protocol</a></p>
<p><span>The output of our</span> <kbd>HandleFunc</kbd> <span>is the standard Go pattern of</span> <kbd>interface{} error</kbd><span>, again the</span> <kbd>interface{}</kbd> <span>which is the response we would like to send to the caller. This is not strongly typed, and it is most likely just a struct which can be serialized down to a</span> <kbd>dnode</kbd> <span>payload, the representation of which is just JSON.</span></p>
<p>One of the nice features of Kite is that authentication is built in and, in our instance, we are disabling this. It is quite common to restrict the actions of a particular service call based upon the permissions of the caller. Under the hood, Kite is using <kbd>JWT</kbd> to break down these permissions into a set of claims. The principle is that a key is signed and therefore a receiving service only has to validate the signature of the key to trust its payload rather than having to call a downstream service. The final line we are calling is <kbd>k.Run()</kbd>; this starts our Kite and blocks our main function.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Code generation</h1>
                </header>
            
            <article>
                
<p>With Kite, there is no code generation or templates to help set up your servers and clients. That said, the simplicity of creating a server does not warrant the need for this.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Tooling</h1>
                </header>
            
            <article>
                
<p>Besides Go, there is little you need to set up Kite. etcd, which is used for your service discovery, and Kite, are easily packaged into a Docker container, which allows a standard testing and deployment workflow.</p>
<p>The cross-platform elements of the framework are limited to areas which can be compiled with the Go framework, which, as I write this, is a rather impressive array.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Maintainable</h1>
                </header>
            
            <article>
                
<p>Kite is a relatively mature framework with active development over a period of three years. It is also actively used by the Koding service which was acquired by Amazon in 2016.</p>
<p>Due to the way that routing works by registering a handler, it would be possible to cleanly separate your implementation from the main Kite packages, which would allow easy updating of the main package when upstream changes are made.</p>
<p>I do have a slight reservation about the lack of contracts around the <kbd>dnode</kbd> messages. This could cause maintenance problems if not properly managed, as the consumer has the responsibility of discovering the protocol implementation and the supplier service must document this protocol and ensure that it is correctly versioned to avoid breaking changes. As far as I am aware, there is no capability to produce documentation from the code source automatically. Since dnode uses JSON under the hood, it might be an idea to have a single argument in the payload containing a JSON object, the type of which is known and could be easily serialized to a struct using the standard package.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Format</h1>
                </header>
            
            <article>
                
<p>Kite uses dnode as its messaging protocol. While this is not a concern if you are doing kite-to-kite communication or if you are using the JavaScript framework for Kite, it might be an issue if you would like to interface from another language in your stack. The protocol definition is listed in the GitHub project at <a href="https://github.com/substack/dnode-protocol/blob/master/doc/protocol.markdown#the-protocol"><span class="URLPACKT">https://github.com/substack/dnode-protocol/blob/master/doc/protocol.markdown#the-protocol</span></a> and it is JSON-based. Looking at the documentation for dnode, it seems that the messaging protocol and the execution framework was never intended to be loosely coupled. My personal recommendation when choosing a messaging protocol is that you should ensure there are encoders and decoders already written for your chosen languages. If there is no package, then you need to assess if the protocol has a large enough user base that the actions of writing this would be warranted.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Patterns</h1>
                </header>
            
            <article>
                
<p>Service discovery is built into Kite with the application kontrol. The backend store for kontrol is not proprietary, but it uses a plugin architecture and supports etcd, consul, and so on.</p>
<p>If we look at our client application, we can see how this works in action.</p>
<p>In line <strong>19</strong>, we are calling the <kbd>GetKites</kbd> method and passing a <kbd>KontrolQuery</kbd> as a parameter. The query contains the username, environment, and the name of the service we would like to reference.</p>
<p>The return type of this call is a slice of Kites. In our simple example, we are just getting a reference to the first item in the list. This process does mean that we have to implement load balancing and circuit breaking ourselves; it would have been nice if we could have had this feature built into kontrol.</p>
<p>To connect to Kite, we have two methods at our disposal:</p>
<pre>
Dial() <br/>DialForever() 
</pre>
<p>The <kbd>Dial()</kbd> method takes a timeout, which, when elapsed, the method will return regardless of whether it has been possible to connect to the downstream service or not. The <kbd>DialForever()</kbd> method, as the method name suggests, will not. In both instances, a channel is returned which we use to pause execution until we have obtained our connection.</p>
<p>Calling the service is now as simple as executing <kbd>Tell</kbd>, and passing the method name, you wish to run and the parameters as an interface for that method. In my humble opinion, Kite loses points here. The contracts for the service calls are very loose and creating an implementation for the consumers will not be without effort.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Language independence</h1>
                </header>
            
            <article>
                
<p>Kite as a framework is predominately Go, and JavaScript based. The JavaScript package <a href="https://github.com/koding/kite.js"><span class="URLPACKT">https://github.com/koding/kite.js</span></a> allows you to write a Kite in JavaScript which would run on the server with NodeJS or you can also use the plugin direct from the browser, which would enable you to build rich user interfaces.</p>
<p>Communicating with Kite from a language such as Ruby would require a degree of effort. Custom code would need to be written to interact with kontrol and to execute queries to the Kites. This would certainly be possible, and if you build this framework, please push it back to the open source community.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Efficiency</h1>
                </header>
            
            <article>
                
<p>Kite is fast. Thanks to the way it uses web sockets there seems to be little overhead once you are connected. When I was testing the system, I did experience some problems with creating multiple Kite connections; this was not on the server but the client. To be honest, I have not dug too far into this, and the performance from using a shared Kite in the client is pretty impressive. In terms of CPU and memory consumption, Kite consumes the most of all the frameworks evaluated. For the 400 connection test, Kite was consuming 1.8 GB of the 2 GB of RAM available on the client; the server was consuming 1.6 GB. Both client and server were heavy users of the CPU:</p>
<p><strong>Results table:</strong></p>
<table class="table">
<tbody>
<tr>
<td>
<p>Threads</p>
</td>
<td>
<p>400</p>
</td>
</tr>
<tr>
<td>
<p>Total Requests:</p>
</td>
<td>
<p>1649754</p>
</td>
</tr>
<tr>
<td>
<p>Avg. Request Time</p>
</td>
<td>
<p>33.55ms</p>
</td>
</tr>
<tr>
<td>
<p>Total Success</p>
</td>
<td>
<p>1649754</p>
</td>
</tr>
<tr>
<td>
<p>Total Timeouts</p>
</td>
<td>
<p>0</p>
</td>
</tr>
<tr>
<td>
<p>Total Failures</p>
</td>
<td>
<p>0</p>
</td>
</tr>
</tbody>
</table>
<div><strong>Requests over time:</strong></div>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="274" width="701" class="image-border" src="assets/eacee694-2628-49ad-98f1-b5495747c2f3.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Quality</h1>
                </header>
            
            <article>
                
<p>The Kite framework uses Travis CI, and there are unit and integration tests executed for each build. Code coverage is not huge; however, it seems to cover the complexities and looking at the issues in GitHub, there is nothing outstanding.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Open source</h1>
                </header>
            
            <article>
                
<p>The project is fairly popular with over 1,200 GitHub stars. However, there is no slack community or forum. The authors are, however, excellent at answering questions when they are posted to GitHub issues.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Security</h1>
                </header>
            
            <article>
                
<p>Security wise, Kite has its own authentication layer using <kbd>JWT</kbd> and supports the standard Go TLS configuration to connect two Kites securely. Request validation does not, however, seem to be present, and I guess this is due to the dnode protocol being quite dynamic. It should be relatively straightforward to implement this as the handlers could be chained in the same way a middleware pattern could be built with <kbd>net/http</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Support</h1>
                </header>
            
            <article>
                
<p>Since Kite is used in a commercial context with Koding, it is very well maintained and mature, receiving regular updates. Documentation, however, is somewhat lacking and while I was working on the example code, I spent quite a lot of time figuring out the various parts. The authors are aware of the problems with the documentation and do plan to improve this facet. Google also has little to offer in the way of help for Kite. When searching for an issue, generally you will end up back on the GitHub repository. This is not a massive problem if you are a relatively experienced developer, as you can simply read through the code and reverse engineer it. However, if you are just starting out this might be a problem as you may not have a solid grasp of the underlying concepts.</p>
<p>There is code level documentation, and the code is self-descriptive; however, there are elements which could do with further explanation.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Extensibility</h1>
                </header>
            
            <article>
                
<p>There is no formal plugin or middleware format for Kite. However, due to the way it has been engineered, it should be possible to extend the framework. You may run into problems, however. For example, if you wish to add a different backend for kontrol storage, the options are hardcoded into the kontrol application, so even though storage is derived from an interface, a modification would need to be made to kontrol's main function to enable this.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summing up Kite</h1>
                </header>
            
            <article>
                
<p>Kite is a nicely written framework, and if you are only building microservices in Go with a requirement for access from the browser, then it could be a right choice. In my opinion, the documentation and tutorials need more work; however, I suspect this is due to Kite being an internal framework of a small company which has been open sourced rather than the intention of producing a community open source framework. Kite loses quite a few points due to a lack of standard patterns built into the framework. Cross-framework integration also suffers due to the messaging protocol dnode and the documentation could be dramatically improved.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">gRPC</h1>
                </header>
            
            <article>
                
<p>We have already taken a look at the Protocol Buffers messaging protocol from Google when we looked at API design in <a href=""><span class="ChapterrefPACKT">Chapter 2</span></a>, <em>Designing a Great API</em>. gRPC is a cross-platform framework which uses HTTP/2 as the transport and Protocol Buffers as the messaging protocol. Google developed it as a replacement for their Stubby framework which they had used internally for many years.</p>
<p>The intention behind the project was to build a framework which promotes good microservice design, concentrating on messages rather than distributed objects. gRPC is also optimized for the many network problems we face in microservice architecture, such as fragile networks, limited bandwidth, the cost of the transport, and so on. One of the other lovely facets of gRPC is its ability to stream data between client and server. This can have a huge benefit in certain application types and is built into the framework as a standard component. Additionally, for microserivice to microservice communication, there is a pure javascript implementation which is designed to enable browser clients to access a gRPC server. At the time of writing, this has not yet been released, the expected shipping date is quarter 3 in 2017.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Setup</h1>
                </header>
            
            <article>
                
<p>The main problem with setting up a gRPC project is installing the <kbd>protoc</kbd> application and the various plugins which are obtained from the following URL:</p>
<p><a href="https://github.com/google/protobuf/releases"><span class="URLPACKT">https://github.com/google/protobuf/releases</span></a></p>
<p>We then need to install the Go packages for gRPC and the code generation plugin for protoc:</p>
<pre>
<strong>$ go get google.golang.org/grpc</strong><br/><strong>$ go get -u github.com/golang/protobuf/{proto,protoc-gen-go}</strong>  
</pre>
<p>For convenience, I have created a Docker container which has all these packages (<kbd>nicholasjackson/building-microservices-in-go</kbd>). If you take a look at the Makefile in the example code at <kbd>chapter4/grpc/Makefile</kbd>, you will see that we are using the power of Docker to save the hassle of having to install any applications.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Code generation</h1>
                </header>
            
            <article>
                
<p>The beauty of gRPC is the code generation. From the simple <kbd>proto</kbd> files that we looked at in <a href=""><span class="ChapterrefPACKT">Chapter 2</span></a>, <em>Designing a Great API</em>, we can generate all our client and server code. All we then have to do is to wire up our handlers which will deal with the business logic.</p>
<p>If we take a look at the proto file in <kbd>chapter4/grpc/proto/kittens.proto</kbd>, we can see that the file is somewhat similar to the one we reviewed in a previous chapter.</p>
<p>The main difference is the following block from line <strong>13</strong>:</p>
<pre>
 13 service Kittens { <br/> 14     rpc Hello(Request) returns (Response) {} <br/> 15 } 
</pre>
<p>This is our service definition, which contains the contract for our handlers. It is nicely semantic and very readable even though it is written in the proto DSL.</p>
<p>To generate our Go code, all we need to do is to call the <kbd>protoc</kbd> command and tell it to use the Go plugin:</p>
<pre>
<strong>protoc -I /proto /proto/kittens.proto --go_out=plugins=grpc:/proto</strong>  
</pre>
<p>This will create our messages and our service definitions, and output them to the <kbd>kittens.pb.go</kbd> file. It is relatively interesting to look at this file, even though the code is auto-generated, to see some of the inner workings of the framework.</p>
<p>Now let's see just how easy it is to use the framework if we take a look at <kbd>grpc/server/main.go</kbd>.</p>
<p>We can see that the first thing we are doing is setting up our handler code:</p>
<pre>
 15 type kittenServer struct{} <br/> 16 <br/> 17 func (k *kittenServer) Hello(ctx context.Context, request <br/>    *proto.Request) (*proto.Response, error) { <br/> 18   response := &amp;proto.Response{}<br/> 19   response.Msg = fmt.Sprintf("Hello %v", request.Name) <br/> 20 <br/> 21   return response, nil <br/> 22 } 
</pre>
<p>In line <strong>15</strong>, we are creating a struct, the methods of which will correspond to the <kbd>KittenServer</kbd> interface, which has been auto-generated for us by the <kbd>protoc</kbd> command:</p>
<pre>
type KittensServer interface { <br/>    Hello(context.Context, *Request) (*Response, error) <br/>} 
</pre>
<p>Line <strong>17</strong> is where we are defining our handler, and again the pattern should look familiar to the one we examined in <a href="ba3a8742-94e7-4e47-8a47-1324a277a7f9.xhtml"><span class="ChapterrefPACKT">Chapter 1</span></a>, <em>Introduction to Microservices</em>. We have our context and an object which corresponds to the request message we defined in our <kbd>protos</kbd> file and the return tuple of response and error.</p>
<p>This method is where we will do the work for the request, and you can see on line <strong>18</strong> that we are creating a response object and then setting the message which will be returned to the client.</p>
<p>Wiring up the server is also really straightforward. We only need to create a listener and then create a new instance of the server, which has been auto-generated for us by the <kbd>protoc</kbd> command:</p>
<pre>
 24 func main() { <br/> 25   lis, err := net.Listen("tcp", fmt.Sprintf(":%d", 9000)) <br/> 26   if err != nil { <br/> 27     log.Fatalf("failed to listen: %v", err) <br/> 28   } <br/> 29   grpcServer := grpc.NewServer() <br/> 30   proto.RegisterKittensServer(grpcServer, &amp;kittenServer{}) <br/> 31   grpcServer.Serve(lis) <br/> 32 } 
</pre>
<p>The client code is similarly straightforward. If we take a look at <kbd>grpc/client/client.go</kbd>, we can see that we are creating a connection to our server and then initiating the request:</p>
<pre>
 12 func main() { <br/> 13   conn, err := grpc.Dial("127.0.0.1:9000", grpc.WithInsecure()) <br/> 14   if err != nil { <br/> 15     log.Fatal("Unable to create connection to server: ", err) <br/> 16   } <br/> 17 <br/> 18   client := proto.NewKittensClient(conn) <br/> 19   response, err := client.Hello(context.Background(), <br/>      &amp;proto.Request{Name: "Nic"}) <br/> 20 <br/> 21   if err != nil { <br/> 22     log.Fatal("Error calling service: ", err) <br/> 23   } <br/> 24 <br/> 25   fmt.Println(response.Msg) <br/> 26 } 
</pre>
<p>The <kbd>grpc.Dial</kbd> method has the following signature:</p>
<pre>
func Dial(target string, opts ...DialOption) (*ClientConn, error) 
</pre>
<p>The target is a string which corresponds to the server's network location and port and opts is a variadic list of <kbd>DialOptions</kbd>. In our example, we are only using <kbd>WithInsecure</kbd>, which disables transport security for the client; the default is that transport security is set so, in our simple example, we need this option.</p>
<p>The list of choices is very comprehensive, and you can specify configuration such as timeouts and using a load balancer. For the full list, please see the documentation which can be found at <a href="https://godoc.org/google.golang.org/grpc#WithInsecure"><span class="URLPACKT">https://godoc.org/google.golang.org/grpc#WithInsecure</span></a>.</p>
<p>Line <strong>18</strong> is where we are creating our client. This is a type which is defined in our auto-generated code file, not the base package. We pass it the connection we created earlier and then we can call the methods on the server as shown in line <strong>19</strong>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Tooling</h1>
                </header>
            
            <article>
                
<p>The tooling for gRPC is rather impressive. There are a huge number of platforms and languages supported, and just with Go and the <kbd>protoc</kbd> application, it is relatively trivial to set up an automated build. In our simple example, I have configured the build to run in a Docker container which further limits the requirements for any software to be installed on the continuous deployment machines. By doing this, we can limit the dependencies which are used in all our builds. This is a technique we will learn more about in a later chapter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Maintainable</h1>
                </header>
            
            <article>
                
<p>Updating gRPC is also incredibly easy. Google has put a significant amount of work into making the new v3 specification for Protocol Buffers backward compatible with v2 and, according to the documentation, there is a desire to maintain this as gRPC and Protocol Buffers move forward.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Format</h1>
                </header>
            
            <article>
                
<p>While we may not have the semantic nature of REST, we do have a very clearly defined messaging protocol with Protocol Buffers. The definitions are easy to understand, and the ability for connecting clients to use the proto files we defined and reuse them to create their clients is a very nice feature.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Patterns</h1>
                </header>
            
            <article>
                
<p>The array of patterns that is also implemented into the framework is very comprehensive, supporting health checks and timeouts. There is no explicit support for middleware; however, many of the requirements for middleware, such as authentication and request validation, we get for free built into the framework. We also do not have circuit breaking, but the balancer can be configured to add this functionality. In the official documentation, there is a statement that this is an experimental API and may be changed or extended in the future. We can, therefore, expect many great updates from this feature.</p>
<p>The clients themselves have configuration to deal with a back off algorithm. This throttling protects your servers in the instance of high load by not flooding a server which may be under pressure with thousands of connections.</p>
<p>From a service discovery perspective there is no implicit handling of this inside the framework; however, the extension points are there to perform this with your backend of choice.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Language independence</h1>
                </header>
            
            <article>
                
<p>The number of languages which are currently supported by gRPC is quite impressive, with 10 languages officially supported and there are many more by a growing community. The ability to generate and distribute client SDKs in multiple languages using the <kbd>protoc</kbd> command is fantastic. To see how this could work from a language other than Go, we have created a simple example in Ruby which shows just how easy it is to make a connection to a gRPC service.</p>
<p>In our example, <kbd>grpc/client/client.rb</kbd>, we can see that there are very few lines of code need to initiate a connection and execute a request to a gRPC endpoint written in Go:</p>
<pre>
  6 require 'kittens_services_pb' <br/>  7 <br/>  8 service = <br/>     Bmigo::Grpc::Kittens::Stub.new('kittenserver_kittenserver_1:9000', <br/>     :this_channel_is_insecure) <br/>  9 <br/> 10 request = Bmigo::Grpc::Request.new <br/> 11 request.name = 'Nic' <br/> 12 <br/> 13 response = service.hello(request) <br/> 14 <br/> 15 puts response.msg 
</pre>
<p>For the non-Rubyists, in line <strong>6</strong>, we are including our auto-generated code, which was generated with the <kbd>protoc</kbd> command and using the Ruby gRPC plugin.</p>
<p>Line <strong>8</strong> then creates an instance to our server, again passing the option of an insecure channel like we did in the Go client.</p>
<p>We then create a request object in line <strong>10</strong>, set the parameters for this request, and execute it. All of the objects for the request and response are defined for us and are incredibly easy to use.</p>
<p>Google are currently working on a version of the framework which would enable connections to a gRPC service from the web browser. When this arrives, it will be very easy to create interactive web applications which are backed by gRPC microservices.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Efficiency</h1>
                </header>
            
            <article>
                
<p>Thanks to the use of HTTP/2 and the binary messaging, gRPC is incredibly quick and capable of supporting a massive throughput. The option for streaming data to the client is a fantastic feature. From a mobile perspective, the client only needs to maintain a single connection to the server which is efficient and the server can push data updates to this open connection. For an example of how this could work, have a look at some code I created for a talk at GoLang UK. This implements a simple server and Android client which receives streaming updates. Rather than use native gRPC clients on Android, I geeked out using GoMobile to compile a native framework which was written in Go and then used this in the Android app:</p>
<p><a href="https://github.com/gokitter"><span class="URLPACKT">https://github.com/gokitter</span></a></p>
<p><strong>Results:</strong></p>
<table class="table">
<tbody>
<tr>
<td>
<p>Threads</p>
</td>
<td>
<p>400</p>
</td>
</tr>
<tr>
<td>
<p>Total Requests:</p>
</td>
<td>
<p>2949094</p>
</td>
</tr>
<tr>
<td>
<p>Avg. Request Time</p>
</td>
<td>
<p>23.81ms</p>
</td>
</tr>
<tr>
<td>
<p>Total Success</p>
</td>
<td>
<p>2949094</p>
</td>
</tr>
<tr>
<td>
<p>Total Timeouts</p>
</td>
<td>
<p>0</p>
</td>
</tr>
<tr>
<td>
<p>Total Failures</p>
</td>
<td>
<p>0</p>
</td>
</tr>
</tbody>
</table>
<div><strong>Requests over time:</strong></div>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="279" width="714" class="image-border" src="assets/4816c507-f962-449a-99c7-1e83cf17f8d1.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Quality</h1>
                </header>
            
            <article>
                
<p>As you may expect from Google, the quality of the project is incredibly high with some awesome architectural patterns and standard language patterns implemented by the framework. All the code is built using continuous integration, and the test coverage is excellent.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Open source</h1>
                </header>
            
            <article>
                
<p>The framework is growing in popularity and is under constant development by both Google and community committers. Everything is open source, and if you want to dig into the code, it is all available for you at the GitHub repository:</p>
<p><a href="https://github.com/grpc"><span class="URLPACKT">https://github.com/grpc</span></a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Security</h1>
                </header>
            
            <article>
                
<p>From a security perspective, we have all the features we could need. gRPC supports TLS encryption, authentication, and request validation. Because the underlying transport is <kbd>net/http</kbd>, we can also be confident that we are receiving the highest quality in the server layer.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Support</h1>
                </header>
            
            <article>
                
<p>Documentation is again excellent with both great examples and source code documentation provided on the gRPC website. There is a growing list of community resource with further examples provided by bloggers and support can also be found on the Google group and Stack overflow.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Extensibility</h1>
                </header>
            
            <article>
                
<p>From an extensibility perspective, it is possible to write custom plugins for both protoc, like the Micro framework does, and also the framework has been well written and is extensible. As a new framework only just reaching version 1, the current options are very impressive, and I can only see these growing in future releases.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">A few lines about gRPC</h1>
                </header>
            
            <article>
                
<p>I am very impressed with the gRPC framework and the array of options and community support which seems to grow by the day. The Protocol Buffers messaging format also appears to be growing with companies such as Apple contributing their implementation, and I can see this becoming an unofficial standard for client-server communication replacing JSON in the very near future.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>Both Micro and gRPC came out top in the evaluation, but for slightly different reasons. Micro is ready to use in a production system out of the box if the majority of your estate is Go. The development on Micro is continuing, and the current focus is on that of performance, which, to be honest, is already pretty impressive. That said, with some work around the missing elements which are essential for microservice development, grpC is a real contender. The polyglot nature and the throughput are excellent, and it is continuously improving.</p>
<p>In this chapter, we have looked at a few different frameworks, and I hope they will have given you a taster of some of the key features needed if you ever have to make a decision yourself. In the next chapter, we are going to look at logging and metrics which are essential techniques for running microservices in production.</p>


            </article>

            
        </section>
    </body></html>