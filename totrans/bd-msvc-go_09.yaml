- en: Event-Driven Architecture
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 事件驱动架构
- en: In the last few chapters, we have looked at issues around stability and performance,
    and some patterns you can employ in your code, which enable more stable systems.
    In this chapter, we are going to take a more in-depth look at event-driven architecture.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的几章中，我们探讨了稳定性和性能方面的问题，以及你可以在代码中采用的某些模式，这些模式能够使系统更加稳定。在本章中，我们将更深入地探讨事件驱动架构。
- en: As your system grows, these patterns become more important; they allow you to
    loosely couple your microservices, and therefore you are not bound to the same
    dependencies of intertwined objects common in monolithic applications. We are
    going to learn that with the right amount of up-front design and effort that loosely
    coupling your systems with events need not be a painful process.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 随着你的系统不断增长，这些模式变得越来越重要；它们允许你松散地耦合你的微服务，因此你不必绑定到在单体应用中常见的相互交织的对象的相同依赖。我们将了解到，通过适当的前期设计和努力，使用事件来松散耦合系统并不一定是一个痛苦的过程。
- en: Before we begin, be sure to fetch the source code from [https://github.com/building-microservices-with-go/chapter9](https://github.com/building-microservices-with-go/chapter9)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，请确保从[https://github.com/building-microservices-with-go/chapter9](https://github.com/building-microservices-with-go/chapter9)获取源代码。
- en: Differences between synchronous and asynchronous processing
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 同步处理和异步处理之间的差异
- en: If there is a choice between processing a message synchronously or asynchronously,
    then I would always choose synchronous as it always makes the application simpler
    with fewer components parts, the code is easier to understand, tests easier to
    write, and the system easier to debug.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在同步处理消息和异步处理消息之间有选择，那么我总是会选择同步，因为它总是使应用程序更简单，组件更少，代码更容易理解，测试更容易编写，系统更容易调试。
- en: Asynchronous processing should be a design decision that is driven by need,
    be that the requirement for decoupling, scale, batch processing, or time-based
    processing. **Event-Driven Systems** give an ability to scale at much higher things
    than monolithic systems and the reason for that is that because of the loose coupling
    the code scales horizontally with both greater granularity and effectiveness.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 异步处理应该是一个由需求驱动的设计决策，无论是解耦、扩展、批量处理还是基于时间的处理。**事件驱动系统**能够以比单体系统更高的水平进行扩展，其原因是由于松散耦合，代码可以水平扩展，具有更大的粒度和效率。
- en: Another problem with asynchronous processing is the additional burden it adds
    to your operations. We need to create infrastructure for message queuing and message
    delivery, this infrastructure needs to be monitored and managed, even if you are
    using your cloud provider's functionality such as SNS/SQS or PubSub.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 异步处理的一个问题是它给你的操作增加了额外的负担。我们需要创建消息队列和消息传递的基础设施，这个基础设施需要被监控和管理，即使你正在使用云提供商的功能，如SNS/SQS或PubSub。
- en: There is even a question about whether you should be implementing microservices
    or building a monolith, however, I think smaller chunks of code are invariably
    easier to deploy and test at the cost of increased duplication for setup of continuous
    integration and provisioning of hardware is a one-time hurdle and something that
    is worth learning. We will look at that in the next chapter when we examine continuous
    deployment and immutable infrastructure, but for now, let's stick with events.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 甚至有一个问题，即你是否应该实现微服务或构建单体，然而，我认为较小的代码块总是更容易部署和测试，尽管这会增加设置持续集成和硬件供应的重复性，但这是一个一次性障碍，也是值得学习的事情。我们将在下一章中探讨这一点，当我们检查持续部署和不可变基础设施时，但现在，让我们继续关注事件。
- en: Having got the warning out of the way, let's retake a look at the difference
    between the two styles of message processing.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在解决了警告之后，让我们重新审视两种消息处理方式的差异。
- en: Synchronous processing
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 同步处理
- en: 'With synchronous processing, all the communication to a downstream application
    happens in the process. A request is sent, and you wait for a reply using the
    same network connection and not using any callbacks. Synchronous processing is
    the simplest method of communication; while you are waiting for an answer the
    downstream service is processing the request. You have to manage the retry logic
    yourself, and it is typically best used only when you need an immediate reply.
    Let''s take a look at the following diagram that depicts synchronous processing:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 使用同步处理，所有与下游应用的通信都在进程中发生。发送一个请求，并使用相同的网络连接等待回复，而不是使用任何回调。同步处理是通信的最简单方法；当你等待答案时，下游服务正在处理请求。你必须自己管理重试逻辑，并且通常仅在需要立即回复时使用最佳。让我们看看以下描述同步处理的图示：
- en: '![](img/8d3ee88c-2980-4100-bc78-12202c4d5537.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8d3ee88c-2980-4100-bc78-12202c4d5537.png)'
- en: Asynchronous processing
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异步处理
- en: 'With asynchronous processing, all the communication to the downstream application
    happens out of process leveraging a queue or a message broker as an intermediary.
    Rather than communicating directly with the downstream service, messages dispatch
    to a queue such as **AWS SQS/SNS**, **Google Cloud Pub/Sub**, or **NATS.io**.
    Because there is no processing performed at this layer the only delay is the time
    it takes to deliver the message, which is very fast, also due to the design of
    these systems, acceptance, or not of a message is the only situation you must
    implement. Retry and connection handling logic is delegated to either the message
    broker or the downstream system as it is the storage of messages for archive or
    replay:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 使用异步处理，所有与下游应用的通信都在进程外发生，利用队列或消息代理作为中介。而不是直接与下游服务通信，消息被调度到队列，例如 **AWS SQS/SNS**、**Google
    Cloud Pub/Sub** 或 **NATS.io**。由于在这一层没有进行任何处理，唯一的延迟就是传递消息所需的时间，这非常快，也得益于这些系统的设计，消息的接受与否是你必须实现的唯一情况。重试和连接处理逻辑委托给消息代理或下游系统，因为它是消息的存储，用于归档或重放：
- en: '![](img/6147298f-87a1-4851-a930-06cf7ce3ac53.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6147298f-87a1-4851-a930-06cf7ce3ac53.png)'
- en: Types of asynchronous messages
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异步消息类型
- en: Asynchronous processing often comes in two different forms, such as push and
    pull. The strategy that you implement is dependent upon your requirements, and
    often a single system implements both patterns. Let's take a look at the two different
    approaches.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 异步处理通常有两种不同的形式，例如推送和拉取。你实施的策略取决于你的需求，通常一个系统会实现这两种模式。让我们来看看这两种不同的方法。
- en: Pull/queue messaging
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 拉取/队列消息
- en: 'The pull pattern is an excellent design where you may have a worker process
    running, which for example is resizing images. The API would receive the request
    and then add this to a queue for background processing. The worker process or
    processes read from the queue retrieving the messages one by one, perform the
    required work, and then delete the message from the queue. Often there is also
    a queue commonly called a "dead letter queue" should the worker process fail for
    any reason then the message would be added to the dead letter queue. The dead
    letter queue allows the messages to be re-processed in the case of an incremental
    failure or for debugging purposes. Let''s take a look the following diagram, which
    summarizes the whole process:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 拉取模式是一种优秀的设计，你可能有一个运行中的工作进程，例如调整图片大小。API 会接收请求，然后将其添加到队列以进行后台处理。工作进程或进程从队列中读取消息，逐个执行所需的工作，然后从队列中删除消息。通常还有一个队列，通常称为“死信队列”，如果工作进程因任何原因失败，则消息将被添加到死信队列。死信队列允许在增量失败或调试目的的情况下重新处理消息。让我们看看以下总结整个过程的图示：
- en: '![](img/70b64a3a-ef18-4935-9a7f-912685e2a231.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/70b64a3a-ef18-4935-9a7f-912685e2a231.png)'
- en: 'Implementing a queue-based service in Go is a relatively straightforward task,
    let''s walk through the example in the source code that accompanies this book.
    This example uses Redis for storing the messages. Redis is an incredibly fast
    data store, and, while it is nice to be able to leverage a cloud providers queue
    rather than managing our infrastructure, this is not always possible. However,
    even if we are using cloud providers queue the pattern we are about to look at
    is easily replaceable with a different data store client. If we consider the following
    listing from the example code in `queue/queue.go`:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Go 中实现基于队列的服务是一个相对直接的任务，让我们通过这本书附带源代码中的示例来了解一下。这个示例使用 Redis 来存储消息。Redis 是一个极快的数据库存储，虽然能够利用云服务提供商的队列而不是管理我们的基础设施是件好事，但这并不总是可能的。然而，即使我们使用云服务提供商的队列，我们即将看到的模式也容易用不同的数据存储客户端替换。如果我们考虑
    `queue/queue.go` 中的示例代码的以下列表：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The first thing we are doing is defining a `Message` object that is used by
    the system and defines three simple parameters that are serializable to JSON.
    ID is never populated by the publisher directly instead this is a calculated ID
    that is unique for every message. Should the consumer need a simple mechanism
    to determine if a message has already been received and processed, then the ID
    can be used. The interface for `Queue` defines three simple methods as follows:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先定义了一个 `Message` 对象，该对象由系统使用，并定义了三个简单的参数，这些参数可以序列化为 JSON。ID 永远不是由发布者直接填充的，而是每个消息都有的一个唯一计算出的
    ID。如果消费者需要一个简单的机制来确定消息是否已经被接收和处理，那么可以使用 ID。`Queue` 接口定义了三个简单的方法，如下所示：
- en: '`Add(messageName string, payload []byte) error`: `Add` is a convenience method
    to publish a new message, the sender only needs to provide the name of the message
    and a slice of byte.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Add(messageName string, payload []byte) error`：`Add` 是一个方便的方法，用于发布一条新消息，发送者只需要提供消息的名称和一个字节数组。'
- en: '`AddMessage(message Message) error`: `AddMessage` performs the same function
    as `Add` with the difference that the caller needs to construct a `Message` type
    and pass this to the method. The implementation of `AddMessage` automatically
    generates the `ID` field on `Message struct` and overwrites any initial `ID` value.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`AddMessage(message Message) error`：`AddMessage` 执行与 `Add` 相同的功能，不同之处在于调用者需要构造一个
    `Message` 类型并将其传递给该方法。`AddMessage` 的实现会自动生成 `Message struct` 中的 `ID` 字段，并覆盖任何初始的
    `ID` 值。'
- en: '`StartConsuming(size int, pollInterval time.Duration, callback func(Message)
    error)`: `StartConsuming` allows a subscriber to retrieve messages from the queue.
    The first parameter size relates to the batch size, which is returned in any one
    connection. The `pollInterval` parameter determines how often the client checks
    for messages on the queue. The `callback` function is executed when messages return
    from the queue. It has a return parameter of error which when not `nil` informs
    the client that processing has failed and the message should not be removed from
    the queue. One thing we need to note is that `StartConsuming` is not a blocking
    method, after it has registered the callback to the queue it immediately returns.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`StartConsuming(size int, pollInterval time.Duration, callback func(Message)
    error)`: `StartConsuming` 允许订阅者从队列中检索消息。第一个参数 `size` 与批次大小相关，它是在任何一次连接中返回的。`pollInterval`
    参数决定了客户端检查队列中消息的频率。当消息从队列返回时，会执行 `callback` 函数。它有一个返回参数 `error`，当它不为 `nil` 时，通知客户端处理失败，并且消息不应该从队列中移除。需要注意的一点是，`StartConsuming`
    不是一个阻塞方法，在它将回调函数注册到队列后，它立即返回。'
- en: 'The implementation at `queue/redis_queue.go` defines the `NewRedisQueue` function,
    which is a convenience function to create our queue. We are using the `github.com/adjust/rmq`
    library, which has an excellent implementation on top of Redis queues and in line
    **27**, we are opening a connection to our Redis data store:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `queue/redis_queue.go` 的实现中定义了 `NewRedisQueue` 函数，这是一个方便的函数，用于创建我们的队列。我们使用
    `github.com/adjust/rmq` 库，该库在 Redis 队列之上有一个出色的实现。在第 **27** 行，我们打开了一个连接到我们的 Redis
    数据存储：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Then on line **29** we need to open a connection to the queue that we are going
    to read and write from:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 **29** 行，我们需要打开一个连接到我们将要从中读取和写入的队列：
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The `Add` method, which is the implementation of our interface's `Add` method,
    is merely a convenience method that creates a message from the given parameters
    and then calls the `AddMessage` function. The `AddMessage` function first generates
    an ID for the message, in this simple implementation we are just generating a
    random number and appending it to the current time in nanoseconds, which should
    give us enough uniqueness without requiring a check to the queue. We then need
    to convert the message to its JSON representation as a slice of bytes before we
    are finally publishing the message to the queue on line **54**.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '`Add` 方法，这是我们的接口 `Add` 方法的实现，仅仅是一个便利方法，它从给定的参数创建一个消息，然后调用 `AddMessage` 函数。`AddMessage`
    函数首先为消息生成一个 ID，在这个简单的实现中，我们只是生成一个随机数并将其附加到当前时间的纳秒数上，这应该足以提供足够的唯一性，而无需检查队列。然后我们需要将消息转换为它的
    JSON 表示形式，作为一个字节数组，在我们最终在第 **54** 行将消息发布到队列之前。'
- en: 'The final part of our implementation is the method that consumes messages from
    the queue:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实现中的最后一部分是消费队列中消息的方法：
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The `StartConsuming` method only has the responsibility for setting the callback
    to the queue instance; we then call the methods `StartConsuming` and `AddConsumer`,
    which are methods on the Redis package. On line **65**, we set the callback consumer
    to that the queue uses to self rather than the callback passed into the method.
    The delegate pattern assigned to an internal method allows us to abstract the
    implementation of the underlying queue from the implementing codebase. When a
    new message is detected on the queue, the `Consume` method is called passing an
    instance of `rmq.Delivery`, which is an interface defined in the `rmq` package:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`StartConsuming` 方法只负责将回调设置到队列实例上；然后我们调用 `StartConsuming` 和 `AddConsumer` 方法，这两个方法属于
    Redis 包。在第 **65** 行，我们将回调消费者设置为队列自身使用，而不是传递到方法中的回调。将委托模式分配给内部方法允许我们从实现代码库中抽象出底层队列的实现。当检测到队列上有新消息时，会调用
    `Consume` 方法，传递 `rmq.Delivery` 的实例，这是一个在 `rmq` 包中定义的接口：'
- en: '[PRE4]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The first thing we need to do is unmarshal the message that is passed as a
    slice of byte into our `Message` structure. If this fails, then we call the `Reject`
    method on the `Delivery` interface, which pushes the message back onto the queue.
    Once we have the message in the format that our callback expects we can then execute
    the `callback` function, which is passed to the `StartConsuming` method. The type
    of callback is as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做的第一件事是将作为字节数组传递的消息反序列化到我们的 `Message` 结构中。如果这失败，我们将在 `Delivery` 接口上调用 `Reject`
    方法，将消息推回队列。一旦我们得到回调期望的消息格式，我们就可以执行传递给 `StartConsuming` 方法的 `callback` 函数。回调的类型如下：
- en: '[PRE5]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: It is the responsibility of the code, which implementing this method, to return
    an error should the processing of the message fail. Returning an error allows
    our consuming code to call `delivery.Reject()`, which would leave the message
    in the queue for later processing. When the message processes successfully, we
    pass a `nil` error and the consumer calls `delivery.Ack()`, which acknowledges
    that the message is successfully processed and removes it from the queue. These
    operations are process safe; they should not be available to other consumers so
    in the instance that we have many workers reading a queue, we can ensure that
    they are all working from distinct lists.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 实现此方法的代码的责任是在消息处理失败时返回一个错误。返回错误允许我们的消费代码调用 `delivery.Reject()`，这将使消息留在队列中以便稍后处理。当消息成功处理时，我们传递一个
    `nil` 错误，并且消费者调用 `delivery.Ack()`，这表示消息已成功处理并从队列中移除。这些操作是进程安全的；它们不应可供其他消费者使用，因此在我们有多个工作者读取队列的情况下，我们可以确保他们都在不同的列表上工作。
- en: 'Let''s take a look at the implementation of a service that would write messages
    to the queue, if we take a look at the example code file at `queue/writer/main.go`
    we can see that there is a very simple implementation. This is a too simple application
    for a production system and there is no message validation or security in the
    handler. However, this example is pared down to the bare minimum to highlight
    how messages are added to the queue:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个将消息写入队列的服务实现，如果我们查看 `queue/writer/main.go` 的示例代码文件，我们可以看到这是一个非常简单的实现。这对于生产系统来说过于简单，处理程序中没有消息验证或安全性。然而，这个例子被简化到最基本的形式，以突出显示消息是如何添加到队列中的：
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We create an instance of `RedisQueue` and pass it the location of our Redis
    server and the name of the queue to which we would like to write messages. We
    then have a very simple implementation of `http.Handler`; this function reads
    the body of the request as a slice of bytes and calls the `Add` method with the
    name of the message and the payload. We then check the outcome of this operation
    before returning and closing the connection.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建一个`RedisQueue`实例，并传递我们Redis服务器的位置和我们想要写入消息的队列名称。然后我们有一个非常简单的`http.Handler`实现；这个函数将请求体作为字节数组读取，并使用消息名称和有效载荷调用`Add`方法。然后我们在返回和关闭连接之前检查此操作的输出。
- en: 'The consumer implementation is even simpler as this code implements a simple
    worker and does not implement any HTTP-based interface:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 消费者实现甚至更简单，因为此代码实现了一个简单的工作者，并且没有实现任何基于HTTP的接口：
- en: '[PRE7]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Like in the client, we create an instance of our queue and then we call the
    `StartConsuming` method with our requested parameters and the `callback` function.
    The `callback` method executes for every message retrieved from the queue, and
    since we are returning batches of 10 potentially every 100 milliseconds this method
    could be called in quick succession, and every execution runs in its own `goroutine`,
    so when writing the implementation, we need to consider this detail. If for example,
    we were processing the messages and then writing them to a database then the number
    of connections to the database are not infinite. To determine an appropriate batch
    size we need to conduct initial testing and follow this up with constant monitoring,
    in order to tweak the application for optimum performance. These settings should
    be implemented as parameters so that they are easily changed as the hardware scales.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 与客户端类似，我们创建我们的队列实例，然后调用带有我们请求参数和`callback`函数的`StartConsuming`方法。`callback`方法为从队列中检索到的每条消息执行，由于我们可能每100毫秒返回一批10条消息，因此此方法可能会快速连续调用，并且每次执行都在自己的`goroutine`中运行，因此在编写实现时，我们需要考虑这个细节。例如，如果我们处理消息并将它们写入数据库，那么数据库的连接数不是无限的。为了确定合适的批量大小，我们需要进行初始测试，并随后进行持续监控，以便调整应用程序以获得最佳性能。这些设置应作为参数实现，以便在硬件扩展时易于更改。
- en: Push messaging
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推送消息
- en: Rather than using a queue, sometimes you want a service to act immediately on
    an event. Your service subscribes to receive messages from a broker such as NATS.io
    or SNS. When the broker receives a message, dispatched from another service, then
    the broker notifies all the registered services by making a call to the registered
    endpoint sending it a copy of the message. The receiver will generally disconnect
    once the message has been received and assumes that the message processes correctly.
    This pattern allows the message broker extreme throughput, in the case of NATS.io
    a single server instance can deliver millions of messages per second. Should the
    client be unable to process the message, then it must handle the logic to manage
    this failure. This logic could be to dispatch a notification to the broker or
    again the message could be added to a dead letter queue for later replay.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，你希望服务能够立即对事件做出反应，而不是使用队列。你的服务订阅从像NATS.io或SNS这样的代理接收消息。当代理收到来自另一个服务的消息时，代理会通过调用已注册的端点并发送消息副本来通知所有已注册的服务。接收者通常在收到消息后断开连接，并假设消息已正确处理。这种模式允许消息代理具有极高的吞吐量，在NATS.io的情况下，单个服务器实例每秒可以处理数百万条消息。如果客户端无法处理消息，则必须处理管理这种失败的逻辑。这种逻辑可能是向代理发送通知，或者消息可以被添加到死信队列以供稍后重放。
- en: '![](img/650704ea-e1b3-4c93-836b-cfd12dab6373.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/650704ea-e1b3-4c93-836b-cfd12dab6373.png)'
- en: 'In this example, we are going to leverage the power of NATS.io to act as a
    message broker for our system, NATS is an incredibly lightweight application that
    is written in Go and provides such astounding performance and stability. Looking
    at `push/writer/main.go`, we can see that there is not very much code we need
    to write to implement NATS.io:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，我们将利用NATS.io的力量作为我们系统的消息代理，NATS是一个由Go编写的极其轻量级的应用程序，提供了惊人的性能和稳定性。查看`push/writer/main.go`，我们可以看到我们不需要编写很多代码来实现NATS.io：
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The first thing we need to do when starting our application is to connect to
    the NATS server by calling the `Connect` function on the `nats` package:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们开始我们的应用程序时，首先需要做的事情是通过在`nats`包上调用`Connect`函数来连接NATS服务器：
- en: '[PRE9]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The `url` parameter, which is defined as a string, requires a little clarification.
    While you can pass a single URL such as `nats://server:port` you can also pass
    a comma separated list of servers. The reason for this is because of fault tolerance,
    NATS implements clustering, in our simple example we only have a single instance,
    however, when running in production you will have multiple instances for redundancy.
    We then define our `http.Handler` function and expose the `/product` endpoint:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '`url` 参数定义为字符串，需要稍作说明。虽然你可以传递单个 URL，如 `nats://server:port`，但你也可以传递以逗号分隔的服务器列表。这样做的原因是为了容错，NATS
    实现了集群，在我们的简单示例中我们只有一个实例，然而，在生产环境中，你将会有多个实例以实现冗余。然后我们定义我们的 `http.Handler` 函数并暴露
    `/product` 端点：'
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The implementation of the handler is straightforward and we delegate the work
    to the `insertProduct` function. Again, in terms of implementation this is brief
    to highlight the use of publishing a message; in production there would be a higher
    level of implementation to manage security and validation.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 处理器的实现非常直接，我们将工作委托给 `insertProduct` 函数。再次强调，在实现方面这很简短，以突出发布消息的使用；在生产环境中会有更高级别的实现来管理安全和验证。
- en: 'On line **53**, we call the `Publish` method on our client; the method has
    an incredibly simple signature with the subject and the payload:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 **53** 行，我们在客户端调用 `Publish` 方法；该方法具有一个极其简单的签名，包含主题和有效载荷：
- en: '[PRE11]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Concerning the subject, we need to consider that this is the same name that
    the subscriber is going to use and that it must be unique otherwise it is possible
    that unintended recipients receive the messages and this is an incredibly difficult
    error to track down. The fully configurable options for NATS are in the GoDoc
    [https://godoc.org/github.com/nats-io/go-nats](https://godoc.org/github.com/nats-io/go-nats),
    which is rather comprehensive.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 关于主题，我们需要考虑这是订阅者将要使用的相同名称，并且它必须是唯一的，否则可能会出现意外收件人接收消息的情况，这是一个极其难以追踪的错误。NATS 的完全可配置选项在
    GoDoc [https://godoc.org/github.com/nats-io/go-nats](https://godoc.org/github.com/nats-io/go-nats)
    中，相当全面。
- en: 'Now we have seen how easy it is to publish messages to NATS, let''s see how
    easy it is to consume them. If we take a look at the example code at `push/reader/main.go`,
    we can see that subscribing to messages is incredibly simple:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到向 NATS 发布消息是多么容易，让我们看看消费它们有多简单。如果我们查看 `push/reader/main.go` 中的示例代码，我们可以看到订阅消息非常简单：
- en: '[PRE12]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Again, we make our connection to the NATS server, but to start receiving events
    we call the `Subscribe` method on the client:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们连接到 NATS 服务器，但要开始接收事件，我们在客户端调用 `Subscribe` 方法：
- en: '[PRE13]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The `Subscribe` method will express interest in the given subject. The subject
    can have wildcards (partial: `*`, full: `>`). Messages will be delivered to the
    associated `MsgHandler`.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`Subscribe` 方法将表达对给定主题的兴趣。主题可以有通配符（部分：`*`，全部：`>`）。消息将被发送到相关的 `MsgHandler`。'
- en: If no `MsgHandler` is given, the subscription is a synchronous subscription,
    and it can be polled via `Subscription.NextMsg()`.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有提供 `MsgHandler`，则订阅是同步订阅，可以通过 `Subscription.NextMsg()` 进行轮询。
- en: 'Unlike in our queue example, we are not polling the NATS server we are exposing
    an endpoint and registering that with NATS. When the NATS server receives a message,
    it attempts to forward that to all the registered endpoints. Using the implementation
    in the previous code sample, we obtain a copy of the message for every worker
    we have running on the system, which is not ideal. Rather than managing this ourselves,
    we can use a different method on the API, `QueueSubscribe`:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们的队列示例不同，我们不是轮询 NATS 服务器，而是暴露一个端点并将其注册到 NATS。当 NATS 服务器接收到一条消息时，它会尝试将其转发给所有已注册的端点。使用前一个代码示例中的实现，我们为系统上运行的每个工作进程获取消息的副本，这并不是最佳方案。我们不必自己管理这一点，可以使用
    API 上的另一种方法，即 `QueueSubscribe`：
- en: '[PRE14]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The `QueueSubscribe` function creates an asynchronous queue subscriber on the
    given subject. All subscribers with the same queue name form the queue group and
    only one member of the group is selected to receive any given message asynchronously.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '`QueueSubscribe` 函数在给定的主题上创建一个异步队列订阅者。具有相同队列名称的所有订阅者形成一个队列组，并且该组中只有一位成员会异步接收任何给定的消息。'
- en: The signature is like the `Subscribe` method with the exception that we pass
    an additional parameter, which is the name of the queue or the unique cluster
    of subscribers who would like to register interest in the given subject.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 签名类似于 `Subscribe` 方法，只是我们传递了一个额外的参数，即队列的名称或希望注册对给定主题感兴趣的唯一订阅者集群的名称。
- en: Now we have defined the two main types of asynchronous messaging and looked
    at the simple implementation of each. Let's take a look at two common patterns
    that leverage this technique.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经定义了两种主要类型的异步消息，并查看每种的简单实现。让我们看看两种利用这种技术的常见模式。
- en: Command Query Responsibility Segregation (CQRS)
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 命令查询责任分离（CQRS）
- en: CQRS is an abbreviation for Command Query Responsibility Segregation, a term
    attributed to Greg Young. The concept is that you use a different model to update
    information than the model used for reading information. The two main reasons
    for implementing CQRS are when the storage of a model differs dramatically from
    the presentation of the model, and when the concepts behind this approach are
    that attempting to create a model which is optimized for storage and a model which
    optimized for display might solve neither problem. For this reason, CQRS splits
    these models into a **Query** model used by the presentation logic and a **Command**
    model that is used for storage and validation. The other benefit is when we would
    like to separate load between reads and writes in high-performance applications.
    The CQRS pattern is not something that is hugely common and certainly should not
    be used everywhere as it does increase complexity; however, it is a very useful
    pattern to have in your arsenal.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: CQRS 是命令查询责任分离的缩写，这个术语归功于格雷格·杨（Greg Young）。这个概念是，你使用不同的模型来更新信息，而不是用于读取信息的模型。实施
    CQRS 的两个主要原因是当模型存储与模型展示有显著差异时，以及当这种方法的背后概念是尝试创建一个针对存储优化的模型和一个针对显示优化的模型可能都无法解决这两个问题时。因此，CQRS
    将这些模型分为用于展示逻辑的 **查询** 模型和用于存储和验证的 **命令** 模型。另一个好处是当我们在高性能应用程序中想要在读取和写入之间分离负载时。CQRS
    模式并不是非常常见，当然也不应该到处使用，因为它确实增加了复杂性；然而，它是一个非常有用的模式，应该纳入你的工具箱中。
- en: 'Let''s take a look at the following diagram:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看以下图表：
- en: '![](img/08eac447-b4d9-4d1f-a639-dbed2064a47f.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/08eac447-b4d9-4d1f-a639-dbed2064a47f.png)'
- en: In our example code, we again were leveraging NATS.io to broker the messages.
    However, this need not be the case. It is a legitimate setup to have a single
    service that has two separate models for reading and writing. Instead of the complexity
    of a message broker in process communication could be used just as effectively.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例代码中，我们再次利用 NATS.io 来代理消息。然而，这并不一定是必须的。拥有一个服务同时具有两个独立的读写模型是合法的设置。而不是在进程通信中使用消息代理的复杂性，也可以同样有效地使用。
- en: 'Take a look at the example code at `cCQRS/product_writer/main.go`:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 查看位于 `cCQRS/product_writer/main.go` 的示例代码：
- en: '[PRE15]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'For simplicity, this example uses an in-memory database, `https://github.com/hashicorp/go-memdb`,
    written by HashiCorp and the bulk of the setup is configuring this data store.
    We will be separating our data stores for read and write and the reader service
    does not implement any methods to return the products to the caller. Instead,
    this responsibility is delegated to a second service that is running a separate
    database and even a different data model:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简单起见，这个例子使用了一个内存数据库，由 HashiCorp 编写的 `https://github.com/hashicorp/go-memdb`，大部分设置是配置这个数据存储。我们将分离我们的读取和写入数据存储，读取服务不实现任何返回产品给调用者的方法。相反，这个责任委托给第二个服务，该服务运行一个独立的数据库，甚至不同的数据模型：
- en: '[PRE16]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Our handler first writes the model to the database and then like our push example
    we are publishing a message to NATS containing the payload of the message.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的处理程序首先将模型写入数据库，然后像我们的推送示例一样，向 NATS 发布包含消息负载的消息。
- en: 'Looking at the reader server at `CQRS/product-read/main.go` again we are setting
    up our data store, however, the model is different from the read model:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 再次查看位于 `CQRS/product-read/main.go` 的读取服务器，我们正在设置我们的数据存储，然而，模型与读取模型不同：
- en: '**Write model**:'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**写入模型**：'
- en: '[PRE17]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '**Read model**:'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**读取模型**：'
- en: '[PRE18]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We are also defining an event structure that contains the details for our event
    received from NATS. In this instance, this structure mirrors the write model;
    however, this does not always need to be the case:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还定义了一个包含从 NATS 收到的事件详细信息的结构。在这个例子中，这个结构反映了写入模型；然而，这并不总是必须的：
- en: '[PRE19]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Upon receipt of a message, we first decode the payload into the expected type
    `productInsertedEvent` and then we convert this to our product model that is stored
    in the database. Finally, we store the information in the database creating our
    copy in a format that our consumers wish to receive:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在接收到消息后，我们首先将有效载荷解码为预期的类型`productInsertedEvent`，然后将其转换为存储在数据库中的产品模型。最后，我们将信息存储在数据库中，以我们的消费者希望接收的格式创建我们的副本：
- en: '[PRE20]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: When a user calls the `/products` endpoint the data that they get back is that
    of the locally cached copy, not the master that is stored in a separate service.
    This process could cause issues with consistency as the two copies of data are
    eventually consistent and when we implement the CQRS pattern we need to consider
    this. If we were exposing the stock level, then it may not be desirable to have
    eventual consistency, however, we can make a design decision that when this information
    is required we sacrifice performance by making a synchronous call to the stock
    endpoint.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户调用`/products`端点时，他们得到的是本地缓存的副本数据，而不是存储在单独服务中的主数据。这个过程可能会引起一致性问题，因为两个数据副本最终是一致的，当我们实现CQRS模式时，我们需要考虑这一点。如果我们公开库存水平，那么可能不希望有最终一致性，然而，我们可以做出设计决策，当需要这个信息时，我们通过向库存端点发起同步调用牺牲性能来获取。
- en: Domain-Driven Design
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 领域驱动设计
- en: When implementing Event Driven Microservices, you need to have a good grasp
    of the way your system operates and the way data, and interactions flow from one
    service to the next. A useful technique for modeling any complex system is Domain-Driven
    Design.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在实现事件驱动微服务时，你需要很好地掌握你的系统运作方式以及数据、交互如何从一个服务流向下一个服务。对任何复杂系统进行建模的一个有用技术是领域驱动设计。
- en: When it comes to Domain-Driven Design, then there is Vernon Vaughn, whose two
    books, *Domain-Driven Design Distilled* and *Implementing Domain-Driven Design*,
    expand upon the seminal and for some slightly difficult to read work by Eric Evans.
    For newcomers to DDD, I recommend starting with DDD distilled and then moving
    to read Implementing Domain Driven Design. Reading DDD distilled first gives you
    a grounding of the terminology before you delve into what is a rather detailed
    book. DDD is most certainly an advanced topic and not something that can be covered
    comprehensively in one section of this book, nor do I profess to have the experience
    to write anything more detailed as DDD is a pattern that is learned by practice.
    DDD is also a tool for more complex large systems with many stakeholders and many
    moving parts. Even if you are not working on such a system, the concepts of aggregation
    and isolation are compelling and applicable to most systems. If nothing else,
    keep reading to become more proficient at buzzword bingo in your next architecture
    meeting.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈到领域驱动设计时，那么就有Vaughn Vaughn，他的两本书《领域驱动设计精粹》和《实现领域驱动设计》扩展了Eric Evans的开创性工作，对于一些人来说，这些工作可能有些难以阅读。对于DDD的新手，我建议从《领域驱动设计精粹》开始阅读，然后转向阅读《实现领域驱动设计》。首先阅读《领域驱动设计精粹》为你提供了术语的基础，然后再深入研究这是一本相当详细的书。DDD绝对是一个高级话题，不可能在这本书的一个章节中全面涵盖，我也不敢声称有足够的经验来写得更详细，因为DDD是一种通过实践学习的模式。DDD也是一个用于更复杂的大型系统、有众多利益相关者和许多动态部件的工具。即使你不在这样的系统上工作，聚合和隔离的概念也是引人入胜的，并且适用于大多数系统。至少，继续阅读以使你在下一次架构会议中更擅长玩“流行词汇接龙”。
- en: What is DDD?
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是DDD？
- en: 'To quote the words of VaughnVernon himself:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 引用Vaughn Vernon自己的话：
- en: '"DDD is a set of tools that assist you in designing and implementing software
    that delivers high value, both strategically and tactically. Your organization
    can''t be the best at everything, so it had better choose carefully at what it
    must excel. The DDD strategic development tools help you and your team make the
    competitively best software design choices and integration decisions for your
    business."'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '"DDD是一套工具，帮助你设计和实现能够带来高价值的软件，无论是战略上还是战术上。你的组织不可能在所有事情上都做得最好，所以它必须谨慎选择必须精通的事情。DDD战略开发工具帮助你和你团队做出最具竞争力的软件设计选择和业务集成决策。"'
- en: -- Vaughn Vernon
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: -- Vaughn Vernon
- en: That is quite an introduction; however, I think it highlights the fact that
    DDD is a tool for designing software and not a software framework. In the dark
    days, a couple of decades ago software architects and project managers would make
    the decisions for the design of a software system, often providing very detailed
    plans that were executed by the development teams. In my experience this was rarely
    an enjoyable way to work and neither did it produce good quality software and
    deliver on-time. The agile revolution proposed a different way of working and
    thankfully has improved the situation. We also now regard ourselves as software
    engineers rather than developers, I do not believe that this shift is a fashion,
    but it is driven by the change in the role that we have seen. Your role as someone
    who creates software is now one of a designer, negotiator of features, architect,
    mediator, and you are also required to have a full understanding of the materials
    at your disposal including the reactions to stress and strain. You now mirror
    the role of a traditional engineer rather than the assembly line worker role that
    software developers performed in the past.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully, that answers the question that may be in your head as to why you
    need to learn about DDD in a book about Go. Well, this book was never written
    to teach you the language, it was designed to show you how you can use it to build
    successful microservices.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: I hear lots of noise surrounding DDD that it is a difficult technique and admittedly
    when I first read DDD I felt the same way, all this stuff about aggregates, ubiquitous
    language, domains, and subdomains. However, once I started to think about DDD
    to engineer separation and thought about many of the problems I have faced in
    the past with confused domain models then it slowly began to sink in.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: Technical debt
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you have ever worked on a monolithic application, you are aware of the coupling
    and dependency that occurs between objects, this is predominately in the data
    layer, however, you also often find code that is not implementing correctly and
    is tightly bound to another object. The problems come when you want to change
    this system; a change in one area has an undesired impact in another and only
    one if you are lucky. An enormous effort happens in refactoring the system before
    changes are made. Often what happens is that the modification is shoehorned into
    the existing codebase without refactoring and to be brutally honest it would be
    kinder to the system to take it outside, around the back of the barn and unload
    two shotgun shells in the back of its head.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: Don't fool yourself that you will ever get the opportunity to do this; if you
    have ever worked on a system of any real age, your job is like Lenin's embalmers.
    You spend an enormous amount of effort to keep a dead body presentable when you
    should just dig a hole in the ground and drop it in. DDD can help with understanding
    the monolith and slowly decoupling it; it is also a tool to prevent the unruly
    monolith from ever occurring. Let's take a quick look at the technical anatomy.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: Anatomy of DDD
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The primary part of the strategic design in DDD is to apply a concept called
    **Bounded Contexts**. Bounded Contexts are a method of segregating your domain
    into models. Using a technique called **Context Mapping** you can integrate multiple
    Bounded Contexts by defining both the team and technical relationships that exist
    between them.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: The tactical design is where you refine the details of your domain model. In
    this phase, we learn how to aggregate entities and value objects together.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: Strategic design
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the phrases you will hear a lot when dealing with DDD is the term Bounded
    Contexts. A Bounded Contexts concept is a semantic contextual boundary that is
    the components inside each boundary has a specific meaning and does specific things.
    One of the most important of these Bounded Contexts is the **Core Domain**; this
    is the domain that distinguishes your organization competitively from all the
    others. We have already mentioned that you cannot do everything and by concentrating
    on your core domain this should be where you spend most of your time.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Tactical design
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'From the base of strategic design is the tactical design, to quote Vaughn Vernon
    again:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '"Tactical design is like using a thin brush to paint the finer details of your
    domain model."'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: --Vaughn Vernon
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: At this stage in the design, we need to start thinking about **Aggregates**
    and **Domain Events**. An aggregate is composed of entities and value objects.
    A value object models an immutable whole, it does not have a unique identity and
    equivalence is determined by comparing the attributes encapsulated by the value
    types. Domain events are published by an aggregate and subscribed to by interested
    parties. This subscription could be from the same Bounded Contexts, or it may
    come from a different source.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: Ubiquitous language
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The term ubiquitous language in DDD refers to a core language that everyone
    on the team understands about the software under development. It is entirely possible
    that a component in a different context and developed by a different team has
    a different meaning for the same terminology. In fact, they are probably talking
    about different components from your model.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: How you develop your ubiquitous language is an activity that the team will form.
    You should not put too much emphasis onto using only nouns to describe your model,
    you should start to build up simple scenarios. Consider our example from the chapter
    on testing where we used BDD for our functional and integration testing. These
    are your scenarios; the language of which you write them is your team's ubiquitous
    language. You should write these scenarios so that they are meaningful to your
    team and not attempt to write something that is meaningful for the entire department.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Bounded Contexts
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the main reasons for using a Bounded Context is that teams often do not
    know when to stop piling things into their software models. As the team adds more
    features, the model soon becomes difficult to manage and understand. Not only
    this, the language of the model starts to become blurred. When software becomes
    vast and convoluted with many unrelated interconnections, it starts to become
    what is known as a *Big Ball of Mud*. The big ball of mud is probably far worse
    than your traditional monolith. Monoliths are not inherently evil just because
    they are monolithic; monoliths are bad as within them exists a place where good
    coding standards are long forgotten. The other problem with a Bounded Context
    that is too large and owned by too many people is that it starts to be difficult
    to describe it using a ubiquitous language.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Context Mapping
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When two Bounded Contexts in DDD need to integrate the integration is known
    as Context Mapping. The importance of defining this Context Mapping is that a
    well-defined contract supports controlled changes over time. In the book *Domain-Driven
    Design Distilled*, Vaughn Vernon describes the following different kinds of mappings:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '**Partnership:** The partnership mapping exists when two teams are each responsible
    for a Bounded Context and have a dependent set of goals.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Shared kernel:** A shared kernel is defined by an intersection of two separate
    Bounded Contexts and exists when two teams share a small but common model.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Customer-supplier:** A customer-supplier describes a relationship between
    two Bounded Contexts and their respective teams. The supplier is the upstream
    context, and the downstream is the customer. The supplier must provide what the
    customer needs, and the two teams must plan together to meet their expectations.
    This is a very typical and practical relationship between the teams as long as
    the supplier still considers the customers need.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Conformist:** A conformist relationship exists when there are upstream, and
    downstream teams and the upstream team has no motivation to support the specific
    needs of the downstream team. Rather than translate the upstream ubiquitous language
    to fit its own needs the downstream team adopts the language of the upstream.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Anti-corruption layer:** This is a standard and recommended model when you
    are connecting two systems together, the downstream team builds a translation
    layer between its ubiquitous language and that of the upstream thus isolating
    it from the upstream.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Open Host Service:** An Open Host Service defines a protocol or interface
    that gives access to your Bounded Contexts as a set of services. The services
    are offered via a well-documented API and are simple to consume.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Published language:** A published language is a well-documented information
    exchange language enabling easy consumption and translation. **XML Schema**, **JSON
    Schema**, and **RPC** based frameworks such as **Protobufs** are often used.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Separate ways:** In this situation, there is no significant payoff through
    the consumption of various ubiquitous languages and the team decides to produce
    their solution inside their Bounded Contexts.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Big ball of mud:** This should be pretty self-explanatory by now and not
    something a team should aim for; in fact, this is the very thing that DDD attempts
    to avoid.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Software
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we start working with DDD and event-oriented architectures in anger, we
    soon find that we need some help brokering our messages to ensure the at-least-once
    and at-most-once delivery that is required by the application. We could, of course,
    implement our strategy for this. However, there are many open source projects
    on the internet that handle this capability for us, and soon we find ourselves
    reaching out to leverage one of these.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: Kafka
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kafka is a distributed streaming platform that allows you to publish and subscribe
    to streams of records. It lets your store streams of documents in a fault-tolerant
    way and process streams of records as they occur. It has been designed to be a
    fast and fault-tolerant system commonly running as a cluster of one or more servers
    to enable redundancy.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: NATS.io
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'NATS.io is an open source messaging system written in Go, and it has the capability
    to perform two roles such as the at-most-once and at-least-once delivery, lets
    look at what this means:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '**at-most-once delivery**: In the basic mode, NATS can act as a Pub/Sub router,
    where listening clients can subscribe to message topics and have new messages
    pushed to them. If a message has no subscriber, then it is sent to `/dev/null`
    and is not stored internally in the system.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**at-least-once delivery**: When a higher level of service and more stringent
    delivery guarantees are required NATS can operate in at-least-once delivery mode.
    In this mode, NATS can no longer function as a standalone entity and needs to
    be backed by a storage device, which at present support is for file and in-memory.
    Now, there is no scaling and replication supported with NATS streaming, and this
    is where Kafka shines. However, we are not all building systems as big as Netflix,
    and the configuration and management of Kafka is a book in its own right, NATS
    can be understood very quickly.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AWS SNS/SQS
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Amazon's **Simple Queue Service** (**SQS**) is a queuing service that allows
    a publisher to add messages to a queue, which can later be consumed by clients.
    A message is read and then removed from the queue making it no longer available
    for other readers.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: There are two different types of SQS, such as the standard mode, which allows
    maximum throughput at the expense that a message may be delivered more than once
    and SQS FIFO, which ensures that messages are only ever delivered once and in
    the order by which they are received. However, FIFO queues are subject to vastly
    reduced throughput, and therefore their use must be carefully considered.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: 'Amazon''s **Simple Notification Service** (**SNS**) is a service for coordinating
    and managing the delivery of queues of messages. SNS stands for Simple Notification
    Service; you configure a topic that you can publish messages to and then subscribers
    can register for notifications. SNS can deliver messages to the following different
    protocols:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: HTTP(S)
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Email
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Email-JSON
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SMS
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AWS Lambda
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SQS
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You may wonder why you would want to add a message to a queue when you can just
    push a message to the recipient? One of the problems with SNS is that it can only
    deliver over HTTP to services that are publicly accessible. If your internal workers
    are not connected to the public internet and from reading [Chapter 8](d38f7017-1c2e-4a12-b1dc-5870121afd4e.xhtml),
    *Security*, I hope that they are not. Therefore, a pull-based approach may be
    your only option; reading from a queue is also potentially a better option for
    managing large streams of messages. You do not need to worry about the availability
    of SQS (most of the time), and you do not need to implement an HTTP interface
    for a simple application worker that can poll a queue.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Google Cloud Pub/Sub
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Google Cloud Pub/Sub is very like AWS SNS in that it is a messaging middleware,
    allowing the creation of topics with publishers and subscribers. At the time of
    writing, there is no formal product on Google Cloud such as SQS. However, it would
    be trivial to implement something using one of the many data storage options you
    have available.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have looked at some of the main patterns for decoupling
    microservices using events, we have also had an introduction to a modern design
    methodology for building distributed systems, DDD. With the right tools and upfront
    design building highly scalable and maintainable systems should not be too challenging
    and you now have all the information you need to do this with Go. In the final
    chapter, we are going to look at automated building and deployment of your code,
    finalizing the information you need to be a successful microservices practitioner.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
