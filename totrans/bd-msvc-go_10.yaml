- en: Continuous Delivery
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 持续交付
- en: We have covered a lot so far, including how to build resilient systems and how
    to keep them secure, but now we need to look at how to replace all the manual
    steps in our process and introduce continuous delivery.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经涵盖了大量的内容，包括如何构建弹性系统以及如何保持它们的安全，但现在我们需要看看如何替换我们流程中的所有手动步骤并引入持续交付。
- en: 'In this chapter, we will discuss the following concepts:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下概念：
- en: Continuous Delivery
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持续交付
- en: Container orchestration
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器编排
- en: Immutable infrastructure
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不可变基础设施
- en: Terraform
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Terraform
- en: Example Application
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 示例应用
- en: What is Continuous Delivery?
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是持续交付？
- en: Continuous delivery is the process of building and deploying code well, continuously.
    The aim is that we move code from development to production as efficiently and
    effectively as possible.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 持续交付是构建和部署代码的过程，持续进行。目标是尽可能高效和有效地将代码从开发转移到生产。
- en: In a traditional or waterfall workflow, releases revolve around the completion
    of a major feature or update. It is not untypical for large enterprises to release
    once a quarter. When we look at the reason for this strategy, risk and effort
    are often cited. There is a risk to releasing as the confidence is weak in the
    software; there is effort involved in releasing because there needs to be a mostly
    manual process involved in quality assurance and the operational aspects of releasing
    the software. One part of this is something that we have covered in [C](905299b5-e8d4-424c-827e-3fed5a58289e.xhtml)hapter
    5, *Common Patterns*, which is the concern with quality, and the possible absence
    of a satisfactory test suite or possibly the ability to run this automatically.
    The second element involves the physical deployment and post deployment testing
    process. We have not covered this aspect much in this book so far; we touched
    on it when we looked at Docker in [Chapter 4](2baaa0cf-170d-4d7f-8449-b26f20a9bbab.xhtml),
    *Testing*.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统的或瀑布式的工作流程中，发布围绕着主要功能或更新的完成。大型企业每季度发布一次并不罕见。当我们审视这种策略的原因时，风险和努力经常被提及。发布存在风险，因为软件的信心较弱；发布需要付出努力，因为需要涉及质量保证和软件发布的操作方面的主要是手动流程。其中一部分是我们已经在第5章“常见模式”中讨论过的内容，即对质量的关注，以及可能缺乏令人满意的测试套件或可能无法自动运行的能力。第二个元素涉及到物理部署和部署后的测试过程。到目前为止，我们在这本书中并没有过多地涉及这个方面；我们在第4章“测试”中提到了Docker。
- en: If we could reduce the risk and effort involved in deploying code, would you
    do it more frequently? How about every time you complete a minor feature, or every
    time a bug is fixed, several times a day even? I would encourage you to do just
    that, and in this chapter, we will look at all the things we need to know and
    building on all the things we have previously learned to deliver continuously.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们能减少部署代码的风险和努力，你会更频繁地做吗？比如每次完成一个小的功能，或者每次修复一个错误，甚至一天好几次？我会鼓励你这样做，在本章中，我们将探讨我们需要了解的所有事情，并基于我们之前学到的所有知识来实现持续交付。
- en: Manual deployment
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 手动部署
- en: Manual deployment is at best problematic; even if you have an amazing team,
    things can and will go wrong. The larger the group, the more distributed the knowledge
    and the greater the need for comprehensive documentation. In a small team, the
    resources are constrained, and the time it takes for deployment can be a distraction
    from building great code. You also end up with a weak link; so, do you suspend
    deployment when the person who usually carries out the process is sick or on holiday?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 手动部署最多是问题重重；即使你有一个出色的团队，事情也可能出错。团队越大，知识分布越广，对全面文档的需求就越大。在小团队中，资源有限，部署所需的时间可能会分散构建优质代码的注意力。你还会遇到一个薄弱环节；所以，当负责执行流程的人生病或度假时，你会暂停部署吗？
- en: The problems with manual deployment
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 手动部署的问题
- en: Issues can arise with the ordering and timing of the various deployment steps
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署步骤的顺序和时间可能会出现问题
- en: The documentation needs to be comprehensive and always up to date
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文档需要全面且始终更新
- en: There is a significant reliance on manual testing
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对手动测试有显著的依赖
- en: There are application servers with different states
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存在不同的状态的应用服务器
- en: There are constant problems with manual deployment due to the preceding points
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于前面的几点，手动部署经常出现持续的问题
- en: As a system grows in complexity, there are more moving parts, and the steps
    required to deploy the code increase with it. Since the steps to deploy need to
    be carried out in a set order, the process can fast become a burden. Consider
    deploying an update to an application, the application and its dependencies install
    on all instances of the application servers. Often a database schema needs to
    be updated, and there needs to be a clean switch over between the old and the
    new application. Even if you are leveraging the power of Docker, this process
    can be fraught with disaster. As the complexity of the application grows, so does
    the required documentation to deploy the application, and this is often a weak
    link. Documentation takes time to update and maintain, in my personal experience,
    this is the first area which suffers when deadlines are approaching. Once the
    application code is deployed, we need to test the function of the application.
    Assuming the application is manually deployed, it is often assumed that the application
    is also manually tested. A tester would need to run through a test plan (assuming
    there is a test plan) to check that the system is in a functioning state. If the
    system is not functioning, then either the process would need to be reversed to
    roll back to a previous state, or a decision would need to be made to hotfix the
    application and again run through the standard build and deploy cycle. When this
    process falls into a planned release, there is a little more safety as the whole
    team is around for the release. However, what happens when this process takes
    place in the middle of the night as a result of an incident? At best, what happens
    is that the fix is deployed, however, without updating any of the documentation
    or processes. At worst, the application ends up in a worse state than before the
    application code was attempted to be hot fixed. Out of hours, incidents are also
    often carried out by first line response, which is often the infrastructure team.
    I assume that if you are not running continuous deployment, then you will also
    not be following the practice of Developer on call. Also, what about the time
    it takes to do a deploy? What is the financial cost of the entire team taking
    time out to babysit a deployment? What about the motivational and mental productivity
    cost of this process? Have you ever felt the stress due to the uncertainty of
    deploying application code into production?
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 随着系统的复杂性增加，涉及的组件更多，部署代码所需的步骤也随之增加。由于部署步骤需要按顺序执行，这个过程很快就会变成负担。考虑一下部署应用程序更新的情况，应用程序及其依赖项需要在所有应用程序服务器实例上安装。通常需要更新数据库模式，并且需要在旧应用程序和新应用程序之间进行干净的切换。即使你正在利用Docker的强大功能，这个过程也可能充满灾难。随着应用程序复杂性的增加，部署应用程序所需的文档也相应增加，这通常是一个薄弱环节。根据我的个人经验，在截止日期临近时，文档的更新和维护通常是首先受到影响的地方。一旦应用程序代码部署完成，我们需要测试应用程序的功能。假设应用程序是手动部署的，通常会假设应用程序也是手动测试的。测试人员需要运行测试计划（假设有测试计划）来检查系统是否处于正常工作状态。如果系统不工作，那么可能需要逆转过程回滚到之前的状态，或者需要决定热修复应用程序并再次运行标准的构建和部署周期。当这个过程纳入计划发布时，由于整个团队都在场，所以会有更多的安全性。然而，当这个过程在深夜由于事件发生时，会发生什么呢？最好的情况是，修复被部署，然而，没有更新任何文档或流程。最坏的情况是，应用程序最终处于比尝试热修复应用程序代码之前更糟糕的状态。在非工作时间，事件通常由一线响应人员执行，这通常是基础设施团队。我假设如果你没有运行持续交付，那么你也不会遵循开发者值班的做法。那么，部署所需的时间呢？整个团队抽出时间来监视部署的财务成本是多少？这个过程的动机和心理生产力成本又是多少？你有没有因为将应用程序代码部署到生产环境中的不确定性而感到压力？
- en: Continuous delivery removes these risks and problems.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 持续交付消除了这些风险和问题。
- en: The benefits of continuous delivery
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 持续交付的好处
- en: 'The concept of continuous delivery is that you plan for these problems and
    spend the up-front work to solve them. Automation of all the steps involved allows
    consistency of operation and is a self-documenting process. No longer do you have
    the requirement for specialized human knowledge, and the additional benefit of
    the removal of the human is that the quality improves due to automation of the
    process. Once we have the automation, improved the quality and speed of our deployments,
    we can then level this up and start to deploy continuously. The benefits of continuous
    delivery are:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 持续交付的概念是，你计划这些问题，并投入前期工作来解决它们。自动化所有涉及步骤允许操作的连续性，并且是一个自我记录的过程。不再需要专门的人类知识，而且移除人类的额外好处是，由于过程的自动化，质量得到了提高。一旦我们有了自动化，提高了部署的质量和速度，我们就可以进一步提高水平，开始持续部署。持续交付的好处包括：
- en: The releases are small and less complicated
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发布更小且更简单
- en: The differences between master and feature branch are smaller
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主分支和功能分支之间的差异更小
- en: There are fewer areas to monitor post deployment
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署后需要监控的区域更少
- en: The rollbacks are potentially easier
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回滚可能更容易
- en: They deliver business value sooner
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们更早地交付业务价值
- en: We start to deploy our code in smaller chunks, no longer waiting for the completion
    of a major feature but potentially after every commit. The primary benefit of
    this is that the differences between the master and the feature branches are smaller
    and less time is spent merging code between branches. Smaller changes also create
    fewer areas to monitor post deploy and because of this, should something go wrong
    it is easier to roll back the changes to a known working state. Most important
    of all, it gives you the capability to deliver business value sooner; whether
    this is in the form of a bug or a new feature, the capability is ready for your
    customers to use far earlier than would be available in a waterfall model.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开始以更小的块部署我们的代码，不再等待主要功能的完成，而是在每次提交后可能就会进行部署。这样做的主要好处是主分支和功能分支之间的差异更小，合并代码所需的时间也更少。较小的更改也创造了更少的监控区域，因此，如果出现问题，更容易将更改回滚到已知的工作状态。最重要的是，它使你能够更快地交付业务价值；无论是以错误还是新功能的形式，这种能力都比瀑布模型中可用的要早得多。
- en: Aspects of continuous delivery
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 持续交付的方面
- en: There are several important aspects to continuous delivery most of which are
    essential to the success of the process. In this section, we will look at what
    these aspects are before we look at how we can implement them to build our own
    pipeline.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 持续交付有几个重要的方面，其中大多数对于流程的成功至关重要。在本节中，我们将在探讨如何实现它们以构建我们自己的管道之前，先看看这些方面是什么。
- en: 'Important aspects of continuous delivery:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 持续交付的重要方面：
- en: Reproducibility and easy setup
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可重复性和易于设置
- en: Artifact storage
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文物存储
- en: Automation of tests
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试自动化
- en: Automation of integration tests
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成测试自动化
- en: Infrastructure as code
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础设施即代码
- en: Security scanning
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全扫描
- en: Static code analysis
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 静态代码分析
- en: Smoke testing
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 烟雾测试
- en: End 2 end testing
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 端到端测试
- en: Monitoring - track deployments in metrics
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控 - 通过指标跟踪部署
- en: Reproducibility and consistency
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可重复性和一致性
- en: 'I have a small doubt, at some point in your career you might have already seen
    this meme:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我有一点疑问，在你们职业生涯的某个时刻，你们可能已经见过这个梗：
- en: '![](img/2876a4cd-de1c-4d29-b7ab-e3492425c7c7.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2876a4cd-de1c-4d29-b7ab-e3492425c7c7.png)'
- en: If you have not, don't worry, I am confident you are going to encounter it at
    some point. *Works on My Machine* why is this meme so popular? Could it be because
    there is a heavy element of truth in it? I certainly know that I have been there
    and many of you have too I am sure. If we are to deliver continuously and by this
    mean as often as possible, then we need to care about consistency and reproducibility.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你们还没有遇到过，不要担心，我确信你们会在某个时刻遇到。*在我的机器上工作*这个梗为什么这么受欢迎？会不会是因为其中包含了很多真实的元素？我确实知道我经历过，我相信你们很多人也经历过。如果我们要持续交付，也就是说尽可能频繁地交付，那么我们需要关注一致性和可重复性。
- en: Reproducibility is the ability of an entire analysis of an experiment or study
    to be duplicated, either by the same researcher or by someone else working independently.
    *Works on my machine* is not acceptable. If we are to deliver continuously, then
    we need to codify our build process and make sure that our dependencies for software
    and other elements are either minimized or managed.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 可重复性是指整个实验或研究的分析可以被复制，无论是同一研究者还是独立工作的其他人。*在我的机器上运行正常*是不被接受的。如果我们想要持续交付，那么我们需要将我们的构建过程编码化，并确保我们的软件和其他元素的依赖项要么最小化，要么得到管理。
- en: The other thing that is important is the consistency of our builds. We cannot
    spend time fixing broken builds or manually deploying software, so we must treat
    them with the same regard that we treat our production code. If the build breaks,
    we need to stop the line and fix it immediately, understand why the build broke,
    and if necessary, introduce new safeguards or processes so that it does not occur
    again.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 另一件重要的事情是我们构建的一致性。我们不能花费时间去修复损坏的构建或手动部署软件，因此我们必须像对待我们的生产代码一样对待它们。如果构建失败，我们需要立即停止生产线并修复它，了解构建失败的原因，并在必要时引入新的安全措施或流程，以防止再次发生。
- en: Artifact storage
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工件存储
- en: When we implement any form of continuous integration, we produce various artifacts
    because of the build process. The artifacts can range from binaries to the output
    of tests. We need to consider how we are going to store this data; thankfully
    cloud computing has many answers to this problem. One solution is cloud storage
    such as AWS S3, which is available in abundance, and at a small cost. Many of
    the software as a service CI providers such as Travis and CircleCI also offer
    this capability built into the system; so for us to leverage it, there is very
    little we need to do. We can also leverage the same storage if, for example, we
    are using Jenkins. The existence of the cloud means we rarely need to worry about
    the management of CI artifacts anymore.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们实施任何形式的持续集成时，由于构建过程，我们会产生各种工件。这些工件的范围可以从二进制文件到测试输出。我们需要考虑我们将如何存储这些数据；幸运的是，云计算为这个问题提供了许多解决方案。一种解决方案是云存储，如AWS
    S3，它非常丰富，且成本较低。许多软件即服务CI提供商，如Travis和CircleCI，也提供内置的这种功能；因此，为了利用它，我们几乎不需要做任何事情。如果我们使用Jenkins，我们也可以利用相同的存储。云的存在意味着我们很少需要担心CI工件的管理。
- en: Automation of tests
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试的自动化
- en: Test automation is essential, and to ensure the integrity of the built application,
    we must run our unit tests on the CI platform. Test automation forces us to consider
    easy and reproducible setup, dependencies need minimizing, and we should only
    be checking the behavior and integrity of the code. In this step, we avoid integration
    tests, the tests should run without anything but the go test command.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 测试自动化是必不可少的，为了确保构建的应用程序的完整性，我们必须在持续集成平台上运行我们的单元测试。测试自动化迫使我们考虑简单且可重复的设置，需要最小化依赖项，我们只应检查代码的行为和完整性。在这一步中，我们避免集成测试，测试应在没有任何东西但`go
    test`命令的情况下运行。
- en: Automation of integration tests
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集成测试的自动化
- en: Of course, we do need to verify the integration between our code and any other
    dependencies such as a database or downstream service. It is easy to misconfigure
    something, especially when database statements are involved. The level of integration
    tests should be far less than the coverage of the unit tests, and again we need
    to be able to run these in a reproducible environment. Docker is an excellent
    ally in this situation; we can leverage the capability of Docker to run in multiple
    environments. This enables us to configure and debug our integration tests on
    our local environment before executing them on the build server. In the same way,
    that unit tests are a gate to a successful build, so are integration tests; failure
    of these tests should never result in a deployment.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们确实需要验证我们的代码与任何其他依赖项（如数据库或下游服务）之间的集成。配置错误很容易发生，尤其是在涉及数据库语句时。集成测试的水平应该远低于单元测试的覆盖率，而且我们还需要能够在可重复的环境中运行这些测试。Docker在这种情况下是一个出色的盟友；我们可以利用Docker在多个环境中运行的能力。这使得我们能够在构建服务器上执行之前，在我们的本地环境中配置和调试集成测试。同样，单元测试是成功构建的门槛，集成测试也是如此；这些测试的失败不应导致部署。
- en: Infrastructure as code
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基础设施即代码
- en: When we automate our build and deploy the process, this step is essential; ideally,
    we do not want to be deploying code to a dirty environment as this raises the
    risk of pollution such as an incorrectly vendored dependency. However, we also
    need to be able to rebuild the environment, if necessary, and this should be possible
    without enacting any of the problems we introduced earlier.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们自动化构建和部署过程时，这一步是必不可少的；理想情况下，我们不希望将代码部署到脏环境中，因为这会增加污染的风险，例如错误地 vendored 依赖项。然而，如果需要，我们也需要能够重新构建环境，而且这应该在没有实施我们之前引入的任何问题的前提下成为可能。
- en: Security scanning
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安全扫描
- en: If possible, security scanning should be integrated into the pipeline; we need
    to be catching bugs early and often. Regardless of whether your service is external
    facing or not, scanning it can ensure that there is a limited attack vector for
    an attacker to misuse. We have looked at fuzzing in a previous chapter, and the
    time it can take to perform this task is quite considerable and possibly not suitable
    for inclusion inside of a pipeline. However, it is possible to include various
    aspects of security scanning into the pipeline without slowing down deployments.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果可能的话，安全扫描应该集成到管道中；我们需要尽早和经常地捕捉到bug。无论你的服务是否面向外部，扫描它都可以确保攻击者有有限的攻击向量可以滥用。我们已经在之前的章节中讨论了模糊测试，执行这项任务所需的时间相当可观，可能不适合包含在管道中。然而，可以在不减缓部署的情况下，将安全扫描的各个方面集成到管道中。
- en: Static code analysis
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 静态代码分析
- en: Static code analysis is an incredibly effective tool to combat bugs and vulnerabilities
    in your applications, and often developers run tools such as **govet** and **gofmt**
    as part of their IDE. When the source is saved, the linter runs and identifies
    issues in the source code. It is important to run these applications inside of
    the pipeline as well as we cannot always guarantee that the change has come from
    an IDE which has it configured in this way. In addition to the save time linters,
    we can also run static code analysis to detect problems with SQL statements and
    code quality issues. These additional tools are often not included in the IDE's
    save workflow, and therefore it is imperative to run them on CI to detect any
    problems, which may have slipped through the net.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 静态代码分析是应对应用程序中bug和漏洞的极其有效的工具，通常开发者会将**govet**和**gofmt**等工具作为他们IDE的一部分来运行。当源代码保存时，代码检查器会运行并识别源代码中的问题。在管道内运行这些应用程序同样重要，因为我们不能总是保证更改来自已经以这种方式配置的IDE。除了节省保存时间之外，我们还可以运行静态代码分析来检测SQL语句的问题和代码质量的问题。这些额外的工具通常不包括在IDE的保存工作流程中，因此，在CI上运行它们以检测任何可能遗漏的问题至关重要。
- en: Smoke tests
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 烟雾测试
- en: Smoke tests are our way of determining whether a deployment has gone successfully.
    We run a test, which can range from a simple curl to a more complex codified test
    to check various integration points within the running application.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 烟雾测试是我们确定部署是否成功的一种方式。我们运行一个测试，这个测试可以从简单的curl到更复杂的编码测试，以检查运行中的应用程序中的各种集成点。
- en: End-to-end tests
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 端到端测试
- en: End-to-end tests are a complete check on the running system and typically follow
    the user flow testing the various parts. Often these tests are global to the application
    not local to the service and are automated using BDD-based tools such as cucumber.
    Determining whether you run E2E tests as a gate to deployment or a parallel process
    which is either triggered by a deployment or set as a continually running process
    is dependent upon your company's appetite for risk. If you are confident that
    your unit, integration, and smoke tests have adequate coverage to give you peace
    of mind or that the service in question is not essential to the core user journey,
    then you may decide to run these in parallel. If, however, the functionality in
    question is part of your core journey, then you may choose to run these tests
    sequentially as a gateway to deployment on a staging environment. Even when E2E
    tests run as a gateway, if any configuration changes are made such as the promotion
    of staging to production, it is advisable to again run the E2E tests before declaring
    a deployment successful.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 端到端测试是对运行系统的全面检查，通常遵循用户流程测试各个部分。通常这些测试是针对整个应用程序的，而不是针对服务的局部，并且使用基于BDD的工具（如cucumber）自动化。你决定将端到端测试作为部署的门槛还是并行过程，这取决于你公司对风险的承受能力。如果你相信你的单元、集成和冒烟测试有足够的覆盖率来给你带来安心，或者所讨论的服务不是核心用户旅程的关键，那么你可以决定并行运行这些测试。然而，如果所讨论的功能是核心旅程的一部分，那么你可能选择将这些测试按顺序运行，作为部署到预发布环境的门槛。即使端到端测试作为门槛运行，如果进行了任何配置更改，例如将预发布提升到生产，在宣布部署成功之前再次运行端到端测试是明智的。
- en: Monitoring
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控
- en: Post deploy, we should not rely on our users to inform us when something has
    gone wrong, which is why we need application monitoring linked to an automated
    notification system such as **PagerDuty**. When a threshold of errors has exceeded,
    the monitor triggers and alerts you to the problem; this gives you the opportunity
    to roll back the last deploy or to fix the issue.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 部署后，我们不应依赖用户通知我们出现问题，这就是为什么我们需要将应用程序监控与自动通知系统（如**PagerDuty**）链接起来的原因。当错误阈值超过时，监控器会触发并提醒你问题；这给你提供了回滚上一个部署或修复问题的机会。
- en: Continuous delivery process
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 持续交付流程
- en: 'So far, we have talked about the problem, and why this is important for us.
    We have also looked at the constituent parts of a successful continuous delivery
    system, but how can we implement such a process for our application, and what
    does Go bring as a language which helps us with this? Now, let''s look at the
    process:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经讨论了问题，以及为什么这对我们很重要。我们还研究了成功持续交付系统的组成部分，但我们是怎样为我们的应用程序实施这样一个流程的，Go语言作为帮助我们的语言，又带来了什么？现在，让我们看看这个过程：
- en: Build
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建
- en: Test
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试
- en: Package
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 打包
- en: Integration test
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成测试
- en: Benchmark test
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基准测试
- en: Security test
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全测试
- en: Provision production
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署生产
- en: Smoke test
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 冒烟测试
- en: Monitor
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控
- en: Overview
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: The build process is mainly a focus for developers to get things up and running
    on their local machine but my recommendation is that we need to be thinking about
    cross-platform and cross-system builds from the beginning. What I mean by cross-system
    builds is that even if we are developing on a Macintosh, we may not be building
    a release product on a Mac. In fact, this behavior is quite common. We need our
    releases built by a third party and preferentially in a clean room environment,
    which is not going to be affected by pollution from other builds.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 构建过程主要是开发者关注的问题，以便在他们本地机器上启动和运行，但我的建议是我们从一开始就需要考虑跨平台和跨系统的构建。我所说的跨系统构建是指，即使我们在Macintosh上开发，我们可能不会在Mac上构建发布产品。实际上，这种行为相当普遍。我们需要第三方构建我们的发布版本，并且优先在无尘室环境中构建，这样就不会受到其他构建的污染。
- en: Every feature should have a branch and every branch should have a build. Every
    time your application code is pushed to the source repository, we should trigger
    the build even if this code is going nowhere near production. It is good practice
    never to leave a build in a broken state, and that includes branch builds. You
    should deal with the issues as and when they occur; delaying this action risks
    your ability to deploy, and while you may not plan to deploy to production until
    the end of the sprint, you must consider unforeseen issues which can occur such
    as the requirement to change the configuration or hotfix a bug. If the build process
    is in a broken state, then you will not be able to deal with the immediate issues,
    and you risk delaying a planned deployment.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 每个功能都应该有一个分支，每个分支都应该有一个构建。每次将应用程序代码推送到源代码库时，我们都应该触发构建，即使这些代码根本不会接近生产环境。永远不要让构建处于损坏状态是一种良好的实践，这包括分支构建。你应该在问题发生时立即处理它们；推迟这一行动可能会危及你的部署能力，而且虽然你可能不打算在冲刺结束时部署到生产环境，但你必须考虑可能发生的意外问题，例如需要更改配置或修复热补丁错误。如果构建过程处于损坏状态，那么你将无法处理即时问题，这可能导致计划中的部署延迟。
- en: The other important aspect other than automatically triggering a build whenever
    you push to a branch is to run a nightly build. Nightly builds for branches, should
    be rebased with the master branch before building and testing. The reason for
    this step is to give you early warning around potential merge conflicts. We want
    to catch these early rather than later; a failed nightly build should be the first
    task of the day.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在每次推送到分支时自动触发构建之外，另一个重要的方面是运行夜间构建。在构建和测试之前，分支的夜间构建应该与主分支进行rebase。这一步骤的原因是给你提供关于潜在合并冲突的早期警告。我们希望尽早捕捉到这些问题；失败的夜间构建应该是当天第一项任务。
- en: We talked about Docker earlier on in [Chapter 4](2baaa0cf-170d-4d7f-8449-b26f20a9bbab.xhtml),
    *Testing*, and we should bring Docker into our build process. Docker through its
    immutability for a container gives us the clean room environment to ensure reproducibility.
    Because we start from scratch with every build, we cannot rely on a pre-existing
    state, which causes differences between the development environment and the built
    environment. Environmental pollution may seem like a trivial thing but the amount
    of time I have wasted over my career debugging a broken build because one application
    was using a dependency installed on a machine and another used a different version
    is immeasurable.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第4章](2baaa0cf-170d-4d7f-8449-b26f20a9bbab.xhtml)“测试”中较早地讨论了Docker，我们应该将Docker引入我们的构建过程。通过其容器的不变性，Docker为我们提供了一个干净的房间环境，以确保可重复性。因为我们每次构建都是从零开始，所以我们不能依赖于预存在状态，这会导致开发环境和构建环境之间的差异。环境污染可能看似微不足道，但我职业生涯中因为一个应用程序使用了安装在机器上的依赖项，而另一个使用了不同版本而浪费在调试损坏构建上的时间是无法衡量的。
- en: What is container orchestration?
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器编排是什么？
- en: Simply container orchestration is the process of running one or more instances
    of an application. Think of the common understanding of an orchestra, a group
    of musicians who work together to produce a piece of music. The containers in
    your application are like the musicians in the orchestra; you may have specialist
    containers, of which there are low numbers of instances such as the percussionists,
    or you may have many instances such as the strings section. In an orchestra, the
    conductor keeps everything in time and ensures that the relevant musicians are
    playing the right music at the right time. In the world of containers, we have
    a scheduler; the scheduler is responsible for ensuring that the correct number
    of containers are running at any one time and that these containers are distributed
    correctly across the nodes in the cluster to ensure high availability. The scheduler,
    like a conductor, is also responsible for ensuring that the right instruments
    play at the right time. In addition to ensuring a constant suite of applications
    is constantly running, the scheduler also can start a container at a particular
    time or based on a particular condition to run ad hoc jobs. This capability is
    similar to what would be performed by **cron** on a Linux-based system.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，容器编排是指运行一个或多个应用程序实例的过程。想象一下我们对管弦乐队的普遍理解，一群音乐家共同合作创作音乐。你应用程序中的容器就像管弦乐队中的音乐家；你可能有一些专业容器，实例数量较少，比如打击乐手，或者你可能有很多实例，比如弦乐部分。在管弦乐队中，指挥保持一切同步，并确保相关音乐家在正确的时间演奏正确的音乐。在容器世界中，我们有一个调度器；调度器负责确保在任何时候运行的容器数量正确，并且这些容器在集群的节点上正确分布，以确保高可用性。调度器，就像指挥一样，也负责确保正确的乐器在正确的时间演奏。除了确保一组应用程序持续运行外，调度器还可以在特定时间或基于特定条件启动容器以运行临时作业。这种能力类似于在基于Linux的系统上由**cron**执行的操作。
- en: Options for container orchestration
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器编排的选项
- en: 'Thankfully, today there are many applications which provide an orchestration
    function, these are broken into two categories: Managed, such as PaaS solutions
    like AWS ECS, and Unmanaged, such as open source schedulers like Kubenetes, which
    need management of both servers and the scheduler application. Unfortunately,
    there is no one-fits-all solution. The option you choose is dependent on the scale
    you require and how complex your application is. If you are a startup or just
    starting to break out into the world of microservices, then the more managed end
    of the spectrum such as **Elastic Beanstalk** will more than suffice. If you are
    planning a large-scale migration, then you might be better looking at a fully
    fledged scheduler. One thing I am confident about is that by containerizing your
    applications using Docker, you have this flexibility, even if you are planning
    a large-scale migration, then start simple and work up to the complexity. We will
    examine how the concepts of orchestration and infrastructure-as-code enable us
    to complete this. We should never ignore the up-front-design and long term thinking,
    but we should not let this stop us from moving fast. Like code infrastructure
    can be refactored and upgraded, the important concepts are the patterns and the
    strong foundations.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，今天有许多应用程序提供了编排功能，这些被分为两类：托管，如AWS ECS这样的PaaS解决方案，以及非托管，如Kubenetes这样的开源调度器，它们需要管理和调度器应用程序。不幸的是，没有一种适合所有情况的解决方案。你选择的选项取决于你需要的规模和应用程序的复杂程度。如果你是初创公司或者刚开始进入微服务领域，那么更托管的一端，如**Elastic
    Beanstalk**，将绰绰有余。如果你计划进行大规模迁移，那么你可能需要考虑一个完整的调度器。我确信的一点是，通过使用Docker容器化你的应用程序，你拥有这种灵活性，即使你计划进行大规模迁移，也可以从简单开始，逐步增加复杂性。我们将探讨编排和基础设施即代码的概念如何帮助我们完成这项工作。我们永远不应该忽视前期设计和长期思考，但我们也不应该让这阻止我们快速行动。就像代码基础设施可以被重构和升级一样，重要的概念是模式和强大的基础。
- en: What is immutable infrastructure?
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是不可变基础设施？
- en: Immutability is the inability to be changed. We have already looked at Docker
    and how a Docker container is an immutable instance of an image. However, what
    about the hardware that the Docker server runs on? Immutable infrastructure gives
    us the same benefits--we have a known state and that state is consistent across
    our estate. Traditionally, the software would be upgraded on an application server,
    but this process was often problematic. The software update process would sometimes
    not go to plan, leaving in the operator with the arduous task of trying to roll
    this back. We would also experience situations where the application servers would
    be in a different state requiring different processes to upgrade each of them.
    The update process may be okay if you only have two application servers, but what
    if you have 200 of them? The cognitive load becomes too high to bear that the
    administration is distributed across a team or multiple teams, and then we need
    to start to maintain documentation to upgrade each of the applications. When we
    were dealing with bare metal servers, there was often no other way to deal with
    this; the time it would take to provision a machine was measured in days. With
    the virtualization, this time improved as it gave us the ability to create a base
    image, which contained a partial config and we could then provision new instances
    in tens of minutes. With the cloud, the level of abstraction became one layer
    greater; no longer did we even need to worry about the virtualization layer as
    we had the capability to spin up compute resource in seconds. So, the cloud solved
    the process of the hardware, but what about the process of provisioning the applications?
    Do we still need to write the documentation and keep it up to date? As it happens,
    we do not. Tooling has been created to allow us to codify our infrastructure and
    application provisioning. The code becomes the documentation and because it is
    code we can version it using the standard version control systems such as Git.
    There are many tools to choose from, such as Chef, Puppet, Ansible, and Terraform;
    however, in this chapter, we will take a look at Terraform because in my personal
    opinion, besides being the most modern of the tools and the easiest to use, it
    embodies all of the principles of immutability.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 不可变性是指无法更改的状态。我们已经探讨了Docker以及Docker容器是如何成为图像的不可变实例的。然而，关于Docker服务器运行的硬件呢？不可变基础设施给我们带来了同样的好处——我们有一个已知的状态，并且该状态在我们整个环境中是一致的。传统上，软件会在应用服务器上升级，但这个过程往往存在问题。软件更新过程有时不会按计划进行，让操作员面临艰难的任务，试图回滚这个过程。我们也会遇到应用服务器处于不同状态的情况，需要不同的过程来升级每个服务器。如果只有两个应用服务器，更新过程可能没问题，但如果你有200个呢？认知负荷变得过高，以至于管理被分散到团队或多个团队，然后我们需要开始维护文档以升级每个应用程序。当我们处理裸机服务器时，通常没有其他方法来处理这种情况；配置一台机器所需的时间以天计算。随着虚拟化的发展，这种时间得到了改善，因为它使我们能够创建一个基础镜像，其中包含部分配置，然后我们可以在几分钟内配置新的实例。随着云的出现，抽象级别又提高了一层；我们甚至不再需要担心虚拟化层，因为我们有能力在几秒钟内启动计算资源。因此，云解决了硬件的过程，但关于应用程序配置的过程呢？我们是否还需要编写文档并保持其更新？实际上，我们不需要。已经创建了工具，使我们能够将基础设施和应用配置编码化。代码成为文档，因为它是代码，我们可以使用标准的版本控制系统（如Git）对其进行版本控制。有众多工具可供选择，例如Chef、Puppet、Ansible和Terraform；然而，在本章中，我们将探讨Terraform，因为在我看来，除了是最现代的工具和最容易使用的工具之外，它还体现了不可变性的所有原则。
- en: Terraform
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Terraform
- en: Terraform ([https://terraform.io](https://terraform.io)) is an application by
    HashiCorp ([https://hashicorp.com](https://hashicorp.com)), which enables the
    provisioning of infrastructure for several applications and cloud providers.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: Terraform ([https://terraform.io](https://terraform.io)) 是由HashiCorp ([https://hashicorp.com](https://hashicorp.com))
    开发的一个应用程序，它能够为多个应用程序和云提供商提供基础设施配置。
- en: It allows you to write codified infrastructure using the HCL language format.
    It enables the concepts of reproducibility and consistency that we have discussed
    are essential for continuous deployment.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 它允许您使用HCL语言格式编写编码化的基础设施。它实现了我们讨论过的可重复性和一致性概念，这些对于持续部署至关重要。
- en: Terraform as an application is a powerful tool and is a bigger topic than this
    book should cover; however, we will look at the basics of how it works to understand
    our demo application.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 作为应用程序的Terraform是一个强大的工具，它比本书应该涵盖的内容更为广泛；然而，我们将探讨其基本工作原理，以便理解我们的演示应用程序。
- en: We will split our infrastructure into multiple chunks with the infrastructure
    code owned by each microservice located in the source code repository.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把我们的基础设施分成多个部分，每个微服务拥有的基础设施代码位于源代码仓库中。
- en: 'In this section, we will look closely at the shared infrastructure and services
    to get a deeper understanding of the Terraform concepts. Let''s take a look at
    the example code in the following GitHub repository:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将仔细研究共享的基础设施和服务，以更深入地理解Terraform的概念。让我们看一下以下GitHub仓库中的示例代码：
- en: '[https://github.com/building-microservices-with-go/chapter11-services-main](https://github.com/building-microservices-with-go/chapter11-services-main)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/building-microservices-with-go/chapter11-services-main](https://github.com/building-microservices-with-go/chapter11-services-main)'
- en: 'The shared infrastructure contains the following components:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 共享基础设施包含以下组件：
- en: '![](img/bc503990-dab7-4129-a762-81a99c403866.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bc503990-dab7-4129-a762-81a99c403866.png)'
- en: '**VPC**: This is the virtual cloud, it allows all of the applications connected
    to it to communicate without needing to go over the public internet'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**VPC**：这是虚拟云，它允许连接到它的所有应用程序无需经过公共互联网即可通信'
- en: '**S3 bucket**: This is the remote storage for config and artifacts'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**S3存储桶**：这是配置和工件远程存储'
- en: '**Elastic Beanstalk**: This is the Elastic Beanstalk application which will
    run the NATS.io messaging system, we can split this over two availability zones
    which are the equivalent to a data center, hosting applications in multiple zones
    gives us redundancy in the instance that the zone suffers an outage'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Elastic Beanstalk**：这是将运行NATS.io消息系统的Elastic Beanstalk应用程序，我们可以将其分布在两个可用区，这相当于数据中心，在多个区域托管应用程序为我们提供了冗余，以防区域出现故障'
- en: '**Internal ALB:** To communication with our NATS.io server when we add other
    applications to our VPC we need to use an internal application load balancer.
    An internal ALB has the same features as an external load balancer but it is only
    accessible to applications which are attached to the VPC, connections from the
    public internet are not allowed'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内部ALB**：当我们向我们的VPC添加其他应用程序时，为了与我们的NATS.io服务器通信，我们需要使用内部应用程序负载均衡器。内部ALB具有与外部负载均衡器相同的功能，但它仅对连接到VPC的应用程序可访问，不允许来自公共互联网的连接'
- en: '**Internet Gateway:** If we need our application to be able to make outbound
    calls to other internet services then we need to attach an internet gateway. For
    security, a VPC has no outbound connections by default'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**互联网网关**：如果我们需要我们的应用程序能够向其他互联网服务发起出站调用，那么我们需要附加一个互联网网关。出于安全考虑，VPC默认没有出站连接'
- en: Now we can understand the components which we need to create let's take a look
    at the Terraform configuration which can create them.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以理解我们需要创建的组件，让我们看一下可以创建它们的Terraform配置。
- en: Providers
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提供者
- en: 'Terraform is broken up into providers. A provider is responsible for understanding
    the API interactions and exposing the resources for the chosen platform. In the
    first section, we will look at the provider configuration for AWS. In the following
    code, the `provider` block allows you to configure Terraform with your credentials
    and set an AWS region:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: Terraform被分解为提供者。提供者负责理解API交互并暴露所选平台上的资源。在第一部分，我们将查看AWS的提供者配置。在以下代码中，`provider`块允许您使用您的凭据配置Terraform并设置AWS区域：
- en: '[PRE0]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Blocks in Terraform typically follow the previous pattern. HCL is not JSON;
    however, it is interoperable with JSON. The design of HCL is to find that balance
    between machine and human-readable format. In this particular provider, we can
    configure some different arguments; however, as a bare minimum, we must set up
    your `access_key`, `secret_key`, and `region`. These are explained as follows:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: Terraform中的块通常遵循之前的模式。HCL不是JSON；然而，它与JSON是互操作的。HCL的设计是为了在机器可读和人类可读格式之间找到平衡。在这个特定的提供者中，我们可以配置一些不同的参数；然而，作为一个基本要求，我们必须设置您的`access_key`、`secret_key`和`region`。以下是对这些参数的解释：
- en: '`access_key`: This is the AWS access key. This is a required argument; however,
    it may also be provided by setting the `AWS_ACCESS_KEY_ID` environment variable.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`access_key`：这是AWS访问密钥。这是一个必需的参数；然而，它也可以通过设置`AWS_ACCESS_KEY_ID`环境变量来提供。'
- en: '`secret_key`: This is the AWS secret key. This is a required argument; however,
    it may also be provided by setting the `AWS_SECRET_ACCESS_KEY` environment variable.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`secret_key`：这是AWS密钥。这是一个必需的参数；然而，它也可以通过设置`AWS_SECRET_ACCESS_KEY`环境变量来提供。'
- en: '`region`: This is the AWS region. This is a required argument; however, it
    may also be provided by setting the `AWS_DEFAULT_REGION` environment variable.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of the required variables can be replaced with environment variables; we
    do not want to commit our AWS secrets to GitHub because if they leak we will most
    likely find that someone has kindly spun up lots of expensive resource to mine
    Bitcoin ([http://www.securityweek.com/how-hackers-target-cloud-services-bitcoin-profit](http://www.securityweek.com/how-hackers-target-cloud-services-bitcoin-profit)).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: 'If we use environment variables, we can then securely inject these into our
    CI service where they are available for the job. Looking at our provider block
    `provider.tf`, we can see that it does not contain any of the settings:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Also, in this file, you will notice that there is a block by the name of `terraform`.
    This configuration block allows us to store the Terraform state in an S3 bucket:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The state is what the `terraform` block uses to understand the resources, which
    have been created for a module. Every time you change your configuration and run
    either of the Terraform plans, Terraform will check the state files for differences
    to understand what it needs to delete, update, or create. A special note on remote
    state is that again it should never be checked into git. The remote state contains
    information about your infrastructure, including potentially secret information,
    not something you would ever want to leak. For this reason, we can use the remote
    state, rather than keep the state on your local disk; Terraform saves the state
    files to a remote backend such as `s3`. We can even implement locking with certain
    backends to ensure that only one run of the configuration takes place at any one
    time. In our config, we are using the AWS `s3` backend, which has the following
    attributes:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '`bucket`: This is the name of the S3 bucket to store the state. S3 buckets
    are globally named and are not namespaced to your user account. So this value
    must not only be unique to you, but specific to AWS.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`key`: This is the key of the bucket object which holds the state. This is
    unique to the bucket. You can use a bucket for multiple Terraform configs as long
    as this key is unique.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`region`: This is the region for the S3 bucket.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Terraform config entry point
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The main entry point for our application is the `terraform.tf` file. There is
    no stipulation on this filename, Terraform is graph based. It recurses through
    all files which end in `.tf` in our directory and build up a dependency graph.
    It does this to understand the order to create resources.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: 'If we look at this file, we see that it is made up of modules. Modules are
    a way for Terraform to create reusable sections of infrastructure code or just
    to logically separate things for readability. They are very similar to the concepts
    of packages in Go:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Let's take a look at the VPC module in greater depth.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: VPC module
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The VPC module creates our private network inside AWS; we do not want to or
    need to expose the NATS server to the outside world, so we can create a private
    network which only allows the resources attached to that network to access it,
    as shown in the following code:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: VPC模块在AWS内部创建我们的私有网络；我们不想也不需要将NATS服务器暴露给外部世界，因此我们可以创建一个仅允许连接到该网络的资源访问它的私有网络，如下面的代码所示：
- en: '[PRE4]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The `source` attribute is the location of the module; Terraform supports the
    following sources:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '`source` 属性是模块的位置；Terraform支持以下来源：'
- en: Local file paths
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本地文件路径
- en: GitHub
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GitHub
- en: Bitbucket
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bitbucket
- en: Generic Git, Mercurial repositories
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通用Git、Mercurial仓库
- en: HTTP URLs
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HTTP URL
- en: S3 buckets
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: S3 存储桶
- en: Following the `source` attribute, we can configure custom attributes, which
    correspond to the variables in the module. Variables are required placeholders
    for a module; when they are not present, Terraform complains when we try to run
    it.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `source` 属性之后，我们可以配置自定义属性，这些属性对应于模块中的变量。变量是模块的必需占位符；当它们不存在时，Terraform在尝试运行时会报错。
- en: 'The `vpc/variables.tf` file contains the following content:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '`vpc/variables.tf` 文件包含以下内容：'
- en: '[PRE5]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The configuration for a variable is very much like that of the provider and
    it follows the following syntax:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 变量的配置与提供者的配置非常相似，它遵循以下语法：
- en: '[PRE6]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'A variable has three possible configuration options:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 变量有三个可能的配置选项：
- en: '`type`: This is an optional attribute which sets the type of the variable.
    The valid values are `string`, `list`, and `map`. If no value is given, then the
    type is assumed to be `string`.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`type`: 这是一个可选属性，用于设置变量的类型。有效的值有 `string`、`list` 和 `map`。如果没有提供值，则默认类型为 `string`。'
- en: '`default`: This is an optional attribute to set the default value for the variable.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`default`: 这是一个可选属性，用于设置变量的默认值。'
- en: '`description`: This is an optional attribute to assign a human-friendly description
    for the variable. The primary purpose of this attribute is for documentation of
    your Terraform configuration.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`description`: 这是一个可选属性，用于为变量分配一个友好的描述。此属性的主要目的是为了记录你的Terraform配置文档。'
- en: 'Variables can be explicitly declared inside a `terraform.tfvars` file like
    the one in the root of our repository:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 变量可以在 `terraform.tfvars` 文件中显式声明，就像我们仓库根目录下的文件一样：
- en: '[PRE7]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We can also set an environment variable by prefixing `TF_VAR_` to the name
    of the variable:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以通过在变量名称前缀添加 `TF_VAR_` 来设置环境变量：
- en: '[PRE8]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Alternatively, we can include the variable in the command when we run the `terraform`
    command:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以在运行 `terraform` 命令时在命令中包含变量：
- en: '[PRE9]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We are configuring the namespace of the application and the IP address block
    allocated to the network. If we look at the file, which contains the VPC blocks,
    we can see how this is used.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在配置应用程序的命名空间和网络分配的IP地址块。如果我们查看包含VPC块的文件，我们可以看到它是如何使用的。
- en: 'The `vpc/vpc.tf` file contains the following content:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '`vpc/vpc.tf` 文件包含以下内容：'
- en: '[PRE10]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'A `resource` block is a Terraform syntax, which defines a resource in AWS and
    has the following syntax:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '`resource` 块是Terraform语法的一部分，用于在AWS中定义资源，其语法如下：'
- en: '[PRE11]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Resources in Terraform map to the objects needed for the API calls in the AWS
    SDK. If you look at the `cidr_block` attribute, you will see that we are referencing
    the variable using the Terraform interpolation syntax:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: Terraform中的资源映射到AWS SDK中API调用所需的对象。如果你查看 `cidr_block` 属性，你会看到我们正在使用Terraform插值语法引用变量：
- en: '[PRE12]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Interpolation syntax is a metaprogramming language inside of Terraform. It allows
    you to manipulate variables and the output from resources and is defined using
    the `${[interpolation]}` syntax. We are using the variables collection, which
    is prefixed by `var` and references the `vpc_cidr_block` variable. When Terraform
    runs `${var.vpc_cidr_block}`, it will be replaced with the `10.1.0.0/16` value
    from our variable's file.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 插值语法是Terraform内部的元编程语言。它允许你操作变量和资源的输出，并使用 `${[interpolation]}` 语法定义。我们正在使用变量集合，它以前缀
    `var` 开头，并引用 `vpc_cidr_block` 变量。当Terraform运行 `${var.vpc_cidr_block}` 时，它将被替换为变量文件中的
    `10.1.0.0/16` 值。
- en: 'Creating a VPC which has external internet access in AWS requires four sections:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在AWS中创建具有外部互联网访问的VPC需要四个部分：
- en: '`aws_vpc`: This is a private network for our instances'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`aws_vpc`: 这是一个为我们实例提供的私有网络'
- en: '`aws_internet_gateway`: This is a gateway attached to our VPC to allow internet
    access'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`aws_internet_gateway`: 这是一个连接到我们的VPC以允许互联网访问的网关'
- en: '`aws_route`: This is the routing table entry to map to the gateway'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`aws_route`: 这是映射到网关的路由表条目'
- en: '`aws_subnet`: This is a subnet which our instances launch into--we create one
    subnet for each availability zone'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`aws_subnet`：这是一个我们的实例启动到的子网--我们为每个可用区域创建一个子网'
- en: This complexity is not Terraform but AWS. The other cloud providers have very
    similar complexity, and unfortunately, it is unavoidable. It feels daunting at
    first, however, there are some amazing resources out there.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这种复杂性不是 Terraform，而是 AWS。其他云提供商也有非常类似的复杂性，遗憾的是，这是不可避免的。一开始可能会觉得令人畏惧，然而，外面有一些非常棒的资源。
- en: 'The next section of the VPC setup is to configure the internet gateway:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: VPC 设置的下一个部分是配置互联网网关：
- en: '[PRE13]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Again, we have a similar format as the `aws_vpc` block; however, in this block,
    we need to set the `vpc_id` block, which needs to reference the VPC, which we
    created in the previous block. We can again use the Terraform interpolation syntax
    to find this reference even though it has not yet been created. The `aws_vpc.default.id`
    reference has the following form which is common across all resources in Terraform:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们有一个与 `aws_vpc` 块类似的格式；然而，在这个块中，我们需要设置 `vpc_id` 块，它需要引用我们在上一个块中创建的 VPC。我们还可以再次使用
    Terraform 插值语法来找到这个引用，即使它尚未创建。`aws_vpc.default.id` 引用具有以下形式，这在 Terraform 的所有资源中都是通用的：
- en: '[PRE14]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: When we reference another block in Terraform, it also tells the dependency graph
    that the referenced block needs to be created before this block. In this way,
    Terraform is capable of organizing which resources can be set up in parallel and
    those which have an exact order. We do not need to declare the order ourselves
    when the graph is created it automatically builds this for us.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在 Terraform 中引用另一个块时，它也告诉依赖关系图，引用的块需要在当前块之前创建。这样，Terraform 能够组织哪些资源可以并行设置，哪些资源有确切的顺序。当创建图时，我们不需要自己声明顺序，它会自动为我们构建这个顺序。
- en: 'The next block sets up the routing table for the VPC, enabling the outbound
    access to the public internet:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个块设置 VPC 的路由表，启用对公共互联网的出站访问：
- en: '[PRE15]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Let''s take a look at the attributes in this block in a little more detail:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看这个块中的属性：
- en: '`route_table_id`: This is the reference to the routing table we would like
    to create a new reference for. We can obtain this from the output attribute `main_route_table_id`
    from `aws_vpc`.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`route_table_id`：这是我们要为要创建的新引用的路由表的引用。我们可以从 `aws_vpc` 的输出属性 `main_route_table_id`
    获取它。'
- en: '`destination_cidr_block`: This is the IP range of the instances which will
    be connected to the VPC who can send traffic to the gateway. We are using the
    block `0.0.0.0/0`, which allows all the connected instances. If required, we could
    only allow external access to certain IP ranges.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`destination_cidr_block`：这是将要连接到 VPC 的实例的 IP 范围，这些实例可以向网关发送流量。我们使用 `0.0.0.0/0`
    块，允许所有连接的实例。如果需要，我们只能允许对某些 IP 范围的外部访问。'
- en: '`gateway_id`: This is a reference to the gateway block we previously created.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gateway_id`：这是对我们之前创建的网关块的引用。'
- en: The next block introduces a new concept for us data sources. Data sources allow
    data to be fetched or computed from information stored outside Terraform or stored
    in separate Terraform configuration. A data source may look up information in
    AWS, for example, you can query a list of existing EC2 instances, which may exist
    in your account. You can also query other providers, for instance, you have a
    DNS entry in CloudFlare, which you would like the details for or even the address
    of a load balancer in a different cloud provider, such as Google or Azure.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个块为我们引入了一个新的数据源概念。数据源允许从存储在 Terraform 外部或存储在单独的 Terraform 配置中的信息中检索或计算数据。例如，数据源可以在
    AWS 中查找信息，你可以查询现有 EC2 实例的列表，这些实例可能存在于你的账户中。你也可以查询其他提供者，例如，你在 CloudFlare 中有一个 DNS
    条目，你想要获取其详细信息或甚至是不同云提供商（如 Google 或 Azure）中负载均衡器的地址。
- en: 'We will use it to retrieve the lists of availability zones in AWS. When we
    create the VPC, we need to create a subnet in each availability zone, because
    we are only configuring the region, we have not set the availability zones for
    that region. We could explicitly configure these in the variables section; however,
    that makes our config more brittle. The best way, whenever possible, is to use
    data blocks:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用它来检索 AWS 中的可用区域列表。当我们创建 VPC 时，我们需要在每个可用区域中创建一个子网，因为我们只配置了区域，我们没有为该区域设置可用区域。我们可以在变量部分显式配置这些；然而，这会使我们的配置更加脆弱。在可能的情况下，最好的方法是使用数据块：
- en: '[PRE16]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The configuration is quite simple and again follows a common syntax:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 配置相当简单，再次遵循常见的语法：
- en: '[PRE17]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We will make use of this information in the final part of the VPC setup, which
    is to configure the subnets; this also introduces another new Terraform feature
    `count`:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在VPC设置的最后一部分使用此信息，即配置子网；这也引入了另一个新的Terraform功能`count`：
- en: '[PRE18]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Let''s look closely at the `count` attribute; a `count` attribute is a special
    attribute, which when set creates *n* instances of the resource. The value of
    our attribute also expands on the interpolation syntax that we examined earlier
    to introduce the `length` function:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们仔细看看`count`属性；一个`count`属性是一个特殊属性，当设置时，会创建*n*个资源实例。我们的属性值也扩展了我们在前面检查的插值语法，以引入`length`函数：
- en: '[PRE19]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The `cidr_blocks` is a Terraform list. In Go, this would be a slice and the
    length will return the number of elements inside a list. For comparison, let''s
    look at how we would write this in Go:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '`cidr_blocks` 是一个Terraform列表。在Go中，这将是一个切片，其长度将返回列表中元素的数量。为了比较，让我们看看我们如何在Go中编写这个：'
- en: '[PRE20]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Interpolation syntax in Terraform is an amazing feature, allowing you to manipulate
    variables with many built-in functions. The documentation for the interpolation
    syntax can be found at the following location:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: Terraform中的插值语法是一个惊人的特性，允许您使用许多内置函数操作变量。插值语法的文档可以在以下位置找到：
- en: '[https://www.terraform.io/docs/configuration/interpolation.html](https://www.terraform.io/docs/configuration/interpolation.html)'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.terraform.io/docs/configuration/interpolation.html](https://www.terraform.io/docs/configuration/interpolation.html)'
- en: 'We also have the capability of using conditional statements. One of the best
    features of the `count` function is that if you set it to `0`, Terraform omits
    creation of a resource; as an example, it would allow us to write something like
    the following:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还有使用条件语句的能力。`count`函数的一个最佳特性是，如果您将其设置为`0`，Terraform将省略资源的创建；例如，它将允许我们编写如下内容：
- en: '[PRE21]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The syntax for conditionals uses the ternary operation, which is present in
    many languages:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 条件语句的语法使用三元运算符，这在许多语言中都有：
- en: '[PRE22]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'When we use the `count` Terraform, it also provides us with an index, which
    we can use to obtain the correct element from a list. Consider how we are using
    this in the `availability_zone` attribute:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用`count` Terraform时，它还为我们提供了一个索引，我们可以使用它从列表中获取正确的元素。考虑我们如何在`availability_zone`属性中使用它：
- en: '[PRE23]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The `count.index` will provide us with a `0` based index and because `data.aws_availability_zones.available.names`
    returns a list, we can use to access this like a slice. Let''s take a look at
    the remaining attributes on our `aws_subnet`:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '`count.index`将为我们提供一个基于0的索引，因为`data.aws_availability_zones.available.names`返回一个列表，我们可以像切片一样访问它。让我们看看`aws_subnet`上的剩余属性：'
- en: '`vpc_id`: This is the ID of the VPC, which we created in an earlier block and
    we would like to attach the subnet'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vpc_id`: 这是VPC的ID，我们在前面的块中创建的，我们希望将其附加到子网'
- en: '`availability_zone`: This is the name of the availability zone for the subnet'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`availability_zone`: 这是子网的可用区名称'
- en: '`cidr_block`: This is the IP range of addresses, which will be given to an
    instance when we launch it in this particular VPC and availability zone'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cidr_block`: 这是地址的IP范围，当我们在特定的VPC和可用区中启动实例时，将分配给实例'
- en: '`map_public_ip_on_launch`: Whether we should attach a public IP address to
    the instance when it is created, this is an optional parameter, and determines
    whether your instance should also have a public IP address in addition to the
    private one, which is allocated from the `cidr_block` attribute'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`map_public_ip_on_launch`: 当实例创建时，我们是否应该附加一个公共IP地址，这是一个可选参数，并确定您的实例是否也应该有一个公共IP地址，除了从`cidr_block`属性分配的私有IP地址之外'
- en: Output variables
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 输出变量
- en: When we are building modules in Terraform, we often need to reference attributes
    from other modules. There is a clean separation between modules, which means that
    they cannot directly access another module resources. For example, in this module,
    we are creating a VPC, and later on, we would like to create an EC2 instance,
    which is attached to this VPC. We could not use the syntax as shown in the upcoming
    code.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在Terraform中构建模块时，我们经常需要引用来自其他模块的属性。模块之间存在清晰的分离，这意味着它们不能直接访问另一个模块的资源。例如，在这个模块中，我们正在创建一个VPC，稍后我们希望创建一个附加到该VPC的EC2实例。我们无法使用即将显示的语法。
- en: 'The `module2/terraform.tf` file contains the following content:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '`module2/terraform.tf`文件包含以下内容：'
- en: '[PRE24]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The previous example would result in an error as we are trying to reference
    a variable which does not exist in this module even though it does exist in your
    global Terraform config. Consider these to be like Go packages. If we had the
    two following Go packages which contained non-exported variables:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的例子会导致错误，因为我们试图引用在这个模块中不存在的变量，尽管它在你的全局 Terraform 配置中存在。将这些视为类似于 Go 包。如果我们有两个以下
    Go 包，它们包含非导出变量：
- en: '`a/main.go`'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '`a/main.go`'
- en: '[PRE25]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '`b/main.go`'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '`b/main.go`'
- en: '[PRE26]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'In Go we could, of course, have the variable exported by capitalizing the name
    of the variable `notExported` to `NotExported`. To achieve the same in Terraform,
    we use output variables:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Go 中，我们当然可以通过将变量的名称 `notExported` 大写为 `NotExported` 来导出变量。要在 Terraform 中实现相同的效果，我们使用输出变量：
- en: '[PRE27]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The syntax should be starting to get familiar to you now:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 语法现在应该开始变得熟悉了：
- en: '[PRE28]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We can then use the output of one module to be the input of another--an example
    found in the `terraform.tf` file:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用一个模块的输出作为另一个模块的输入--这是在 `terraform.tf` 文件中找到的一个例子：
- en: '[PRE29]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The `vpc_id` attribute is referencing an output from the `vpc` module:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '`vpc_id` 属性引用了 `vpc` 模块的输出：'
- en: '[PRE30]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The syntax for the preceding statement is as follows:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 上述语句的语法如下：
- en: '[PRE31]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: In addition to allowing us to keep our code dry and clean, output variables
    and module references allow Terraform to build its dependency graph. In this instance,
    Terraform knows that because there is a reference to the `vpc` module from the
    `nats` module, it needs to create the `vpc` module resources before the `nats`
    module. This might feel like a lot of information and it is. I did not say infrastructure
    as code was easy, but by the time we get to the end of this example, it will start
    to become clear. Applying these concepts to create other resources becomes quite
    straightforward with the only complexity being how the resource works, not the
    Terraform configuration which is needed to create it.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 除了让我们保持代码的简洁和清晰外，输出变量和模块引用还允许 Terraform 构建其依赖图。在这个例子中，Terraform 知道由于 `nats`
    模块中存在对 `vpc` 模块的引用，它需要在 `nats` 模块之前创建 `vpc` 模块资源。这可能会感觉信息量很大，确实如此。我并没有说基础设施即代码很容易，但当我们到达这个例子的结尾时，它将开始变得清晰。将这些概念应用到创建其他资源变得相当直接，唯一的复杂性在于资源的工作方式，而不是创建该资源所需的
    Terraform 配置。
- en: Creating the infrastructure
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建基础设施
- en: 'To run Terraform and to create our infrastructure, we must first set some environment
    variables:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行 Terraform 并创建我们的基础设施，我们首先必须设置一些环境变量：
- en: '[PRE32]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We then need to initialize Terraform to reference the modules and remote data
    store. We normally only need to perform this step whenever we first clone the
    repository or if we make changes to the modules:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来需要初始化 Terraform 以引用模块和远程数据存储。我们通常只有在第一次克隆仓库或对模块进行更改时才需要执行此步骤：
- en: '[PRE33]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The next step is to run a plan; we use the plan command in Terraform to understand
    which resources are created, updated, or deleted by the `apply` command. It will
    also syntax check our config without creating any resources:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是运行计划；我们使用 Terraform 中的计划命令来了解 `apply` 命令将创建、更新或删除哪些资源。它还将对我们的配置进行语法检查，而不会创建任何资源：
- en: '[PRE34]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The `-out` argument saves the plan to `main.terraform` file. This is an optional
    step, but if we run `apply` with the output from the plan, we can ensure that
    nothing changes from when we inspected and approved the output of the `plan` command.
    To create the infrastructure, we can then run the `apply` command:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '`-out` 参数将计划保存到 `main.terraform` 文件。这是一个可选步骤，但如果我们使用计划的输出运行 `apply`，我们可以确保从检查和批准
    `plan` 命令的输出以来没有发生变化。然后，我们可以运行 `apply` 命令来创建基础设施：'
- en: '[PRE35]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The first argument to the `apply` command is the `plan` output, which we created
    in the previous step. Terraform now creates your resources in AWS, this can take
    anything from a few seconds to 30 minutes depending upon the type of resource
    you are creating. Once the creation is complete, Terraform writes the output variables,
    which we defined in the `output.tf` file to `stdout`.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '`apply` 命令的第一个参数是我们在上一步中创建的计划输出。Terraform 现在将在 AWS 中创建你的资源，这取决于你创建的资源类型，可能需要几秒钟到
    30 分钟。一旦创建完成，Terraform 将将我们在 `output.tf` 文件中定义的输出变量写入 `stdout`。'
- en: We have only covered one of the modules in our main infrastructure project.
    I recommend that you read through the remaining modules and familiarize yourself
    with both the Terraform code and the AWS resources it is creating. Excellent documentation
    is available on the Terraform website ([https://terraform.io](https://terraform.io))
    and the AWS website.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在我们的主要基础设施项目中只覆盖了一个模块。我建议您阅读剩余的模块，并熟悉Terraform代码及其创建的AWS资源。Terraform网站([https://terraform.io](https://terraform.io))和AWS网站上有优秀的文档。
- en: Example application
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例应用
- en: Our sample application is a simple distributed system consisting of three services.
    The three main services, product, search and authentication, have a dependency
    on a database which they use to store their state. For simplicity, we are using
    MySQL; however, in a real production environment, you would want to choose the
    most appropriate data store for your use case. The three services are connected
    via the messaging system for which we are using NATS.io, which is a provider-agnostic
    system, which we looked at in [C](2952a830-163e-4610-8554-67498ec77e1e.xhtml)hapter
    9, *Event-Driven Architecture*.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的示例应用是一个简单的分布式系统，由三个服务组成。这三个主要服务，产品、搜索和认证，依赖于一个数据库，它们使用该数据库来存储它们的状态。为了简单起见，我们使用MySQL；然而，在实际的生产环境中，您可能希望为您的用例选择最合适的数据存储。这三个服务通过我们使用的NATS.io消息系统连接，该系统是一个供应商无关的系统，我们在第9章“事件驱动架构”中进行了探讨[2952a830-163e-4610-8554-67498ec77e1e.xhtml]。
- en: '![](img/88b91630-a430-4c82-92c3-b6236f8d42fd.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/88b91630-a430-4c82-92c3-b6236f8d42fd.png)'
- en: 'To provision this system, we have broken down the infrastructure and source
    code into four separate repositories:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 为了配置此系统，我们将基础设施和源代码分解为四个独立的存储库：
- en: '**Shared infrastructure and services** ([https://github.com/building-microservices-with-go/chapter11-services-main](https://github.com/building-microservices-with-go/chapter11-services-main))'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**共享基础设施和服务** ([https://github.com/building-microservices-with-go/chapter11-services-main](https://github.com/building-microservices-with-go/chapter11-services-main))'
- en: '**Authentication service** ([https://github.com/building-microservices-with-go/chapter11-services-auth](https://github.com/building-microservices-with-go/chapter11-services-auth))'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**认证服务** ([https://github.com/building-microservices-with-go/chapter11-services-auth](https://github.com/building-microservices-with-go/chapter11-services-auth))'
- en: '**Product service** ([https://github.com/building-microservices-with-go/chapter11-services-product](https://github.com/building-microservices-with-go/chapter11-services-product))'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**产品服务** ([https://github.com/building-microservices-with-go/chapter11-services-product](https://github.com/building-microservices-with-go/chapter11-services-product))'
- en: '**Search service** ([https://github.com/building-microservices-with-go/chapter11-services-search](https://github.com/building-microservices-with-go/chapter11-services-search))'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**搜索服务** ([https://github.com/building-microservices-with-go/chapter11-services-search](https://github.com/building-microservices-with-go/chapter11-services-search))'
- en: The individual repositories enable us to separate our application in such a
    way that we only build and deploy the components that change. The shared infrastructure
    repository contains Terraform configuration to create a shared network and components
    to create the NATS.io server. The authentication service creates a JWT-based authentication
    microservice and contains separate Terraform configuration to deploy the service
    to Elastic Beanstalk. The product service and the search service repositories
    also each contain a microservice and Terraform infrastructure configuration. All
    the services are configured to build and deploy using Circle CI.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 单个存储库使我们能够以这种方式将应用程序分离，我们只构建和部署更改的组件。共享基础设施存储库包含用于创建共享网络和创建NATS.io服务器的Terraform配置。认证服务创建了一个基于JWT的认证微服务，并包含用于将服务部署到Elastic
    Beanstalk的单独的Terraform配置。产品服务和搜索服务存储库也各自包含一个微服务和Terraform基础设施配置。所有服务都配置为使用Circle
    CI构建和部署。
- en: Continuous delivery workflow
  id: totrans-239
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 持续交付工作流程
- en: 'For the remainder of this chapter, we concentrate on the search service as
    the build pipeline is the most complex. In our example application, we have the
    following steps which to build a pipeline:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的剩余部分，我们将专注于搜索服务，因为构建管道是最复杂的。在我们的示例应用中，我们有以下步骤来构建管道：
- en: Compile application
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编译应用程序
- en: Unit test
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单元测试
- en: Benchmark
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基准测试
- en: Static code analysis
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 静态代码分析
- en: Integration test
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成测试
- en: Build Docker image
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建Docker镜像
- en: Deploy application
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署应用程序
- en: Smoke test
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 烟雾测试
- en: 'Many of these steps are independent and can run in parallel, so when we compose
    the pipeline, it looks like the following diagram:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 许多这些步骤是独立的，可以并行运行，因此当我们构建管道时，它看起来像以下图示：
- en: '![](img/bd2372fa-3304-48e9-ad93-b0e66e5a71ab.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/bd2372fa-3304-48e9-ad93-b0e66e5a71ab.png)'
- en: 'Take a look at the example code at [https://github.com/building-microservices-with-go/chapter11-services-auth](https://github.com/building-microservices-with-go/chapter11-services-auth).
    We are building this application with Circle CI; however, the concepts apply to
    whatever platform you use. If we look at the `circleci/config.yml` file, we see
    that we are first setting up the configuration for the process, which includes
    choosing the version of the Docker container within which the build executes and
    install some initial dependencies. We then compose the jobs, which are performed
    in the workflow and the various steps for each of the jobs:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看[https://github.com/building-microservices-with-go/chapter11-services-auth](https://github.com/building-microservices-with-go/chapter11-services-auth)上的示例代码。我们使用
    Circle CI 构建这个应用程序；然而，这些概念适用于你使用的任何平台。如果我们查看 `circleci/config.yml` 文件，我们会看到我们首先设置过程的配置，这包括选择构建执行的
    Docker 容器的版本以及安装一些初始依赖项。然后我们组合作业，这些作业在工作流程中执行，并为每个作业定义各种步骤：
- en: '[PRE36]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Finally, we will compose these jobs into a workflow or a pipeline. This workflow
    defines the relationship between the steps as there are obvious dependencies.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将这些作业组合成一个工作流程或管道。这个工作流程定义了步骤之间的关系，因为存在明显的依赖关系。
- en: To isolate dependencies in our configuration and to ensure that the commands
    for building and testing are consistent across various processes, the commands
    have been placed into the Makefile in the root of the repository.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在我们的配置中隔离依赖项，并确保构建和测试的命令在各种过程中保持一致，这些命令已经被放置在仓库根目录下的 Makefile 中。
- en: '[PRE37]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Build
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建
- en: Let's take a closer look at the build process. Inside the build job configuration,
    we have three steps. The first is to check out the repository. The jobs themselves
    are broken up into steps, and the first notable one of these is to install the
    dependencies. Glide is our package manager for the repository, and we need this
    to be installed to fetch updates to our vendored packages. We also need a `go-junit-report`
    utility package. This application allows us to convert the Go test output into
    JUnit format, which Circle requires for presenting certain dashboard information.
    We then execute `glide up` to fetch any updates. In this example, I have checked
    in the `vendor` folder to the repository; however, I am not pinning the packages
    to a version. You should set a minimum package version rather than an exact package
    version, updating your packages frequently allows you to take advantage of regular
    releases in the open source community. You do of course run the risk that there
    will be a breaking change in a package and that change breaks the build, but as
    mentioned earlier, it is better to catch this as soon as possible rather than
    deal with the problem when you are under pressure to release.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看构建过程。在构建作业配置中，我们有三个步骤。第一步是检出仓库。作业本身被分解成步骤，其中第一个值得注意的步骤是安装依赖项。Glide
    是我们仓库的包管理器，我们需要安装它以获取我们供应商包的更新。我们还需要一个 `go-junit-report` 工具包。这个应用程序允许我们将 Go 测试输出转换为
    JUnit 格式，这是 Circle 所需的，以便展示某些仪表板信息。然后我们执行 `glide up` 来获取任何更新。在这个例子中，我已经将 `vendor`
    文件夹检入到仓库中；然而，我没有将包锁定到特定版本。你应该设置一个最低包版本，而不是一个确切的包版本，频繁更新你的包可以让你利用开源社区中的常规发布。当然，你运行的风险是包中可能会有破坏性的更改，这种更改会破坏构建，但如前所述，最好是尽快捕捉到这个问题，而不是在你面临发布压力时处理问题。
- en: Because we are building for production, we need to create a Linux binary, which
    is why we are setting the `GOOS=linux` environment variable before running the
    build. Setting the environment is redundant when we are running the build on Circle
    CI as we are already running in a Linux-based Docker container; however, to enable
    cross-platform builds from our developer machines, if they are not Linux-based,
    it is useful to have a common command.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们是为生产构建，所以我们需要创建一个 Linux 二进制文件，这就是为什么我们在运行构建之前设置 `GOOS=linux` 环境变量的原因。当我们运行构建在
    Circle CI 上时设置环境是多余的，因为我们已经在基于 Linux 的 Docker 容器中运行；然而，为了使我们的开发机器能够进行跨平台构建（如果它们不是基于
    Linux 的），有一个共同的命令是有用的。
- en: 'Once we have built our application, we need to persist the workspace so that
    the other jobs can use this. In Circle CI, we use the special step `persist_to_workspace`;
    however, this capability is common to pipeline-based workflows:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们构建了我们的应用程序，我们需要持久化工作区，以便其他作业可以使用它。在 Circle CI 中，我们使用特殊的步骤 `persist_to_workspace`；然而，这种能力在基于管道的工作流程中是通用的：
- en: '![](img/93745586-831c-4ac4-a792-f60b688bd807.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/93745586-831c-4ac4-a792-f60b688bd807.png)'
- en: Testing
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试
- en: We also mentioned the fact that we need consistency and that, if we are deploying
    continuously, we need to have a good solid testing suite, which replaces almost
    all our manual testing. I am not saying there is no place for manual testing as
    there is always a use for exploratory testing but when we are deploying continuously,
    we need to automate all of this. Even if you are adding manual testing into your
    process, it will be most likely running as an asynchronous process complimentary
    to your build pipeline not as a gate to it.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还提到，我们需要一致性，如果我们持续部署，我们需要有一个良好的稳定的测试套件，它几乎取代了我们的所有手动测试。我并不是说没有手动测试的地方，因为探索性测试总有用途，但当我们持续部署时，我们需要自动化所有这些。即使你在流程中添加手动测试，它也更有可能作为一个与构建管道互补的异步过程运行，而不是作为它的关卡。
- en: The testing section of the configuration runs our unit tests as we saw in [Chapter
    4](2baaa0cf-170d-4d7f-8449-b26f20a9bbab.xhtml), *Testing*. With the following
    configuration, we first need to attach the workspace that we created in the build
    step. The reason for this is that we do not need to check out the repository again.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 配置中的测试部分运行我们的单元测试，正如我们在[第4章](2baaa0cf-170d-4d7f-8449-b26f20a9bbab.xhtml)“测试”中看到的。使用以下配置，我们首先需要附加我们在构建步骤中创建的工作区。这样做的原因是我们不需要再次检出仓库。
- en: '[PRE38]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The second thing we need to do is to install the dependencies, Circle CI requires
    the output of the tests to be in JUnit format for presentation. To enable this,
    we can fetch the `go-junit-report` package, which can take the output of our tests
    and convert them into JUnit format.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做的第二件事是安装依赖项，Circle CI要求测试输出以JUnit格式呈现。为了启用这一点，我们可以获取`go-junit-report`包，它可以将我们的测试输出转换为JUnit格式。
- en: To run the tests, we have to do something slightly different, if we just ran
    our unit tests and piped them into the `go-junit-report` command, then we would
    lose the output. Reading the command in reverse order, we run our unit tests and
    output, `make unit | tee ${TEST_RESULTS}/go-test.out`; the `tee` command takes
    the input piped to it and writes to both the output file specified as well as
    to the `stdout` file. We can then use trap, which executes a command when an exit
    code is matched from another command. In our instance, if the unit tests exit
    with a status code 0 (normal condition), then we execute the `go-junit-report`
    command. Finally, we write our test results for Circle CI to be able to interpret
    them using the `store_test_results` step.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行测试，我们必须做一些稍微不同的事情，如果我们只是运行了单元测试并将它们管道化到`go-junit-report`命令中，那么我们会丢失输出。按相反的顺序读取命令，我们运行单元测试和输出，`make
    unit | tee ${TEST_RESULTS}/go-test.out`；`tee`命令将输入管道化到它并写入指定的输出文件以及`stdout`文件。然后我们可以使用trap，它在另一个命令匹配退出代码时执行命令。在我们的例子中，如果单元测试以状态码0（正常情况）退出，那么我们执行`go-junit-report`命令。最后，我们写入测试结果以便Circle
    CI能够使用`store_test_results`步骤来解释它们。
- en: Benchmarking
  id: totrans-267
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基准测试
- en: Benchmarking is an important feature for our CI pipeline; we need to understand
    when the performance of our application degrades. To do this, we are going to
    both run our benchmark tests and use the handy tool **benchcmp**, which compares
    two runs of tests. The standard version of benchcmp only outputs the difference
    between two test runs. While this is fine for comparison, it does not give us
    the capability to fail our CI job should this difference be within a certain threshold.
    To enable this capability, I have forked the benchcmp tool and added `flag-tollerance=[FLOAT]`.
    If any of the benchmarks change +/- the given tolerance, then benchcmp exits with
    status code 1, allowing us to fail the job and investigate why this change has
    taken place. For this to work, we need to keep the previous benchmark data available
    for comparison, so we can use the caching feature to store the last run data.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 基准测试是我们CI管道的一个重要特性；我们需要了解我们的应用程序性能何时会下降。为此，我们将运行基准测试并使用方便的工具**benchcmp**，它比较两次测试运行。benchcmp的标准版本仅输出两次测试运行之间的差异。虽然这对于比较来说是不错的，但它并不提供在差异在一定阈值内时使我们的CI作业失败的能力。为了启用这种能力，我已经分叉了benchcmp工具并添加了`flag-tollerance=[FLOAT]`。如果任何基准测试变化±给定的容差，那么benchcmp将以状态码1退出，允许我们失败作业并调查这种变化发生的原因。为了使这可行，我们需要保留以前的基准数据以供比较，因此我们可以使用缓存功能来存储最后运行的测试数据。
- en: Static code analysis
  id: totrans-269
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 静态代码分析
- en: Static code analysis is a fast and efficient way to check for any problems in
    our source code automatically. In our example, we will run two different static
    code analysis tools, the first is **megacheck** by Dominik Honnef, which examines
    the code for common problems such as misuse of the standard library, concurrency
    issues, and many more problems.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 静态代码分析是一种快速高效的方法，可以自动检查源代码中可能存在的问题。在我们的例子中，我们将运行两个不同的静态代码分析工具，第一个是由 Dominik
    Honnef 开发的 **megacheck**，它检查代码中常见的错误，例如标准库的误用、并发问题以及许多其他问题。
- en: Second is **SafeSQL** from the Stripe team. SafeSQL runs through our code and
    looks for uses of the SQL package. It then examines the ones looking for vulnerabilities
    such as incorrectly constructed queries, which may be open to SQL injection.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个是来自 Stripe 团队的 **SafeSQL**。SafeSQL 遍历我们的代码，寻找 SQL 包的使用情况。然后，它检查那些看起来有漏洞的查询，例如不正确构造的查询，这些查询可能容易受到
    SQL 注入的影响。
- en: 'Lastly, we will be checking our code, including the tests for unhandled errors,
    for example, you have the following function:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将检查我们的代码，包括对未处理错误的测试，例如，你有一个以下函数：
- en: '[PRE39]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'When invoking a method like this, the error object can be thrown away and not
    handled:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 当调用此类方法时，错误对象可以被丢弃而不被处理：
- en: '[PRE40]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Unhandled errors are more often found in tests rather than the main body of
    code; however, even in tests, this could introduce a bug due to unhandled behavior,
    `errcheck` runs through the code looking for instances like this and reports an
    error when found and fails the build:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 未处理的错误通常在测试中而不是代码的主体中找到；然而，即使在测试中，这也可能由于未处理的行为引入错误，`errcheck` 会遍历代码寻找此类实例，并在找到时报告错误并失败构建：
- en: '[PRE41]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Static check invokes the megacheck linter which runs `staticcheck` a static
    code analysis tool which helps to detect bugs, Go simple which identifies areas
    of the source code which should be improved by re-writing in a simpler way and
    unused which identifies unused constants, types, and functions. The first checker
    is designed to spot bugs; however, the remaining three are concerned with your
    application life cycle management.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 静态检查调用 megacheck 检查器，该检查器运行 `staticcheck`，这是一个静态代码分析工具，有助于检测错误，Go simple 识别应该通过以更简单的方式重写来改进的源代码区域，以及
    unused 识别未使用的常量、类型和函数。第一个检查器旨在发现错误；然而，其余三个关注你的应用程序生命周期管理。
- en: Clean code is essential to bug-free code; the easier and the simpler your code
    is the more the reduced likelihood that you have logic bugs. Why? Because the
    code is easier to understand and since you spend more of your time reading code
    than writing, it makes sense to optimize for readability. Static code analysis
    should not be a replacement for the code review. However, these tools allow you
    to focus on logic flaws rather than semantics. Integrating this into your continuous
    integration pipeline acts as a gatekeeper to the sanity of your codebase, the
    checks run incredibly quickly and in my humble opinion are an essential step.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 清洁的代码对于无错误代码至关重要；你的代码越简单、越简单，逻辑错误的概率就越低。为什么？因为代码更容易理解，而且你花在阅读代码上的时间比写代码的时间多，所以优化可读性是有意义的。静态代码分析不应取代代码审查。然而，这些工具允许你专注于逻辑错误而不是语义。将它们集成到你的持续集成管道中，充当代码库健全性的守门人，检查运行得非常快，在我看来，这是一个必不可少的步骤。
- en: '[https://github.com/dominikh/go-tools/tree/master/cmd/megacheck](https://github.com/dominikh/go-tools/tree/master/cmd/megacheck)'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/dominikh/go-tools/tree/master/cmd/megacheck](https://github.com/dominikh/go-tools/tree/master/cmd/megacheck)'
- en: SafeSQL from the Stripe team is a static code analysis tool which protects against
    SQL injections. It attempts to find problems with usage of the `database/sql`
    package.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 来自 Stripe 团队的 SafeSQL 是一个静态代码分析工具，用于防止 SQL 注入。它试图找出对 `database/sql` 包使用不当的问题。
- en: '[https://github.com/stripe/safesql](https://github.com/stripe/safesql)'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/stripe/safesql](https://github.com/stripe/safesql)'
- en: Integration tests
  id: totrans-283
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集成测试
- en: Then, there are integration tests. In this example, we are again using GoDog
    BDD; however, when we are running on Circle CI, we need to modify our setup a
    little because of the way that Circle deals with security for Docker. The first
    steps are again to attach the workspace, including the binary that we built in
    a previous step; then we can get the dependencies which are only the GoDog application.
    The `setup_remote_docker` command requests a Docker instance from Circle CI. The
    current build is running in a Docker container; however, because of the security
    configuration, we cannot access the Docker host, which is currently running the
    current build.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，还有集成测试。在这个例子中，我们再次使用GoDog BDD；然而，当我们运行在Circle CI上时，我们需要稍微修改我们的设置，因为Circle处理Docker安全的方式。第一步仍然是附加工作区，包括我们在前一步骤中构建的二进制文件；然后我们可以获取依赖项，这些依赖项仅是GoDog应用程序。`setup_remote_docker`命令从Circle
    CI请求一个Docker实例。当前的构建正在Docker容器中运行；然而，由于安全配置，我们无法访问当前构建正在运行的Docker主机。
- en: '[PRE42]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The section of the Makefile for running on CI is quite a bit more complex than
    when we run it on our local machine. We need this modification because we need
    to copy the source code and install the `godog` command to a container, which
    will be running on the same network as the stack we start with Docker compose.
    When we are running locally, this is not necessary as we have the capability to
    connect to the network. This access is forbidden on Circle CI and most likely
    other shared continuous integration environments.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在CI上运行的Makefile部分比在我们本地机器上运行时要复杂得多。我们需要这个修改，因为我们需要将源代码和安装`godog`命令复制到容器中，该容器将在与Docker
    compose启动的堆栈相同的网络上运行。当我们本地运行时，这并不是必要的，因为我们有连接到网络的能力。在Circle CI以及大多数其他共享的持续集成环境中，这种访问是被禁止的。
- en: '[PRE43]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: We build our temporary container, which contains the current directory and adds
    the `godog` dependency. We can then start the stack as normal by running `docker-compose
    up` and then the `godog` command.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建我们的临时容器，它包含当前目录并添加了`godog`依赖。然后我们可以通过运行`docker-compose up`和`godog`命令来正常启动堆栈。
- en: Integration tests on continuous delivery are an essential gate before we deploy
    to production. We also want to be able to test our Docker image to ensure that
    the startup process is functioning correctly and that we have tested all our assets.
    When we looked at integration tests in [Chapter 4](2baaa0cf-170d-4d7f-8449-b26f20a9bbab.xhtml),
    *Testing*, we were only running the application, which is fine for our development
    process--it gives us the happy medium of quality and speed. When it comes to building
    our production images, however, this compromise is not acceptable, and therefore,
    we need to make some modifications to the development process to ensure that we
    include the production image in our test plan.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 在持续交付上的集成测试在我们部署到生产环境之前是一个必不可少的关卡。我们还想能够测试我们的Docker镜像，以确保启动过程运行正确，并且我们已经测试了所有我们的资产。当我们查看[第4章](2baaa0cf-170d-4d7f-8449-b26f20a9bbab.xhtml)中的集成测试，“测试”时，我们只是运行了应用程序，这对于我们的开发过程来说是可以接受的——它给我们提供了质量和速度之间的快乐平衡。然而，当我们构建我们的生产镜像时，这种妥协是不可接受的，因此，我们需要对开发过程进行一些修改，以确保我们将生产镜像包含在我们的测试计划中。
- en: Deployment
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署
- en: Since we have all our application code build tested and packaged, it is time
    to think about deploying this into production. We need to start thinking about
    our infrastructure as immutable, that is, we will not make changes to the infrastructure
    but replace it. The level with which this occurs can be multiple. For example,
    we have our container scheduler, which only runs the containers. When we deploy
    an update to our application binary, we are replacing a container on the scheduler
    not refreshing the application in it. Containers give us one level of immutability,
    the other is the scheduler itself. To operate successful continuous delivery,
    the setup of this facet also needs to be automated, we need to think of our infrastructure
    as code.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经构建、测试并打包了所有应用程序代码，现在是时候考虑将其部署到生产环境中了。我们需要开始考虑我们的基础设施为不可变，也就是说，我们不会更改基础设施，而是替换它。这种发生的级别可以是多个。例如，我们有我们的容器调度器，它只运行容器。当我们更新我们的应用程序二进制文件时，我们是在调度器上替换容器而不是刷新其中的应用程序。容器给我们提供了一个不可变级别，另一个级别是调度器本身。为了成功进行持续交付，这个方面的设置也需要自动化，我们需要将我们的基础设施视为代码。
- en: For our application, we are splitting the infrastructure up into separate parts.
    We have a main infrastructure repository, which creates the VPC, S3 buckets used
    by deployments and creates an Elastic Beanstalk instance for our messaging platform
    NATS.io. We also have Terraform config for each of the services. We could create
    one massive Terraform config as Terraform replaces or destroys infrastructure,
    which has changed; however, there are several reasons why we would not want this.
    The first is that we want to be able to break down our infrastructure code into
    small parts in the same way we break up our application code; the second is due
    to the way Terraform works. To ensure the consistency of the state, we can only
    run a single operation against the infrastructure code at any one time. Terraform
    obtains a lock when it runs to ensure that you cannot run it multiple times at
    once. If we consider a situation where there are many microservices and that these
    services are being continuously deployed, then having a single deployment which
    is single threaded becomes a terrible thing. When we decompose the infrastructure
    configuration and localize it with each service, then this no longer becomes a
    problem. One problem with this distributed configuration is that we still need
    a method of accessing resource information in the master repository. In our case,
    we are creating the main VPC in this repository, and we need the details to be
    able to connect our microservices to it. Thankfully, Terraform manages rather
    pleasantly using the concept of remote state.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的应用程序，我们将基础设施拆分成单独的部分。我们有一个主要的基础设施仓库，它创建VPC、部署使用的S3存储桶，并为我们的消息平台NATS.io创建一个Elastic
    Beanstalk实例。我们还有每个服务的Terraform配置。我们可以创建一个巨大的Terraform配置，因为Terraform会替换或销毁已更改的基础设施，然而，有几个原因我们不希望这样做。首先，我们希望能够将基础设施代码分解成小块，就像我们分解应用程序代码一样；第二个原因是由于Terraform的工作方式。为了确保状态的一致性，我们一次只能对基础设施代码运行一个操作。Terraform在运行时获取锁，以确保您不能同时运行多次。如果我们考虑一个有多个微服务并且这些服务正在持续部署的情况，那么有一个单线程的单一部署就变得非常糟糕。当我们分解基础设施配置并将其与每个服务本地化时，这个问题就不再存在了。这个分布式配置的一个问题是，我们仍然需要一个方法来访问主仓库中的资源信息。在我们的案例中，我们在这个仓库中创建主要VPC，我们需要详细信息来连接我们的微服务。幸运的是，Terraform使用远程状态的概念管理得相当愉快。
- en: '[PRE44]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'We can configure our master Terraform config to use remote state, which we
    can then access from the search Terraform config using the remote state data element:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以配置我们的主Terraform配置使用远程状态，然后我们可以使用远程状态数据元素从搜索Terraform配置中访问它：
- en: '[PRE45]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: When all the previous steps in the build process complete, we deploy this to
    AWS automatically. This way we always deploy every time a new instance of the
    master branch builds.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 当构建过程中的所有前一步骤完成时，我们会自动将其部署到AWS。这样，每次主分支构建新实例时，我们都会进行部署。
- en: Smoke tests
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 烟雾测试
- en: Smoke testing the application post deploy is an essential step in continuous
    delivery we need to ensure that the application is functioning correctly and that
    nothing has gone wrong in the build and deploy steps. In our example, we are simply
    checking that we can reach the health endpoint. However, a smoke test can be as
    simple or as complex as required. Many organizations run more detail checks, which
    confirm that the core integration to the deployed system is correct and functioning.
    The smoke tests are conducted as either a codified test re-using many of the steps
    in the GoDog integration tests or a specialized test. In our example, we are simply
    checking the health endpoint for the search service.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署后对应用程序进行烟雾测试是持续交付中一个必不可少的步骤，我们需要确保应用程序运行正常，并且在构建和部署步骤中没有出错。在我们的例子中，我们只是检查我们能否到达健康端点。然而，烟雾测试可以像所需的那样简单或复杂。许多组织运行更详细的检查，这些检查确认了与已部署系统的核心集成是正确且正常工作的。烟雾测试是以编码测试的形式进行的，它重用了GoDog集成测试中的许多步骤，或者是一个专门的测试。在我们的例子中，我们只是检查搜索服务的健康端点。
- en: '[PRE46]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: In our application, we can run this test because the endpoint is public. When
    an endpoint is not public, testing becomes more complicated, and we need to check
    the integration by calling through a public endpoint.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的应用程序中，我们可以运行这个测试，因为端点是公开的。当一个端点不是公开的，测试就会变得更加复杂，我们需要通过公开端点调用以检查集成。
- en: One of the considerations for end-to-end testing is that you need to be careful
    of polluting the data inside the production database. A complimentary or even
    alternative approach is to ensure that your system has extensive logging and monitoring.
    We can set up dashboards and alerts, which actively check for user errors. When
    an issue occurs post deploy, we can investigate the problem, and if necessary,
    rollback to a previous version of the build with a known good state.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 端到端测试的考虑因素之一是，你需要小心不要污染生产数据库中的数据。一种补充或替代的方法是确保你的系统有广泛的日志记录和监控。我们可以设置仪表板和警报，这些仪表板和警报会主动检查用户错误。当部署后发生问题时，我们可以调查问题，并在必要时回滚到具有已知良好状态的构建的先前版本。
- en: Monitoring/alerting
  id: totrans-302
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控/警报
- en: When the application is running, we need to be sure of the health and status
    of the application. Monitoring is an incredibly important facet of the continuous
    deployment life cycle. If we are deploying automatically, we need to understand
    how our application is performing and how this differs from the previous release.
    We have seen how we can use StatsD to emit data about our service to a backend
    such as Prometheus or a managed application such as Datadog. Should our recent
    deploy exhibit anomalous behavior, we are alerted about this and from there we
    can act to help identify the source of the problem, intermittently rolling back
    if necessary or modifying our alerts as our server may just be doing more work.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 当应用程序运行时，我们需要确保应用程序的健康状况和状态。监控是持续部署生命周期中一个极其重要的方面。如果我们正在自动部署，我们需要了解我们的应用程序表现如何，以及这与之前的版本有何不同。我们看到了如何使用StatsD将关于我们服务的数据发射到后端，如Prometheus或像Datadog这样的托管应用程序。如果我们的最近部署表现出异常行为，我们会收到警报，然后我们可以采取行动来帮助确定问题的根源，必要时间歇性地回滚，或者根据服务器可能正在做更多工作来修改我们的警报。
- en: '[PRE47]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Again, using the concepts of infrastructure as code, we can provision these
    monitors at build time using Terraform. While errors are useful for monitoring,
    it is also important to not forget timing data. An error tells you that something
    is going wrong; however, with the clever use of timing information in the service,
    we can learn that something is about to go wrong.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，使用基础设施即代码的概念，我们可以在构建时使用Terraform来配置这些监控器。虽然错误对于监控很有用，但也不应忘记时间数据。错误告诉你某件事出了问题；然而，通过在服务中巧妙地使用时间信息，我们可以了解到某件事即将出错。
- en: Complete workflow
  id: totrans-306
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 完整的工作流程
- en: Assuming all is functioning well, we should have a successful build, and the
    UI in our build environment should show all steps passing. Remember our warning
    from the beginning of this chapter--when your build fails, you need to make it
    your primary objective to fix it; you never know when you are going to need it.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 假设一切运行良好，我们应该有一个成功的构建，并且我们构建环境中的UI应该显示所有步骤都通过。记住我们本章开头的一个警告——当你的构建失败时，你需要将其作为首要目标来修复它；你永远不知道你什么时候会需要它。
- en: '![](img/345f20fb-eaf2-4666-9081-45a2eb830e63.png)'
  id: totrans-308
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/345f20fb-eaf2-4666-9081-45a2eb830e63.png)'
- en: Summary
  id: totrans-309
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have learned that it need not be an arduous task to set
    up continuous integration and deployment for your application, and in fact, this
    is essential to the health and success of your application. We have built on all
    the concepts covered in the previous chapters, and while the final example is
    somewhat simple, it has all the constituent parts for you to build into your applications
    to ensure that you spend your time developing new features and not fixing production
    issues or wasting time repetitively and riskily deploying application code. Like
    all aspects of our development, we should practice and test this process. Before
    releasing continuous delivery to your production workflow, you need to ensure
    that you can deal with problems such as hot fixing and rolling back a release.
    This activity should be completed across teams and depending on your process for
    out-of-hours support should also involve any support staff. A well-practiced and
    functioning deployment process gives you the confidence that when an issue occurs,
    and it most likely will, you can comfortably and confidently deal with it.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: I hope that by working through this book, you now have a greater understanding
    of most of the things you need to build microservices with go successfully. The
    one thing I cannot teach is the experience that you need to find out for yourself
    by getting out there and performing. I wish you luck on this journey, and the
    one thing that I have learned from my career is that you never regret putting
    in the time and effort to learn these techniques. I am sure you will be hugely
    successful.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
