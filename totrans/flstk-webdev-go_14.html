<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer115">
<h1 class="chapter-number" id="_idParaDest-172"><a id="_idTextAnchor278"/>14</h1>
<h1 id="_idParaDest-173"><a id="_idTextAnchor279"/>Cloud Deployment</h1>
<p>In this chapter, we will learn about cloud deployment, specifically using AWS as the cloud provider. We will look at some of the infrastructure services provided by AWS and how to use them. We will learn about using and writing code for creating the different AWS infrastructure services using an open source tool called Terraform. Understanding the cloud and how cloud deployment works has become a necessity for developers nowadays rather than an exception. Gaining a good understanding of the different aspects of cloud deployment will allow you to think outside the box about how your application should run in <span class="No-Break">the cloud.</span></p>
<p>Upon completion of this chapter, we will have learned about the following <span class="No-Break">key topics:</span></p>
<ul>
<li>Learning basic <span class="No-Break">AWS infrastructure</span></li>
<li>Understanding and <span class="No-Break">using Terraform</span></li>
<li>Writing Terraform for local and <span class="No-Break">cloud deployment</span></li>
<li>Deploying to AWS Elastic <span class="No-Break">Container Service</span></li>
</ul>
<p>The end goal of this chapter is to provide you with some knowledge about the cloud and how to perform certain basic operations for deploying applications to <span class="No-Break">the cloud.</span></p>
<h1 id="_idParaDest-174"><a id="_idTextAnchor280"/>Technical requirements</h1>
<p>All the source code explained in this chapter can be checked out <span class="No-Break">at </span><a href="https://github.com/PacktPublishing/Full-Stack-Web-Development-with-Go/tree/main/chapter14"><span class="No-Break">https://github.com/PacktPublishing/Full-Stack-Web-Development-with-Go/tree/main/chapter14</span></a><span class="No-Break">.</span></p>
<p>This chapter uses AWS services, so you are expected to have an AWS account. AWS provides a Free Tier for new user registration; more information can be found <span class="No-Break">at </span><a href="https://aws.amazon.com/free"><span class="No-Break">https://aws.amazon.com/free</span></a><span class="No-Break">.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">Using any kind of AWS services will incur a cost. Please read and inform yourself before using the service. We highly recommend reading what is available on the Free Tier on the <span class="No-Break">AWS website.</span></p>
<h1 id="_idParaDest-175"><a id="_idTextAnchor281"/>AWS refresher</h1>
<p><strong class="bold">AWS</strong> stands for <strong class="bold">Amazon Web Services</strong> and belongs to Amazon, which provides the <a id="_idIndexMarker472"/>e-commerce platform <a href="http://amazon.com.au">amazon.com.au</a>. AWS provides services that allow organizations to run their applications in a complete infrastructure without owning any of the <span class="No-Break">hardware required.</span></p>
<p>The AWS brand is a household name for developers and almost all developers have some basic direct/indirect exposure to using AWS tools or its services. In this section, we will look at some services provided by AWS as <span class="No-Break">a refresher.</span></p>
<p>The question that comes to our mind is, why bother using services such as AWS? <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.1</em> summarizes the answer nicely. AWS provides services that are available across different continents of the world and ready to be used by organizations to fulfill their needs. Imagine that your organization has customers across different continents. How much easier would it be to run your application on different continents without having the burden of investing in hardware on each of <span class="No-Break">those continents?</span></p>
<div>
<div class="IMG---Figure" id="_idContainer105">
<img alt="Figure 14.1: Global AWS Regions" height="456" src="image/Figure_14.01_B18295.jpg" width="624"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.1: Global AWS Regions</p>
<p>In the next section, we will look at the basic service provided by AWS called AWS EC2, which provides <span class="No-Break">computing resources.</span></p>
<h2 id="_idParaDest-176"><a id="_idTextAnchor282"/>Amazon Elastic Compute Cloud</h2>
<p>Amazon <strong class="bold">Elastic Compute Cloud</strong> (<strong class="bold">EC2</strong>) is the <a id="_idIndexMarker473"/>basic computing resource for developers to run their applications on. You can think of EC2 as a virtual computer on Amazon infrastructure somewhere on the internet that runs your application. You can select from a number of computer configurations that you want to run your application on, from a small 512-MB memory to a gigantic 384-GB memory computer with different configurations of storage. <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.2</em> shows the Instance Type Explorer<a id="_idIndexMarker474"/> that can be accessed using the following <span class="No-Break">URL: </span><a href="https://aws.amazon.com/ec2/instance-explorer/"><span class="No-Break">https://aws.amazon.com/ec2/instance-explorer/</span></a><span class="No-Break">.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer106">
<img alt="Figure 14.2: Instance Type Explorer" height="391" src="image/Figure_14.02_B18295.jpg" width="572"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.2: Instance Type Explorer</p>
<p>In the next section, we will look at another AWS resource related to computing that is super important for applications, and that <span class="No-Break">is storage.</span></p>
<p><a id="_idTextAnchor283"/><span class="No-Break">Storage</span></p>
<p>Computing power is great for running applications, but applications require long-term storage to store data such as log files and databases. There are a number of different kinds of storage provided by AWS. For example, <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.3</em> shows the <strong class="bold">Elastic Block Store</strong> (<strong class="bold">EBS</strong>), which<a id="_idIndexMarker475"/> is a block storage service. This block storage is like the normal storage that you have on your local computer and is offered as a hard drive or <a id="_idIndexMarker476"/>a <strong class="bold">solid-state </strong><span class="No-Break"><strong class="bold">drive</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">SSD</strong></span><span class="No-Break">).</span></p>
<div>
<div class="IMG---Figure" id="_idContainer107">
<img alt="Figure 14.3: EBS" height="203" src="image/Figure_14.03_B18295.jpg" width="577"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.3: EBS</p>
<p>The amazing thing about having this kind of storage is its elastic nature – what this means is you can increase or decrease the size of storage anytime you need without the worry of adding new hardware. Imagine what would happen if you were running out of hard drive space on your local computer. You would need to buy a new hard drive and install and configure it, none of which is required when you use the AWS storage service. Attaching storage to the EC2 instance of your choice enables your application to run and store data in <span class="No-Break">the cloud.</span></p>
<p>We will look at another AWS service that is as important as the one that we have just <span class="No-Break">discussed: networking<a id="_idTextAnchor284"/>.</span></p>
<h2 id="_idParaDest-177"><a id="_idTextAnchor285"/>Virtual Private Cloud</h2>
<p>Now that your application is running in its own virtual computer, complete with storage, the next question is how we configure a network in AWS so that users can access the application. This is called<a id="_idIndexMarker477"/> a <strong class="bold">Virtual Private Cloud</strong> (<strong class="bold">VPC</strong>). Think about a VPC as your own network setup, but without cables – everything is configured and run using software. <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.4</em> shows the powerful capability of a VPC, enabling you to connect different networks configured in <span class="No-Break">different Regions.</span></p>
<p>Think of a Region as the physical location where AWS stores its hardware, and if you run your applications in different physical locations, you are able to connect them using <span class="No-Break">a VPC.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer108">
<img alt="Figure 14.4: Virtual Private Networking" height="307" src="image/Figure_14.04_B18295.jpg" width="625"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.4: Virtual Private Networking</p>
<p>You have full control to configure the network of each Region your application is running on, how these Regions communicate with your own network, and how your application will be accessible via the <span class="No-Break">public internet.</span></p>
<p>In the next section, we will look at another important service that a lot of applications require which is storing data in <span class="No-Break">a database.</span><a id="_idTextAnchor286"/></p>
<h2 id="_idParaDest-178"><a id="_idTextAnchor287"/>Database storage</h2>
<p>No matter what kind of applications you are building, you will require a database to store data, and this requires a database server to be running. AWS provides different database services ranging from those that store small amounts of data to massively distributed databases across different continents. One of these services is called Amazon <strong class="bold">Relational Database Service</strong> (<strong class="bold">RDS</strong>), a managed service to set up, scale, and <span class="No-Break">operate databases.</span></p>
<p>The databases that RDS can support are MySQL, PostgreSQL, MariaDB, Oracle, and SQL Server. <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.5</em> outlines the features provided <span class="No-Break">by RDS.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer109">
<img alt="Figure 14.5: RDS" height="138" src="image/Figure_14.05_B18295.jpg" width="439"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.5: RD<a id="_idTextAnchor288"/>S</p>
<h2 id="_idParaDest-179"><a id="_idTextAnchor289"/>Elastic Container Service</h2>
<p>In <a href="B18295_13.xhtml#_idTextAnchor261"><span class="No-Break"><em class="italic">Chapter 13</em></span></a>, <em class="italic">Dockerizing an Application</em>, we learned how to create Docker images to package our application so it can run as a container. Packaging applications as Docker images allows us to run our application in any kind of environment, from a local machine to the cloud. AWS provides<a id="_idIndexMarker478"/> a related service called <strong class="bold">Elastic Container </strong><span class="No-Break"><strong class="bold">Service</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">ECS</strong></span><span class="No-Break">).</span></p>
<p>ECS helps us to deploy, manage, and scale out applications that have been built as containers. A key scaling feature of ECS is the ability to scale your application using the Application Auto Scaling capability. This feature allows developers to scale applications based on certain conditions, such as <span class="No-Break">the following:</span></p>
<ul>
<li><strong class="bold">Step scaling</strong>: This <a id="_idIndexMarker479"/>means scaling an application based on the breach of <span class="No-Break">an alarm</span></li>
<li><strong class="bold">Scheduled scaling</strong>: This is <a id="_idIndexMarker480"/>scaling based on a <span class="No-Break">predetermined t<a id="_idTextAnchor290"/>ime</span></li>
</ul>
<h2 id="_idParaDest-180"><a id="_idTextAnchor291"/>AWS tools</h2>
<p>AWS provides <a id="_idIndexMarker481"/>different ways to <a id="_idIndexMarker482"/>use its services, including a web user interface and the <strong class="bold">command-line interface</strong> (<strong class="bold">CLI</strong>). The main page of the web UI can be seen in <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.6</em>. You will need to register for an AWS account first before using any of the <span class="No-Break">AWS tools.</span></p>
<p>The UI is a very good place to start exploring the different services and go through some sample tutorials to get a better understanding of <span class="No-Break">each service.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer110">
<img alt="Figure 14.6: AWS web UI" height="304" src="image/Figure_14.06_B18295.jpg" width="625"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.6: AWS web UI</p>
<p>The other AWS tool that is used to interact with the services is the CLI, which needs to be installed locally (<a href="https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.xhtml">https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.xhtml</a>). The CLI makes it easier to interact with the AWS services than the web UI. If you have installed it locally, when you run <strong class="source-inline">aws</strong> from your terminal, you will see the <span class="No-Break">following output:</span></p>
<pre class="console">
usage: aws [options] &lt;command&gt; &lt;subcommand&gt; [&lt;subcommand&gt; ...] [parameters]
To see help text, you can run:
  aws help
  aws &lt;command&gt; help
  aws &lt;command&gt; &lt;subcommand&gt; help
aws: error: the following arguments are required: command</pre>
<p>In the next section, we will look at how to use some of the features described here to deploy our application <span class="No-Break">in<a id="_idTextAnchor292"/> AWS.</span></p>
<h1 id="_idParaDest-181"><a id="_idTextAnchor293"/>Understanding and using Terraform</h1>
<p>In this section, we will look at another tool that makes it easier for us to work with AWS services: Terraform. In the previous section, we learned that AWS provides tools of its own, which is great for small tasks, but once you start combining the different services it becomes harder to <span class="No-Break">use them.</span></p>
<h2 id="_idParaDest-182"><a id="_idTextAnchor294"/>What is Terraform?</h2>
<p>Terraform (<a href="https://www.terraform.io/">https://www.terraform.io/</a>) is an<a id="_idIndexMarker483"/> open source tool that provides <strong class="bold">infrastructure as code</strong> (<strong class="bold">IaC</strong>). What this means is you write code to define what kind of <a id="_idIndexMarker484"/>service <a id="_idIndexMarker485"/>you want to use and how you want to use it, and this way, you can combine and link the different services together as a single piece. This makes it easy for you as a developer to run and destroy infrastructure as a unit instead of <span class="No-Break">separate fragments.</span></p>
<p>The other benefit that Terraform provides is the ability to version control the infrastructure code like normal application code, where it goes through the normal review process, including the peer review process and also unit testing, before deploying the infrastructure to production. With this, your application and infrastructure will now go through the same development process, which <span class="No-Break">is tr<a id="_idTextAnchor295"/>ackable.</span></p>
<h2 id="_idParaDest-183"><a id="_idTextAnchor296"/>Installing Terraform</h2>
<p>The Terraform installation<a id="_idIndexMarker486"/> process is straightforward: you can find a complete set of instructions for your operating system in the HashiCorp documentation <span class="No-Break">at </span><a href="https://www.terraform.io/downloads"><span class="No-Break">https://www.terraform.io/downloads</span></a><span class="No-Break">.</span></p>
<p>For example, when writing this book we are using an Ubuntu-based distro, so we download the AMD64 binary from <a href="https://releases.hashicorp.com/terraform/1.3.0/terraform_1.3.0_linux_amd64">https://releases.hashicorp.com/terraform/1.3.0/terraform_1.3.0_linux_amd64</a><strong class="source-inline">.zip</strong> and include the Terraform directory into our <strong class="source-inline">PATH</strong>, as in the following snippet. The directory added to the <strong class="source-inline">PATH</strong> variable environment is a temporary solution for the terminal that you are using. In order to store it, you need to put it as part of your shell script (for Linux, if you are using Bash, you can add this to your <strong class="source-inline">.</strong><span class="No-Break"><strong class="source-inline">bashrc</strong></span><span class="No-Break"> file):</span></p>
<pre class="console">
export PATH=$PATH:/home/user/Downloads/</pre>
<p>To test whether the installation was successful, open the terminal and <span class="No-Break">execute </span><span class="No-Break"><strong class="source-inline">Terraform</strong></span><span class="No-Break">:</span></p>
<pre class="console">
Terraform</pre>
<p>You should get the <span class="No-Break">following output:</span></p>
<pre class="console">
Usage: terraform [global options] &lt;subcommand&gt; [args]
The available commands for execution are listed below.
The primary workflow commands are given first, followed by
less common or more advanced commands.
Main commands:
  init          Prepare your working directory for other
                commands
  ...
All other commands:
  console       Try Terraform expressions at an interactive
                command prompt
  fmt           Reformat your configuration in the standard
                style
  ...</pre>
<p>For detailed information on <a id="_idIndexMarker487"/>how to install Terraform for your environment, <span class="No-Break">see </span><a href="https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli"><span class="No-Break">https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli</span></a><span class="No-Break">.</span></p>
<p>Now that we have completed the Terraform installation, we will learn how to use some of the basic commands available in Terraform. The commands will enable you to jumpstart your journey into the world of <span class="No-Break">cloud <a id="_idTextAnchor297"/>deployment.</span></p>
<h1 id="_idParaDest-184"><a id="_idTextAnchor298"/>Terraform basic commands</h1>
<p>In this section, we will learn some basic Terraform commands that are often used when writing code. We will also examine concepts that are relevant <span class="No-Break">to <a id="_idTextAnchor299"/>Terraform.</span></p>
<h2 id="_idParaDest-185"><a id="_idTextAnchor300"/>The init command</h2>
<p>Every time we start<a id="_idIndexMarker488"/> writing<a id="_idIndexMarker489"/> Terraform code, the first command that we run is <strong class="source-inline">terraform init</strong>. This command prepares all the necessary dependencies required to run the code locally. The command performs the <span class="No-Break">following steps:</span></p>
<ol>
<li>Downloads all the necessary modules that are used in <span class="No-Break">the code.</span></li>
<li>Initializes plugins that are used in the code. For example, if the code is deployed on AWS it will download the <span class="No-Break">AWS plugins.</span></li>
<li>Creates a file called a lock file that registers the different dependencies and versions that are used by <span class="No-Break">the code.</span></li>
</ol>
<p>To gain a better understanding of the previous steps, let’s run the command. Open the terminal and change to the <strong class="source-inline">chapter14/simple</strong> directory, and execute the <span class="No-Break">following command:</span></p>
<pre class="console">
terraform init</pre>
<p>You will see an output <span class="No-Break">as follows:</span></p>
<pre class="console">
Initializing the backend...
Initializing provider plugins...
- Finding kreuzwerker/docker versions matching "~&gt; 2.16.0"...
- Installing kreuzwerker/docker v2.16.0...
- Installed kreuzwerker/docker v2.16.0 (self-signed, key ID BD080C4571C6104C)
...</pre>
<p>Once the <strong class="source-inline">init</strong> process <a id="_idIndexMarker490"/>is <a id="_idIndexMarker491"/>complete, your directory will look like <span class="No-Break">the following:</span></p>
<pre class="console">
.
├── main.tf
├── .terraform
│   └── providers
│       └── registry.terraform.io
│           └── kreuzwerker
│               └── docker
│                   └── 2.16.0
│                       └── linux_amd64
│                           ├── CHANGELOG.md
│                           ├── LICENSE
│                           ├── README.md
│                           └── terraform-provider-docker_v2.16.0
├── .terraform.lock.hcl
└── versions.tf</pre>
<p>The <strong class="source-inline">.terraform</strong> directory contains the dependencies that are specified in the code. In this<a id="_idIndexMarker492"/> example, it uses the <strong class="source-inline">kreuzwerker/docker</strong> plugin, which is <a id="_idIndexMarker493"/>used to run <span class="No-Break">Docker containers.</span></p>
<p>The <strong class="source-inline">.terraform.lock.hcl</strong> file contains the version information of the dependencies, and it looks like <span class="No-Break">the following:</span></p>
<pre class="console">
# This file is maintained automatically by "terraform
# init".
# Manual edits may be lost in future updates.
provider "registry.terraform.io/kreuzwerker/docker" {
 version     = "2.16.0"
 constraints = "~&gt; 2.16.0"
 hashes = [
   "h1:OcTn2QyCQNjDiJYy1vqQFmz2dxJdOF/2/HBXBvGxU2<a id="_idTextAnchor301"/>E=",
   ...
 ]
}</pre>
<h2 id="_idParaDest-186"><a id="_idTextAnchor302"/>The plan command</h2>
<p>The <strong class="source-inline">plan</strong> command is used <a id="_idIndexMarker494"/>to help us understand the execution plan that Terraform will be <a id="_idIndexMarker495"/>doing. This is a very important feature as it gives us visibility of what changes will be performed to our infrastructure. This will give us a better understanding of which parts of the infrastructure will be impacted by the code. Unlike tools such as Chef or Ansible, Terraform is interesting in that it will tend towards a target state and only make the changes necessary to reach it. For example, if you had a target of five EC2 instances but Terraform only knew of three, it would take the steps needed to reach that target <span class="No-Break">of five.</span></p>
<p>Open the terminal, change to the <strong class="source-inline">chapter14/simple</strong> directory, and execute the <span class="No-Break">following command:</span></p>
<pre class="console">
terraform plan</pre>
<p>You will<a id="_idIndexMarker496"/> get <a id="_idIndexMarker497"/>the <span class="No-Break">following output:</span></p>
<pre class="console">
...
Terraform will perform the following actions:
  # docker_container.nginx will be created
  + resource "docker_container" "nginx" {
      + attach           = false
      + bridge           = (known after apply)
      + command          = (known after apply)
      + container_logs   = (known after apply)
      + entrypoint       = (known after apply)
      + env              = (known after apply)
      + exit_code        = (known after apply)
      ...
      + remove_volumes   = true
      + restart          = "no"
      + rm               = false
      + security_opts    = (known after apply)
      + shm_size         = (known after apply)
      + start            = true
      + stdin_open       = false
      + tty              = false
      + healthcheck {
          + interval     = (known after apply)
          + retries      = (known after apply)
          + start_period = (known after apply)
          + test         = (known after apply)
          + timeout      = (known after apply)
        }
      + labels {
          + label = (known after apply)
          + value = (known after apply)
        }
      + ports {
          + external = 8000
          + internal = 80
          + ip       = "0.0.0.0"
          + protocol = "tcp"
        }
    }
  # docker_image.nginx will be created
  + resource "docker_image" "nginx" {
      + id           = (known after apply)
      ...
      + repo_digest  = (known after apply)
    }
Plan: 2 to add, 0 to change, 0 to destroy.
...</pre>
<p>The output <a id="_idIndexMarker498"/>shows that there will be <strong class="source-inline">2</strong> things added and <strong class="source-inline">0</strong> operations for <a id="_idIndexMarker499"/>changing or destroying, which tells us that this is the first time we are running the code<a id="_idTextAnchor303"/> or it’s <span class="No-Break">still fresh.</span></p>
<h3>The apply command</h3>
<p>The normal process of running <a id="_idIndexMarker500"/>Terraform is that after <strong class="source-inline">init</strong>, we run <strong class="source-inline">apply</strong> (however, if we<a id="_idIndexMarker501"/> are not sure about the impact, we use the <strong class="source-inline">plan</strong> command as shown previously). Open the terminal, change to the <strong class="source-inline">chapter14/simple</strong> directory, and execute the <span class="No-Break">following command:</span></p>
<pre class="console">
terraform apply –auto-aprove</pre>
<p>You will get the <span class="No-Break">following output:</span></p>
<pre class="console">
...
Terraform will perform the following actions:
  # docker_container.nginx will be created
  + resource "docker_container" "nginx" {
      + attach           = false
      + bridge           = (known after apply)
      ...
    }
  # docker_image.nginx will be created
  + resource "docker_image" "nginx" {
      + id           = (known after apply)
      ...
    }
Plan: 2 to add, 0 to change, 0 to destroy.
docker_image.nginx: Creating...
docker_image.nginx: Still creating... [10s elapsed]
docker_image.nginx: Creation complete after 17s [id=sha256:2d389e545974d4a93ebdef09b650753a55f72d1ab4518d17a 30c0e1b3e297444nginx:latest]
docker_container.nginx: Creating...
docker_container.nginx: Creation complete after 2s [id=d0c94bd4 b548e6a19c3afb907a777bcb602e965bc05db8ef6d0d380601bb0694]
Apply complete! Resources: 2 added, 0 changed, 0 destroyed.</pre>
<p>As seen in the<a id="_idIndexMarker502"/> output, the <strong class="source-inline">nginx</strong> container will be downloaded (if it does not exist as yet) and then run. Once the <a id="_idIndexMarker503"/>command is successfully run you can test it by opening your browser and accessing http://localhost:8080. You will see something like <span class="No-Break"><em class="italic">Figure 14</em></span><span class="No-Break"><em class="italic">.7</em></span><span class="No-Break">.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer111">
<img alt="Figure 14.7: nginx running in a container" height="170" src="image/Figure_14.07_B18295.jpg" width="421"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.7: ngi<a id="_idTextAnchor304"/>nx running in a container</p>
<h2 id="_idParaDest-187"><a id="_idTextAnchor305"/>The destroy command</h2>
<p>The last command <a id="_idIndexMarker504"/>that we will look at is <strong class="source-inline">destroy</strong>. As the name implies, it is <a id="_idIndexMarker505"/>used to destroy the infrastructure that was created using the <strong class="source-inline">apply</strong> command. Use this command with caution if you are unsure about the impact of the code on your infrastructure. Use the <strong class="source-inline">plan</strong> command before running this to get better visibility of what will be removed from <span class="No-Break">the infrastructure.</span></p>
<p>Open the terminal and run the following command from the <span class="No-Break"><strong class="source-inline">chapter14/simple</strong></span><span class="No-Break"> directory:</span></p>
<pre class="console">
Terraform destroy –auto-approve</pre>
<p>You will get the <span class="No-Break">following output:</span></p>
<pre class="console">
docker_image.nginx: Refreshing state... [id=sha256:2d389e545974d4a93ebdef09b650753a55f72d1ab4518d17a30c 0e1b3e297444nginx:latest]
docker_container.nginx: Refreshing state... [id=9c46cff8 1a27edb6aba08a448d715599c644aaa79b192728016db0d903da9fb0]
...
Terraform will perform the following actions:
  # docker_container.nginx will be destroyed
  - resource "docker_container" "nginx" {
      - attach            = false -&gt; null
      - command           = [
          - "nginx",
          - "-g",
          - "daemon off;",
        ] -&gt; null
      - cpu_shares        = 0 -&gt; null
      …
    }
  # docker_image.nginx will be destroyed
  - resource "docker_image" "nginx" {
      - id           =
         "sha256:2d389e545974d4a93ebdef09b650753a55f7
         2d1ab4518d17a30c0e1b3e297444nginx:latest" -&gt;
         null
      - keep_locally = false -&gt; null
      - latest       =
         "sha256:2d389e545974d4a93ebdef09b650753a55f72
          d1ab4518d17a30c0e1b3e297444" -&gt; null
      - name         = "nginx:latest" -&gt; null
      - repo_digest  =
          "nginx@sha256:0b970013351304af46f322da126351
           6b188318682b2ab1091862497591189ff1" -&gt; null
    }
Plan: 0 to add, 0 to change, 2 to destroy.
docker_container.nginx: Destroying... [id=9c46cff81a27edb6aba 08a448d715599c644aaa79b192728016db0d903da9fb0]
docker_container.nginx: Destruction complete after 1s
docker_image.nginx: Destroying... [id=sha256:2d389e545974d4a93 ebdef09b650753a55f72d1ab4518d17a30c0e1b3e297444nginx:latest]
docker_image.nginx: Destruction complete after 0s
Destroy complete! Resources: 2 destroyed.</pre>
<p>In the output, we<a id="_idIndexMarker506"/> can see that there are <strong class="source-inline">2</strong> infrastructures that are destroyed – one is <a id="_idIndexMarker507"/>the container removed from memory, and the other is the removal of the image from the local <span class="No-Break">Docker registry.</span></p>
<p>The <strong class="source-inline">–auto-approve</strong> command is used to automatically approve the steps; normally, without using this, Terraform will stop execution and ask the user to enter <strong class="source-inline">Yes</strong> or <strong class="source-inline">No</strong> to continue at each step. This is a precautionary measure to ensure that the user does indeed want to destroy <span class="No-Break">the infrastructure.</span></p>
<p>In the next section, we will look at writing Terraform code and how it uses providers. We will look at a few Terraform examples to get an understanding of how it works to spin up different AWS infrastructure service<a id="_idTextAnchor306"/>s for <span class="No-Break">deploying applications.</span></p>
<h1 id="_idParaDest-188"><a id="_idTextAnchor307"/>Coding in Terraform</h1>
<p>HashiCorp, the creator of Terraform, created <strong class="bold">HashiCorp configuration language</strong> (<strong class="bold">HCL</strong>), which is used <a id="_idIndexMarker508"/>in writing Terraform code. HCL is a functional programming language with features such as loops, if statements, variables, and logic flow that are normally found in programming languages. Complete<a id="_idIndexMarker509"/> in-depth HCL documentation can be found <span class="No-Break">at </span><a href="https://www.terraform.io/language/"><span class="No-Break">https<span id="_idTextAnchor308"/>://www.terraform.io/language/</span></a><span class="No-Break">.</span></p>
<h2 id="_idParaDest-189"><a id="_idTextAnchor309"/>Providers</h2>
<p>The reason why Terraform is so widely used is the number of extensions that are available from the company and open source communities; these extensions are called providers. A provider is a <a id="_idIndexMarker510"/>piece of software that interacts with the different cloud providers and other resources in the cloud. We will look at Terraform code to understand more about providers. The following code snippets can be found inside the <span class="No-Break"><strong class="source-inline">chapter14/simple</strong></span><span class="No-Break"> directory:</span></p>
<pre class="console">
terraform {
 required_providers {
   docker = {
     source = "kreuzwerker/docker"
     version = "~&gt; 2.16.0"
   }
 }
}
resource "docker_image" "nginx" {
 name         = "nginx:latest"
 keep_locally = false
}
resource "docker_container" "nginx" {
 image = docker_image.nginx.name
 name  = "hello-terraform"
 ports {
   internal = 80
   external = 8000
 }
}</pre>
<p>The <strong class="source-inline">resource</strong> block in <a id="_idIndexMarker511"/>the code can be used to declare infrastructure or an API. In this example, we are using Docker, specifically, <strong class="source-inline">docker_image</strong> and <strong class="source-inline">docker_container</strong>. When Terraform runs the code it detects the <strong class="source-inline">required_providers</strong> block, which is used to define a provider. A provider is an external module that the code will be using, and this will be automatically downloaded by Terraform from a central repository. In our example, the provider that we are using is the <strong class="source-inline">kreuzwerker/docker</strong> Docker provider. More information on this provider can be found at the following <span class="No-Break">link: </span><a href="https://registry.terraform.io/providers/kreuzwerker/docker/"><span class="No-Break">https://registry.terraform.io/providers/kreuzwerker/docker/</span></a><span class="No-Break">.</span></p>
<p>Open the terminal, make sure you are inside the <strong class="source-inline">chapter14/simple</strong> directory, and run the <span class="No-Break">following command:</span></p>
<pre class="console">
terraform init</pre>
<p>You will see the following output in <span class="No-Break">your terminal:</span></p>
<pre class="console">
Initializing the backend...
Initializing provider plugins...
- Finding kreuzwerker/docker versions matching "~&gt; 2.16.0"...
- Installing kreuzwerker/docker v2.16.0...
- Installed kreuzwerker/docker v2.16.0 (self-signed, key ID BD080C4571C6104C)
...</pre>
<p>Terraform downloads the provider and stores it inside the <strong class="source-inline">chapter14/simple/.terraform</strong> folder. Now, let’s run the sample code and see what we get, by running the following command in the <span class="No-Break">same terminal:</span></p>
<pre class="console">
terraform apply -auto-approve</pre>
<p>You will see the<a id="_idIndexMarker512"/> <span class="No-Break">following output:</span></p>
<pre class="console">
…
  # docker_container.nginx will be created
  + resource "docker_container" "nginx" {
      + attach           = false
      ...
    }
  # docker_image.nginx will be created
  + resource "docker_image" "nginx" {
      + id           = (known after apply)
     …
    }
Plan: 2 to add, 0 to change, 0 to destroy.
  …
docker_image.nginx: Creation complete after 22s [id=sha256:2d389e545974d4a93ebdef09b650753a55f72d1ab4518d17a 30c0e1b3e297444nginx:latest]
docker_container.nginx: Creating...
docker_container.nginx: Creation complete after 2s [id=b860780 af83a4c719a916b87171d96801cc2243a61242354815f6d82dc6a5e40]</pre>
<p>Open your browser and go to http://localhost:8000. You will see something like <span class="No-Break"><em class="italic">Figure 14</em></span><span class="No-Break"><em class="italic">.7</em></span><span class="No-Break">.</span></p>
<p>Terraform downloads the <strong class="source-inline">nginx</strong> Docker image automatically to your local machine and runs the <strong class="source-inline">nginx</strong> container using the port defined in the <strong class="source-inline">ports</strong> code block (port <strong class="source-inline">8000</strong>). To destroy the running container and delete the image locally from the Docker registry, all you have to do is run the <span class="No-Break">following command:</span></p>
<pre class="console">
terraform destroy -auto-approve</pre>
<p>If you<a id="_idIndexMarker513"/> compare the steps involved to do the same thing manually using the Docker command, it is more involved and error-prone; writing it in Terraform makes it much easier to run and remove containers with a <span class="No-Break">single command.</span></p>
<p>In the next section, we will explore more examples to better understand how to use Te<a id="_idTextAnchor310"/>rraform for <span class="No-Break">deploying applications.</span></p>
<h1 id="_idParaDest-190"><a id="_idTextAnchor311"/>Terraform examples</h1>
<p>In the following sections, we <a id="_idIndexMarker514"/>will look at different ways we can use Terraform, such as pulling images from GitHub and running them locally, or building and publishing <span class="No-Break">Docker images.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">Make sure every time you run Terraform examples that create AWS resources to remember to destroy the resources using the <strong class="source-inline">terraform </strong><span class="No-Break"><strong class="source-inline">destroy</strong></span><span class="No-Break"> command.</span></p>
<p class="callout">All resources created in AWS incur charges, and by destroying them, you will ensure<a id="_idTextAnchor312"/> there will be no <span class="No-Break">surprise charges.</span></p>
<h2 id="_idParaDest-191"><a id="_idTextAnchor313"/>Pulling from GitHub Packages</h2>
<p>The example code for this<a id="_idIndexMarker515"/> section can be found inside the <strong class="source-inline">chapter14/github</strong> folder. The following snippet is <span class="No-Break">from </span><span class="No-Break"><strong class="source-inline">pullfromgithub.tf</strong></span><span class="No-Break">:</span></p>
<pre class="console">
#script to pull chapter12 image and run it locally
#it also store the image locally
terraform {
 required_providers {
   docker = {
     source  = "kreuzwerker/docker"
     version = "~&gt; 2.13.0"
   }
 }
}
data "docker_registry_image" "github" {
 name = "ghcr.io/nanikjava/golangci/chapter12:latest"
}
resource "docker_image" "embed" {
 ...
}
resource "docker_container" "embed" {
 ...
}</pre>
<p>The main objective of the code is to download the Docker image that we built in <a href="B18295_12.xhtml#_idTextAnchor241"><span class="No-Break"><em class="italic">Chapter 12</em></span></a><em class="italic">, Building Continuous Integration</em>. Once the Docker image is downloaded, it will be run locally. Open your terminal, make sure you are inside the <strong class="source-inline">chapter14/github</strong> directory, and run the <span class="No-Break">following command:</span></p>
<pre class="console">
terraform init</pre>
<p>Then run the <span class="No-Break">following command:</span></p>
<pre class="console">
terraform apply -auto-approve</pre>
<p>You will see <a id="_idIndexMarker516"/>output in your terminal that looks like <span class="No-Break">the following:</span></p>
<pre class="console">
…
data.docker_registry_image.github: Reading...
data.docker_registry_image.github: Read complete after 1s [id=sha256:a355f55c33a400290776faf20b33d45096eb19a6431fb 0b3f723c17236e8b03e]
…
  # docker_container.embed will be created
  + resource "docker_container" "embed" {
      + attach           = false
     …
      + ports {
          + external = 3333
          + internal = 3333
          …
        }
    }
  # docker_image.embed will be created
  + resource "docker_image" "embed" {
      …
      + name         =
         "ghcr.io/nanikjava/golangci/chapter12:latest"
       …
    }
Plan: 2 to add, 0 to change, 0 to destroy.
… [id=sha256:684e34e77f40ee1e75bfd7d86982a4f4fae1dbea3286682af 3222a270faa49b7ghcr.io/nanikjava/golangci/chapter12:latest]
docker_container.embed: Creation complete after 7s [id=f47d1ab90331dd8d6dd677322f00d9a06676b71dda3edf2cb2e66 edc97748329]
Apply complete! Resources: 2 added, 0 changed, 0 destroyed.</pre>
<p>Open your <a id="_idIndexMarker517"/>browser and go to http://localhost:3333. You will see the login page of the <span class="No-Break">sample app.</span></p>
<p>The code uses the same <strong class="source-inline">docker</strong> provider that we discussed in the previous section, and we use a new <strong class="source-inline">docker_registry_image</strong> command to specify the address to download the Docker image from, in this case from the <strong class="source-inline">ghcr.io/nanikjava/golangci/chapter12:latest</strong> <span class="No-Break">GitHub package.</span></p>
<p>The other HCL feature we are using is the <strong class="source-inline">data</strong> block, as <span class="No-Break">shown here:</span></p>
<pre class="console">
...
data "docker_registry_image" "github" {
 name = "ghcr.io/nanikjava/golangci/chapter12:latest"
}
...</pre>
<p>The <strong class="source-inline">data</strong> block works similarly to <strong class="source-inline">resource</strong>, except it is only used for reading values and not creating or destroying resources or to get data that will be used internally as configuration to<a id="_idIndexMarker518"/> another resource. In our sample, it is used by the <strong class="source-inline">docker_image</strong> resource, as <span class="No-Break">shown here:</span></p>
<pre class="console">
resource "docker_image" "embed" {
 keep_locally = true
 name         = "${da<a id="_idTextAnchor314"/>t<a id="_idTextAnchor315"/>a.docker_registry_image.github.name}"
}</pre>
<h2 id="_idParaDest-192"><a id="_idTextAnchor316"/>AWS EC2 setup</h2>
<p>In the previous examples, we <a id="_idIndexMarker519"/>looked at using the Docker provider to run Docker containers locally. In this example, we will look at creating AWS resources, specifically EC2 instances. An EC2 instance is basically a virtual machine that can be initialized with a certain configuration to run in the cloud to host <span class="No-Break">your application.</span></p>
<p>In order to create resources in AWS, you will first need to already have an AWS account. If you don’t have an AWS account, you can create one at <a href="https://aws.amazon.com/">https://aws.amazon.com/</a>. Once you have your AWS account ready, log in to the AWS website, and in the main console (<span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.6</em>) web page, click on your name on the right side and it will display a drop-down menu, as shown in <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.8</em>. Then click on <span class="No-Break"><strong class="bold">Security credentials</strong></span><span class="No-Break">.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer112">
<img alt="Figure 14.8: Security credentials option" height="300" src="image/Figure_14.08_B18295.jpg" width="223"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.8: Security credentials option</p>
<p>Your browser <a id="_idIndexMarker520"/>will now show the <strong class="bold">identity and access management</strong> (<strong class="bold">IAM</strong>) page, as shown in <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.9</em>. Select the <strong class="bold">Access keys (access key ID and secret access key)</strong> option. Since you haven’t created any key, it will be empty. Click on the <strong class="bold">Create New Access Key</strong> button and follow the instructions to create a <span class="No-Break">new key.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer113">
<img alt="Figure 14.9: Access keys section" height="168" src="image/Figure_14.09_B18295.jpg" width="625"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.9: Access keys section</p>
<p>Once you complete the steps you will get two keys – an Access Key ID and Secret Access Key. Keep these keys safe as they are used like a username and password combination you use to create resources in <span class="No-Break">AWS infrastructure.</span></p>
<p>Now that you have the keys required, you can now open a terminal and change into the <strong class="source-inline">chapter14/simpleec2</strong> directory, and run the example <span class="No-Break">as follows:</span></p>
<pre class="console">
terraform init</pre>
<p>Next, run the following command to create the <span class="No-Break">EC2 instance:</span></p>
<pre class="console">
terraform apply  -var="aws_access_key=xxxx" -var="aws_secret_key=xxx" -auto-approve</pre>
<p>Once completed <a id="_idIndexMarker521"/>you will see the output <span class="No-Break">as follows:</span></p>
<pre class="console">
...
Terraform will perform the following actions:
  # aws_instance.app_server will be created
  + resource "aws_instance" "app_server" {
      + ami = "ami-0ff8a91507f77f867"
      ...
    }
  # aws_subnet.default-subnet will be created
  + resource "aws_subnet" "default-subnet" {
      ...
    }
  # aws_vpc.default-vpc will be created
  + resource "aws_vpc" "default-vpc" {
      + arn                      = (known after apply)
      ...
    }
Plan: 3 to add, 0 to change, 0 to destroy.
...
aws_instance.app_server: Creation complete after 24s [id=i-0358d1df58e055d70]</pre>
<p>The output <a id="_idIndexMarker522"/>shows three resources were created – the AWS instance (EC2), an IP subnet, and a network VPC. Now, let’s take a look at the code (the complete code can be seen inside the <strong class="source-inline">chapter14/simpleec2</strong> directory). The code requires your AWS keys, storing them inside the <strong class="source-inline">variable</strong> block as <strong class="source-inline">aws_access_key</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">aws_secret_key</strong></span><span class="No-Break">:</span></p>
<pre class="console">
terraform {
 ...
}
variable "aws_access_key" {
 type = string
}
variable "aws_secret_key" {
 type = string
}
provider "aws" {
 region     = "us-east-1"
 access_key = var.aws_access_key
 secret_key = var.aws_secret_key
}</pre>
<p>The keys will be passed to the <strong class="source-inline">aws</strong> provider to enable the provider to communicate with the AWS service using <span class="No-Break">our keys.</span></p>
<p>The following part of the code creates the VPC and IP subnet, which will be used as a private network by <span class="No-Break">EC2 instances:</span></p>
<pre class="console">
resource "aws_vpc" "default-vpc" {
 cidr_block           = "10.0.0.0/16"
 enable_dns_hostnames = true
 tags                 = {
   env = "dev"
 }
}
resource "aws_subnet" "default-subnet" {
 cidr_block = "10.0.0.0/24"
 vpc_id     = aws_vpc.default-vpc.id
}</pre>
<p>The last <a id="_idIndexMarker523"/>resource the code defines is the EC2 instance, <span class="No-Break">as follows:</span></p>
<pre class="console">
resource "aws_instance" "app_server" {
 ami             = "ami-0ff8a91507f77f867"
 instance_type   = "t2.nano"
 subnet_id       = aws_subnet.default-subn<a id="_idTextAnchor317"/>et.id
 tags = {
   Name = "Chapter14"
 }
}</pre>
<p>The EC2 <a id="_idIndexMarker524"/>instance type is <strong class="source-inline">t2.nano</strong>, which is the smallest virtual machine that can be configured. It is linked to the IP subnet defined earlier by assignin<a id="_idTextAnchor318"/>g the subnet ID to the <span class="No-Break"><strong class="source-inline">subnet_id</strong></span><span class="No-Break"> parameter.</span></p>
<h2 id="_idParaDest-193"><a id="_idTextAnchor319"/>Deploying to ECS with a load balancer</h2>
<p>The <a id="_idIndexMarker525"/>last example that we are going to look at is using AWS ECS. The source code can be found inside the <strong class="source-inline">chapter14/lbecs</strong> directory. The code will use ECS to deploy our <a href="B18295_12.xhtml#_idTextAnchor241"><span class="No-Break"><em class="italic">Chapter 12</em></span></a> container hosted in GitHub Packages and made scalable by using a load balancer. <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.9</em> shows the infrastructure configuration after running <span class="No-Break">the code.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer114">
<img alt="Figure 14.10: ECS with a load balancer" height="419" src="image/Figure_14.10_B18295.jpg" width="340"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.10: ECS with a load balancer</p>
<p>The code uses the <span class="No-Break">following services:</span></p>
<ul>
<li><strong class="bold">An internet gateway</strong>: As<a id="_idIndexMarker526"/> the name implies, this is a gateway that enables communication to be established between the AWS VPC private network and the internet. With the help of the gateway, we open our application to <span class="No-Break">the world.</span></li>
<li><strong class="bold">A load balancer</strong>: This service<a id="_idIndexMarker527"/> helps balance the incoming traffic across the different networks configured, ensuring that the application can take care of all <span class="No-Break">incoming requests.</span></li>
</ul>
<p>ECS provides the capability to scale the deployment process for containers. This means that, as developers, we don’t have to worry about how to scale the containers that are running our application, as this is all taken care of by ECS. More in-depth information can be found at <a href="https://aws.amazon.com/ecs/">https://aws.amazon.com/ecs/</a>. The application is run the same way as in the previous examples, using the <strong class="source-inline">terraform init</strong> and <strong class="source-inline">terraform </strong><span class="No-Break"><strong class="source-inline">apply</strong></span><span class="No-Break"> commands.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">The ECS example takes a bit longer to execute compared to the <span class="No-Break">other examples.</span></p>
<p>You will get<a id="_idIndexMarker528"/> output that looks like <span class="No-Break">the following:</span></p>
<pre class="console">
...
Terraform will perform the following actions:
  # aws_default_route_table.lbecs-subnet-default-route-
  # table will be created
  + resource "aws_default_route_table"
             "lbecs-subnet-default-route-table" {
      ...
    }
  # aws_ecs_cluster.lbecs-ecs-cluster will be created
  + resource "aws_ecs_cluster" "lbecs-ecs-cluster" {
      ...
    }
  # aws_ecs_service.lbecs-ecs-service will be created
  + resource "aws_ecs_service" "lbecs-ecs-service" {
      ...
    }
  # aws_ecs_task_definition.lbecs-ecs-task-definition will
  # be created
  + resource "aws_ecs_task_definition"
             "lbecs-ecs-task-definition" {
      ...
    }
  # aws_internet_gateway.lbecs-igw will be created
  + resource "aws_internet_gateway" "lbecs-igw" {
     ...
    }
  # aws_lb.lbecs-load-balancer will be created
  + resource "aws_lb" "lbecs-load-balancer" {
      ...
    }
  # aws_lb_listener.lbecs-load-balancer-listener will be
  # created
  + resource "aws_lb_listener"
             "lbecs-load-balancer-listener" {
      ...
    }
  # aws_lb_target_group.lbecs-load-balancer-target-group
  # will be created
  + resource "aws_lb_target_group"
             "lbecs-load-balancer-target-group" {
      ...
    }
  # aws_security_group.lbecs-security-group will be created
  + resource "aws_security_group" "lbecs-security-group" {
      ...
    }
  # aws_subnet.lbecs-subnet will be created
  + resource "aws_subnet" "lbecs-subnet" {
      ...
    }
  # aws_subnet.lbecs-subnet-1 will be created
  + resource "aws_subnet" "lbecs-subnet-1" {
      ...
    }
  # aws_vpc.lbecs-vpc will be created
  + resource "aws_vpc" "lbecs-vpc" {
      ...
    }
Plan: 12 to add, 0 to change, 0 to destroy.
...
aws_ecs_service.lbecs-ecs-service: Creation complete after 2m49s [id=arn:aws:ecs:us-east-1:860976549008:service/lbecs-ecs-cluster/lbecs-ecs-service]
...
Outputs:
url = "load-balancer-1956367690.us-east-1.elb.amazonaws.com"</pre>
<p>Let’s <a id="_idIndexMarker529"/>break down the code to see how it uses ECS and configures the internet gateway, load balancer, and network. The following code shows the internet gateway declaration, which is simple enough as it requires to be attached to <span class="No-Break">a VPC:</span></p>
<pre class="console">
resource "aws_internet_gateway" "lbecs-igw" {
 vpc_id = aws_vpc.lbecs-vpc.id
 tags = {
   Name = "Internet Gateway"
 }
}
resource "aws_default_route_table" "lbecs-subnet-default-route-table" {
 default_route_table_id =
   aws_vpc.lbecs-vpc.default_route_table_id
 route {
   cidr_block = "0.0.0.0/0"
   gateway_id = "${aws_internet_gateway.lbecs-igw.id}"
 }
}</pre>
<p>Besides that, the gateway will also be attached to a routing table declared inside the <strong class="source-inline">aws_default_route_table</strong> block. This is necessary as this tells the gateway how to route the incoming and outgoing traffic through the internal private <span class="No-Break">VPC network.</span></p>
<p>Now that our<a id="_idIndexMarker530"/> internal private network can communicate to the internet via a gateway, we need to have network rules in place to ensure our network is secure, and this is done in the <span class="No-Break">following code:</span></p>
<pre class="console">
resource "aws_security_group" "lbecs-security-group" {
 name        = "allow_http"
 description = "Allow HTTP inbound traffic"
 vpc_id      = aws_vpc.lbecs-vpc.id
 egress {
   from_port   = 0
   to_port     = 0
   protocol    = "-1"
   cidr_blocks = ["0.0.0.0/0"]
 }
 ingress {
   description = "Allow HTTP for all"
   from_port   = 80
   to_port     = 3333
   protocol    = "tcp"
   cidr_blocks = ["0.0.0.0/0"]
 }
}</pre>
<p>The <strong class="source-inline">egress</strong> block declares the rule for outgoing network traffic, allowing all protocols to pass through. The incoming network traffic rule is declared in the <strong class="source-inline">ingress</strong> block, and allows ports between <strong class="source-inline">80</strong>-<strong class="source-inline">3333</strong> and only <span class="No-Break">over TCP.</span></p>
<p>Using a load<a id="_idIndexMarker531"/> balancer requires two different subnets to be declared. In our code example, this is <span class="No-Break">as follows:</span></p>
<pre class="console">
resource "aws_lb" "lbecs-load-balancer" {
 name               = "load-balancer"
 internal           = false
 load_balancer_type = "application"
 security_groups    = [aws_security_group.lbecs-security-group.                       id]
 subnets            = [aws_subnet.lbecs-subnet.id,
                       aws_subnet.lbecs-subnet-1.id]
 tags               = {
   env = "dev"
 }
}</pre>
<p>The last<a id="_idIndexMarker532"/> piece of code that we will look at is the ECS block, <span class="No-Break">as follows:</span></p>
<pre class="console">
resource "aws_ecs_cluster" "lbecs-ecs-cluster" {
 name = "lbecs-ecs-cluster"
}
resource "aws_ecs_task_definition" "lbecs-ecs-task-definition" {
 family                   = "service"
 requires_compatibilities = ["FARGATE"]
 network_mode             = "awsvpc"
 cpu                      = 1024
 memory                   = 2048
 container_definitions    = jsonencode([
   {
     name         = "lbecs-ecs-cluster-chapter14"
     image        =
       "ghcr.io/nanikjava/golangci/chapter12:latest"
     ...
     portMappings = [
       {
         containerPort = 3333
       }
     ]
   }
 ])
}
resource "aws_ecs_service" "lbecs-ecs-service" {
 name            = "lbecs-ecs-service"
 cluster         = aws_ecs_cluster.lbecs-ecs-cluster.id
 task_definition =
   aws_ecs_task_definition.lbecs-ecs-task-definition.arn
 desired_count   = 1
 launch_type     = "FARGATE"
 network_configuration {
   ...
 }
 load_balancer {
   target_group_arn = aws_lb_target_group.lbecs-load-
                      balancer-target-group.arn
   container_name   = "lbecs-ecs-cluster-chapter14"
   container_port   = 3333
 }
 tags = {
   env = "dev"
 }
}</pre>
<p>The preceding code contains <a id="_idIndexMarker533"/>three different code blocks that are explained <span class="No-Break">as follows:</span></p>
<ul>
<li><strong class="source-inline">aws_ecs_cluster</strong>: This block configures the name of the <span class="No-Break">ECS cluster</span></li>
<li><strong class="source-inline">aws_ecs_task_definition</strong>: This block configures the ECS task, which specifies what kind of container it has to run, the virtual machine configuration that the container will be running on, the network mode, security group, and <span class="No-Break">other options</span></li>
<li><strong class="source-inline">aws_ecs_service</strong>: This block ties together the different services to describe the complete infrastructure that will be run, such as security, ECS task, network configuration, load balancers, public IP address, <span class="No-Break">and more</span></li>
</ul>
<p>Once ECS has been spun up, it will print out in your console the load-balanced public address you can use to access the application. For example, when it was run, we got the following output in <span class="No-Break">the terminal:</span></p>
<pre class="console">
…
aws_lb_listener.lbecs-load-balancer-listener: Creating...
aws_lb_listener.lbecs-load-balancer-listener: Creation complete after 1s [id=arn:aws:elasticloadbalancing:us-east-1:860976549008:listener/app/load-balancer/4ad0f8b815a06f02/d945bba078d0c365]
aws_ecs_service.lbecs-ecs-service: Creation complete after 2m27s [id=arn:aws:ecs:us-east-1:860976549008:service/lbecs-ecs-cluster/lbecs-ecs-service]
Apply complete! Resources: 12 added, 0 changed, 0 destroyed.
Outputs:
url = "load-balancer-375816308.us-east-1.elb.amazonaws.com"</pre>
<p>Using <a id="_idIndexMarker534"/>the <strong class="source-inline">load-balancer-375816308.us-east-1.elb.amazonaws.com</strong> address in the browser will show the application login page. This address is dynamically generated by AWS, and you will get somethi<a id="_idTextAnchor320"/>ng different than what is shown in the <span class="No-Break">previous output.</span></p>
<h1 id="_idParaDest-194"><a id="_idTextAnchor321"/>Summary</h1>
<p>In this chapter, we explored cloud solutions provided by AWS, and we briefly looked at the different services offered, such as EC2, VPC, storage, and others. We learned about the open source Terraform tools that make it easy to create, manage, and destroy cloud infrastructure <span class="No-Break">in AWS.</span></p>
<p>We learned how to install and use Terraform locally, and how to write Terraform code to use Docker as a provider, allowing us to run containers locally. Terraform also allows us to download, run, and destroy containers locally with a <span class="No-Break">single command.</span></p>
<p>We also explored different Terraform examples for creating AWS infrastructure resources and looked at one of the advanced features of <span class="No-Break">AWS ECS.</span></p>
<p>In this last chapter of the book, you have learned the different things that need to be done to deploy an application to the <span class="No-Break">AWS cloud.</span></p>
</div>
</div></body></html>