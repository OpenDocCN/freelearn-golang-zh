- en: Chapter 9. Concurrency Patterns - Barrier, Future, and Pipeline Design Patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we are familiar with the concepts of concurrency and parallelism,
    and we have understood how to achieve them by using Go''s concurrency primitives,
    we can see some patterns regarding concurrent work and parallel execution. In
    this chapter we''ll see the following patterns:'
  prefs: []
  type: TYPE_NORMAL
- en: Barrier is a very common pattern, especially when we have to wait for more than
    one response from different Goroutines before letting the program continue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Future pattern allows us to write an algorithm that will be executed eventually
    in time (or not) by the same Goroutine or a different one
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pipeline is a powerful pattern to build complex synchronous flows of Goroutines
    that are connected with each other according to some logic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Take a quick look at the description of the three patterns. They all describe
    some sort of logic to synchronize execution in time. It's very important to keep
    in mind that we are now developing concurrent structures with all the tools and
    patterns we have seen in the previous chapters. With Creational patterns we were
    dealing with creating objects. With the Structural patterns we were learning how
    to build idiomatic structures and in Behavioral patterns we were managing mostly
    with algorithms. Now, with Concurrency patterns, we will mostly manage the timing
    execution and order execution of applications that has more than one *flow*.
  prefs: []
  type: TYPE_NORMAL
- en: Barrier concurrency pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are going to start with the Barrier pattern. Its purpose is simple--put up
    a barrier so that nobody passes until we have all the results we need, something
    quite common in concurrent applications.
  prefs: []
  type: TYPE_NORMAL
- en: Description
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Imagine the situation where we have a microservices application where one service
    needs to compose its response by merging the responses of another three microservices.
    This is where the Barrier pattern can help us.
  prefs: []
  type: TYPE_NORMAL
- en: Our Barrier pattern could be a service that will block its response until it
    has been composed with the results returned by one or more different Goroutines
    (or services). And what kind of primitive do we have that has a blocking nature?
    Well, we can use a lock, but it's more idiomatic in Go to use an unbuffered channel.
  prefs: []
  type: TYPE_NORMAL
- en: Objectives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As its name implies, the Barrier pattern tries to stop an execution so it doesn''t
    finish before it''s ready to finish. The Barrier pattern''s objectives are as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Compose the value of a type with the data coming from one or more Goroutines.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Control the correctness of any of those incoming data pipes so that no inconsistent
    data is returned. We don't want a partially filled result because one of the pipes
    has returned an error.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An HTTP GET aggregator
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For our example, we are going to write a very typical situation in a microservices
    application-an app that performs two HTTP `GET` calls and joins them in a single
    response that will be printed on the console.
  prefs: []
  type: TYPE_NORMAL
- en: Our small app must perform each request in a different Goroutine and print the
    result on the console if both responses are correct. If any of them returns an
    error, then we print just the error.
  prefs: []
  type: TYPE_NORMAL
- en: 'The design must be concurrent, allowing us to take advantage of our multicore
    CPUs to make the calls in parallel:'
  prefs: []
  type: TYPE_NORMAL
- en: '![An HTTP GET aggregator](img/00039.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding diagram, the solid lines represent calls and the dashed lines
    represent channels. The balloons are Goroutines, so we have two Goroutines launched
    by the `main` function (which could also be considered a Goroutine). These two
    functions will communicate back to the `main` function by using a **common channel**
    that they received when they were created on the `makeRequest` calls.
  prefs: []
  type: TYPE_NORMAL
- en: Acceptance criteria
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our main objective in this app is to get a merged response of two different
    calls, so we can describe our acceptance criteria like this:'
  prefs: []
  type: TYPE_NORMAL
- en: Print on the console the merged result of the two calls to `http://httpbin.org/headers`
    and `http://httpbin.org/User-Agent` URLs. These are a couple of public endpoints
    that respond with data from the incoming connections. They are very popular for
    testing purposes. You will need an internet connection to do this exercise.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If any of the calls fails, it must not print any result-just the error message
    (or error messages if both calls failed).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The output must be printed as a composed result when both calls have finished.
    It means that we cannot print the result of one call and then the other.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unit test - integration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To write unit or integration tests for concurrent designs can sometimes be
    tricky, but this won''t stop us from writing our awesome unit tests. We will have
    a single `barrier` method that accepts a set of endpoints defined as a `string`
    type. The barrier will make a `GET` request to each endpoint and compose the result
    before printing it out. In this case, we will write three integration tests to
    simplify our code so we don''t need to generate mock responses:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We have a single test that will execute three subtests:'
  prefs: []
  type: TYPE_NORMAL
- en: The first test makes two calls to the correct endpoints
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second test will have an incorrect endpoint, so it must return an error
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The last test will return the maximum timeout time so that we can force a timeout
    error
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will have a function called `barrier` that will accept an undetermined number
    of endpoints in the form of strings. Its signature could be like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the `barrier` function doesn''t return any value because its
    result will be printed on the console. Previously, we have written an implementation
    of an `io.Writer` interface to emulate the writing on the operating system''s
    `stdout` library. Just to change things a bit, we will capture the `stdout` library
    instead of emulating one. The process to capture the `stdout` library isn''t difficult
    once you understand concurrency primitives in Go:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Don't feel daunted by this code; it's really simple. First we created a pipe;
    we have done this before in [Chapter 3](part0117_split_000.html#3FIHQ2-9c484ed022e64a0fb0e1aebf8e05d4fd
    "Chapter 3. Structural Patterns - Composite, Adapter, and Bridge Design Patterns"),
    *Structural Patterns - Adapter, Bridge, and Composite Design Patterns*, when we
    talked about the Adapter design pattern. To recall, a pipe allows us to connect
    an `io.Writer` interface to an `io.Reader` interface so that the reader input
    is the `Writer` output. We define the `os.Stdout` as the writer. Then, to capture
    `stdout` output, we will need a different Goroutine that listens while we write
    to the console. As you know, if we write, we don't capture, and if we capture,
    we are not writing. The keyword here is `while`; it is a good rule of thumb that
    if you find this word in some definition, you'll probably need a concurrent structure.
    So we use the `go` keyword to launch a different Goroutine that copies reader
    input to a bytes buffer before sending the contents of the buffer through a channel
    (that we should have previously created).
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we have a listening Goroutine, but we haven't printed anything
    yet, so we call our (not yet written) function `barrier` with the provided endpoints.
    Next, we have to close the writer to signal the Goroutine that no more input is
    going to come to it. Our channel called out blocks execution until some value
    is received (the one sent by our launched Goroutine). The last step is to return
    the contents captured from the console.
  prefs: []
  type: TYPE_NORMAL
- en: 'OK, so we have a function called `captureBarrierOutput` that will capture the
    outputs in `stdout` and return them as a string. We can write our tests now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'All the tests are very easy to implement. All in all, it is the `captureBarrierOutput`
    function that calls the `barrier` function. So we pass the endpoints and check
    the returned result. Our composed response directed to [http://httpbin.org](http://httpbin.org)
    must contain the text *Accept-Encoding* and *User-Agent* in the responses of each
    endpoint. If we don''t find those texts, the test will fail. For debugging purposes,
    we log the response in case we want to check it with the `-v` flag on the go test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This time we used an incorrect endpoint URL, so the response must return the
    error prefixed with the word *ERROR* that we will write ourselves in the `barrier`
    function.
  prefs: []
  type: TYPE_NORMAL
- en: 'The last function will reduce the timeout of the HTTP `GET` client to a minimum
    of 1 ms, so we force a timeout:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The `timeoutMilliseconds` variable will be a package variable that we will have
    to define later during implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We needed to define a package variable called `timeoutMilliseconds`. Let''s
    start from there:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The initial timeout delay is 5 seconds (5,000 milliseconds) and we will need
    those packages in our code.
  prefs: []
  type: TYPE_NORMAL
- en: OK, so we need a function that launches a Goroutine for each endpoint URL. Do
    you remember how we achieve the communication between Goroutines? Exactly--channels!
    So we will need a channel to handle responses and a channel to handle errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'But we can simplify it a bit more. We will receive two correct responses, two
    errors, or a response and an error; in any case, there are always two responses,
    so we can join errors and responses in a merged type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: So, each Goroutine will send back a value of the `barrierResp` type. This value
    will have a value for `Err` or a value for the `Resp` field.
  prefs: []
  type: TYPE_NORMAL
- en: 'The procedure is simple: we create a channel of size 2, the one that will receive
    responses of the `barrierResp` type, we launch both requests and wait for two
    responses, and then check to see if there is any error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Following the previous description, we created a buffered channel called `in`,
    making it the size of the incoming endpoints, and we deferred channel closing.
    Then, we launched a function called `makeRequest` with each endpoint and the response
    channel.
  prefs: []
  type: TYPE_NORMAL
- en: Now we will loop  twice, once for each endpoint. In the loop, we block the execution
    waiting for data from the `in` channel. If we find an error, we print it prefixed
    with the word *ERROR* as we expect in our tests, and set `hasErrorvar` to true.
    After two responses, if we don't find any error (`hasError== false`) we print
    every response and the channel will be closed.
  prefs: []
  type: TYPE_NORMAL
- en: 'We still lack the `makeRequest` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The `makeRequest` function is a very straightforward functions that accepts
    a channel to output `barrierResp` values to and a URL to request. We create an
    `http.Client` and set its timeout field to the value of the `timeoutMilliseconds`
    package variable. This is how we can change the timeout delay before the `in`
    function tests. Then, we simply make the `GET` call, take the response, parse
    it to a byte slice, and send it through the `out` channel.
  prefs: []
  type: TYPE_NORMAL
- en: We do all this by filling a variable called `res` of the `barrierResp` type.
    If we find an error while performing a `GET` request or parsing the body of the
    result, we fill the `res.Err` field, send it to the `out` channel (which has the
    opposite side connected to the original Goroutine), and exit the function (so
    we don't send two values through the `out` channel by mistake).
  prefs: []
  type: TYPE_NORMAL
- en: 'Time to run the tests. Remember that you need an Internet connection, or the
    first two tests will fail. We will first try the test that has two endpoints that
    are correct:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Perfect. We have a JSON response with a key, `headers`, and another JSON response
    with a key `User-Agent`. In our integration tests, we were looking for the strings, `User-Agent`
    and `Accept-Encoding`, which are present, so the test has passed successfully.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we will run the test that has an incorrect endpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: We can see that we have had an error where `http://malformed-url` has returned
    a *no such host* error. A request to this URL must return a text with the word
    `ERROR:` prefixed, as we stated during the acceptance criteria, that's why this
    test is correct (we don't have a false positive).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In testing, it''s very important to understand the concepts of "false positive"
    and "false negative" tests. A false positive test is roughly described as a test
    that passes a condition when it shouldn''t (result: all passed) while the false
    negative is just the reverse (result: test failed). For example, we could be testing
    that a string is returned when doing the requests but, the returned string could
    be completely empty! This will lead to a false negative, a test that doesn''t
    fail even when we are checking a behavior that is incorrect on purpose (a request
    to `http://malformed-url`).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The last test reduced the timeout time to 1 ms:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Again, the test passed successfully and we have got two timeout errors. The
    URLs were correct, but we didn't have a response in less than one millisecond,
    so the client has returned a timeout error.
  prefs: []
  type: TYPE_NORMAL
- en: Waiting for responses with the Barrier design pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Barrier pattern opens the door of microservices programming with its composable
    nature. It could be considered a Structural pattern, as you can imagine.
  prefs: []
  type: TYPE_NORMAL
- en: The Barrier pattern is not only useful to make network requests; we could also
    use it to split some task into multiple Goroutines. For example, an expensive
    operation could be split into a few smaller operations distributed in different
    Goroutines to maximize parallelism and achieve better performance.
  prefs: []
  type: TYPE_NORMAL
- en: Future design pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Future design pattern (also called **Promise**) is a quick and easy way
    to achieve concurrent structures for asynchronous programming. We will take advantage
    of first class functions in Go to develop *Futures*.
  prefs: []
  type: TYPE_NORMAL
- en: Description
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In short, we will define each possible behavior of an action before executing
    them in different Goroutines. Node.js uses this approach, providing event-driven
    programming by default. The idea here is to achieve a *fire-and-forget* that handles
    all possible results in an action.
  prefs: []
  type: TYPE_NORMAL
- en: To understand it better, we can talk about a type that has embedded the behavior
    in case an execution goes well or in case it fails.
  prefs: []
  type: TYPE_NORMAL
- en: '![Description](img/00040.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding diagram, the `main` function launches a **Future** within a
    new Goroutine. It won't wait for anything, nor will it receive any progress of
    the Future. It really fires and forgets it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The interesting thing here is that we can launch a new Future within a Future
    and embed as many Futures as we want in the same Goroutine (or new ones). The
    idea is to take advantage of the result of one Future to launch the next. For
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Description](img/00041.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Here, we have the same Future. In this case, if the `Execute` function returned
    a correct result, the `Success` function is executed, and only in this case we
    execute a new Goroutine with another Future inside (or even without a Goroutine).
  prefs: []
  type: TYPE_NORMAL
- en: This is a kind of lazy programming, where a Future could be calling to itself
    indefinitely or just until some rule is satisfied. The idea is to define the behavior
    in advance and let the future resolve the possible solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Objectives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With the Future pattern, we can launch many new Goroutines, each with an action
    and its own handlers. This enables us to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Delegate the action handler to a different Goroutine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stack many asynchronous calls between them (an asynchronous call that calls
    another asynchronous call in its results)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A simple asynchronous requester
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We are going to develop a very simple example to try to understand how a Future
    works. In this example, we will have a method that returns a string or an error,
    but we want to execute it concurrently. We have learned ways to do this already.
    Using a channel, we can launch a new Goroutine and handle the incoming result
    from the channel.
  prefs: []
  type: TYPE_NORMAL
- en: But in this case, we will have to handle the result (string or error), and we
    don't want this. Instead, we will define what to do in case of success and what
    to do in case of error and fire-and-forget the Goroutine.
  prefs: []
  type: TYPE_NORMAL
- en: Acceptance criteria
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We don''t have functional requirements for this task. Instead, we will have
    technical requirements for it:'
  prefs: []
  type: TYPE_NORMAL
- en: Delegate the function execution to a different Goroutine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The function will return a string (maybe) or an error
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The handlers must be already defined before executing the function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The design must be reusable
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unit tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So, as we mentioned, we will use first class functions to achieve this behavior,
    and we will need three specific types of function:'
  prefs: []
  type: TYPE_NORMAL
- en: '`type SuccessFunc func(string)`: The `SuccessFunc` function will be executed
    if everything went well. Its string argument will be the result of the operation,
    so this function will be called by our Goroutine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`type FailFunc func(error)`: The `FailFunc` function handles the opposite result,
    that is, when something goes wrong, and, as you can see, it will return an error.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`type ExecuteStringFunc func() (string, error)`: Finally, the `ExecuteStringFunc` function
    is a type that defines the operation we want to perform. Maybe it will return
    a string or an error. Don''t worry if this all seems confusing; it will be clearer
    later.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So, we create the `future` object, we define a success behavior, we define
    a fail behavior, and we pass an `ExecuteStringFunc` type to be executed. In the
    implementation file, we''ll need a new type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We will also create two tests in the `_test.go` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We will define functions by chaining them, as you would usually see in Node.js.
    Code like this is compact and not particularly difficult to follow:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The `future.Success` function must be defined in the `MaybeString` structure
    to accept a `SuccessFunc` function that will be executed if everything goes correctly
    and return the same pointer to the `future` object (so we can keep chaining).
    The `Fail` function must also be defined in the `MaybeString` structure and must
    accept a `FailFunc` function to later return the pointer. We return the pointer
    in both cases so we can define the `Fail` and the `Success` or vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we use the `Execute` method to pass an `ExecuteStringFunc` type (a
    function that accepts nothing and returns a string or an error). In this case,
    we return a string and nil, so we expect that the `SuccessFunc` function will
    be executed and we log the result to the console. In case that fail function is
    executed, the test has failed because the `FailFunc` function shouldn't be executed
    for a returned nil error.
  prefs: []
  type: TYPE_NORMAL
- en: 'But we still lack something here. We said that the function must be executed
    asynchronously in a different Goroutine, so we have to synchronize this test somehow
    so that it doesn''t finish too soon. Again, we can use a channel or a `sync.WaitGroup`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: We have seen WaitGroups before in the previous channel. This WaitGroup is configured
    to wait for one signal (`wg.Add(1)`). The `Success` and `Fail` methods will trigger
    the `Done()` method of the `WaitGroup` to allow execution to continue and finish
    testing (that is why the `Wait()` method is at the end). Remember that each `Done()`
    method will subtract one from the WaitGroup, and we have added only one, so our
    `Wait()` method will only block until one `Done()` method is executed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using what we know of making a `Success` result unit test, it''s easy to make
    a Failed result unit test by swapping the `t.Fail()` method call from the error
    to success so that the test fails if a call to success is done:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'If you are using an IDE like me, your `Success`, `Fail`, and `Execute` method
    calls must be in red. This is because we lack our method''s declaration in the
    implementation file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Our test seems ready to execute. Let''s try it out:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Well... the tests have failed, yes... but not in a controllable way. Why is
    this? We don't have any implementation yet, so no `Success` or `Fail` functions
    are being executed either. Our WaitGroup is waiting forever for a call to the `Done()`
    method that will never arrive, so it can't continue and finish the test. That's
    the meaning of *All Goroutines are asleep - deadlock!*. In our specific example,
    it would mean *Nobody is going to call Done(), so we are dead!*.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Thanks to the Go compiler and the runtime executor, we can detect deadlocks
    easily. Imagine if Go runtime couldn't detect deadlocks--we would be effectively
    stuck in a blank screen without knowing what was wrong.
  prefs: []
  type: TYPE_NORMAL
- en: So how can we solve this? Well, an easy way would be with a timeout that calls
    the `Done()` method after waiting a while for completion. For this code, it's
    safe to wait for 1 second because it's not doing long-running operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will declare a `timeout` function within our `test` file that waits for
    a second, then prints a message, sets the test as failed, and lets the WaitGroup
    continue by calling its `Done()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The final look of each subtest is similar to our previous example of the `"Success
    result"`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see what happens when we execute our tests again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Our tests failed, but in a controlled way. Look at the end of the `FAIL` lines--notice
    how the elapsed time is 1 second because it has been triggered by the timeout,
    as we can see in the logging messages.
  prefs: []
  type: TYPE_NORMAL
- en: It's time to pass to the implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: According to our tests, the implementation must take a `SuccessFunc`, a `FailFunc`,
    and an `ExecuteStringFunc` function in a chained fashion within the `MaybeString`
    type and launches the `ExecuteStringFunc` function asynchronously to call `SuccessFunc`
    or `FailFunc` functions according to the returned result of the `ExecuteStringFunc`
    function.
  prefs: []
  type: TYPE_NORMAL
- en: 'The chain is implemented by storing the functions within the type and returning
    the pointer to the type. We are talking about our previously declared type methods,
    of course:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: We needed two fields to store the `SuccessFunc` and `FailFunc` functions, which
    are named the `successFunc` and `failFunc` fields respectively. This way, calls
    to the `Success` and `Fail` methods simply store their incoming functions to our
    new fields. They are simply setters that also return the pointer to the specific
    `MaybeString` value. These type methods take a pointer to the `MaybeString` structure,
    so don't forget to put "`*`" on `MaybeString` after the `func` declaration.
  prefs: []
  type: TYPE_NORMAL
- en: Execute takes the `ExecuteStringFunc` method and executes it asynchronously.
    This seems quite simple with a Goroutine, right?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Looks quite simple because it is simple! We launch the Goroutine that executes
    the `f` method (an `ExecuteStringFunc`) and takes its result--maybe a string and
    maybe an error. If an error is present, we call the field `failFunc` in our `MaybeString`
    structure. If no error is present, we call the `successFunc` field. We use a Goroutine
    to delegate a function execution and error handling so our Goroutine doesn't have
    to do it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s run unit tests now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Great! Look how the execution time is now nearly zero, so our timeouts have
    not been executed (actually, they were executed, but the tests already finished
    and their result was already stated).
  prefs: []
  type: TYPE_NORMAL
- en: What's more, now we can use our `MaybeString` type to asynchronously execute
    any type of function that accepts nothing and returns a string or an error. A
    function that accepts nothing seems a bit useless, right? But we can use closures
    to introduce a context into this type of function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s write a `setContext` function that takes a string as an argument and
    returns an `ExecuteStringFunc` method that returns the previous argument with
    the suffix `Closure!`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'So, we can write a new test that uses this closure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The `setContext` function returns an `ExecuteStringFunc` method it can pass
    directly to the `Execute` function. We call the `setContext` function with an
    arbitrary text that we know will be returned.
  prefs: []
  type: TYPE_NORMAL
- en: Let's execute our tests again. Now everything has to go well!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: It gave us an OK too. Closure test shows the behavior that we explained before.
    By taking a message `"Hello"` and appending it with something else (`"Closure!"`),
    we can change the context of the text we want to return. Now scale this to a HTTP
    `GET` call, a call to a database, or anything you can imagine. It will just need
    to end by returning a string or an error. Remember, however, that everything within
    the `setContext` function but outside of the anonymous function that we are returning
    is not concurrent, and will be executed asynchronously before calling execute,
    so we must try to put as much logic as possible within the anonymous function.
  prefs: []
  type: TYPE_NORMAL
- en: Putting the Future together
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have seen a good way to achieve asynchronous programming by using a function
    type system. However, we could have done it without functions by setting an interface
    with `Success`, `Fail`, and `Execute` methods and the types that satisfy them,
    and using the Template pattern to execute them asynchronously, as we have previously
    seen in this chapter. It is up to you!
  prefs: []
  type: TYPE_NORMAL
- en: Pipeline design pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The third and final pattern we will see in this chapter is the Pipeline pattern.
    You will use this pattern heavily in your concurrent structures, and we can consider
    it one of the most useful too.
  prefs: []
  type: TYPE_NORMAL
- en: Description
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We already know what a pipeline is. Every time that we write any function that
    performs some logic, we are writing a pipeline: If *this* then *that*, or else
    *something else*. Pipelines pattern can be made more complex by using a few functions
    that call to each other. They can even get looped in their out execution.'
  prefs: []
  type: TYPE_NORMAL
- en: The Pipeline pattern in Go works in a similar fashion, but each step in the
    Pipeline will be in a different Goroutine and communication, and synchronizing
    will be done using channels.
  prefs: []
  type: TYPE_NORMAL
- en: Objectives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When creating a Pipeline, we are mainly looking for the following benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: We can create a concurrent structure of a multistep algorithm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can exploit the parallelism of multicore machines by decomposing an algorithm
    in different Goroutines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, just because we decompose an algorithm in different Goroutines doesn't
    necessarily mean that it will execute the fastest. We are constantly talking about
    CPUs, so ideally the algorithm must be CPU-intensive to take advantage of a concurrent
    structure. The overhead of creating Goroutines and channels could make an algorithm
    smaller.
  prefs: []
  type: TYPE_NORMAL
- en: A concurrent multi-operation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We are going to do some math for our example. We are going to generate a list
    of numbers starting with 1 and ending at some arbitrary number N. Then we will
    take each number, power it to 2, and sum the resulting numbers to a unique result.
    So, if *N=3*, our list will be [1,2,3]. After powering them to 2, our list becomes
    [1,4,9]. If we sum the resulting list, the resulting value is 14.
  prefs: []
  type: TYPE_NORMAL
- en: Acceptance criteria
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Functionally speaking, our Pipeline pattern needs to raise to the power of
    2 every number and then sum them all. It will be divided into a number generator
    and two operations, so:'
  prefs: []
  type: TYPE_NORMAL
- en: Generate a list from 1 to N where N can be any integer number.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Take each number of this generated list and raise it to the power of 2.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sum each resulting number into a final result and return it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Beginning with tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will create only one function that will manage everything. We will call
    this function `LaunchPipeline` to simplify things. It will take an integer as
    an argument, which will be our N number, the number of items in our list. The
    declaration in the implementation file looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'In our test file, we will create a table of tests by using a slice of slices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Our table is a slice of slices of integer types. On each slice, the first integer
    represents the list size and the second position represents the item within the
    list. It is, effectively, a matrix. When passing 3, it must return 14\. When passing
    5, it must return 55\. Then we have to iterate over the table and pass the first
    index of each array to the `LaunchPipeline` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Using `range`, we get every row in the matrix . Each row is contained in a
    temporary variable called `test`. `test[0]` represents `N` and `test[1]` the expected
    result. We compare the expected result with the returning value of the `LaunchPipeline`
    function. If they aren''t the same, the test fails:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The key for our implementation is to separate every operation in a different
    Goroutine and connect them with channels. The `LaunchPipeline` function is the
    one that orchestrates them all, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Implementation](img/00042.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The operation consist of three steps: generate a list of numbers, raise them
    to the power of 2, and add the resulting numbers.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Each step in this Pipeline pattern will have the following structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'This function represents a common step. Let''s dissect it in the same order
    that the Go scheduler will probably take to execute it:'
  prefs: []
  type: TYPE_NORMAL
- en: The `functionName` function will commonly receive a channel to take values from
    (`in <-chan int`). We call it the `in` function, as in the word incoming. We can't
    send values through it within the scope of this function; that's why the arrow
    points `out` of the keyword `chan`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `functionName` function returns a channel (`<-chan in`) that the function
    caller will only be allowed to take values from (again, represented by the arrow
    pointing `out` of the keyword `chan`). This also means that any value that goes
    through that channel must be generated within the scope of the function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the first line of the function, we create a channel called `out` that will
    be the return of the function (*point 2* in this list).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, we will launch a new Goroutine. Its scope will enter into play after returning
    this function, so let's continue.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We return the previously created `out` channel.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Eventually, after finishing the execution of the function and returning the
    channel `out`, the Goroutine executes. It will take values from the `in` channel
    until it's closed. So the caller of this function is responsible for closing this
    channel, otherwise the Goroutine will never end!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When the `in` channel is closed, the for loop finishes and we close the `out`
    channel. Any Goroutine making use of this channel will not receive any new values
    since the last that was sent.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The only step that doesn''t completely fit this approach is the first step
    that receives a number, representing the upper threshold on the list instead of
    a channel of incoming values. So, if we code this operation for each step in our
    pipeline, the final diagram looks more like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Implementation](img/00043.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Although the idea is exactly the same, now we can see that it's the function
    `LaunchPipeline` that is the one that is going to be receiving channels and sending
    them back to the next step in the Pipeline. Using this diagram, we can clearly
    see the flow of the pipeline creation by following the numbers of the arrows.
    A solid arrow represents a function call and a dashed arrow a channel.
  prefs: []
  type: TYPE_NORMAL
- en: Let's look a little more closely at the code.
  prefs: []
  type: TYPE_NORMAL
- en: The list generator
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The first step in the operation is list generation. The list starts at `1`
    and we will receive an integer representing the higher threshold. We have to pass
    each number in the list to the next step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'As we mentioned earlier, this is the pattern that we will follow in each step:
    create a channel, launch the Goroutine that will send the data through the channel,
    and immediately return the channel. This Goroutine will iterate from 1 to the
    max argument, which is the higher threshold for our list, and send each number
    through the channel. After sending every number, the channel is closed so that
    no more data can be sent through it, but the data already buffered can be retrieved.'
  prefs: []
  type: TYPE_NORMAL
- en: Raising numbers to the power of 2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The second step will take every incoming number from the first step''s channel
    (that is taken from the arguments) and raise it to the power of 2\. Every result
    must be sent to the third step using a new channel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'We use the same pattern again: create a channel and launch the Goroutine while
    we return the created channel.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `for-range` loop keeps taking values from a channel indefinitely until the
    channel is closed.
  prefs: []
  type: TYPE_NORMAL
- en: Final reduce operation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The third and final step receives every number from the second step and keeps
    adding them to a local value until the connection channel is closed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: The function sum also takes a channel as an argument (the one returned from
    *step 2*). It also follows the same pattern of creating a channel, launching the
    Goroutine, and returning a channel. Goroutine keeps adding values to a variable
    called `sum` until the `in` channel is closed. When the `in` channel is closed,
    the value of sum is sent to the `out` channel, and it's immediately closed.
  prefs: []
  type: TYPE_NORMAL
- en: Launching the Pipeline pattern
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Finally, we can implement the `LaunchPipeline` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The function `generator` first returns the channel that is passed to the power
    function. The `power` function returns the second channel that is passed to the `sum`
    function. The function `sum` finally returns the first channel that will receive
    a unique value, the result. Let''s try to test this now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Awesome! It''s worth mentioning that the `LaunchPipeline` function doesn''t
    need to allocate every channel, and can be rewritten like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: The result of the `generator` function is passed directly to the `power` function
    and the result of `power` to `sum` functions.
  prefs: []
  type: TYPE_NORMAL
- en: Final words on the Pipeline pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With the Pipeline pattern, we can create really complex concurrent workflows
    in a very easy way. In our case, we created a linear workflow, but it could also
    have conditionals, pools, and fan-in and fan-out behavior. We will see some of
    these in the following chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Concurrency design patterns are a step forward in difficulty, and take some
    time to grasp. Our biggest mistake as concurrent programmers is thinking in terms
    of parallelism (How can I make this parallel? or How can I run this in a new thread?)
    instead of in terms of concurrent structures.
  prefs: []
  type: TYPE_NORMAL
- en: Pure functions (functions that will always produce the same output (given the
    same input) without affecting anything outside their scope) help in this design.
  prefs: []
  type: TYPE_NORMAL
- en: Concurrent programming requires practice and more practice. Go makes it easy
    once you understand the basic primitives. Diagrams can help you to understand
    the possible flow of data, but the best way of understanding it all is simply
    to practice.
  prefs: []
  type: TYPE_NORMAL
- en: In the following chapter, we will see how to use a pool of pipeline workers
    to do some work instead of having a unique pipeline. Also, we will learn how to
    create the publish/subscriber pattern in a concurrent structure and see how different
    the same pattern can be when we build by using concurrency.
  prefs: []
  type: TYPE_NORMAL
