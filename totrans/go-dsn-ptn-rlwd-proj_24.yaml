- en: Chapter 10. Concurrency Patterns - Workers Pool and Publish/Subscriber Design
    Patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have reached the final chapter of the book, where we will discuss a couple
    of patterns with concurrent structures. We will explain every step in detail so
    you can follow the examples carefully.
  prefs: []
  type: TYPE_NORMAL
- en: The idea is to learn about patterns to design concurrent applications in idiomatic
    Go. We are using channels and Goroutines heavily, instead of locks or sharing
    variables.
  prefs: []
  type: TYPE_NORMAL
- en: We will look at one way to develop a pool of workers. This is useful to control
    the number of Goroutines in an execution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second example is a rewrite of the Observer pattern, which we saw on [Chapter
    7](part0134_split_000.html#3VPBC2-9c484ed022e64a0fb0e1aebf8e05d4fd "Chapter 7. Behavioral
    Patterns - Visitor, State, Mediator, and Observer Design Patterns"), *Behavioral
    Patterns - Visitor, State, Mediator, and Observer Design Patterns*, written with
    a concurrent structure. With this example we'll dig a bit more into the concurrent
    structures and look at how they can differ from a common approach.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Workers pool
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One problem we may face with some of the previous approaches to concurrency
    is their unbounded context. We cannot let an app create  an unlimited amount of
    Goroutines. Goroutines are light, but the work they perform could be very heavy.
    A workers pool helps us to solve this problem.
  prefs: []
  type: TYPE_NORMAL
- en: Description
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With a pool of workers, we want to bound the amount of Goroutines available
    so that we have a deeper control of the pool of resources. This is easy to achieve
    by creating a channel for each worker and having workers with either an idle or
    busy status. The task can seem daunting, but it's not at all.
  prefs: []
  type: TYPE_NORMAL
- en: Objectives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Creating a Worker pool is all about resource control: CPU, RAM, time, connections,
    and so on. The workers pool design pattern helps us to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Control access to shared resources using quotas
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a limited amount of Goroutines per app
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide more parallelism capabilities to other concurrent structures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A pool of pipelines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous chapter, we saw how to work with a pipeline. Now we will launch
    a bounded number of them so that the Go scheduler can try to process requests
    in parallel. The idea here is to control the number of Goroutines, stop them gracefully
    when the app has finished, and maximize parallelism using a concurrent structure
    without race conditions.
  prefs: []
  type: TYPE_NORMAL
- en: The pipeline we will use is similar to the one we used in the previous chapter,
    where we were generating numbers, raising them to the power of 2, and summing
    the final results. In this case, we are going to pass strings to which we will
    append and prefix data.
  prefs: []
  type: TYPE_NORMAL
- en: Acceptance criteria
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In business terms, we want something that tells us that, worker has processed
    a request, a predefined ending, and incoming data parsed to uppercase:'
  prefs: []
  type: TYPE_NORMAL
- en: When making a request with a string value (any), it must be uppercase.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the string is uppercase, a predefined text must be appended to it. This
    text should not be uppercase.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With the previous result, the worker ID must be prefixed to the final string.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The resulting string must be passed to a predefined handler.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We haven't talked about how to do it technically, just what the business wants.
    With the entire description, we'll at least have workers, requests, and handlers.
  prefs: []
  type: TYPE_NORMAL
- en: Implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The very beginning is a request type. According to the description, it must
    hold the string that will enter the pipeline as well as the handler function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Where is the `return`? We have a `Data` field of type `interface{}` so we can
    use it to pass a string. By using an interface, we can reuse this type for a `string`,
    an `int`, or a `struct` data type. The receiver is the one who must know how to
    deal with the incoming interface.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Handler` field has the type `Request` handler, which we haven''t defined
    yet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: A request handler is any function that accepts an interface as its first argument,
    and returns nothing. Again, we see the `interface{}`, where we would usually see
    a string. This is one of the receivers we mentioned previously, which we'll need
    to cast the incoming result.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, when sending a request, we must fill it with some value in the `Data` field
    and implement a handler; for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The handler is defined by using a closure. We again check the type if the interface
    (and we defer the call to the `Done()` method at the end). In case of an improper
    interface, we simply print its contents and return. If the casting is OK, we also
    print them, but here is where we will usually do something with the result of
    the operation; we have to use type casting to retrieve the contents of the `interface{}`
    (which is a string). This must be done in every step in the pipeline, although
    it will introduce a bit of overhead.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we need a type that can handle `Request` types. Possible implementations
    are virtually infinite, so it is better to define an interface first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The `WorkerLauncher` interface must implement only the `LaunchWorker(chan Request)`
    method. Any type that implements this interface will have to receive a channel
    of `Request` type to satisfy it. This channel of the `Request` type is the single
    entrance point to the pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: The dispatcher
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now, to launch workers in parallel and handle all the possible incoming channels,
    we''ll need something like a dispatcher:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: A `Dispatcher` interface can launch an injected `WorkerLaunchers` type in its
    own `LaunchWorker` method. The `Dispatcher` interface must use the `LaunchWorker`
    method of any of the `WorkerLauncher` types to initialize a pipeline. This way
    we can reuse the `Dispatcher` interface to launch many types of `WorkerLaunchers`.
  prefs: []
  type: TYPE_NORMAL
- en: When using `MakeRequest(Request)`, the `Dispatcher` interface exposes a nice
    method to inject a new `Request` into the workers pool.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the user must call stop when all Goroutines must be finished. We must
    handle graceful shutdown in our apps, and we want to avoid Goroutine leaks.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have enough interfaces, so let''s start with the dispatcher which is a bit
    less complicated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Our `dispatcher` structure stores a channel of `Request` type in one of its
    fields. This is going to be the single point of entrance for requests in any pipeline.
    We said that it must implement three methods, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In this example, the `Dispatcher` interface doesn't need to do anything special
    to itself before launching a worker, so the `LaunchWorker` method on the `Dispatcher`
    simply executes the `LaunchWorker` method of the incoming `WorkerLauncher,`which
    also has a `LaunchWorker` method to initiate itself. We have previously defined
    that a `WorkerLauncher` type needs at least an ID and a channel for incoming requests,
    so that's what we are passing through.
  prefs: []
  type: TYPE_NORMAL
- en: It may seem unnecessary to implement the `LaunchWorker` method in the `Dispatcher`
    interface. In different scenarios, it could be interesting to save running worker
    IDs in the dispatcher to control which ones are up or down; the idea is to hide
    launching implementation details. In this case, the `Dispatcher` interface is
    merely acting as a Facade design pattern hiding some implementation details from
    the user.
  prefs: []
  type: TYPE_NORMAL
- en: The second method is `Stop`. It closes the incoming requests channel, provoking
    a chain reaction. We saw in the pipeline example that, when closing the incoming
    channel, each for-range loop within the Goroutines breaks and the Goroutine is
    also finished. In this case, when closing a shared channel, it will provoke the
    same reaction, but in every listening Goroutine, so all pipelines will be stopped.
    Cool, huh?
  prefs: []
  type: TYPE_NORMAL
- en: 'Request implementation is very simple; we just pass the request in the argument
    to the channel of incoming requests. The Goroutine will block there forever until
    the opposite end of the channel retrieves the request. Forever? That seems like
    a lot if something happens. We can introduce a timeout, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'If you remember from previous chapters, we can use select to control which
    operation is performed over a channel. Like a `switch` case, just one operation
    can be executed. In this case, we have two different operations: sending and receiving.'
  prefs: []
  type: TYPE_NORMAL
- en: The first case is a sending operation--try to send this, and it will block there
    until someone takes the value in the opposite side of the channel. Not a huge
    improvement, then. The second case is a receiving operation; it will be triggered
    after 5 seconds if the upper request can't be sent successfully, and the function
    will return. It would be very convenient to return an error here, but to make
    things simple, we will leave it empty
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, in the dispatcher, for convenience, we will define a `Dispatcher`
    creator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: By using this function instead of creating the dispatcher manually, we can simply
    avoid small mistakes, such as forgetting to initialize the channel field. As you
    can see, the `b` argument refers to the buffer size in the channel.
  prefs: []
  type: TYPE_NORMAL
- en: The pipeline
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'So, our dispatcher is done and we need to develop the pipeline described in
    the acceptance criteria. First, we need a type to implement the `WorkerLauncher`
    type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The `PreffixSuffixWorker` variable stores an ID, a string to prefix, and another
    string to suffix the incoming data of the `Request` type. So, the values to prefix
    and append will be static in these fields, and we will take them from there.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will implement the `LaunchWorker` method later and begin with each step
    in the pipeline. According to *first acceptance criteria*, the incoming string
    must be uppercase. So, the uppercase method will be the first step in our pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Good. As in the previous chapter, a step in the pipeline accepts a channel of
    incoming data and returns a channel of the same type. It has a very similar approach
    to the examples we developed in the previous chapter. This time, though, we aren't
    using package functions, and uppercase is part of the `PreffixSuffixWorker` type
    and the incoming data is a `struct` instead of an `int`.
  prefs: []
  type: TYPE_NORMAL
- en: The `msg` variable is a `Request` type and it will have a handler function and
    data in the form of an interface. The `Data` field should be a string, so we type
    cast it before using it. When type casting a value, we will receive the same value
    with the requested type and a `true` or `false` flag (represented by the `ok`
    variable). If the `ok` variable is `false`, the cast could not be done and we
    won't throw the value down the pipeline. We stop this `Request` here by sending
    a `nil` to the handler (which will also provoke a type-casting error).
  prefs: []
  type: TYPE_NORMAL
- en: Once we have a nice string in the `s` variable, we can uppercase it and store
    it again in the `Data` field to send down the pipeline to the next step. Be aware
    that the value will be sent as an interface again, so the next step will need
    to cast it again. This is the downside of using this approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the first step done, let''s continue with the second. According to the
    *second acceptance criteria* now, a predefined text must be appended. This text
    is the one stored in the `suffixS` field:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The `append` function has the same structure as the `uppercase` function. It
    receives and returns a channel of incoming requests, and launches a new Goroutine
    that iterates over the incoming channel until it is closed. We need to type cast
    the incoming value, as mentioned previously.
  prefs: []
  type: TYPE_NORMAL
- en: In this step in the pipeline the incoming string is uppercase (after doing a
    type assertion). To append any text to it, we just need to use the `fmt.Sprintf()`
    function, as we have done many times before, which formats a new string with the
    provided data. In this case, we pass the value of the `suffixS` field as the second
    value, to append it to the end of the string.
  prefs: []
  type: TYPE_NORMAL
- en: 'Just the last step in the pipeline is missing, the prefix operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: What's calling your attention in this function? Yes, it doesn't return any channel
    now. We could have done this entire pipeline in two ways. I suppose you have realized
    that we have used a `Future` handler function to execute with the final result
    in the pipeline. A second approach would be to pass a channel to return the data
    back to its origin. In some cases, a Future would be enough, while in others it
    could be more convenient to pass a channel so that it can be connected to a different
    pipeline (for example).
  prefs: []
  type: TYPE_NORMAL
- en: In any case, the structure of a step in a pipeline must be very familiar to
    you already. We cast the value, check the result of the casting, and send nil
    to the handler if anything went wrong. But, in case everything was OK, the last
    thing to do is to format the text again to place the `prefixS` field at the beginning
    of the text, to send the resulting string back to the origin by calling the request's
    handler.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, with our worker almost finished, we can implement the `LaunchWorker` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: That's all for workers! We simply pass the returning channels to the next steps
    in the Pipeline, as we did in the previous chapter. Remember that the pipeline
    is executed from inside to outside of the calls. So, what's the order of execution
    of any incoming data to the pipeline?
  prefs: []
  type: TYPE_NORMAL
- en: The data enters the pipeline through the Goroutine launched in the `uppercase`
    method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, it goes to the Goroutine launched in `append`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, in enters the Goroutine launched in `prefix` method, which doesn't
    return anything but executes the handler after prefixing the incoming string with
    more data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now we have a full pipeline and a dispatcher of pipelines. The dispatcher will
    launch as many instances of the pipelines as we want to route the incoming requests
    to any available worker.
  prefs: []
  type: TYPE_NORMAL
- en: If none of the workers takes the request within 5 seconds, the request is lost.
  prefs: []
  type: TYPE_NORMAL
- en: Let's use this library in a small app.
  prefs: []
  type: TYPE_NORMAL
- en: An app using the workers pool
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will launch three workers of our defined pipeline. We use the `NewDispatcher`
    function to create the dispatcher and the channel that will receive all requests.
    This channel has a fixed buffer, which will be able to store up to 100 incoming
    messages before blocking:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we will launch the workers by calling the `LaunchWorker` method in the
    `Dispatcher` interface three times with an already filled `WorkerLauncher` type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Each `WorkerLauncher` type is an instance of `PreffixSuffixWorker`. The prefix
    will be a small text showing the worker ID and the suffix text `world`.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, we have three workers with three Goroutines, each running concurrently
    and waiting for messages to arrive:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We will make 10 requests. We also need a WaitGroup to properly synchronize
    the app so that it doesn''t exit too early. You can find yourself using WaitGroups
    quite a lot when dealing with concurrent applications. For 10 requests, we''ll
    need to wait for 10 calls to the `Done()` method, so we call the `Add()` method
    with a *delta* of 10\. It''s called delta because you can also pass a -5 later
    to leave it in five requests. In some situations, it can be useful:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: To make requests, we will iterate a `for` loop. First, we create a `Request`
    using the function `NewStringRequest` that we wrote at the beginning of the Implementation
    section. In this value, the `Data` field will be the text we'll pass down the
    pipeline, and it will be the text that is "in the middle" of the appending and
    suffixing operation. In this case, we will send the message number and the word
    `hello`.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have a request, we call the `MakeRequest` method with it. After all
    requests have been done, we stop the dispatcher that, as explained previously,
    will provoke a chain reaction that will stop all Goroutines in the pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we wait for the group so that all calls to the `Done()` method are
    received, which signals that all operations have been finished. It''s time to
    try it out:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s analyze the first message:'
  prefs: []
  type: TYPE_NORMAL
- en: 'This would be zero, so the message sent is `(Msg_id: 0) -> Hello`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Then, the text is uppercased, so now we have `(MSG_ID: 0) -> HELLO`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After uppercasing an append operation with the text `world` (note the space
    at the beginning of the text) is done. This will give us the text `(MSG_ID: 0)
    -> HELLO World`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Finally, the text `WorkerID: 1` (in this case, the first worker took the task,
    but it could be any of them) is appended to the text from step 3 to give us the
    full returned message, `WorkerID: 1 -> (MSG_ID: 0) -> HELLO World`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: No tests?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Concurrent applications are difficult to test, especially if you are doing
    networking operations. It can be difficult, and code can change a lot just to
    test it. In any case, it is not justifiable to not perform tests. In this case,
    it is not especially difficult to test our small app. Create a test and copy/paste
    the contents of the `main` function there:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we have to rewrite our handler to test that the returned contents are the
    ones we are expecting. Go to the `for` loop to modify the function that we are
    passing as a handler on each `Request`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: We are going to use regular expressions to test the business. If you are not
    familiar with regular expressions, they are a quite powerful feature that help
    you to match content within a string. If you remember in our exercises when we
    were using the `strings` package. `Contains` is the function to find a text inside
    a string. We can also do it with regular expressions.
  prefs: []
  type: TYPE_NORMAL
- en: The problem is that regular expressions are quite expensive and consume a lot
    of resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are using the `Match` function of the `regexp` package to provide a template
    to match. Our template is `WorkerID\: \d* -> \(MSG_ID: \d\) -> [A-Z]*\sWorld`
    (without quotes). Specifically, it describes the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A string that has the content `WorkerID: \d* -> (MSG_ID: \d*", here "\d*` indicates
    any digit written zero or more times, so it will match `WorkerID: 10 -> (MSG_ID:
    1"` and `"WorkerID: 1 -> (MSG_ID: 10`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"\) -> [A-Z]*\sWorld"` (parentheses must be escaped using backslashes). "`*`"
    means any uppercase character written zero or more times, so `"\s"` is a white
    space and it must finish with the text `World`, so `) -> HELLO World"` will match,
    but `) -> Hello World"` won''t, because `"Hello` must be all uppercase.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Running this test gives us the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Not bad, but we aren't testing that code is being executed concurrently, so
    this is more a business test than a unit test. Concurrency testing would force
    us to write the code in a completely different manner to check that it is creating
    the proper amount of Goroutines and the pipeline is following the expected workflow.
    This is not bad, but it's quite complex, and outside of the context of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping up the Worker pool
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With the workers pool, we have our first complex concurrent application that
    can be used in real-world production systems. It also has room to improve, but
    it is a very good design pattern to build concurrent bounded apps.
  prefs: []
  type: TYPE_NORMAL
- en: It is key that we always have the number of Goroutines that are being launched
    under control. While it's easy to launch thousands to achieve more parallelism
    in an app, we must be very careful that they don't have code that can hang them
    in an infinite loop, too.
  prefs: []
  type: TYPE_NORMAL
- en: With the workers pool, we can now fragment a simple operation in many parallel
    tasks. Think about it; this could achieve the same result with one simple call
    to `fmt.Printf`, but we have done a pipeline with it; then, we launched few instances
    of this pipeline and finally, distributed the workload between all those pipes.
  prefs: []
  type: TYPE_NORMAL
- en: Concurrent Publish/Subscriber design pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will implement the Observer design pattern that we showed
    previously on Behavioral patterns, but with a concurrent structure and thread
    safety.
  prefs: []
  type: TYPE_NORMAL
- en: Description
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you remember from the previous explanation, the Observer pattern maintains
    a list of observers or subscribers that want to be notified of a particular event.
    In this case, each subscriber is going to run in a different Goroutine as well
    as the publisher. We will have new problems with building this structure:'
  prefs: []
  type: TYPE_NORMAL
- en: Now, the access to the list of subscribers must be serialized. If we are reading
    the list with one Goroutine, we cannot be removing a subscriber from it or we
    will have a race.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When a subscriber is removed, the subscriber's Goroutine must be closed too,
    or it will keep iterating forever and we will run into Goroutine leaks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When stopping the publisher, all subscribers must stop their Goroutines, too.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Objectives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The objectives of this publish/subscriber are the same as the ones we wrote
    on the Observer pattern. The difference here is the way we will develop it. The
    idea is to make a concurrent structure to achieve the same functionality, which
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Providing an event-driven architecture where one event can trigger one or more
    actions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uncoupling the actions that are performed from the event that triggers them
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Providing more than one source event that triggers the same action
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The idea is to uncouple senders from receivers, hiding from the sender the identity
    of the receivers that will process its event, and hiding the receivers from the
    number of senders that can communicate with them.
  prefs: []
  type: TYPE_NORMAL
- en: In particular, if I develop a click in a button in some application, it could
    do something (such as log us in somewhere). Weeks later, we might decide to make
    it show a popup, too. If, every time we want to add some functionality to this
    button, we have to change the code where it handles the click action, that function
    will become huge and not very portable to other projects. If we use a publisher
    and one observer for every action, the click function only needs to publish one
    single event using a publisher, and we will just write subscribers to this event
    every time we want to improve the functionality. This is especially important
    in applications with user interfaces where many things to do in a single UI action
    can slow the responsiveness of an interface, completely destroying the user experience.
  prefs: []
  type: TYPE_NORMAL
- en: By using a concurrent structure to develop the Observer pattern, a UI cannot
    feel all the tasks that are being executed in the background if a concurrent structure
    is defined and the device allows us to execute parallel tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Example - a concurrent notifier
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will develop a *notifier* similar to the one we developed in  [Chapter 7](part0134_split_000.html#3VPBC2-9c484ed022e64a0fb0e1aebf8e05d4fd
    "Chapter 7. Behavioral Patterns - Visitor, State, Mediator, and Observer Design
    Patterns"), *Behavioral Patterns - Visitor, State, Mediator, and Observer Design
    Patterns*. This is to focus on the concurrent nature of the structure instead
    of detailing too many things that have already been explained. We have developed
    an observer already, so we are familiar with the concept.
  prefs: []
  type: TYPE_NORMAL
- en: This particular notifier will work by passing around `interface{}` values, like
    in the workers pool example. This way, we can use it for more than a single type
    by introducing some overhead when casting on the receiver.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will work with two interfaces now. First, a `Subscriber` interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Like in the previous example, it must have a `Notify` method in the `Subscriber`
    interface of new events. This is the `Notify` method that accepts an `interface{}`
    value and returns an error. The `Close()` method, however, is new, and it must
    trigger whatever actions are needed to stop the Goroutine where the subscriber
    is listening for new events.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second and final interface is the `Publisher` interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The `Publisher` interface has the same actions we already know for a publisher
    but to work with channels. The `AddSubscriberCh` and `RemoveSubscriberCh` methods
    accepts a `Subscriber` interface (any type that satisfies the `Subscriber` interface).
    It must have a method to publish messages and a `Stop` method to stop them all
    (publisher and subscriber Goroutines)
  prefs: []
  type: TYPE_NORMAL
- en: Acceptance criteria
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Requirements between this example and the one in the [Chapter 7](part0134_split_000.html#3VPBC2-9c484ed022e64a0fb0e1aebf8e05d4fd
    "Chapter 7. Behavioral Patterns - Visitor, State, Mediator, and Observer Design
    Patterns") *, Behavioral patterns - Visitor, State, Mediator, and Observer Design
    Patterns* must not change. The objective in both examples is the same so the requirements
    must also be the same. In this case, our requirements are technical, so we actually
    need to add some more acceptance criteria:'
  prefs: []
  type: TYPE_NORMAL
- en: We must have a publisher with a `PublishingCh` method that returns a channel
    to send messages through and triggers a `Notify` method on every observer subscribed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We must have a method to add new subscribers to the publisher.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We must have a method to remove new subscribers from the publisher.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We must have a method to stop a subscriber.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We must have a method to stop a `Publisher` interface that will also stop all
    subscribers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: All inter Goroutine communication must be synchronized so that no Goroutine
    is locked waiting for a response. In such cases, an error is returned after the
    specified timeout period has passed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Well, these criteria seem quite daunting. We have left out some requirements
    that would add even more complexity, such as removing non-responding subscribers
    or checks to monitor that the publisher Goroutine is always on.
  prefs: []
  type: TYPE_NORMAL
- en: Unit test
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have mentioned previously that testing concurrent applications can be difficult.
    With the correct mechanism, it still can be done, so let's see how much we can
    test without big headaches.
  prefs: []
  type: TYPE_NORMAL
- en: Testing subscriber
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Starting with subscribers, which seem to have a more encapsulated functionality,
    the first subscriber must print incoming messages from the publisher to an `io.Writer`
    interface. We have mentioned that the subscriber has an interface with two methods,
    `Notify(interface{}) error` and the `Close()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'OK. This is going to be our `writer_sub.go` file. Create the corresponding
    test file, called the `writer_sub_test.go` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the first problem we have is that the functionality prints to the `stdout`,
    so there''s no return value to check. We can solve it in three ways:'
  prefs: []
  type: TYPE_NORMAL
- en: Capturing the `stdout` method.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Injecting an `io.Writer` interface to print to it. This is the preferred solution,
    as it makes the code more manageable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Redirecting the `stdout` method to a different file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We''ll take the second approach. Redirection is also a possibility. The `os.Stdout`
    is a pointer to an `os.File` type, so it involves replacing this file with one
    we control, and reading from it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The `NewWriterSubscriber` subscriber isn''t defined yet. It must help in the
    creation of this particular subscriber, returning a type that satisfies the `Subscriber`
    interface, so let''s quickly declare it on the `writer_sub.go` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Ideally, it must accept an ID and an `io.Writer` interface as the destination
    for its writes. In this case, we need a custom `io.Writer` interface for our test,
    so we''ll create a `mockWriter` on the `writer_sub_test.go` file for it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The `mockWriter` structure will accept a `testingFunc` as one of its fields.
    This `testingFunc` field accepts a string that represents the bytes written to
    the `mockWriter` structure. To implement an `io.Writer` interface, we need to
    define a `Write([]byte) (int, error)` method. In our definition, we pass the contents
    of `p` as a string (remember that we always need to return the bytes read and
    an error, or not, on every `Write` method). This approach delegates the definition
    of `testingFunc` to the scope of the test.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to call the `Notify` method on the `Subcriber` interface, which
    must write on the `io.Writer` interface like the `mockWriter` structure. So, we''ll
    define the `testingFunc` of a `mockWriter` structure before calling the `Notify`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: We will send the `Hello` message. This also means that whatever the `Subscriber`
    interface does, it must eventually print the `Hello` message on the provided `io.Writer`
    interface.
  prefs: []
  type: TYPE_NORMAL
- en: So if, eventually, we receive a string on the testing function, we'll need to
    synchronize with the `Subscriber` interface to avoid race conditions on tests.
    That's why we use so much `WaitGroup`. It's a very handy and easy-to-use type
    to handle this scenario. One `Notify` method call will need to wait for one call
    to the `Done()` method, so we call the `Add(1)` method (with one unit).
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, the `NewWriterSubscriber` function must return an interface, so we
    need to type assert it to the type we are working with during the test, in this
    case, the `stdoutPrinter` method. I have omitted error checking when doing the
    casting on purpose, just to make things easier. Once we have a `writerSubscriber`
    type, we can access its `Write` field to replace it with the `mockWriter` structure.
    We could have directly passed an `io.Writer` interface on the `NewWriterSubscriber`
    function, but we wouldn't cover the scenario where a nil object is passed and
    it sets the `os.Stdout` instance to a default value.
  prefs: []
  type: TYPE_NORMAL
- en: So, the testing function will eventually receive a string containing what was
    written by the subscriber. We just need to check if the received string, the one
    that the `Subscriber` interface will receive, prints the word `Hello` at some
    point and nothing better that `strings.Contains` function for it. Everything is
    defined under the scope of the testing function, so we can use the value of the
    `t` object to also signal that the test has failed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have done the checking, we must call to the `Done()` method to signal
    that we have already tested the expected result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: We must actually call the `Notify` and `Wait` methods for the call to the `Done`
    method to check that everything was correct.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Did you realize that we have defined the behavior on tests more or less in reverse?
    This is very common in concurrent apps. It can be confusing sometimes, as it becomes
    difficult to know what a function could be doing if we can't follow calls linearly,
    but you get used to it quite quickly. Instead of thinking "it does this, then
    this, then that," it's more like "this will be called when executing that." This
    is also because the order of execution in a concurrent application is unknown
    until some point, unless we use synchronization primitives (such as WaitGroups
    and channels) to pause execution at certain moments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s execute the test for this type now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'It has exited fast but it has failed. Actually, the call to the `Done()` method
    has not been executed, so it would be nice to change the last part of our test
    to this instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Now, it doesn't stop execution because we are calling the `Error` function instead
    of the `Fatal` function, but we call the `Done()` method and the test ends where
    we prefer it to end, after the `Wait()` method is called. You can try to run the
    tests again, but the output will be the same.
  prefs: []
  type: TYPE_NORMAL
- en: Testing publisher
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We have already seen a `Publisher` interface and the type that will satisfy
    which was the `publisher` type. The only thing we know for sure is that it will
    need some way to store subscribers, so it will at least have a `Subscribers` slice:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'To test the `publisher` type, we will also need a mock for the `Subscriber`
    interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: The `mockSubscriber` type must implement the `Subscriber` interface, so it must
    have a `Close()` and a `Notify(interface{}) error` method. We can embed an existing
    type that implements it, such as,  the `writerSubscriber`, and override just the
    method that is interesting for us, but we will need to define both, so we won't
    embed anything.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, we need to override the `Notify` and `Close` methods in this case to call
    the testing functions stored on the fields of the `mockSubscriber` type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'First of all, we will be sending messages through channels directly, this could
    lead to potential unwanted deadlocks so the first thing to define is a panic handler
    for cases such as, sending to close channels or no Goroutines listening on a channel.
    The message we will send to subscribers is `Hello`. So, each subscriber that has
    been received using the channel returned by the `AddSubscriberCh` method must
    receive this message. We will also use a *New* function to create Publishers,
    called `NewPublisher`. Change the `publisher.go` file now to write it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we''ll define the `mockSubscriber` to add it to the publisher list of known
    subscribers. Back to the `publisher_test.go` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: As usual, we start with a WaitGroup. First, testing the function in our subscriber
    defers a call to the `Done()` method at the end of its execution. Then it needs
    to type cast `msg` variable because it's coming as an interface. Remember that
    this way, we can use the `Publisher` interface with many types by introducing
    the overhead of the type assertion. This is done on line `s, ok := msg.(string)`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have type cast `msg` to a string, `s`, we just need to check if the
    value received in the subscriber is the same as the value we sent, or fail the
    test if not:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: We add the `mockSubscriber` type using the `AddSubscriberCh` method. We publish
    our message just after getting ready, by adding one to the `WaitGroup`, and just
    before setting the `WaitGroup` to wait so that the test doesn't continue until
    the `mockSubscriber` type calls the `Done()` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, we need to check if the number of the `Subscriber` interface has grown
    after calling the `AddSubscriberCh` method, so we''ll need to get the concrete
    instance of publisher on the test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Type assertion is our friend today! Once we have the concrete type, we can
    access the underlying slice of subscribers for the `Publisher` interface. The
    number of subscribers must be 1 after calling the `AddSubscriberCh` method once,
    or the test will fail. The next step is to check just the opposite--when we remove
    a `Subscriber` interface, it must be taken from this list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: The final step in our test is to stop the publisher so no more messages can
    be sent and all the Goroutines are stopped.
  prefs: []
  type: TYPE_NORMAL
- en: 'The test is finished, but we can''t run tests until the `publisher` type has
    all the methods implemented; this must be the final result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'With this empty implementation, nothing good can happen when running the tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Yes it has failed but, it's not a controlled fail at all. This was done on purpose
    to show a couple of things to be careful of in Go. First of all, the error produced
    in this test is a **fatal** error, which usually points to a bug in the code.
    This is important because while a **panic** error can be recovered, you cannot
    do the same with a fatal error.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, the error is telling us the problem: `goroutine 5 [chan send
    (nil chan)]`, a nil channel so it''s actually a bug in our code. How can we solve
    this? Well, this is also interesting.'
  prefs: []
  type: TYPE_NORMAL
- en: The fact that we have a `nil` channel is caused by the code we wrote to compile
    unit tests but this particular error won't be raised once the appropriate code
    is written (because we'll never return a nil channel in this case). We could return
    a channel that is never use we cause a fatal error with a deadlock, which wouldn't
    be any progress at all either.
  prefs: []
  type: TYPE_NORMAL
- en: An idiomatic way to solve it would be to return a channel and an error so that
    you can have an error package with a type implementing the `Error` interface that
    returns a specific error such as `NoGoroutinesListening` or `ChannelNotCreated`.
    We have already seen many of this implementations so we'll leave these as an exercise
    to the reader and we will move forward to maintain focus on the concurrent nature
    of the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Nothing surprising there, so we can move to the implementation phase.
  prefs: []
  type: TYPE_NORMAL
- en: Implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To recall, the `writerSubscriber` must receive messages that it will write on
    a type that satisfies the `io.Writer` interface.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, where do we start? Well, each subscriber will run its own Goroutine, and
    we have seen that the best method to communicate with a Goroutine is a channel.
    So, we will need a field with a channel in the `Subscriber` type. We can use the
    same approach as in pipelines to end with the `NewWriterSubscriber` function and
    the `writerSubscriber` type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: In the first step, if no writer is specified (the `out` argument is nil), the
    default `io.Writer` interface is `stdout`. Then, we create a new pointer to the
    `writerSubscriber` type with the ID passed in the first argument, the value of
    out (`os.Stdout`, or whatever came in the argument if it wasn't nil), and a channel
    called in to maintain the same naming as in previous examples.
  prefs: []
  type: TYPE_NORMAL
- en: Then we launch a new Goroutine; this is the launching mechanism we mentioned.
    Like in the pipelines, the subscriber will iterate over the `in` channel every
    time a new message is received and it will format its contents to a string, which
    also contains the ID of the current subscriber.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we learned previously, if the `in` channel is closed, the `for range` loop
    will stop and that particular Goroutine will finish, so the only thing we need
    to do in the `Close` method is to actually close the `in` channel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'OK, only the `Notify` method is left; the `Notify` method is a convenient method
    to manage a particular behavior when communicating, and we will use a pattern
    that is common in many calls:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'When communicating with a channel, there are two behavior that we must usually
    control: one is waiting time and the other is when the channel is closed. The
    deferred function actually works for any panicking error that can occur within
    the function. If the Goroutine panics, it will still execute the deferred function
    with the `recover()` method. The `recover()` method returns an interface of whatever
    the error was, so in our case, we set the returning variable error to the formatted
    value returned by `recover` (which is an interface). The `"%#v"` parameter gives
    us most of the information about any type when formatted to a string. The returned
    error will be ugly, but it will contain most of the information we can extract
    about the error. For a closed channel, for example, it will return "send on a
    closed channel". Well, this seems clear enough.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The second rule is about waiting time. When we send a value over a channel,
    we will be blocked until another Goroutine takes the value from it (it will happen
    the same with a filled buffered channel). We don''t want to get blocked forever,
    so we set a timeout period of one second by using a select handler. In short,
    with select we are saying: either you take the value in less than 1 second or
    I will discard it and return an error.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We have the `Close`, `Notify`, and `NewWriterSubscriber` methods, so we can
    try our test again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Much better now. The `Writer` has taken the mock writer we wrote on the test
    and has written to it the value we pass to the Notify method. At the same time,
    close has probably closed the channel effectively, because the `Notify` method
    is returning an error after calling the `Close` method. One thing to mention is
    that we can't check if a channel is closed or not without interacting with it;
    that's why we had to defer the execution of a closure that will check the contents
    of the `recover()` function in the `Notify` method.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the publisher
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: OK, the publisher will need also a launching mechanism, but the main problems
    to deal with are race conditions accessing the subscriber list. We can solve this
    issue with a Mutex object from the `sync` package but we have already seen how
    to use this so we will use channels instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'When using channels, we will need a channel for each action that can be considered
    dangerous--add a subscriber, remove a subscriber, retrieve the list of subscribers
    to `Notify` method them of a message, and a channel to stop all the subscribers.
    We also need a channel for incoming messages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Names are self-descriptive but, in short, subscribers maintain the list of subscribers;
    this is the slice that needs multiplexed access. The `addSubCh` instance is the
    channel to communicate with when you want to add a new subscriber; that's why
    it's a channel of subscribers. The same explanation applies to the `removeSubCh`
    channel, but this channel is to remove the subscriber. The `in` channel will handle
    incoming messages that must be broadcast to all subscribers. Finally, the stop
    channel must be called when we want to kill all Goroutines.
  prefs: []
  type: TYPE_NORMAL
- en: 'OK, let''s start with the `AddSubscriberCh`, `RemoveSubscriber` and `PublishingCh`
    methods, which must return the channel to add and remove subscribers and the channel
    to send messages to all of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Stop()` function the `stop` channel by closing it. This will effectively
    spread the signal to every listening Goroutine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: The `Stop` method, the function to stop the publisher and the subscribers, also
    pushes to its respective channel, called stop.
  prefs: []
  type: TYPE_NORMAL
- en: You may be wondering why we don't simply leave the channels available so that
    users push directly to this channel instead of using the proxying function. Well,
    the idea is that the user that integrates the library in their app doesn't have
    to deal with the complexity of the concurrent structure associated with the library,
    so they can focus on their business while maximizing performance as much as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Handling channels without race conditions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Until now, we have forwarded data to the channels on the publisher but we haven't
    actually handled any of that data. The launcher mechanism that is going to launch
    a different Goroutine will handle them all.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will create a launch method that we will execute by using the `go` keyword
    instead of embedding the whole function inside the `NewPublisher` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '`Launch` is a private method and we haven''t tested it. Remember that private
    methods are usually called from public methods (the ones we have tested). Generally,
    if a private method is not called from a public method, it can''t be called at
    all!'
  prefs: []
  type: TYPE_NORMAL
- en: The first thing we notice with this method is that it is an infinite for loop
    that will repeat a select operation between many channels but only one of them
    can be executed each time. The first of these operations is the one that receives
    a new message to publish to subscribers. The `case msg := <- p.in:` code handles
    this incoming operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, we are iterating over all subscribers and executing their `Notify`
    method. You may be wondering why we don''t add the `go` keyword in front so that
    the `Notify` method is executed as a different Goroutine and therefore iterates
    much faster. Well, this because we aren''t demultiplexing the actions of receiving
    a message and of closing the message. So, if we launch the subscriber in a new
    Goroutine and it is closed while the message is processed in the `Notify` method,
    we''ll have a race condition where a message will try to be sent within the `Notify`
    method to a closed channel. In fact, we are considering this scenario when we
    develop the `Notify` method but, still, we won''t control the number of Goroutines
    launched if we call the `Notify` method in a new Goroutine each time. For simplicity,
    we just call the `Notify` method, but it is a nice exercise to control the number
    of Goroutines waiting for a return in a `Notify` method execution. By buffering
    the `in` channel in each subscriber, we can also achieve a good solution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'The next operation is what to do when a value arrives to the channel to add
    subscribers. In this case it''s simple: we update it, appending the new value
    to it. While this case is executed, not other calls can be executed in this selection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: When a value arrives at the remove channel, the operation is a bit more complex
    because we have to search for the subscriber in the slice. We use a *O(N)* approach
    for it, iterating from the beginning until we find it, but the search algorithm
    could be greatly improved. Once we find the corresponding `Subscriber` interface,
    we remove it from the subscribers slice and stop it. One thing to mention is that
    on tests, we are accessing the length of the subscribers slice directly without
    demultiplexing the operation. This is clearly a race condition, but generally,
    it isn't reflected when running the race detector.
  prefs: []
  type: TYPE_NORMAL
- en: 'The solution will be to develop a method just to multiplex calls to get the
    length of the slice, but it won''t belong to the public interface. Again, for
    simplicity, we''ll leave it like this, or this example may become too complex
    to handle:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: The last operation to demultiplex is the `stop` operation, which must stop all
    Goroutines in the publisher and subscribers. Then we have to iterate through every
    Subscriber stored in the subscribers field to execute their `Close()` method,
    so their Goroutines are closed, too. Finally, if we return this Goroutine, it
    will finish, too.
  prefs: []
  type: TYPE_NORMAL
- en: 'OK, time to execute all tests and see how is it going:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Not so bad. All tests have passed successfully and we have our Observer pattern
    ready. While the example can still be improved, it is a great example of how we
    must handle an Observer pattern using channels in Go. As an exercise, we encourage
    you to try the same example using mutexes instead of channels to control access.
    It's a bit easier, and will also give you an insight of how to work with mutexes.
  prefs: []
  type: TYPE_NORMAL
- en: A few words on the concurrent Observer pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This example has demonstrated how to take advantage of multi-core CPUs to build
    a concurrent message publisher by implementing the Observer pattern. While the
    example was long, we have tried to show a common pattern when developing concurrent
    apps in Go.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have seen few approaches to develop concurrent structures that can be run
    in parallel. We have tried to show a few ways to solve the same problem, one without
    concurrency primitives and one with them. We have seen how different the publish/subscriber
    example written with a concurrent structure can be compared to the classic one.
  prefs: []
  type: TYPE_NORMAL
- en: We have also seen how to build a concurrent operation using a pipeline and we
    have parallelize it by using a worker pool, a very common Go pattern to maximize
    parallelism.
  prefs: []
  type: TYPE_NORMAL
- en: Both examples were simple enough to grasp, while digging as much as possible
    in to the nature of the Go language instead of in the problem itself.
  prefs: []
  type: TYPE_NORMAL
