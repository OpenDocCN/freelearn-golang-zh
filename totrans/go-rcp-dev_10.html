<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><div id="_idContainer022">
			<h1 id="_idParaDest-263" class="chapter-number"><a id="_idTextAnchor264"/>10</h1>
			<h1 id="_idParaDest-264"><a id="_idTextAnchor265"/>Working with Large Data</h1>
			<p>There are several ways you can utilize Go concurrency primitives to process large amounts of data efficiently. Unlike threads, goroutines can be created without much overhead. Having thousands of goroutines in a program is common. With that in mind, we will look at some common patterns of dealing with large amounts of <span class="No-Break">data concurrently.</span></p>
			<p>This chapter includes the <span class="No-Break">following recipes:</span></p>
			<ul>
				<li><span class="No-Break">Worker pools</span></li>
				<li><span class="No-Break">Connection pools</span></li>
				<li><span class="No-Break">Pipelines</span></li>
				<li>Working with large <span class="No-Break">result sets</span></li>
			</ul>
			<h1 id="_idParaDest-265"><a id="_idTextAnchor266"/>Worker pools</h1>
			<p>Let’s say you have large amounts of data elements (for instance, image files) and you want to apply the <a id="_idIndexMarker364"/>same logic to each of them. You can write a function that processes one instance of the input, and then call this function in a <strong class="source-inline">for</strong> loop. Such a program will process the input elements sequentially, and if each element takes <strong class="source-inline">t</strong> seconds to process, all inputs will be completed at last at <strong class="source-inline">n.t</strong> seconds, <strong class="source-inline">n</strong> being the number <span class="No-Break">of inputs.</span></p>
			<p>If you want to increase throughput by using concurrent programming, you can create a pool of worker goroutines. You can feed the next input to an idle member of the worker pool, and while that is being processed, you can assign the subsequent input to another member. If you have <strong class="source-inline">p</strong> logical processors (which can be cores of physical processors) running in parallel, the result can be available in as fast as <strong class="source-inline">n.t/p</strong> seconds (this is a theoretical upper limit because the distribution of load among parallel processes is not always perfect, and there is also synchronization and <span class="No-Break">communication overhead).</span></p>
			<p>We will look at two different ways of implementing worker <span class="No-Break">pools next.</span></p>
			<h2 id="_idParaDest-266"><a id="_idTextAnchor267"/>Capped worker pools</h2>
			<p>If there is not <a id="_idIndexMarker365"/>an expensive initialization (for instance, loading a file <a id="_idIndexMarker366"/>or establishing a network connection can be expensive) for each worker, it is best to create workers as necessary with a given limit on the number <span class="No-Break">of workers.</span></p>
			<h3>How to do it...</h3>
			<p>Create a new goroutine for each input. Use a channel as a synchronized counter to limit the maximum number of workers (here, the channel is used as a <em class="italic">semaphore</em>). Use an output channel to collect the results, <span class="No-Break">if any:</span></p>
			<pre class="source-code">
// Establish a maximum pool size
const maxPoolSize = 100
func main() {
    // 1. Initialization
    // Receive outputs from the pool via outputCh
    outputCh := make(chan Output)
    // A semaphore to limit the pool size
    sem := make(chan struct{}, maxPoolSize)
    // 2. Read outputs
    // Reader goroutine reads results until outputCh is closed
    readerWg := sync.WaitGroup{}
    readerWg.Add(1)
    go func() {
        defer readerWg.Done()
        for result := range outputCh {
            // process result
            fmt.Println(result)
        }
    }()
    // 3. Processing loop
    // Create the workers as needed, but the number of active workers
    // are limited by the capacity of sem
    wg := sync.WaitGroup{}
    // This loop sends the inputs to workers, creating them as 
    // necessary
    for {
        nextInput, done := getNextInput()
        if done {
            break
        }
        wg.Add(1)
        // This will block if there are too many goroutines
        sem &lt;- struct{}{}
        go func(inp Input) {
            defer wg.Done()
            defer func() {
                &lt;-sem
            }()
            outputCh &lt;- doWork(inp)
        }(nextInput)
    }
    // 4. Wait until processing is complete
    // This goroutine waits until all worker pool goroutines are done, 
    // then closes the output channel
    go func() {
        // Wait until processing is complete
        wg.Wait()
        // Close the output channel so the reader goroutine can 
        // terminate
        close(outputCh)
    }()
    // Wait until the output channel is closed
    readerWg.Wait()
    // If we are here, all goroutines are done
}</pre>			<h3>How it works...</h3>
			<ol>
				<li>First is <a id="_idIndexMarker367"/>initialization. We <a id="_idIndexMarker368"/>create <span class="No-Break">two channels:</span><ul><li><strong class="source-inline">outputCh</strong>: The output of the worker pool. Each worker will write the result to <span class="No-Break">this channel.</span></li><li><strong class="source-inline">sem</strong>: The semaphore channel that will be used to limit the number of active workers. It is created with a <strong class="source-inline">maxPoolSize</strong> capacity. When we start a new worker goroutines, we send one element to this channel. Send operations will not block as long as the <strong class="source-inline">sem</strong> channel has fewer than <strong class="source-inline">maxPoolSize</strong> elements in it. When a worker goroutine is done, it receives one element from the channel, freeing capacity. Since this channel has <strong class="source-inline">maxPoolSize</strong> capacity, a <strong class="source-inline">send</strong> operation will block until a goroutine ends and receives from the channel if <strong class="source-inline">maxPoolSize</strong> workers <span class="No-Break">are running.</span></li></ul></li>
				<li><strong class="bold">Read outputs</strong>: We start a goroutine to read from the <strong class="source-inline">outputCh</strong> before starting the process, so the results can be read before all the input is sent to workers. Since the number of workers is limited, the workers will block after creating <strong class="source-inline">maxPoolSize</strong> of them, so we have to start listening for the outputs before creating the <span class="No-Break">worker pool.</span></li>
				<li><strong class="bold">Processing loop</strong>: We read the next input and create a new worker to work on it. Active workers are tracked with the <strong class="source-inline">wg</strong> WaitGroup, which will later be used to wait for the workers to finish. Before creating a new worker, we send an element to the semaphore channel. If there are already <strong class="source-inline">maxPoolSize</strong> workers running, this will block until one of them terminates. The worker processes the input, writes the output to the <strong class="source-inline">outputCh</strong> and terminates, receiving one element from <span class="No-Break">the semaphore.</span></li>
				<li>This goroutine waits for the WaitGroup that keeps track of the workers. When all workers are done, the output channel is closed. That also signals the reader WaitGroup created at <span class="No-Break"><em class="italic">Step 2</em></span><span class="No-Break">.</span></li>
				<li>Wait until output processing is complete. The program has to wait until all outputs are generated. This only happens after the closing of the <strong class="source-inline">outputCh</strong> (which happens at #4), and then releasing of <span class="No-Break">the </span><span class="No-Break"><strong class="source-inline">readerWg</strong></span><span class="No-Break">.</span></li>
			</ol>
			<h2 id="_idParaDest-267"><a id="_idTextAnchor268"/>Fixed-size worker pools</h2>
			<p>A fixed-size <a id="_idIndexMarker369"/>worker pool makes sense if creating a <a id="_idIndexMarker370"/>worker is an expensive operation. Simply create the maximum number of workers that read from a common input channel. This input channel deals with distributing work among the <span class="No-Break">available workers.</span></p>
			<h3>How to do it...</h3>
			<p>There are several ways this can be achieved. We will look <span class="No-Break">at two.</span></p>
			<p>In the following function, a fixed-size worker pool is created with <strong class="source-inline">poolSize</strong> workers. All workers read from the same input channel and write the output to the same output channel. This program uses a reader goroutine to collect the results from the worker pool while providing the inputs in the same goroutine as <span class="No-Break">the caller:</span></p>
			<pre class="source-code">
const poolSize = 50
func workerPoolWithConcurrentReader() {
    // 1. Initialization
    // Send inputs to the pool via inputCh
    inputCh := make(chan Input)
    // Receive outputs from the pool via outputCh
    outputCh := make(chan Output)
    // 2. Create the pool of workers
    wg := sync.WaitGroup{}
    for i := 0; i &lt; poolSize; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for work := range inputCh {
                outputCh &lt;- doWork(work)
            }
        }()
    }
    // 3.a Reader goroutine
    // Reader goroutine reads results until outputCh is closed
    readerWg := sync.WaitGroup{}
    readerWg.Add(1)
    go func() {
        defer readerWg.Done()
        for result := range outputCh {
            // process result
            fmt.Println(result)
        }
    }()
    // 4. Wait workers
    // This goroutine waits until all worker pool goroutines are done, 
    // then closes the output channel
    go func() {
        // Wait until processing is complete
        wg.Wait()
        // Close the output channel so the reader goroutine can 
        // terminate
        close(outputCh)
    }()
    // 5.a Send inputs
    // This loop sends the inputs to the worker pool
    for {
        nextInput, done := getNextInput()
        if done {
            break
        }
        inputCh &lt;- nextInput
    }
    // Close the input channel, so worker pool goroutines terminate
    close(inputCh)
    // Wait until the output channel is closed
    readerWg.Wait()
    // If we are here, all goroutines are done
}</pre>			<p>The following <a id="_idIndexMarker371"/>version uses a goroutine to submit the <a id="_idIndexMarker372"/>work to the worker pool, while reading the results in the same goroutine as <span class="No-Break">the caller:</span></p>
			<pre class="source-code">
func workerPoolWithConcurrentWriter() {
    // 1. Initialization
    // Send inputs to the pool via inputCh
    inputCh := make(chan Input)
    // Receive outputs from the pool via outputCh
    outputCh := make(chan Output)
    // 2. Create the pool of workers
    wg := sync.WaitGroup{}
    for i := 0; i &lt; poolSize; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for work := range inputCh {
                outputCh &lt;- doWork(work)
            }
        }()
    }
    // 3.b Writer goroutine
    // Writer goroutine submits work to the worker pool
    go func() {
        for {
            nextInput, done := getNextInput()
            if done {
                break
            }
            inputCh &lt;- nextInput
        }
        // Close the input channel, so worker pool goroutines 
        // terminate
        close(inputCh)
    }()
    // 4. Wait workers
    // This goroutine waits until all worker pool goroutines are done, 
    // then closes the output channel
    go func() {
        // Wait until processing is complete
        wg.Wait()
        // Close the output channel so the reader goroutine can 
        // terminate
        close(outputCh)
    }()
    // 5.b Read results
    // Read results until outputCh is closed
    for result := range outputCh {
        // process result
        fmt.Println(result)
    }
}</pre>			<h3>How it works...</h3>
			<ol>
				<li>First is initialization. We create <span class="No-Break">two channels:</span><ul><li><strong class="source-inline">inputCh</strong>: This is the input to the worker pool. Each worker in the pool reads from the same <strong class="source-inline">inputCh</strong> in a <strong class="source-inline">for-range</strong> loop, so when a worker receives an input, it stops listening from the channel, allowing another worker to pick up the <span class="No-Break">next input.</span></li><li><strong class="source-inline">outputCh</strong>: This is the output of the worker pool. All workers write the output to this channel when they <span class="No-Break">are done.</span></li></ul></li>
				<li>Create the <a id="_idIndexMarker373"/>pool of workers: Since this is a fixed-size pool, we can create the workers in a simple for-loop. A <strong class="source-inline">WaitGroup</strong> is necessary so that we can wait for the processing to complete. Each worker <a id="_idIndexMarker374"/>reads from the <strong class="source-inline">inputCh</strong> until it is closed, processes the input, and writes to <span class="No-Break">the </span><span class="No-Break"><strong class="source-inline">outputCh</strong></span><span class="No-Break">.</span></li>
			</ol>
			<p>The rest of the algorithm is different for the two examples. Let’s start by looking at the <span class="No-Break">first case:</span></p>
			<ol>
				<li><strong class="bold">Reader goroutine</strong>: The output of the worker pool is read in this separate goroutine <a id="_idIndexMarker375"/>until the <strong class="source-inline">outputCh</strong> is closed. When the <strong class="source-inline">outputCh</strong> is closed, the <strong class="source-inline">readerWg</strong> <span class="No-Break">is signaled.</span></li>
				<li><strong class="bold">Wait workers</strong>: This <a id="_idIndexMarker376"/>is a separate goroutine that waits for the completion of all workers. When all workers terminate (which happens because the <strong class="source-inline">inputCh</strong> is closed), it closes <span class="No-Break">the </span><span class="No-Break"><strong class="source-inline">outputCh</strong></span><span class="No-Break">.</span></li>
				<li>This <strong class="source-inline">for</strong> loop sends inputs to the <strong class="source-inline">inputCh</strong>, and then closes the <strong class="source-inline">inputCh</strong>. This causes all the workers to terminate when they complete their work. When all the workers terminate, the <strong class="source-inline">outputCh</strong> is closed by the goroutine created at #4. When the output processing is complete, <strong class="source-inline">readerWg</strong> is signaled, <span class="No-Break">terminating computation.</span></li>
			</ol>
			<p>Next, let’s look at the <span class="No-Break">second case:</span></p>
			<ol>
				<li><strong class="bold">Writer goroutine</strong>: The inputs to the worker pool are generated by this goroutine. It <a id="_idIndexMarker377"/>sends all inputs to the <strong class="source-inline">inputCh</strong> one by one, and when all inputs are sent, it closes the <strong class="source-inline">inputCh</strong>, causing the worker pool <span class="No-Break">to terminate.</span></li>
				<li><strong class="bold">Wait workers</strong>: These work the same as in the <span class="No-Break">preceding case.</span></li>
				<li><strong class="bold">Read results</strong>: This <strong class="source-inline">for</strong> loop reads the results from the <strong class="source-inline">outputCh</strong> until it is closed. The <strong class="source-inline">outputCh</strong> will be closed when all workers <span class="No-Break">are completed.</span></li>
			</ol>
			<h2 id="_idParaDest-268"><a id="_idTextAnchor269"/>Connection pools</h2>
			<p>A connection pool is <a id="_idIndexMarker378"/>useful when dealing with multiple users <a id="_idIndexMarker379"/>of a scarce resource where establishing an instance of that resource can be expensive, such as a network connection, or database connection. Using a pair of channels, you can implement an efficient thread-safe <span class="No-Break">connection pool.</span></p>
			<h3>How to do it...</h3>
			<p>Create a connection pool type with two channels with <strong class="source-inline">PoolSize</strong> <span class="No-Break">capacity :</span></p>
			<ul>
				<li><strong class="source-inline">available</strong> keeps the connections that are already established, but returned to <span class="No-Break">the pool</span></li>
				<li><strong class="source-inline">total</strong> keeps the total number of connections, that is, the number of <strong class="source-inline">available</strong> plus the number of connections that are actively <span class="No-Break">in use</span></li>
			</ul>
			<p>To get a connection from the pool, check the <strong class="source-inline">available</strong> channel. If one is available, return that. Otherwise, check the <strong class="source-inline">total</strong> connection pool , and create a new one if the limit is <span class="No-Break">not exceeded.</span></p>
			<p>Users of this pool should return the connections to the pool after they are done by sending the connection to the <span class="No-Break"><strong class="source-inline">available</strong></span><span class="No-Break"> channel.</span></p>
			<p>The following <a id="_idIndexMarker380"/>code snippet illustrates such a <span class="No-Break">connection </span><span class="No-Break"><a id="_idIndexMarker381"/></span><span class="No-Break">pool:</span></p>
			<pre class="source-code">
type ConnectionPool struct {
    // This channel keeps connections returned to the pool
    available chan net.Conn
    // This channel counts the total number of connection active
    total     chan struct{}
}
func NewConnectionPool(poolSize int) *ConnectionPool {
  return &amp;ConnectionPool {
    available: make(chan net.Conn,poolSize),
    total: make(chan struct{}, poolSize),
 }
}
func (pool *ConnectionPool) GetConnection() (net.Conn, error) {
    select {
    // If there are connections available in the pool, return one
    case conn := &lt;-pool.available:
        fmt.Printf("Returning an idle connection.\n")
        return conn, nil
    default:
        // No connections are available
        select {
        case conn := &lt;-pool.available:
            fmt.Printf("Returning an idle connection.\n")
            return conn, nil
        case pool.total &lt;- struct{}{}: // Wait until pool is not full
            fmt.Println("Creating a new connection")
            // Create a new connection
            conn, err := net.Dial("tcp", "localhost:2000")
            if err != nil {
                return nil, err
            }
            return conn, nil
        }
    }
}
func (pool *ConnectionPool) Release(conn net.Conn) {
    pool.available &lt;- conn
    fmt.Printf("Releasing a connection. \n")
}
func (pool *ConnectionPool) Close(conn net.Conn) {
    fmt.Println("Closing connection")
    conn.Close()
    &lt;-pool.total
}</pre>			<h3>How it works...</h3>
			<ol>
				<li>Initialize the <a id="_idIndexMarker382"/>connection pool with <span class="No-Break">a </span><span class="No-Break"><strong class="source-inline">PoolSize</strong></span><span class="No-Break">:</span><pre class="source-code">
pool := NewConnectionPool(PoolSize)</pre></li>				<li>This will <a id="_idIndexMarker383"/>create two channels, both with <strong class="source-inline">PoolSize</strong> capacity. The <strong class="source-inline">available</strong> channel will hold all connections that are returned to the pool while <strong class="source-inline">total</strong> will keep the number of <span class="No-Break">established connections.</span></li>
				<li>To get a new connection, use <span class="No-Break">the following:</span><pre class="source-code">
conn, err := pool.GetConnection()</pre><p class="list-inset">This implementation of <strong class="source-inline">GetConnection</strong> illustrates how channel priorities can be established. <strong class="source-inline">GetConnection</strong> will return an idle connection if one is available in the <strong class="source-inline">available</strong> channel. Otherwise, it will enter the <strong class="source-inline">default</strong> case where it will either create a new connection or use one that is returned to the <span class="No-Break"><strong class="source-inline">available</strong></span><span class="No-Break"> channel.</span></p><p class="list-inset">Note the pattern of nested <strong class="source-inline">select</strong> statements in <strong class="source-inline">GetConnection</strong>. This is a common pattern for implementing priority among channels. If there is a connection available, then <strong class="source-inline">case conn := &lt;-pool.available</strong> will be chosen and the connection will be removed from the available connections channel. However, if there are no connections available when the first <strong class="source-inline">select</strong> statement is run, the <strong class="source-inline">default</strong> case will execute, which will execute a <strong class="source-inline">select</strong> between the <strong class="source-inline">conn:=&lt;-pool.available</strong> and <strong class="source-inline">pool.total&lt;-struct{}{}</strong> cases. If the first case becomes available (which happens when some other goroutine returns a connection to the pool), that connection will be returned to the caller. If the second case becomes available (which happens when a connection is closed, thus removing an element from <strong class="source-inline">pool.total</strong>), a new connection is created and returned to <span class="No-Break">the caller.</span></p></li>				<li>When the <a id="_idIndexMarker384"/>client of the pool is done with the connection, it should call <span class="No-Break">the following:</span><pre class="source-code">
pool.Release(conn)</pre></li>				<li>This will add <a id="_idIndexMarker385"/>the connection to the <span class="No-Break"><strong class="source-inline">available</strong></span><span class="No-Break"> channel.</span><p class="list-inset">If a connection becomes unresponsive, it can be closed by the client. When this happens, the pool should be notified, and <strong class="source-inline">total</strong> should be decremented but the connection should not be added to <strong class="source-inline">available</strong>. This is done by <span class="No-Break">the following:</span></p><pre class="source-code">
pool.Close(conn)</pre></li>			</ol>
			<h1 id="_idParaDest-269"><a id="_idTextAnchor270"/>Pipelines</h1>
			<p>Whenever <a id="_idIndexMarker386"/>you have several stages of operations performed on an input, you can construct a pipeline. Goroutines and channels can be used to construct high-throughput processing pipelines with <span class="No-Break">different structures.</span></p>
			<h2 id="_idParaDest-270"><a id="_idTextAnchor271"/>Simple pipeline without fan-out/fan-in</h2>
			<p>A simple <a id="_idIndexMarker387"/>pipeline can be constructed by connecting each stage running in its own goroutine using channels. The structure of the pipeline looks like <span class="No-Break"><em class="italic">Figure 10</em></span><span class="No-Break"><em class="italic">.1</em></span><span class="No-Break">.</span></p>
			<div>
				<div id="_idContainer019" class="IMG---Figure">
					<img src="image/B21961_10_1.jpg" alt="Figure 10.1: Simple asynchronous pipeline" width="1211" height="73"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.1: Simple asynchronous pipeline</p>
			<h3>How to do it...</h3>
			<p>This pipeline <a id="_idIndexMarker388"/>uses a separate error channel to report processing errors. We use a custom error type to capture <span class="No-Break">diagnostic information:</span></p>
			<pre class="source-code">
type PipelineError struct {
    // The stage in which error happened
    Stage   int
    // The payload
    Payload any
    // The actual error
    Err     error
}</pre>			<p>Every stage is implemented as a function that creates a new goroutine. The goroutine reads input data from an input channel, and writes the output to an <span class="No-Break">output channel:</span></p>
			<pre class="source-code">
func Stage1(input &lt;-chan InputPayload, errCh chan&lt;- error) &lt;-chan Stage2Payload {
    // 1. Create the output channel for this stage.
    // This will be the input for the next stage
    output := make(chan Stage2Payload)
    // 2. Create processing goroutine
    go func() {
        // 3. Close the output channel when done
        defer close(output)
        // 4. Process all inputs until input channel is closed
        for in := range input {
            // 5. Process data
            err := processData(in.Id)
            // 6. Send errors to the error channel
            if err != nil {
                errCh &lt;- PipelineError{
                    Stage:   1,
                    Payload: in,
                    Err:     err,
                }
                continue
            }
            // 7. Send the output to the next stage
            output &lt;- Stage2Payload{
                Id: in.Id,
            }
        }
    }()
    return output
}</pre>			<p>Stages 2 and 3 are <a id="_idIndexMarker389"/>implemented using the <span class="No-Break">same pattern.</span></p>
			<p>The pipeline is put together <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
func main() {
    // 1. Create the input and error channels
    errCh := make(chan error)
    inputCh := make(chan InputPayload)
    // 2. Prepare the pipeline by attaching stages
    outputCh := Stage3(Stage2(Stage1(inputCh, errCh), errCh), errCh)
    // 3. Feed input asynchronously
    go func() {
        defer close(inputCh)
        for i := 0; i &lt; 1000; i++ {
            inputCh &lt;- InputPayload{
                Id: i,
            }
        }
    }()
    // 4. Listen to the error channel asynchronously
    go func() {
        for err := range errCh {
            fmt.Println(err)
        }
    }()
    // 5. Read outputs
    for out := range outputCh {
        fmt.Println(out)
    }
    // 6. Close the error channel
    close(errCh)
}</pre>			<p>For each stage, follow <span class="No-Break">these steps:</span></p>
			<ol>
				<li>Create the <a id="_idIndexMarker390"/>output channel for the stage. This will be passed into the next stage as the <span class="No-Break"><strong class="source-inline">input</strong></span><span class="No-Break"> channel.</span></li>
				<li>The processing goroutine continues running after the stage <span class="No-Break">function returns.</span></li>
				<li>Make sure the output channel of this stage is closed when the processing <span class="No-Break">goroutine terminates.</span></li>
				<li>Read inputs from the previous stage until the input channel <span class="No-Break">is closed.</span></li>
				<li>Process <span class="No-Break">the input.</span></li>
				<li>If there is an error, send the error to the error channel. No output will <span class="No-Break">be generated.</span></li>
				<li>Send the output to the <span class="No-Break">next stage.</span></li>
			</ol>
			<p class="callout-heading">Warning</p>
			<p class="callout">Each stage runs in its own goroutine. That means that once you pass the payload to the next stage, you should not access that payload in the current stage. If the payload contains pointers, or if the payload itself is a pointer, data races <span class="No-Break">may occur.</span></p>
			<p>The pipeline setup is done <span class="No-Break">as follows:</span></p>
			<ol>
				<li>Create the input channel and the <span class="No-Break">error channel.</span><p class="list-inset">Attach stages to form the pipeline. The output of stage <strong class="source-inline">n</strong> becomes the input of stage <strong class="source-inline">n+1</strong>. The output of the last stage becomes the <span class="No-Break"><strong class="source-inline">output</strong></span><span class="No-Break"> channel.</span></p></li>
				<li>Send the inputs to the input channel asynchronously. When all inputs are sent, close the input channel. This will terminate the first stage, closing its output channel, which is also the input channel for stage 2. This goes on until all <span class="No-Break">stages exit.</span></li>
				<li>Start a <a id="_idIndexMarker391"/>goroutine to listen and <span class="No-Break">record errors.</span></li>
				<li>Collect <span class="No-Break">the outputs.</span></li>
				<li>Close the error channel so that the error collecting <span class="No-Break">goroutine terminates.</span></li>
			</ol>
			<h2 id="_idParaDest-271"><a id="_idTextAnchor272"/>Pipeline with worker pools as stages</h2>
			<p>The previous <a id="_idIndexMarker392"/>example used a single worker for each stage. You can increase the throughput of a pipeline by replacing each stage with worker pools. The resulting pipeline is depicted in <span class="No-Break"><em class="italic">Figure 10</em></span><span class="No-Break"><em class="italic">.2</em></span><span class="No-Break">.</span></p>
			<div>
				<div id="_idContainer020" class="IMG---Figure">
					<img src="image/B21961_10_2.jpg" alt="Figure 10.2: Pipeline with worker pools as stages" width="1210" height="221"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.2: Pipeline with worker pools as stages</p>
			<h3>How to do it...</h3>
			<p>Each stage now creates multiple goroutines, all reading from the same input channel (fan-out). The output of each worker is written to a common output channel (fan-in), which becomes the input for the next stage. We can no longer close the stage output channel whenever the input channel is closed because there are now multiple goroutines writing to that output channel. Instead, we use a wait group and a second goroutine to close the output when all of the processing <span class="No-Break">goroutines terminate:</span></p>
			<pre class="source-code">
func Stage1(input &lt;-chan InputPayload, errCh chan&lt;- error, nInstances int) &lt;-chan Stage2Payload {
    // 1. Create the common output channel
    output := make(chan Stage2Payload)
    // 2. Close the output channel when all the processing is done
    wg := sync.WaitGroup{}
    // 3. Create nInstances goroutines
    for i := 0; i &lt; nInstances; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            // Process all inputs
            for in := range input {
                // Process data
                err := processData(in.Id)
                if err != nil {
                    errCh &lt;- PipelineError{
                        Stage:   1,
                        Payload: in,
                        Err:     err,
                    }
                    continue
                }
                //Send output to the common output channel
                output &lt;- Stage2Payload{
                    Id: in.Id,
                }
            }
        }()
    }
    // 4. Another goroutine waits until all workers are done, and 
    //closes the output channel
    go func() {
        wg.Wait()
        close(output)
    }()
    return output
}</pre>			<p>The <a id="_idIndexMarker393"/>pipeline is constructed as in the <span class="No-Break">previous case:</span></p>
			<pre class="source-code">
func main() {
    errCh := make(chan error)
    inputCh := make(chan InputPayload)
    nInstances := 5
    // Prepare the pipeline by attaching stages
    outputCh := Stage3(Stage2(Stage1(inputCh, errCh, nInstances), 
    errCh, nInstances), errCh, nInstances)
    // Feed input asynchronously
    go func() {
        defer close(inputCh)
        for i := 0; i &lt; 1000; i++ {
            inputCh &lt;- InputPayload{
                Id: i,
            }
        }
    }()
    // Listen to the error channel asynchronously
    go func() {
        for err := range errCh {
            fmt.Println(err)
        }
    }()
    // Read outputs
    for out := range outputCh {
        fmt.Println(out)
    }
    // Close the error channel
    close(errCh)
}</pre>			<h3>How it works...</h3>
			<p>For <a id="_idIndexMarker394"/>each stage, follow <span class="No-Break">these steps:</span></p>
			<ol>
				<li>Create the output channel, which will become the input channel for the <span class="No-Break">next stage.</span><p class="list-inset">There are multiple goroutines reading from the same input channel in a for-range loop, so when the input channel is closed, all those goroutines will terminate. However, we cannot <strong class="source-inline">defer close</strong> the output channel, because that will result in closing the output channel multiple times (which will panic). So instead, we use a <strong class="source-inline">WaitGroup</strong> to keep track of the worker goroutines. A separate <a id="_idIndexMarker395"/>goroutine waits on that wait group, and when all goroutines terminate, it closes the <span class="No-Break">output channel.</span></p></li>
				<li>Create <strong class="source-inline">nInstances</strong> goroutines that all read from the same input channel, and write to the output channel. In case of an error, the workers send the error to the <span class="No-Break">error channel.</span></li>
				<li>This is the goroutine that waits for the worker goroutines to finish. When they do, it closes the <span class="No-Break">output channel.</span></li>
			</ol>
			<p>The pipeline setup is identical to the previous section, except that the initialization also sends the worker pool size to <span class="No-Break">stage functions.</span></p>
			<h2 id="_idParaDest-272"><a id="_idTextAnchor273"/>Pipeline with fan-out and fan-in</h2>
			<p>In this <a id="_idIndexMarker396"/>setup, stages are wired one after the other using dedicated channels, as shown in <span class="No-Break"><em class="italic">Figure 10</em></span><span class="No-Break"><em class="italic">.3</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer021" class="IMG---Figure">
					<img src="image/B21961_10_3.jpg" alt="Figure 10.3: Pipeline with fan-out and fan-in" width="1210" height="221"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.3: Pipeline with fan-out and fan-in</p>
			<h3>How to do it...</h3>
			<p>Each pipeline <a id="_idIndexMarker397"/>stage reads from a given input channel, and writes to an output channel, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
func Stage1(input &lt;-chan InputPayload, errCh chan&lt;- error) &lt;-chan Stage2Payload {
    output := make(chan Stage2Payload)
    go func() {
        defer close(output)
        // Process all inputs
        for in := range input {
            // Process data
            err := processData(in.Id)
            if err != nil {
                errCh &lt;- PipelineError{
                    Stage:   1,
                    Payload: in,
                    Err:     err,
                }
                continue
            }
            output &lt;- Stage2Payload{
                Id: in.Id,
            }
        }
    }()
    return output
}</pre>			<p>A separate <strong class="source-inline">fanIn</strong> function takes a list of output channels, and combines them using a goroutine <a id="_idIndexMarker398"/>listening to <span class="No-Break">each channel:</span></p>
			<pre class="source-code">
func fanIn(inputs []&lt;-chan OutputPayload) &lt;-chan OutputPayload {
    result := make(chan OutputPayload)
    // Listen to input channels in separate goroutines
    inputWg := sync.WaitGroup{}
    for inputIndex := range inputs {
        inputWg.Add(1)
        go func(index int) {
            defer inputWg.Done()
            for data := range inputs[index] {
                // Send the data to the output
                result &lt;- data
            }
        }(inputIndex)
    }
    // When all input channels are closed, close the fan in ch
    go func() {
        inputWg.Wait()
        close(result)
    }()
    return result
}</pre>			<p>The pipeline <a id="_idIndexMarker399"/>is setup in a for-loop by combining the output of each stage to the input of the next stage. The resulting output channels are all directed to the <span class="No-Break"><strong class="source-inline">fanIn</strong></span><span class="No-Break"> function:</span></p>
			<pre class="source-code">
func main() {
    errCh := make(chan error)
    inputCh := make(chan InputPayload)
    poolSize := 5
    outputs := make([]&lt;-chan OutputPayload, 0)
    // All Stage1 goroutines listen to a single input channel
    for i := 0; i &lt; poolSize; i++ {
        outputCh1 := Stage1(inputCh, errCh)
        outputCh2 := Stage2(outputCh1, errCh)
        outputCh3 := Stage3(outputCh2, errCh)
        outputs = append(outputs, outputCh3)
    }
    outputCh := fanIn(outputs)
    // Feed input asynchronously
    go func() {
        defer close(inputCh)
        for i := 0; i &lt; 1000; i++ {
            inputCh &lt;- InputPayload{
                Id: i,
            }
        }
    }()
    // Listen to the error channel asynchronously
    go func() {
        for err := range errCh {
            fmt.Println(err)
        }
    }()
    // Read outputs
    for out := range outputCh {
        fmt.Println(out)
    }
    // Close the error channel
    close(errCh)
}</pre>			<h3>How it works...</h3>
			<p>The worker <a id="_idIndexMarker400"/>stages are identical to the simple pipeline case. The fan-in stage works <span class="No-Break">as follows.</span></p>
			<p>For every output channel, the fan-in function creates a goroutine that reads data from that output channel and writes to a common channel. This common channel becomes the combined output channel of the pipeline. The fan-in function creates another goroutine that waits on a <strong class="source-inline">wait</strong> group that keeps track of all the goroutines. When they are all complete, this goroutine closes the <span class="No-Break">output channel.</span></p>
			<p>The <strong class="source-inline">main</strong> constructs the pipeline by connecting the output of each stage to the input of the next. The output channels of the last stage are stored in a slice and passed to the fan-in function. The output channel of the fan-in function becomes the combined output of <span class="No-Break">the pipeline.</span></p>
			<p>Note that all <a id="_idIndexMarker401"/>these pipeline variations use a separate error channel. An alternative approach is to store any error in the payload and pass it to the next stage. If the incoming payload has a non-nil error, all stages pass it to the next one, so the payload can be recorded as an error at the end of <span class="No-Break">the pipeline:</span></p>
			<pre class="source-code">
type Stage2Paylaod struct {
   // Payload data
   Err error
}
func Stage2(input &lt;-chan Stage2Payload) &lt;-chan Stage3Payload {
    output := make(chan Stage2Payload)
    go func() {
        defer close(output)
        // Process all inputs
        for in := range input {
            // If there is error, pass it
            if in.Err!=nil {
               output &lt;- StagerPayload {
                  Err: in.Err,
               }
               continue
             }
             ...</pre>			<p>Also note <a id="_idIndexMarker402"/>that except for the simple pipeline case, they also return results out of order because multiple inputs go through the pipeline at any given moment, and there is no guarantee on the order they arrive at <span class="No-Break">the output.</span></p>
			<h1 id="_idParaDest-273"><a id="_idTextAnchor274"/>Working with large result sets</h1>
			<p>When working with potentially large result sets, it may not always be feasible to load all data to memory <a id="_idIndexMarker403"/>and work on it. You may need to stream data elements in a controlled manner. This section shows how to deal with such situations using <span class="No-Break">concurrency primitives.</span></p>
			<h2 id="_idParaDest-274"><a id="_idTextAnchor275"/>Streaming results using a goroutine</h2>
			<p>In this use case, a goroutine <a id="_idIndexMarker404"/>sends the results of a <a id="_idIndexMarker405"/>query via a channel. A context can be used to cancel the <span class="No-Break">streaming goroutine.</span></p>
			<h3>How to do it...</h3>
			<p>Create a data structure that holds the data elements and <span class="No-Break">error information:</span></p>
			<pre class="source-code">
type Result struct {
  Err error
  // Other data elements
}</pre>			<p>The <strong class="source-inline">StreamResults</strong> function runs <a id="_idIndexMarker406"/>the database query and creates a goroutine that iterates the query results. The goroutine sends each result via <span class="No-Break">a channel:</span></p>
			<pre class="source-code">
func StreamResults(
    ctx context.Context,
    db *sql.DB,
    query string,
    args ...any,
) (&lt;-chan Result, error) {
    rows, err := db.QueryContext(ctx, query, args...)
    if err != nil {
        return nil, err
    }
    output := make(chan Result)
    go func() {
        defer rows.Close()
        defer close(output)
        var result Result
        for rows.Next() {
            // Check context cancellation
            if result.Err = ctx.Err(); result.Err != nil {
                // Context canceled. return
                output &lt;- result
                return
            }
            // Set result fields
            result.Err = buildResult(rows, &amp;result)
            output &lt;- result
        }
        // If there was an error, return it
        if result.Err = rows.Err(); result.Err != nil {
            output &lt;- result
        }
    }()
    return output, nil
}</pre>			<p>Use the <a id="_idIndexMarker407"/>streaming <a id="_idIndexMarker408"/>results <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
// Setup a cancelable context
cancelableCtx, cancel := context.WithCancel(ctx)
defer cancel()
// Call the streaming API
results, err := StreamResults(cancelableCtx,db,"SELECT EMAIL FROM USERS")
if err!=nil {
  return err
}
// Collect and process results
for result:=range results {
   if result.Err!=nil {
      // Handle error in the result
      continue
    }
    // Process the result
    if err:=ProcessResult(result); err!=nil {
      // Processing error. Cancel streaming results
      cancel()
      // Expect to receive at least one more message from the channel,
      // because the streaming gorutine sends the error
      for range results {}
    }
}</pre>			<h3>How it works...</h3>
			<p>Even though <a id="_idIndexMarker409"/>we looked at a database query example, this pattern is useful any time you are dealing with a function that generates potentially large <a id="_idIndexMarker410"/>amounts of data. Instead of loading all data into memory, this pattern loads and processes data items one <span class="No-Break">by one.</span></p>
			<p>The <strong class="source-inline">StreamResults</strong> generator function starts a goroutine closure that captures the context and additional <a id="_idIndexMarker411"/>information necessary to produce results (in this case, a <strong class="source-inline">sql.Rows</strong> instance). The generator function creates a channel and returns immediately. The goroutine collects results and sends them to the channel. When all results are processed or an error is detected, the channel <span class="No-Break">is closed.</span></p>
			<p>It is now up to the caller to communicate with the goroutine. The caller collects the results from the channel until the channel is closed, and processes them one by one. The caller also checks the error field in the received message to handle any errors detected by <span class="No-Break">the goroutine.</span></p>
			<p>This scheme uses a cancelable context. When the context is canceled, the goroutine sends another message through the channel before closing it, so the caller must drain the channel if context <span class="No-Break">cancellation happens.</span></p>
		</div>
	</div></div></body></html>