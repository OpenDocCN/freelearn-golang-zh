["```go\n// Establish a maximum pool size\nconst maxPoolSize = 100\nfunc main() {\n    // 1\\. Initialization\n    // Receive outputs from the pool via outputCh\n    outputCh := make(chan Output)\n    // A semaphore to limit the pool size\n    sem := make(chan struct{}, maxPoolSize)\n    // 2\\. Read outputs\n    // Reader goroutine reads results until outputCh is closed\n    readerWg := sync.WaitGroup{}\n    readerWg.Add(1)\n    go func() {\n        defer readerWg.Done()\n        for result := range outputCh {\n            // process result\n            fmt.Println(result)\n        }\n    }()\n    // 3\\. Processing loop\n    // Create the workers as needed, but the number of active workers\n    // are limited by the capacity of sem\n    wg := sync.WaitGroup{}\n    // This loop sends the inputs to workers, creating them as \n    // necessary\n    for {\n        nextInput, done := getNextInput()\n        if done {\n            break\n        }\n        wg.Add(1)\n        // This will block if there are too many goroutines\n        sem <- struct{}{}\n        go func(inp Input) {\n            defer wg.Done()\n            defer func() {\n                <-sem\n            }()\n            outputCh <- doWork(inp)\n        }(nextInput)\n    }\n    // 4\\. Wait until processing is complete\n    // This goroutine waits until all worker pool goroutines are done, \n    // then closes the output channel\n    go func() {\n        // Wait until processing is complete\n        wg.Wait()\n        // Close the output channel so the reader goroutine can \n        // terminate\n        close(outputCh)\n    }()\n    // Wait until the output channel is closed\n    readerWg.Wait()\n    // If we are here, all goroutines are done\n}\n```", "```go\nconst poolSize = 50\nfunc workerPoolWithConcurrentReader() {\n    // 1\\. Initialization\n    // Send inputs to the pool via inputCh\n    inputCh := make(chan Input)\n    // Receive outputs from the pool via outputCh\n    outputCh := make(chan Output)\n    // 2\\. Create the pool of workers\n    wg := sync.WaitGroup{}\n    for i := 0; i < poolSize; i++ {\n        wg.Add(1)\n        go func() {\n            defer wg.Done()\n            for work := range inputCh {\n                outputCh <- doWork(work)\n            }\n        }()\n    }\n    // 3.a Reader goroutine\n    // Reader goroutine reads results until outputCh is closed\n    readerWg := sync.WaitGroup{}\n    readerWg.Add(1)\n    go func() {\n        defer readerWg.Done()\n        for result := range outputCh {\n            // process result\n            fmt.Println(result)\n        }\n    }()\n    // 4\\. Wait workers\n    // This goroutine waits until all worker pool goroutines are done, \n    // then closes the output channel\n    go func() {\n        // Wait until processing is complete\n        wg.Wait()\n        // Close the output channel so the reader goroutine can \n        // terminate\n        close(outputCh)\n    }()\n    // 5.a Send inputs\n    // This loop sends the inputs to the worker pool\n    for {\n        nextInput, done := getNextInput()\n        if done {\n            break\n        }\n        inputCh <- nextInput\n    }\n    // Close the input channel, so worker pool goroutines terminate\n    close(inputCh)\n    // Wait until the output channel is closed\n    readerWg.Wait()\n    // If we are here, all goroutines are done\n}\n```", "```go\nfunc workerPoolWithConcurrentWriter() {\n    // 1\\. Initialization\n    // Send inputs to the pool via inputCh\n    inputCh := make(chan Input)\n    // Receive outputs from the pool via outputCh\n    outputCh := make(chan Output)\n    // 2\\. Create the pool of workers\n    wg := sync.WaitGroup{}\n    for i := 0; i < poolSize; i++ {\n        wg.Add(1)\n        go func() {\n            defer wg.Done()\n            for work := range inputCh {\n                outputCh <- doWork(work)\n            }\n        }()\n    }\n    // 3.b Writer goroutine\n    // Writer goroutine submits work to the worker pool\n    go func() {\n        for {\n            nextInput, done := getNextInput()\n            if done {\n                break\n            }\n            inputCh <- nextInput\n        }\n        // Close the input channel, so worker pool goroutines \n        // terminate\n        close(inputCh)\n    }()\n    // 4\\. Wait workers\n    // This goroutine waits until all worker pool goroutines are done, \n    // then closes the output channel\n    go func() {\n        // Wait until processing is complete\n        wg.Wait()\n        // Close the output channel so the reader goroutine can \n        // terminate\n        close(outputCh)\n    }()\n    // 5.b Read results\n    // Read results until outputCh is closed\n    for result := range outputCh {\n        // process result\n        fmt.Println(result)\n    }\n}\n```", "```go\ntype ConnectionPool struct {\n    // This channel keeps connections returned to the pool\n    available chan net.Conn\n    // This channel counts the total number of connection active\n    total     chan struct{}\n}\nfunc NewConnectionPool(poolSize int) *ConnectionPool {\n  return &ConnectionPool {\n    available: make(chan net.Conn,poolSize),\n    total: make(chan struct{}, poolSize),\n }\n}\nfunc (pool *ConnectionPool) GetConnection() (net.Conn, error) {\n    select {\n    // If there are connections available in the pool, return one\n    case conn := <-pool.available:\n        fmt.Printf(\"Returning an idle connection.\\n\")\n        return conn, nil\n    default:\n        // No connections are available\n        select {\n        case conn := <-pool.available:\n            fmt.Printf(\"Returning an idle connection.\\n\")\n            return conn, nil\n        case pool.total <- struct{}{}: // Wait until pool is not full\n            fmt.Println(\"Creating a new connection\")\n            // Create a new connection\n            conn, err := net.Dial(\"tcp\", \"localhost:2000\")\n            if err != nil {\n                return nil, err\n            }\n            return conn, nil\n        }\n    }\n}\nfunc (pool *ConnectionPool) Release(conn net.Conn) {\n    pool.available <- conn\n    fmt.Printf(\"Releasing a connection. \\n\")\n}\nfunc (pool *ConnectionPool) Close(conn net.Conn) {\n    fmt.Println(\"Closing connection\")\n    conn.Close()\n    <-pool.total\n}\n```", "```go\n    pool := NewConnectionPool(PoolSize)\n    ```", "```go\n    conn, err := pool.GetConnection()\n    ```", "```go\n    pool.Release(conn)\n    ```", "```go\n    pool.Close(conn)\n    ```", "```go\ntype PipelineError struct {\n    // The stage in which error happened\n    Stage   int\n    // The payload\n    Payload any\n    // The actual error\n    Err     error\n}\n```", "```go\nfunc Stage1(input <-chan InputPayload, errCh chan<- error) <-chan Stage2Payload {\n    // 1\\. Create the output channel for this stage.\n    // This will be the input for the next stage\n    output := make(chan Stage2Payload)\n    // 2\\. Create processing goroutine\n    go func() {\n        // 3\\. Close the output channel when done\n        defer close(output)\n        // 4\\. Process all inputs until input channel is closed\n        for in := range input {\n            // 5\\. Process data\n            err := processData(in.Id)\n            // 6\\. Send errors to the error channel\n            if err != nil {\n                errCh <- PipelineError{\n                    Stage:   1,\n                    Payload: in,\n                    Err:     err,\n                }\n                continue\n            }\n            // 7\\. Send the output to the next stage\n            output <- Stage2Payload{\n                Id: in.Id,\n            }\n        }\n    }()\n    return output\n}\n```", "```go\nfunc main() {\n    // 1\\. Create the input and error channels\n    errCh := make(chan error)\n    inputCh := make(chan InputPayload)\n    // 2\\. Prepare the pipeline by attaching stages\n    outputCh := Stage3(Stage2(Stage1(inputCh, errCh), errCh), errCh)\n    // 3\\. Feed input asynchronously\n    go func() {\n        defer close(inputCh)\n        for i := 0; i < 1000; i++ {\n            inputCh <- InputPayload{\n                Id: i,\n            }\n        }\n    }()\n    // 4\\. Listen to the error channel asynchronously\n    go func() {\n        for err := range errCh {\n            fmt.Println(err)\n        }\n    }()\n    // 5\\. Read outputs\n    for out := range outputCh {\n        fmt.Println(out)\n    }\n    // 6\\. Close the error channel\n    close(errCh)\n}\n```", "```go\nfunc Stage1(input <-chan InputPayload, errCh chan<- error, nInstances int) <-chan Stage2Payload {\n    // 1\\. Create the common output channel\n    output := make(chan Stage2Payload)\n    // 2\\. Close the output channel when all the processing is done\n    wg := sync.WaitGroup{}\n    // 3\\. Create nInstances goroutines\n    for i := 0; i < nInstances; i++ {\n        wg.Add(1)\n        go func() {\n            defer wg.Done()\n            // Process all inputs\n            for in := range input {\n                // Process data\n                err := processData(in.Id)\n                if err != nil {\n                    errCh <- PipelineError{\n                        Stage:   1,\n                        Payload: in,\n                        Err:     err,\n                    }\n                    continue\n                }\n                //Send output to the common output channel\n                output <- Stage2Payload{\n                    Id: in.Id,\n                }\n            }\n        }()\n    }\n    // 4\\. Another goroutine waits until all workers are done, and \n    //closes the output channel\n    go func() {\n        wg.Wait()\n        close(output)\n    }()\n    return output\n}\n```", "```go\nfunc main() {\n    errCh := make(chan error)\n    inputCh := make(chan InputPayload)\n    nInstances := 5\n    // Prepare the pipeline by attaching stages\n    outputCh := Stage3(Stage2(Stage1(inputCh, errCh, nInstances), \n    errCh, nInstances), errCh, nInstances)\n    // Feed input asynchronously\n    go func() {\n        defer close(inputCh)\n        for i := 0; i < 1000; i++ {\n            inputCh <- InputPayload{\n                Id: i,\n            }\n        }\n    }()\n    // Listen to the error channel asynchronously\n    go func() {\n        for err := range errCh {\n            fmt.Println(err)\n        }\n    }()\n    // Read outputs\n    for out := range outputCh {\n        fmt.Println(out)\n    }\n    // Close the error channel\n    close(errCh)\n}\n```", "```go\nfunc Stage1(input <-chan InputPayload, errCh chan<- error) <-chan Stage2Payload {\n    output := make(chan Stage2Payload)\n    go func() {\n        defer close(output)\n        // Process all inputs\n        for in := range input {\n            // Process data\n            err := processData(in.Id)\n            if err != nil {\n                errCh <- PipelineError{\n                    Stage:   1,\n                    Payload: in,\n                    Err:     err,\n                }\n                continue\n            }\n            output <- Stage2Payload{\n                Id: in.Id,\n            }\n        }\n    }()\n    return output\n}\n```", "```go\nfunc fanIn(inputs []<-chan OutputPayload) <-chan OutputPayload {\n    result := make(chan OutputPayload)\n    // Listen to input channels in separate goroutines\n    inputWg := sync.WaitGroup{}\n    for inputIndex := range inputs {\n        inputWg.Add(1)\n        go func(index int) {\n            defer inputWg.Done()\n            for data := range inputs[index] {\n                // Send the data to the output\n                result <- data\n            }\n        }(inputIndex)\n    }\n    // When all input channels are closed, close the fan in ch\n    go func() {\n        inputWg.Wait()\n        close(result)\n    }()\n    return result\n}\n```", "```go\nfunc main() {\n    errCh := make(chan error)\n    inputCh := make(chan InputPayload)\n    poolSize := 5\n    outputs := make([]<-chan OutputPayload, 0)\n    // All Stage1 goroutines listen to a single input channel\n    for i := 0; i < poolSize; i++ {\n        outputCh1 := Stage1(inputCh, errCh)\n        outputCh2 := Stage2(outputCh1, errCh)\n        outputCh3 := Stage3(outputCh2, errCh)\n        outputs = append(outputs, outputCh3)\n    }\n    outputCh := fanIn(outputs)\n    // Feed input asynchronously\n    go func() {\n        defer close(inputCh)\n        for i := 0; i < 1000; i++ {\n            inputCh <- InputPayload{\n                Id: i,\n            }\n        }\n    }()\n    // Listen to the error channel asynchronously\n    go func() {\n        for err := range errCh {\n            fmt.Println(err)\n        }\n    }()\n    // Read outputs\n    for out := range outputCh {\n        fmt.Println(out)\n    }\n    // Close the error channel\n    close(errCh)\n}\n```", "```go\ntype Stage2Paylaod struct {\n   // Payload data\n   Err error\n}\nfunc Stage2(input <-chan Stage2Payload) <-chan Stage3Payload {\n    output := make(chan Stage2Payload)\n    go func() {\n        defer close(output)\n        // Process all inputs\n        for in := range input {\n            // If there is error, pass it\n            if in.Err!=nil {\n               output <- StagerPayload {\n                  Err: in.Err,\n               }\n               continue\n             }\n             ...\n```", "```go\ntype Result struct {\n  Err error\n  // Other data elements\n}\n```", "```go\nfunc StreamResults(\n    ctx context.Context,\n    db *sql.DB,\n    query string,\n    args ...any,\n) (<-chan Result, error) {\n    rows, err := db.QueryContext(ctx, query, args...)\n    if err != nil {\n        return nil, err\n    }\n    output := make(chan Result)\n    go func() {\n        defer rows.Close()\n        defer close(output)\n        var result Result\n        for rows.Next() {\n            // Check context cancellation\n            if result.Err = ctx.Err(); result.Err != nil {\n                // Context canceled. return\n                output <- result\n                return\n            }\n            // Set result fields\n            result.Err = buildResult(rows, &result)\n            output <- result\n        }\n        // If there was an error, return it\n        if result.Err = rows.Err(); result.Err != nil {\n            output <- result\n        }\n    }()\n    return output, nil\n}\n```", "```go\n// Setup a cancelable context\ncancelableCtx, cancel := context.WithCancel(ctx)\ndefer cancel()\n// Call the streaming API\nresults, err := StreamResults(cancelableCtx,db,\"SELECT EMAIL FROM USERS\")\nif err!=nil {\n  return err\n}\n// Collect and process results\nfor result:=range results {\n   if result.Err!=nil {\n      // Handle error in the result\n      continue\n    }\n    // Process the result\n    if err:=ProcessResult(result); err!=nil {\n      // Processing error. Cancel streaming results\n      cancel()\n      // Expect to receive at least one more message from the channel,\n      // because the streaming gorutine sends the error\n      for range results {}\n    }\n}\n```"]