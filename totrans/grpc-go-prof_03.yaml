- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Introduction to gRPC
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have a basic understanding of how data flows over the network and
    how Protobuf works, we can enter the gRPC world. In this chapter, the goal is
    to understand what gRPC is doing on top of HTTP/2 and why Protobuf is the perfect
    fit for gRPC, and also to see that gRPC is a mature technology backed up by major
    companies in the industry. This will give us a sense of why gRPC is described
    as “Protobuf over HTTP/2” and make us confident in using it without fearing that
    the technology is too new and without community.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Major use cases for gRPC
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advantages of using Protobuf
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The role of gRPC on top of Protobuf
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prerequisites
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can find the code for this chapter at [https://github.com/PacktPublishing/gRPC-Go-for-Professionals/tree/main/chapter3](https://github.com/PacktPublishing/gRPC-Go-for-Professionals/tree/main/chapter3).
    During this chapter, I will be using protoc to generate Go code out of `.proto`
    files. This means that you need to make sure you have protoc installed. You can
    download a zip file from the `readme.txt` instructions (note: we do intend to
    use Well-Known Types in the future so make sure you also install the includes).
    On top of protoc, you are going to need two protoc plugins: `protoc-gen-go` and
    `protoc-gen-go-grpc`. The former generates Protobuf code, and the latter generates
    gRPC code. To add them, you can simply run the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'And finally, make sure that your `GOPATH` environment variable is in your `PATH`
    environment variable. Normally, this is already done for you on the installation
    of Golang, but if you get any error related to not finding `protoc-gen-go` or
    `protoc-gen-go-grpc`, you will need to do it manually. To get the `GOPATH` environment
    variable, you can run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: And then, depending on your OS, you can go through the steps of adding the output
    to your `PATH` environment variable.
  prefs: []
  type: TYPE_NORMAL
- en: A mature technology
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: gRPC is not just another new cool framework that you can disregard as being
    a fad It is a framework that has been battle-tested at scale for over a decade
    by Google. Originally, the project was for internal use, but in 2016, Google decided
    to provide an open source version of it that was not tied to the specifics of
    the company’s internal tooling and architecture.
  prefs: []
  type: TYPE_NORMAL
- en: After that, companies such as Uber—and a lot more—migrated their existing services
    to gRPC for efficiency but also for all the extra features that it offers. Moreover,
    some open projects such as etcd, which is a distributed key-value store used at
    the core of Kubernetes, use gRPC for communication across multiple instances.
  prefs: []
  type: TYPE_NORMAL
- en: Recently, Microsoft joined the effort around building a .NET implementation
    of gRPC. While it is not the goal of this book to explain what it did, it clearly
    shows an interest in the project. Furthermore, the more that companies such as
    this are willing to contribute, the more resources will be out there and the greater
    the community/tooling available will be. The project has a powerful backup, and
    this is good for all of us.
  prefs: []
  type: TYPE_NORMAL
- en: Now, all of this sounds amazing, but I am aware that most of us will not reach
    the scale of these giants, so it is important to understand what gRPC is good
    at. Let us see some use cases where it shines. The first use case that everyone
    is talking about is communication for microservices. This use case is an appealing
    one, especially for polyglot microservices. Our job as software engineers is to
    choose the right job for the right tool and code generation in different languages
    to enable us to do that.
  prefs: []
  type: TYPE_NORMAL
- en: Another use case is real-time updates. As we saw, gRPC gives us the possibility
    of streaming data. This comes in multiple flavors such as server streaming, which
    could be useful for keeping up to date with data such as stock prices. Then, we
    have client streaming, which could be useful for sensors streaming data to backends.
    And finally, we have bi-directional streaming, which could be interesting when
    both the client and server need to be aware of each other’s updates, such as messaging
    apps.
  prefs: []
  type: TYPE_NORMAL
- en: Another important use case is **inter-process communication** (**IPC**). This
    is communication happening on the same machine between different processes. It
    can be useful for synchronizing two or more distinct applications, implementing
    **separation of concerns** (**SOC**) with a modular architecture, or increasing
    security by having application sandboxing.
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, I presented the most common applications of gRPC that I can see out
    there, but there are a lot more applications of it, and it is important that you
    test it on your use case to see whether it fits your requirements. And if you
    are interested in testing gRPC, you will need to start trying to find out how
    Protobuf can reduce your payloads and application efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: Why Protobuf?
  prefs: []
  type: TYPE_NORMAL
- en: By now, you should understand that Protobuf provides us with a way of writing
    data schemas describing how our data should be serialized and deserialized. Then,
    the Protobuf compiler (protoc) lets us generate some code from these schemas to
    use the generated types in our code, and these serializable types are exactly
    what gRPC uses to let user code interact with request and response objects and
    let the gRPC framework send binary representations of them over the wire.
  prefs: []
  type: TYPE_NORMAL
- en: The binary representation of messages is the biggest reason Protobuf is used
    as the default data schema for gRPC. The data is serialized in way fewer bytes
    than traditional data schemas (XML, JSON, and so on). This means that not only
    can the message be delivered faster, but also that it will be deserialized faster.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The following experiment is mostly done to show Protobuf’s performance. Examples
    are exaggerated, but this will give you a sense of the additional cost that JSON
    has during deserialization. The results might vary across the run, OS, and hardware,
    so if you want to run your own experiment, you can find the benchmarking code
    and data in the `chapter3` folder ([https://github.com/PacktPublishing/gRPC-Go-for-Professionals/tree/main/chapter3](https://github.com/PacktPublishing/gRPC-Go-for-Professionals/tree/main/chapter3)).
    To get the data, you will have to unzip it with gzip. You can do that by running
    the `gzip -dk accounts.json.gz` or `gzip -dk accounts.bin.gz` command. After that,
    to run the experiment, you first need to compile the `.proto` files with `protoc
    --go_out=proto -Iproto --go_opt=module=`https://github.com/PacktPublishing/gRPC-Go-for-Professionals/proto
    proto/*`.proto`, and then you can execute the Go code by running `go run main.go`
    in the `chapter3` folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate that, we can do a simple experiment—we can generate 100,000
    accounts (with an ID + username), run the deserialization 1,000 times, and calculate
    the mean time needed to deserialize all the data. Here are the results from one
    of the runs with untrimmed (newlines and spaces) JSON against the Protobuf binary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'However, most developers do trim their JSON, so here is the result after removing
    newlines and spaces:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: It is better but still significantly slower than Protobuf.
  prefs: []
  type: TYPE_NORMAL
- en: 'And finally, we can look at the serialized data size for the data used in the
    experiment. For the uncompressed JSON versus uncompressed Protobuf, we have the
    following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'And for the compressed version (gzip), we have this output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: I encourage you to experiment more with this and especially experiment for your
    use cases but, unless there is a big mistake in the proto file design, you will
    find that Protobuf is way more efficient in terms of size and serialization/deserialization
    time.
  prefs: []
  type: TYPE_NORMAL
- en: On top of providing data serialization, we saw that Protobuf also has a concept
    of service, which is a contract between clients and servers. While this concept
    is not linked exclusively to gRPC (you could generate code wrapping other frameworks),
    gRPC uses that to generate the appropriate API endpoints. This provides us with
    type safety on both the client and server sides. If we try to send incorrect data
    and we work in a compiled language, we will get a compilation error instead of
    getting an error at runtime. This dramatically shortens the feedback loop for
    developers and reduces the area of possible failures in our code.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, Protobuf itself is language-agnostic. This means that this is an independent
    data schema, and it can be shared across multiple projects. If you have code written
    in C++ for some microcontroller, sending data to a backend written in Go, which
    is in turn sending data to a web frontend in JS, you can simply share the same
    Protobuf file and generate your models with protoc. You do not have to rewrite
    them every time in the different projects. This decreases the area that needs
    to be updated on adding or updating features and provides an interface that multiple
    teams need to agree on.
  prefs: []
  type: TYPE_NORMAL
- en: In the end, Protobuf enables faster communication (for example, through gRPC)
    by creating smaller payloads, it provides us with type safety on both ends of
    the communication, and it does all that across multiple languages so that we can
    use the right tool for the right job.
  prefs: []
  type: TYPE_NORMAL
- en: What is gRPC doing?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: gRPC is described as “Protobuf over HTTP/2.” This means that gRPC will generate
    all the communication code wrapping the gRPC framework and stand on Protobuf’s
    shoulders to serialize and deserialize data. To know which API endpoints are available
    on the client and server, gRPC will look at the services defined in our `.proto`
    files, and from that, it will learn the basic information needed to generate some
    metadata and the functions needed.
  prefs: []
  type: TYPE_NORMAL
- en: The first thing to understand with gRPC is that there are multiple implementations.
    In Go, for example, you get a pure implementation of gRPC. This means that the
    entire code generation process and communication is written in Go. Other languages
    might have similar implementations, but a lot of them are wrappers around the
    C implementation. While we do not need to know anything about them in the context
    of this book, it is important to know that they are available because it explains
    the presence of plugins for the protoc compiler.
  prefs: []
  type: TYPE_NORMAL
- en: As you know, there are a lot of languages out there. Some are relatively new,
    and some are pretty old, so staying on top of every language’s evolution is practically
    infeasible. That is why we have protoc plugins. Every developer or company interested
    in supporting a language can write such a plugin to generate code that will send
    Protobuf over HTTP/2\. This is, for example, the case for Swift support, which
    was added by Apple.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we are talking about Go, we want to look at what kind of code is generated
    to get a sense of how gRPC works but also to know how to debug and where to look
    for function signatures. Let us start with a simple service—in `proto/account.proto`,
    we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In this service, we have an API endpoint named `Logout` that takes as a parameter
    `LogoutRequest` (a wrapper around `Account`) and returns a `LogoutResponse` parameter.
    `LogoutResponse` is an empty message because we want to send the account for which
    the session needs to be stopped and we do not need any result, just an indicator
    that the call went well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, to generate Protobuf and gRPC code out of this, we will run the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: We already saw with Protobuf that the messages will be turned into structs,
    but now we also have a `_grpc.pb.go` file that contains the gRPC communication
    code.
  prefs: []
  type: TYPE_NORMAL
- en: The server
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let us look at what was generated on the server side first. We are going to
    start from the bottom of the file with the service descriptor. But first, we need
    to know what a descriptor is. In Protobuf and gRPC context, a descriptor is a
    meta object that represents Protobuf code. This means that, in our case, we have
    a Go object representing a service or other concepts. In fact, we did not deep-dive
    into it in the previous chapter but if you look at the generated code for `Account`,
    you will also find `Desc` being mentioned.
  prefs: []
  type: TYPE_NORMAL
- en: 'For our `AccountService` service, we have the following descriptor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This means that we have a service called `AccountService` that is linked to
    a type called `AccountServiceServer`, and this service has a method called `Logout`
    that should be handled by a function called `_AccountService_Logout_Handler`.
  prefs: []
  type: TYPE_NORMAL
- en: 'You should find the handler above the service descriptor. This looks like the
    following (simplified):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This handler is responsible for creating a new object of type `LogoutRequest`
    and populating it before passing it to the `Logout` function in an object of type
    `AccountServiceServer`. Note here that we are going to assume that we always have
    an interceptor equal to `nil` because this is a more advanced feature, but later,
    we are going to see an example of how to set one up and use it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we see the `AccountServiceServer` type being mentioned. Here is what
    it looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This is a type that contains the function signatures of our RPC endpoints and
    a `mustEmbed``UnimplementedAccountServiceServer` function.
  prefs: []
  type: TYPE_NORMAL
- en: Before going to the `Logout` function, let us understand `mustEmbedUnimplemented`
    **AccountServiceServer**. This is an important concept for gRPC because it is
    here to provide a forward-compatible implementation of our service, and what it
    means is that older versions of our API will be able to communicate with newer
    ones without crashing.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you check under the definition of `AccountServiceServer`, you will see the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'With that, we can understand that this `UnimplementedAccountServiceServer`
    type must be embedded somewhere, and this *somewhere* is in a type that we are
    going to define later in this book when we are going to write our API endpoints.
    We are going to have the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This is called type embedding, and this is the way Go goes about adding properties
    and methods from another type. You might have heard the advice to prefer composition
    over inheritance, and that is just that. We add the methods’ definitions from
    `UnimplementedAccountServiceServer` to `Server`. This will let us have the default
    implementations that return `method Logout not implemented` generated for us.
    This means that if a server without a full implementation receives a call on one
    of its unimplemented API endpoints, it will return an error but not crash because
    of the non-existent endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: Once we understand that, the `Logout` method signature is trivial. As mentioned,
    later we are going to define our own server type that embeds the `UnimplementedAccountServiceServer`
    type, and we are going to override the `Logout` function with the implementation.
    Any call to `Logout` will then be redirected to the implementation and not to
    the default generated code.
  prefs: []
  type: TYPE_NORMAL
- en: The client
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The generated code for the client is even simpler than the server code. We
    have an interface called `AccountServiceClient` that contains all the API endpoints:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'And we have the actual implementation of that interface, called `accountServiceClient`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: We can notice one important thing in this piece of code. We have an endpoint
    route called `/AccountService/Logout`. If you take a look back at the `AccountService_ServiceDesc`
    variable described in the section titled *The server*, you will find out that
    this route is a concatenation of the `ServiceName` and `MethodName` properties.
    This will let the server know how to route that request to the `_AccountService_Logout_Handler`
    handler
  prefs: []
  type: TYPE_NORMAL
- en: That is all. We can see that gRPC is handling all the boilerplate code to call
    an endpoint. We just need to create an object following the `AccountServiceClient`
    interface by calling `NewAccountServiceClient`, and then with that object, we
    can call the `Logout` member.
  prefs: []
  type: TYPE_NORMAL
- en: The read/write flow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have seen what Protobuf and gRPC are, it is time to go back to the
    read/write flow that we presented in [*Chapter 1*](B19664_01.xhtml#_idTextAnchor014).
    The goal of doing this is to make it a little bit more detailed and include what
    we learned.
  prefs: []
  type: TYPE_NORMAL
- en: As a quick reminder, we saw that they are mostly three levels when writing and
    reading data. We have the user code, the gRPC framework, and the transport layers.
    What is interesting for us here is mostly the user code. We did not go into too
    much detail in [*Chapter 1*](B19664_01.xhtml#_idTextAnchor014) but now that we
    are equipped with more knowledge on what gRPC is doing, we can understand the
    process more clearly.
  prefs: []
  type: TYPE_NORMAL
- en: The user-code layer is the code that developers write and interacts with the
    gRPC framework. For the client, this is calling the endpoints, and for the server,
    this is the implementation of the endpoints. If we keep going with our `AccountService`
    service, we can give a concrete example of the read/write flow.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing that we can do is separate the user-code layer into two parts:
    the implementation and the generated code. Furthermore, in [*Chapter 1*](B19664_01.xhtml#_idTextAnchor014),
    we gave a rather generic schema where we described the overall flow and drew a
    cryptic component called `Other Actor`. Let us now split the server and the client
    into two different actors, and we have the following system:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.1 – Specialization of the read/write flow for AccountService](img/B19664_03_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.1 – Specialization of the read/write flow for AccountService
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding diagram, I am using abbreviations “c” and “s” to refer to the
    client and server respectively. “c” is an instance of `AccountServiceClient` created
    by `NewAccountServiceClient`, and “s” is an instance of a type defined in `Implementation`
    that defines the `Logout` function.
  prefs: []
  type: TYPE_NORMAL
- en: We can see a few important things happening once we expand the diagram. The
    first interesting concept is that the generated code is shared across the different
    communication actors. We saw that the gRPC Go plugin will generate a single file
    containing the server and client types. This means that this file should be shared
    between all actors written in Go.
  prefs: []
  type: TYPE_NORMAL
- en: We can also notice that the gRPC framework and generated code abstract everything
    for us. This lets us focus only on calling an endpoint with a `Request` object
    and on writing the endpoint handling that `Request` object and returning a `Response`
    object. This highly limits the amount of code we need to write and thus makes
    our code more testable because we need to focus on less code.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the last important thing to notice is that we can limit ourselves to
    reading the generated code to understand the parameters and return types of each
    of our endpoints. This is helpful because either the generated code will be picked
    up by your IDE and you will have autocompletion or you can simply check one file
    to get the information you need.
  prefs: []
  type: TYPE_NORMAL
- en: Why does gRPC matter?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have a sense of what gRPC is, we can get into why it matters. To
    explain gRPC’s role, we are going to compare it with two other ways of performing
    client/server communication. The first one is the traditional REST API architecture
    based on HTTP and JSON, and the second one is GraphQL.
  prefs: []
  type: TYPE_NORMAL
- en: REST
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While I am assuming that most of you reading this book are familiar with REST
    APIs, I still believe that it is important to introduce the principles of designing
    such APIs. It will help us understand in which ways gRPC is like REST and in which
    it differs.
  prefs: []
  type: TYPE_NORMAL
- en: A REST API, as with every other technology in this comparison study, is an interface
    between an information provider and a consumer. When writing such an API, we expose
    endpoints on specific URLs (routes) that can be used by a client to create, read,
    update, and delete resource(s).
  prefs: []
  type: TYPE_NORMAL
- en: 'However, REST APIs are different from gRPC and GraphQL. The main difference
    is that REST is not a framework—it is a set of architectural practices that can
    be implemented in different ways. The main constraints are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The client, server, and resources are the main entities during communication.
    The client requests resources from the server and the server returns the relevant
    resources.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Requests and responses are managed by HTTP. `GET` is used to read resources,
    `POST` to create resources, `PUT` to update resources, `PATCH` to update part
    of a resource, and `DELETE` to remove resources.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No client-related information should be stored between requests. This is a stateless
    communication, and each request is separate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, even though such APIs are not bound to any data format, the most used
    one is JSON. This is mostly because JSON has a wide community, and a lot of languages
    and frameworks can handle this data format.
  prefs: []
  type: TYPE_NORMAL
- en: GraphQL
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: GraphQL is presented as a query language for APIs. It lets developers write
    data schemas that describe the data available, and it lets them query a specific
    set of fields present in the schema.
  prefs: []
  type: TYPE_NORMAL
- en: As it lets us write queries, we can have more generic endpoints and request
    only the fields that we are interested in for a certain feature. This solves the
    problem of overfetching and underfetching because we only get the amount of data
    that we asked for.
  prefs: []
  type: TYPE_NORMAL
- en: On top of all of this, as GraphQL mainly uses JSON as data format and uses explicit
    types and comments in its own data schema, this makes GraphQL more readable and
    self-documenting. This makes this technology more mature for companies at scale
    because we can do type-checking at compile time and shorten the feedback loop,
    and we do not have to separate documentation and code, thus it will be less likely
    to be not in sync.
  prefs: []
  type: TYPE_NORMAL
- en: Comparison with gRPC
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have had an overview of what each technology does, we can get started
    with comparing them with gRPC. We are going to focus on the biggest differentiators
    between these four ways of designing an API. These differentiators are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The transport, data format, and data schema used for communication
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Separation of concern of API endpoints
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The developers’ workflow when writing APIs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The convenience of out-of-the-box features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transport, data format, and data schema
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this regard, GraphQL and REST APIs are similar. They both use HTTP/1.1 for
    the underlying transport and, more often than not, developers use JSON for sending
    structured data. On the other side, gRPC uses HTTP/2 and Protobuf by default.
    This means that, with gRPC, we have smaller payloads to send over the wire and
    we have more efficient connection handling.
  prefs: []
  type: TYPE_NORMAL
- en: There are certain things to be more careful about when we are dealing with Protobuf
    than when we have to deal with JSON. Protobuf provides implicit default values
    depending on the type of field, and these default values do not get serialized
    into the final binary. For example, `int32` has a default value of 0\. This means
    that we cannot differentiate between the value 0 being set or whether the field
    was not set. Of course, there are ways of dealing with that, but it makes the
    client-side usage a little bit more involved. In this respect, GraphQL handles
    default values differently. We can pass the default values as parameters of our
    endpoints, and this means that we can handle particular cases in a more user-friendly
    way.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, it is important to mention that all these technologies are quite flexible
    regarding the kind of data format that you can transport over the wire. REST APIs
    handle binary and other kinds of data, GraphQL can also accept binary data, and
    gRPC can send JSON data. However, problems come with this flexibility. If you
    are using binary over a REST API, you let both the client and the server interpret
    what this binary means. There is no type safety and we need to handle serialization/deserialization
    errors that otherwise would be handled by libraries or frameworks. If you use
    binary with GraphQL, you are greatly reducing the number of community tools that
    you can use. And finally, if you use JSON with gRPC, you are losing all the advantages
    of Protobuf.
  prefs: []
  type: TYPE_NORMAL
- en: Separation of concern of API endpoints
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Designing separation of concern for APIs can be tricky and lead to problems
    such as underfetching or overfetching. GraphQL was designed to solve these problems
    of getting too much or too little data when making a request. With it, you can
    simply ask for a specific set of fields that you need for a certain feature. While
    it is possible to do a similar thing with gRPC and REST APIs, it remains non-user-friendly
    when your API is facing external users.
  prefs: []
  type: TYPE_NORMAL
- en: However, separation of concern in APIs can help us with a few things. First,
    it can help us reduce the scope of testing for an endpoint. Instead of thinking
    about all the possible inputs and outputs that an endpoint might have, we are
    only focusing on a specific input and a specific output.
  prefs: []
  type: TYPE_NORMAL
- en: And second, having smaller and more specific endpoints will help in the case
    of API abuse. As we can clearly know which request was made to which endpoint,
    we can rate-limit them per client and thus secure our APIs. With more flexible
    API endpoints such as in GraphQL, this is intrinsically harder to implement because
    we need to ponder whether to rate limit on the whole route, a specific input,
    or just a simple query.
  prefs: []
  type: TYPE_NORMAL
- en: The developers’ workflow
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another important aspect of these technologies that is often overlooked is the
    developers’ workflow when writing an API. With REST APIs, we are mostly working
    on the server and the client separately, and this process is error-prone. If we
    do not have specifications on what data to expect, we are in for long sessions
    of debugging. Furthermore, even if we have specifications on the data, developers
    are humans and humans make mistakes. The client might have expected a certain
    kind of data, but the server is sending another.
  prefs: []
  type: TYPE_NORMAL
- en: Now, this is not a problem that concerns only REST APIs—gRPC and GraphQL APIs
    also have this problem. However, the problem scope is reduced because we can make
    sure that only a certain type can be used as a request and another as a response.
    This lets us focus on the happy path instead of writing code that is checking
    whether the serialization and deserialization failed.
  prefs: []
  type: TYPE_NORMAL
- en: The gRPC and GraphQL way of developing APIs is called `int`, and it will tell
    us that at compile time. This also makes the scope of tests much smaller because
    we can now focus on the feature itself and not on the many possible errors that
    could happen due to external problems.
  prefs: []
  type: TYPE_NORMAL
- en: Convenience
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Finally, another overlooked topic is how convenient using technology is. This
    can be due to the community developing tools or simply out-of-the-box features
    coming with the framework. In this case, technologies using JSON often have more
    tools and support. This is the case because JSON has been widely used for a long
    time and it is attractive because of its human readability.
  prefs: []
  type: TYPE_NORMAL
- en: However, even with the lack of tool compared to JSON-backed APIs, gRPC was designed
    on principles that helped Google scale and secure its products, it has a lot of
    amazing features that you can get without any extra dependencies. gRPC has interceptors,
    TLS authentication, and many other high-end features built in as part of the official
    framework, and thus it is simpler to write secure and performant code.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, GraphQL is the only technology of the three that is explicit about
    endpoints having side effects. This can be documented for gRPC or REST APIs; however,
    this cannot be checked statically. This is important because this makes the APIs’
    users more aware of what is happening in the background, and it might lead to
    better choices for appropriate routes.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To summarize, gRPC is a mature technology adopted by tech giants but also the
    open source community to create efficient and performant client/server communication.
    This is not only true in the distributed system but also in the local environment
    with the use of IPC. gRPC uses Protobuf by default due to its compact binary serialization
    and fast deserialization but also for its type safety and language agnosticism.
    On top of that, gRPC generates code to send Protobuf over HTTP/2\. It generates
    a server and a client for us so that we do not have to think about the details
    of communication. All the details are handled by the gRPC framework.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we are finally going to get our hands dirty. We are going
    to set up a gRPC project, make sure that our code generation is working properly,
    and write some boilerplate code for both the server and the client.
  prefs: []
  type: TYPE_NORMAL
- en: Quiz
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is one of the reasons Protobuf is the default data format for gRPC?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The serialized data is human-readable
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It is dynamically typed
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It is type-safe
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: In the Go implementation, which component generates server/client code?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Protoc
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The gRPC Go plugin
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Other
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What are service descriptors in the context of gRPC-generated code?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: They describe which endpoints a service has and how to handle requests
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: They describe how to return responses
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Both of these
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: How will the user code be able to implement the logout endpoint?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By writing code in the generated `Logout` function
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: By creating a copy of the generated code and editing it
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: By using type embedding with the generated server and implementing `Logout`
    for that type
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Answers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: C
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: B
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: C
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
