<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Asynchronous API Design</h1>
                </header>
            
            <article>
                
<p class="mce-root">In this chapter, <span>we are going to discuss how to design an asynchronous API for clients. We will look into strategies such as queuing tasks and publish/subscribe paradigms. A synchronous request waits on the server to compute the result. On the other hand, an <strong>asynchronousÂ </strong>(<strong>async</strong>) request receives a response immediately with the information about the eventual result. The real world is composed of many synchronous and asynchronous events.</span></p>
<p class="mce-root"><span>Asynchronous events are very popular in browsers. An async API mimics the same behavior as an event loop in modern browsers. In this chapter, we'll look at the difference between the request types. We'll also write a few clients in Go that can consume an asynchronous API.<br/></span></p>
<p>In this chapter, we will cover the following <span><span>topics:</span></span></p>
<ul>
<li>Understanding sync/async API requests</li>
<li>Fan-in/fan-out of services</li>
<li>Delaying API jobs with queuing</li>
<li>Long-running task design</li>
<li>Caching strategies for APIs</li>
<li>Event-driven API</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>You will need to install the following software to run the code samples in this chapter:</p>
<ul>
<li>OS: Linux (Ubuntu 18.04)/Windows 10/Mac OS X &gt;=10.13</li>
<li>Go stable version compiler &gt;= 1.13.5</li>
<li>Dep: A dependency management tool for Go &gt;= 0.5.3</li>
<li>Docker version &gt;= 18.09.2</li>
</ul>
<p><span>You can download the code for this chapter from</span> <a href="https://github.com/PacktPublishing/Hands-On-Restful-Web-services-with-Go/tree/master/chapter9" target="_blank">https://github.com/PacktPublishing/Hands-On-Restful-Web-services-with-Go/tree/master/chapter9</a><span>. Clone the code and use the code samples in the</span> <kbd>chapter9</kbd> <span>directory.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding sync/async API requests</h1>
                </header>
            
            <article>
                
<p>A synchronous request is an HTTP request that blocks the server until the response is returned. The majority of the services on the web run in this fashion. Nowadays, with the advent of distributed systems and loose coupling, API requests can also be asynchronous. In other words, an asynchronous request returns with information that can be used to fetch the information of a process. These asynchronous requests on a server are closely related to how concurrently the server can execute a job for multiple clients. Let's look at what a synchronous request looks like:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img src="assets/6ed7e24a-abe2-45fb-b25c-a4716b31faaf.png"/></div>
<p>In this type of request, the web server performs all the actions and returns an <strong>Immediate Response</strong> to the <strong>Web client</strong>/<strong>Mobile client</strong>. The drawback of this approach is that if the server takes too much time to render the result, the client is blocked on the server's action.</p>
<p>An asynchronous request instantly returns a response but not with the result. It issues a ticket for finding the status of the requested operation. A client can use that ticket (a different response) to check the status and the final result of the operation:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/841cf354-4327-437d-987d-36d99bca8471.png"/></p>
<p>As shown in the preceding diagram, the client is sending a request to the server and the server returns a response to the client. This response is not something the client can consume instantly. Long-running tasks/jobs can be made asynchronous by the server. The client can then use the received response to find out the status of the job. Once the job is done, either the server can notify the client or the client can poll the result by looking at the status. So far, we have only built a synchronous API. This chapter will discuss its implementation in detail.</p>
<p>In the next section, we'll discuss how APIs can diverge into multiple or submerge into a single call. These techniques are called fan-out and fan-in, respectively.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Fan-in/fan-out of services</h1>
                </header>
            
            <article>
                
<p>Let's take a real-world example of an e-commerce website integrating itself with a third-party payment gateway. Here, the website uses an API from the payment gateway to pop up the payment screen and enters security credentials. At the same time, the website may call another API called analytics to record the attempt of payment. This process of forking a single request into multiple is called <strong>fan-out</strong>. In the real world, there can be many fan-out services involved in a single client request.</p>
<p>Another example is <strong>MapReduce</strong>. Map is a fan-in operation, while Reduce is a fan-out operation. A server can fan out a piece of information to the next set of services (API) and ignore the result or can wait until all the responses from those servers are returned. As shown in the following diagram<span>, an incoming request is being multiplexed by the server into two outgoing requests:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/cb751d20-f1e0-4b5e-8c27-a02390d0d5bc.png"/></p>
<p>This process is a simple fan-out.</p>
<p><strong>Fan-in</strong> is an operation where two or more incoming requests converge into a single request. This scenario is how an API aggregates results from multiple backend services and returns the result on the fly to a client. For example, think about a hotel price aggregator or flight ticket aggregator that fetches requested information about multiple hotels or flights from various data providers and displays them. <span>The following diagram shows how a fan-in operation combines multiple requests and prepares a final response that's consumed by a client</span>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/8b9179a1-4dc9-4c6a-9213-33a5deb5649e.png"/></p>
<p>The client can also be a server that serves further clients. As shown in the preceding diagram, the left-side hand server is collecting the responses from <strong>Hotel A</strong>, <strong>Hotel B</strong>, and <strong>Airline Provider A</strong> and preparing another response for a different client. Therefore, fan-in and fan-out operations are not always completely independent of each other. Mostly, it will be a hybrid scenario where both fan-in and fan-out operations fit with each other.</p>
<p>Please remember that the fan-out operation to the next set of servers can be asynchronous too. This may not be true with fan-in requests. A fan-in operation is sometimes called an API call.</p>
<p>In this section, we've seen how fan-in and fan-out work. To use these techniques, we need to know how to implement an asynchronous service (API). In the next section, we'll try to implement such a service using a mechanism called job queuing.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Delaying API jobs with queuing</h1>
                </header>
            
            <article>
                
<p>In synchronous APIs, the blocking code plays a crucial role in preparing the response that is sent to the client. However, in the asynchronous design, non-blocking is key. A queue and workers can be helpful in achieving non-blocking code. A server can have multiple workers running in parallel who can exhaust the contents of a queue and work on them. Whenever a client requests an operation through an asynchronous API, the server can put that request in a job queue, and all the workers can pick up a task whenever their turn comes.</p>
<p>This approach can offload an API server and focus on its business logic instead of getting blocked on parallel/independent tasks such as sending emails, contacting third-party services, and so on.</p>
<p>A few use cases of queuing are as follows:</p>
<ul>
<li>Compress images and email the final result</li>
<li>Automatic back pressuring (limiting the load on the server to predictable amounts)</li>
</ul>
<p>To explain this concept in detail, let's formulate an example and try to implement it.</p>
<p>Let's develop an asynchronous API server that can perform two different kinds of jobs:</p>
<ul>
<li>Logging given information to the database</li>
<li>Sending an email</li>
</ul>
<p>The condition is that it should not block other operations. The API should return a Job ID ticket to the client who can use that information to fetch the running information of the job.</p>
<p>Before jumping into the implementation, we should know about a few basics of enabling queuing to our service. We can implement queue/worker from scratch, but there are many good open source queuing systems such as RabbitMQ or ZeroMQ to choose from.</p>
<p>We, as part of implementing the preceding problem, will use RabbitMQ due to its popularity and the maturity of Go bindings.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">RabbitMQ, a powerful message queue</h1>
                </header>
            
            <article>
                
<p>RabbitMQ implements a messaging protocol called <strong>Advanced Message Queueing Protocol</strong> (<strong>AMQP</strong>). It uses it to support worker queues. It also supports many other data exchange patterns, such as the following:</p>
<ul>
<li>Publish/Subscribe</li>
<li>Topic/Subscription</li>
<li>Routing messages</li>
<li><strong>Remote Procedure Call</strong> (<span><strong>RPC</strong>)</span></li>
</ul>
<p>In this section, we'll focus on the messaging functionality of RabbitMQ. We can install RabbitMQ on our system using Docker, like so:</p>
<pre><strong>docker run --hostname rabbitmq-host --name rabbitmq-server -p 5672:5672 -p 15672:15672 rabbitmq:3</strong></pre>
<p>It starts the RabbitMQ broker with the given hostname, <kbd>rabbitmq-host</kbd>, and container name, <kbd>rabbitmq-server</kbd>. We use <kbd>rabbitmq:3</kbd> as the base image for our server. Docker pulls the image from the Docker hub and creates a container. You will see an output similar to this:</p>
<pre><strong>              Starting broker...</strong><br/><strong>2019-08-10 08:19:20.371 [info] &lt;0.223.0&gt;</strong><br/><strong> node           : rabbit@rabbitmq-host</strong><br/><strong> home dir       : /var/lib/rabbitmq</strong><br/><strong> config file(s) : /etc/rabbitmq/rabbitmq.conf</strong><br/><strong> cookie hash    : tUgaG2zTrSrf/yZv3KRV5Q==</strong><br/><strong> log(s)         : &lt;stdout&gt;</strong><br/><strong> database dir   : /var/lib/rabbitmq/mnesia/rabbit@rabbitmq-host</strong><br/><br/><strong>....</strong><br/><strong>2019-08-10 08:19:20.873 [info] &lt;0.497.0&gt; started TCP listener on [::]:5672</strong></pre>
<p>RabbitMQ uses default port <kbd>5672</kbd> for its operations. You can change this using the initial settings for the Docker command.</p>
<div class="packt_tip">The preceding RabbitMQ broker runs in the foreground. However, in production, you have to run it in the background. This means you need to pass the <kbd>-d</kbd> flag to the Docker command to run it in the background, like so:<br/>
<br/>
<kbd>docker run -d --hostname rabbitmq-host --name rabbitmq-server -p 5672:5672 -p 15672:15672 rabbitmq:3</kbd></div>
<p>By default, if we don't pass user credentials while launching the container (<kbd>docker run ...</kbd>), a default <kbd>&lt;guest:guest&gt;</kbd> user's credentials are created for the broker. You can reset them at any time or pass them while launching a container. You can find out more at <a href="https://hub.docker.com/_/rabbitmq" target="_blank">https://hub.docker.com/_/rabbitmq</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Communicating with RabbitMQ in Go</h1>
                </header>
            
            <article>
                
<p class="mce-root">Now, we have a message broker (RabbitMQ). Before building an asynchronous API, we should learn how a Go program can talk to the message broker and send/receive the messages. While doing so, we'll create clients for production and consumption.</p>
<p class="mce-root">First, we have to create a <kbd>connection</kbd> to dial to the broker. If the connection is successful, a <kbd>Channel</kbd> needs to be created out of the connection. It has the API for performing operations on the message broker. Then, we can define a queue that messages are sent to. Finally, we publish a message to the queue.</p>
<p class="mce-root">We use an open source Go package called <kbd>amqp</kbd> for working with RabbitMQ.</p>
<p class="mce-root">Let's create our first program of this chapter:</p>
<ol>
<li class="mce-root">Create a directory like this for a message sender:</li>
</ol>
<pre style="padding-left: 60px"><strong>mkdir -p $GOPATH/src/github.com/git-user/chapter9/basicSender</strong></pre>
<ol start="2">
<li>Install the <kbd>amqp</kbd> package using the <kbd>dep</kbd> tool:</li>
</ol>
<pre style="padding-left: 60px"><strong>dep ensure --add "github.com/streadway/amqp"</strong></pre>
<p style="padding-left: 60px">This creates the <kbd>Gopkg.toml</kbd> and <kbd>Gopkg.lock</kbd> files in the directory.</p>
<p>Now, we are ready to go. We're going to look at an example that creates a queue in RabbitMQ and sends a message to it:</p>
<ol start="1">
<li>First, let's import the necessary packages/libraries inside <kbd>main.go</kbd>. These are <kbd>log</kbd> and <kbd>amqp</kbd>:</li>
</ol>
<pre style="padding-left: 60px">package main<br/><br/>import (<br/>    "log"<br/><br/>    "github.com/streadway/amqp"<br/>)</pre>
<ol start="2">
<li>Now, we need a handler to handle errors that will be generated from every step. Go's error handling can be messy, which hampers readability. To have a clean code structure, we need to handle errors in one single place:</li>
</ol>
<pre style="padding-left: 60px">func handleError(err error, msg string) {<br/>    if err != nil {<br/>        log.Fatalf("%s: %s", msg, err)<br/>    }<br/>}</pre>
<p style="padding-left: 60px">This function takes an error and a message and logs the information to <kbd>STDOUT</kbd>.</p>
<ol start="3">
<li>Now, let's write the logic for sending and receiving messages. In the program's main block, create a connection and channel. Then, dial to RabbitMQ using a connection string that contains user credentials. Once the connection is successful, obtain the <kbd>Channel</kbd> object to push messages. The code looks like this:</li>
</ol>
<pre style="padding-left: 60px">func main() {<br/>    conn, err := amqp.Dial("amqp://guest:guest@localhost:5672/")<br/>    handleError(err, "Dialing failed to RabbitMQ broker")<br/>    defer conn.Close()<br/><br/>    channel, err := conn.Channel()<br/>    handleError(err, "Fetching channel failed")<br/>    defer channel.Close()<br/>}</pre>
<p style="padding-left: 60px">This is the connection string:</p>
<pre style="padding-left: 60px">amqp://guest:guest@localhost:5672/</pre>
<p style="padding-left: 60px">It is formed with the details of <kbd>protocol ://user:password@host:port</kbd>, where <kbd>host</kbd>, <kbd>port</kbd>, <kbd>user</kbd>, and <kbd>password</kbd> are the credentials of the RabbitMQ server.</p>
<div class="packt_infobox">You should never use the default credentials for RabbitMQ in production. Please set strong passwords for all your sensitive information, includingÂ <span>â</span> RabbitMQ.</div>
<ol start="4">
<li>Declare a queue called <kbd>test</kbd> for publishing the messages:</li>
</ol>
<pre style="padding-left: 60px">testQueue, err := channel.QueueDeclare(<br/>    "test", // Name of the queue<br/>    false,  // Message is persisted or not<br/>    false,  // Delete message when unused<br/>    false,  // Exclusive<br/>    false,  // No Waiting time<br/>    nil,    // Extra args<br/>)<br/><br/>handleError(err, "Queue creation failed")</pre>
<ol start="5">
<li>Now, we have a queue. Let's prepare an <kbd>amqp</kbd> message (RabbitMQ message) to push it into the queue. Let's say the message body is a log of server time:</li>
</ol>
<pre style="padding-left: 60px">serverTime := time.Now()<br/>message := amqp.Publishing{<br/>    ContentType: "text/plain",<br/>    Body:        []byte(serverTime.String()),<br/>}</pre>
<ol start="6">
<li>Publish the preceding message to the predefined queue, that is <kbd>testQueue</kbd>:</li>
</ol>
<pre style="padding-left: 60px">err = channel.Publish(<br/>    "",             // exchange<br/>    testQueue.Name, // routing key(Queue)<br/>    false,          // mandatory<br/>    false,          // immediate<br/>    message,<br/>)<br/><br/>handleError(err, "Failed to publish a message")<br/>log.Println("Successfully published a message to the queue")</pre>
<p>The <kbd>Publish</kbd> method publishes a given message into a RabbitMQ queue.</p>
<p>We've finished creating a sender. Now, if we run this program, it pushes a message instantly.</p>
<p>Now, let's write a receiver (worker) to consume those messages:</p>
<ol>
<li>The logic is to define a <kbd>Consumer</kbd> and receive the messages. The code for the worker is mostly the same as it was previously:</li>
</ol>
<pre style="padding-left: 60px"><strong>mkdir -p $GOPATH/src/github.com/git-user/chapter9/basicReceiver<br/></strong><strong>touch $GOPATH/src/github.com/git-user/chapter9/basicReceiver/<br/>main.go</strong></pre>
<ol start="2">
<li>Dial to RabbitMQ using the connection string, fetch the <kbd>Channel</kbd>, and create a representation for <kbd>testQueue</kbd>:</li>
</ol>
<pre style="padding-left: 60px">package main<br/><br/>import (<br/>    "log"<br/><br/>    "github.com/streadway/amqp"<br/>)<br/><br/>func handleError(err error, msg string) {<br/>    if err != nil {<br/>        log.Fatalf("%s: %s", msg, err)<br/>    }<br/>}<br/><br/>func main() {<br/>    conn, err := amqp.Dial("amqp://guest:guest@localhost:5672/")<br/>    handleError(err, "Dialing failed to RabbitMQ broker")<br/>    defer conn.Close()<br/><br/>    channel, err := conn.Channel()<br/>    handleError(err, "Fetching channel failed")<br/>    defer channel.Close()<br/><br/>    testQueue, err := channel.QueueDeclare(<br/>        "test", // Name of the queue<br/>        false,  // Message is persisted or not<br/>        false,  // Delete message when unused<br/>        false,  // Exclusive<br/>        false,  // No Waiting time<br/>        nil,    // Extra args<br/>    )<br/><br/>    handleError(err, "Queue creation failed")<br/><br/>}</pre>
<ol start="3">
<li>We need to add some extra functionality to consume. Just after <kbd>handleError</kbd> in the main section, we need to define which queue to consume and its properties:</li>
</ol>
<pre style="padding-left: 60px">messages, err := channel.Consume(<br/>    testQueue.Name, // queue<br/>    "",             // consumer<br/>    true,           // auto-acknowledge<br/>    false,          // exclusive<br/>    false,          // no-local<br/>    false,          // no-wait<br/>    nil,            // args<br/>)<br/><br/>handleError(err, "Failed to register a consumer")</pre>
<ol start="4">
<li><kbd>messages</kbd> is a consumable that can be read for messages that are pushed into <kbd>testQueue</kbd>. Let's see how we can read it:</li>
</ol>
<pre style="padding-left: 60px">go func() {<br/>    for message := range messages {<br/>        log.Printf("Received a message from the queue: %s",<br/>         message.Body)<br/>    }<br/>}()</pre>
<p style="padding-left: 60px">This runs a go-routine that spawns a function that runs an infinite loop to c<span>ollect messages and process them. A go-routine is a lightweight thread that's managed by Go's runtime engine. We can spawn a go-routine from a function. Here, we are simply logging the message to</span><span>Â </span><kbd>STDOUT</kbd> <span>in our go-routine. If we don't block the main program, the whole process ends, quickly killing the go-routine.</span></p>
<ol start="5">
<li>Let's create a channel and read from it to block the main program:</li>
</ol>
<pre style="padding-left: 60px">log.Println("Worker has started")<br/>wait := make(chan bool)<br/>&lt;-wait</pre>
<p style="padding-left: 90px">In this way, we have a worker.</p>
<ol start="6">
<li>Let's run both programs to see how they work. First, run the worker. It creates a Queue called "text" if it doesn't exist. Then, run the sender to send a message to the queue on a Terminal:</li>
</ol>
<pre style="padding-left: 60px"><strong>go run $GOPATH/src/github.com/git-user/chapter9/basicReceiver/<br/>main.go<br/>2019/08/10 16:02:29 Worker has started<br/></strong></pre>
<ol start="7">
<li>In another window of the Terminal (shell), run the sender program, which pushes a server time log into the queue:</li>
</ol>
<pre style="padding-left: 60px"><strong>go run $GOPATH/src/github.com/git-user/chapter9/basicSender/<br/>main.go<br/>2019/08/10 16:03:15 Successfully published a message to the queue<br/></strong></pre>
<ol start="8">
<li>If you check the first Terminal, you'll see the following message:</li>
</ol>
<pre style="padding-left: 60px"><strong>2019/08/10 16:03:15 Received a message from the queue: 2019-08-10 16:03:15.367476 +0200 CEST m=+0.014980319</strong></pre>
<p>This means the worker is successfully able to retrieve the messages from the queue. This functionality can be leveraged by API servers to put long-running jobs into message queues and let dedicated workers handle them.</p>
<p>After grasping the basics of queuing and how it can help us build asynchronous APIs, we should implement a real-world problem. In the next section, we'll define the problem statement and try to design a long-running task that performs various functions at the same time.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Long-running task design</h1>
                </header>
            
            <article>
                
<p>So far, we've learned about the basics of queuing and how to delay jobs. Now, we're going to design a solution to a problem regarding asynchronous APIs. The problem is that we want to build a system that can handle requests for the following scenarios:</p>
<ul>
<li>The server should save information to the database as one operation.</li>
<li>It should send an email to the given email address.</li>
<li>It should perform a long-running job and POST the result to a callback. This is known as a web-hook.</li>
</ul>
<p>Let's say these three operations are asynchronous and long-running. We need a mechanism to facilitate a long-running process that has the following characteristics:</p>
<ul>
<li>The client can fire an API and receive a job ID back.</li>
<li>The job is pushed onto a queue with the respective message format.</li>
<li>A worker picks the job and starts performing it.</li>
<li>Finally, the worker saves the result on various endpoints and sends the status to the database.</li>
</ul>
<p>The following diagram shows the preceding requirements in detail:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img src="assets/32f92cad-16d3-40c7-bb77-9dacb758c13f.png" style="width:43.33em;height:30.58em;"/></div>
<p>The preceding diagram shows a few engaging entities:</p>
<ul>
<li><strong>API server</strong></li>
<li><strong><strong>Database server</strong></strong></li>
<li><strong>Queue</strong></li>
<li><strong>Workers</strong></li>
</ul>
<p><strong>API Server</strong> is accepting asynchronous requests from the client and pushing those jobs into a message queue. Then, the workers are picking those jobs and performing some action on them.</p>
<p><strong>Worker A</strong> saves the information from the message into a database. <strong>Worker B</strong> picks a job. After working on the message, it posts some information to a callback that was received as part of a request. <strong>Worker C</strong>'s job is to send an email.</p>
<p>For the sake of simplicity, we'll mock the end actions (DB insert, Email sending, and Callback). We're doing this in order to focus on the asynchronous API design over concrete actions.</p>
<p>To design this flow, we need to reuse the same message and make it fit all use cases. JSON is a better format for storing information about a job.</p>
<p>We need to create some structs that hold information about the jobs, as follows:</p>
<ul>
<li><strong>Job</strong>: Global storage for a job</li>
<li><strong>Log</strong>: Information dedicated to Job A</li>
<li><strong>CallBack</strong>: Information dedicated to Job B</li>
<li><strong>Mail</strong>: Information dedicated to Job C</li>
</ul>
<p>A, B, and C are the worker types mentioned in the previous diagram.</p>
<p>Now, let's define our project. Creating a project directory and developing each piece shown in the preceding architecture is part of this process:</p>
<ol>
<li>Create the project:</li>
</ol>
<pre style="padding-left: 60px"><strong>mkdir -p $GOPATH/src/github.com/git-user/chapter9/longRunningTaskV1</strong></pre>
<p style="padding-left: 60px">We're naming it <kbd>V1</kbd> (<kbd>Version 1</kbd>) because it is our first attempt to achieve asynchronicity. We'll add more features with more versions in the upcoming sections.</p>
<ol start="2">
<li>We need to store our structs in the <kbd>models</kbd> directory. Create a package called <kbd>models</kbd> and add a new file to store the preceding structs:</li>
</ol>
<pre style="padding-left: 60px"><strong>mkdir -p $GOPATH/src/github.com/git-user/chapter9/longRunningTaskV1<br/>/models<br/></strong><strong>touch $GOPATH/src/github.com/git-user/chapter9/longRunningTaskV1<br/>/models/job.go<br/></strong></pre>
<ol start="3">
<li>For the fields, we have <kbd>UUID</kbd> to track the job, <kbd>type</kbd> to distinguish between jobs, and extra data that is specific to respective jobs. We use Google's <kbd>UUID</kbd> package to generate a <kbd>UUID</kbd> string and set a Job ID. <kbd>type</kbd> could be "A", "B", or "C".<kbd>Log</kbd> is used for time-related operations, so it needs a time field. <kbd>callback</kbd> needs a callback URL to post data. <kbd>mail</kbd> needs an email address to send a message to. The struct file contains the following constructs:</li>
</ol>
<pre style="padding-left: 60px">package models<br/><br/>import (<br/>    "time"<br/><br/>    "github.com/google/uuid"<br/>)<br/><br/>// Job represents UUID of a Job<br/>type Job struct {<br/>    ID      uuid.UUID   `json:"uuid"`<br/>    Type      string      `json:"type"`<br/>    ExtraData interface{} `json:"extra_data"`<br/>}<br/><br/>// Worker-A data<br/>type Log struct {<br/>    ClientTime time.Time `json:"client_time"`<br/>}<br/><br/>// CallBack data<br/>type CallBack struct {<br/>    CallBackURL string `json:"callback_url"`<br/>}<br/><br/>// Mail data<br/>type Mail struct {<br/>    EmailAddress string `json:"email_address"`<br/>}</pre>
<p style="padding-left: 60px">The important field from the preceding file is <kbd>ExtraData</kbd>:</p>
<pre style="padding-left: 30px">    ExtraData interface{} `json:"extra_data"`</pre>
<p style="padding-left: 60px">We define it as an interface and make it a placeholder for Log, Callback, and Mail. We instantiate the respective structs when we publish the message.</p>
<ol start="4">
<li>In the main program, we have to define a few helper functions and constants. We add these to our project's main file:</li>
</ol>
<pre style="padding-left: 60px"><strong>touch $GOPATH/src/github.com/git-user/chapter9/longRunningTaskV1<br/>/main.go</strong></pre>
<ol start="5">
<li>Define the queue name, the address that the HTTP server runs on, and an error handler that handles any errors:</li>
</ol>
<pre style="padding-left: 60px">const queueName string = "jobQueue"<br/>const hostString string = "127.0.0.1:8000"<br/><br/>func handleError(err error, msg string) {<br/>    if err != nil {<br/>        log.Fatalf("%s: %s", msg, err)<br/>    }<br/>}</pre>
<p style="padding-left: 60px"><span>This is done to avoid duplicate code.</span></p>
<p style="padding-left: 60px">We have to bake a few more components in our project:</p>
<ul>
<li style="padding-left: 60px">An HTTP server</li>
<li style="padding-left: 60px">Workers</li>
<li style="padding-left: 60px">URL handlers</li>
</ul>
<p style="padding-left: 60px">A <kbd>Handler</kbd> takes an incoming request and tries to create an instant Job ID. Once it successfully places the job in the queue, it returns the Job ID to the caller. Now, the workers who are already started and listening to the job queue pick those tasks and execute them concurrently.</p>
<ol start="6">
<li>Create a file for the worker:</li>
</ol>
<pre style="padding-left: 60px"><strong>touch $GOPATH/src/github.com/git-user/chapter9/longRunningTaskV1<br/>/worker.go</strong></pre>
<p style="padding-left: 60px"><kbd>Workers</kbd> is a <kbd>struct</kbd> that holds a connection to the message queue. Using that connection, all the workers read from the queue:</p>
<pre style="padding-left: 60px">type Workers struct {<br/>    conn *amqp.Connection<br/>}</pre>
<p style="padding-left: 60px">At some point, we need to start the workers. To do this, we need to define a run method that initiates/boots workers. The worker should listen to the message queue for messages and consume them.</p>
<ol start="7">
<li>Once there is an incoming message, check the type of work and delegate it to the respective functions, that is,<kbd>dbWork</kbd>, <kbd>callbackWork</kbd>, and <kbd>emailWork</kbd>:</li>
</ol>
<pre style="padding-left: 60px">func (w *Workers) run() {<br/>    log.Printf("Workers are booted up and running")<br/>    channel, err := w.conn.Channel()<br/>    handleError(err, "Fetching channel failed")<br/>    defer channel.Close()<br/><br/>    jobQueue, err := channel.QueueDeclare(<br/>        queueName, // Name of the queue<br/>        false,     // Message is persisted or not<br/>        false,     // Delete message when unused<br/>        false,     // Exclusive<br/>        false,     // No Waiting time<br/>        nil,       // Extra args<br/>    )<br/>    handleError(err, "Job queue fetch failed")<br/><br/>    messages, err := channel.Consume(<br/>        jobQueue.Name, // queue<br/>        "",            // consumer<br/>        true,          // auto-acknowledge<br/>        false,         // exclusive<br/>        false,         // no-local<br/>        false,         // no-wait<br/>        nil,           // args<br/>    )<br/>    go func() {<br/>        for message := range messages {<br/><br/>            job := models.Job{}<br/>            err = json.Unmarshal(message.Body, &amp;job)<br/><br/>            log.Printf("Workers received a message from the queue:<br/>             %s", job)<br/>            handleError(err, "Unable to load queue message")<br/><br/>            switch job.Type {<br/>            case "A":<br/>                w.dbWork(job)<br/>            case "B":<br/>                w.callbackWork(job)<br/>            case "C":<br/>                w.emailWork(job)<br/>            }<br/>        }<br/>    }()<br/>    defer w.conn.Close()<br/>    wait := make(chan bool)<br/>    &lt;-wait // Run long-running worker<br/>}</pre>
<ol start="8">
<li>At the end of the function, we closed the channel and blocked the worker since go-routines are running in the background.</li>
<li>Now, we can mock the actual work of the workers with delays for three functions:Â <kbd>dbWork</kbd>, <kbd>callbackWork</kbd>, and <kbd>emailWork</kbd>. We use delays to simulate the background work and log messages accordingly. We will define those functions on the <kbd>workers</kbd> <span>struct so that the functions are tightly attached:</span></li>
</ol>
<pre style="padding-left: 60px"><br/>func (w *Workers) dbWork(job models.Job) {<br/>    result := job.ExtraData.(map[string]interface{})<br/>    log.Printf("Worker %s: extracting data..., JOB: %s",<br/>     job.Type, result)<br/>    time.Sleep(2 * time.Second)<br/>    log.Printf("Worker %s: saving data to database...,<br/>     JOB: %s", job.Type, job.ID)<br/>}<br/><br/>func (w *Workers) callbackWork(job models.Job) {<br/>    log.Printf("Worker %s: performing some long running process...,<br/>     JOB: %s", job.Type, job.ID)<br/>    time.Sleep(10 * time.Second)<br/>    log.Printf("Worker %s: posting the data back to the given<br/>     callback..., JOB: %s", job.Type, job.ID)<br/>}<br/><br/>func (w *Workers) emailWork(job models.Job) {<br/>    log.Printf("Worker %s: sending the email..., JOB: %s",<br/>     job.Type, job.ID)<br/>    time.Sleep(2 * time.Second)<br/>    log.Printf("Worker %s: sent the email successfully,<br/>     JOB: %s", job.Type, job.ID)<br/>}</pre>
<p style="padding-left: 60px">These workers work independent of the main program. They listen to the message queue and process incoming messages according to their type. By doing this, we have defined the endpoints/workers.</p>
<ol start="10">
<li>Now, it's time to define a few endpoints for our HTTP server that accept the API requests and publish messages to the queue. These will go into a new file called <kbd>handlers.go</kbd>:</li>
</ol>
<pre style="padding-left: 60px"><strong>touch $GOPATH/src/github.com/git-user/chapter9/longRunningTaskV1<br/>/handlers.go</strong></pre>
<ol start="11">
<li>Our handlers also need access to the message queue's connection, which is a channel where we can publish messages. Due to this, it is better to have a struct for the server and define the handlers as methods. Let's call it <kbd>JobStruct</kbd>:</li>
</ol>
<pre style="padding-left: 60px">// JobServer holds handler functions<br/>type JobServer struct {<br/>    Queue   amqp.Queue<br/>    Channel *amqp.Channel<br/>    Conn    *amqp.Connection<br/>}</pre>
<ol start="12">
<li>We should attach a method called <kbd>publish</kbd> to the preceding struct. All the handlers can use this method to publish a JSON body to the message queue. It is similar to the logic we explored when we introduced the RabbitMQ channel:</li>
</ol>
<pre style="padding-left: 60px">func (s *JobServer) publish(jsonBody []byte) error {<br/>    message := amqp.Publishing{<br/>        ContentType: "application/json",<br/>        Body:        jsonBody,<br/>    }<br/>    err := s.Channel.Publish(<br/>        "",        // exchange<br/>        queueName, // routing key(Queue)<br/>        false,     // mandatory<br/>        false,     // immediate<br/>        message,<br/>    )<br/><br/>    handleError(err, "Error while generating JobID")<br/>    return err<br/>}</pre>
<p>Now, let's define three handlers that will work on three types of jobs, as follows:</p>
<ul>
<li>The first handler creates a job for work type A<span>â</span> saving client time to the database.</li>
<li>The second handler creates a job for work type B<span>â</span> a callback to the URL after some time.</li>
<li>The third handler creates a job for work type C<span>â</span> sending an email.</li>
</ul>
<p>For the first handler, we take a query parameter called <kbd>client_time</kbd> from an HTTP request and use it to save in the DB. We use <kbd>json</kbd> and <kbd>strconv</kbd> to make required data conversions. Once we have the necessary information for the worker, we can compose the JSON and publish it to the queue:</p>
<pre style="padding-left: 30px">func (s *JobServer) asyncDBHandler(w http.ResponseWriter,<br/>r *http.Request) {<br/>    jobID, err := uuid.NewRandom()<br/>    queryParams := r.URL.Query()<br/>    // Ex: client_time: 1569174071<br/>    unixTime, err := strconv.ParseInt(queryParams.Get("client_time"),<br/>     10, 64)<br/>    clientTime := time.Unix(unixTime, 0)<br/>    handleError(err, "Error while converting client time")<br/><br/>    jsonBody, err := json.Marshal(models.Job{ID: jobID,<br/>        Type:      "A",<br/>        ExtraData: models.Log{ClientTime: clientTime},<br/>    })<br/>    handleError(err, "JSON body creation failed")<br/><br/>    if s.publish(jsonBody) == nil {<br/>        w.WriteHeader(http.StatusOK)<br/>        w.Header().Set("Content-Type", "application/json")<br/>        w.Write(jsonBody)<br/>    } else {<br/>        w.WriteHeader(http.StatusInternalServerError)<br/>    }<br/>}</pre>
<p>As you can see, this function handler composes a message that is required for the worker that processes <kbd>"A"</kbd>(database job). Extra information is passed inside the <kbd>ExtraData</kbd> field. As we mentioned previously, the interface can fit any kind of new struct in it. So, at runtime, we set what could fit into <kbd>ExtraData</kbd>.</p>
<p>The other two handlers look exactly the same, except for the composition of <kbd>jsonBody</kbd>.</p>
<p>The JSON message for handler 2 is as follows:</p>
<pre>    jsonBody, err := json.Marshal(models.Job{ID: jobID,<br/>        Type:      "B",<br/>        ExtraData: "", // Can be custom data, Ex: {"client_time":<br/>                       // "2020-01-22T20:38:15+02:00"}<br/> })</pre>
<p>The JSON message for handler 3 is as follows:</p>
<pre>    jsonBody, err := json.Marshal(models.Job{ID: jobID,<br/>        Type:      "C",<br/>        ExtraData: "", // Can be custom data, Ex: {"email_address":<br/>                       // "packt@example.org"}<br/> })</pre>
<p>Next is the main program. We have to glue workers, handlers, and structs using our main logic. Previously, we added the constants, but now we have to extend this to bring the workers and API to life.</p>
<p>Finally, we should glue everything we have built so far together. Follow these steps to do so:</p>
<ol start="1">
<li>We need a function that returns a <kbd>JobServer</kbd> object. Let's add that function, called <kbd>getServer</kbd>, to the <kbd>main.go</kbd> file. The job server holds a connection and a queue. The code looks like this:</li>
</ol>
<pre style="padding-left: 60px">func getServer(name string) JobServer {<br/>    /*<br/>        Creates a server object and initiates<br/>        the Channel and Queue details to publish messages<br/>    */<br/>    conn, err := amqp.Dial("amqp://guest:guest@localhost:5672/")<br/>    handleError(err, "Dialing failed to RabbitMQ broker")<br/><br/>    channel, err := conn.Channel()<br/>    handleError(err, "Fetching channel failed")<br/><br/>    jobQueue, err := channel.QueueDeclare(<br/>        name,  // Name of the queue<br/>        false, // Message is persisted or not<br/>        false, // Delete message when unused<br/>        false, // Exclusive<br/>        false, // No Waiting time<br/>        nil,   // Extra args<br/>    )<br/>    handleError(err, "Job queue creation failed")<br/>    return JobServer{Conn: conn, Channel: channel, Queue: jobQueue}<br/>}</pre>
<p style="padding-left: 60px">Using this server, we can link URL endpoints to handler functions. These functions use the instantiated connection properties of RabbitMQ/Message Queue.</p>
<ol start="2">
<li>Now, get a <kbd>JobServer</kbd> by calling the preceding function with <kbd>queueName</kbd>, which we defined as a constant:</li>
</ol>
<pre style="padding-left: 60px">func main() {<br/>    jobServer := getServer(queueName)<br/><br/>    // Rest of the code goes here....<br/>}</pre>
<ol start="3">
<li>Next, we should start the workers. If we start them normally, they'll block the main execution thread. Therefore, we have to make them goroutines:</li>
</ol>
<pre style="padding-left: 60px">// Start Workers<br/>go func(conn *amqp.Connection) {<br/>    workerProcess := Workers{<br/>        conn: jobServer.Conn,<br/>    }<br/>    workerProcess.run()<br/>}(jobServer.Conn)</pre>
<ol start="4">
<li>To take client requests and make our application possible, we have to attach handlers to the URL. The Gorilla Mux router can be used for this. We discussed it extensively in <a href="72226cd9-cd86-497f-ba6c-4a273e0e3193.xhtml">Chapter 2</a>,<a href="72226cd9-cd86-497f-ba6c-4a273e0e3193.xhtml">Â </a><em>Handling Routing for our REST Services</em>. We'll reuse the same pattern we used there to attach the routes to the handlers:</li>
</ol>
<pre style="padding-left: 60px">router := mux.NewRouter()<br/>// Attach handlers<br/>router.HandleFunc("/job/database", jobServer.asyncDBHandler)<br/>router.HandleFunc("/job/mail", jobServer.asyncMailHandler)<br/>router.HandleFunc("/job/callback", jobServer.asyncCallbackHandler)<br/><br/>httpServer := &amp;http.Server{<br/>    Handler:      router,<br/>    Addr:         hostString,<br/>    WriteTimeout: 15 * time.Second,<br/>    ReadTimeout:  15 * time.Second,<br/>}<br/><br/>// Run HTTP server<br/>log.Fatal(httpServer.ListenAndServe())</pre>
<p style="padding-left: 60px">This starts an HTTP server and routes requests to the URL we defined previously. As you may have noticed, we are using a job server's handlers as endpoints.</p>
<ol start="5">
<li>Last but not least, we should safely close the connection and channel:</li>
</ol>
<pre style="padding-left: 60px">// Cleanup resources<br/>defer jobServer.Channel.Close()<br/>defer jobServer.Conn.Close()</pre>
<p>This completes our example. Let's build the Go project from the project root (<kbd>longRunningTask</kbd>) and see the output:</p>
<div class="packt_infobox">Make sure your RabbitMQ server isn't down. Our job server uses RabbitMQ as a message queue.</div>
<ol>
<li>Run the <kbd>go build</kbd> command:</li>
</ol>
<pre style="padding-left: 60px"><strong>go build .</strong></pre>
<ol start="2">
<li>This generates an executable with the same name as the project, that is,Â <kbd>longRunningTaskV1</kbd>. We can start our HTTP server like so:</li>
</ol>
<pre style="padding-left: 60px"><strong>./longRunningTaskV1</strong><br/><strong>2019/09/22 20:36:06 Workers are booted up and running</strong></pre>
<ol start="3">
<li>The server is now running on port <kbd>8000</kbd>. Make a few <kbd>curl</kbd> <kbd>GET</kbd> requests to the server:</li>
</ol>
<pre style="padding-left: 60px"><strong>&gt; curl -X GET http://localhost:8000/job/database\?client_time\=1569177495</strong><br/><strong>{"uuid":"9dfbc374-a046-4b29-b6f8-5414a277aaa2","type":"A","extra_data":{"client_time":"2019-09-22T20:38:15+02:00"}}</strong><br/><br/><strong>&gt; curl -X GET http://localhost:8000/job/callback</strong><br/><strong>{"uuid":"ac297c92-74ec-4fcb-b3e6-6dfb96eb45e0","type":"B","extra_data":""}</strong><br/><br/><strong>&gt; curl -X GET http://localhost:8000/job/mail</strong><br/><strong>{"uuid":"4ed59a6f-24d8-4179-8432-fe4adcdd4f51","type":"C","extra_data":""}</strong></pre>
<ol start="4">
<li>Instead of blocking the requests, the server returns quickly with a Job ID for the tasks. Let's take a look at the server logs:</li>
</ol>
<pre style="padding-left: 60px"><strong>2019/09/22 20:39:56 Workers received a message from the queue: {9dfbc374-a046-4b29-b6f8-5414a277aaa2 A map[client_time:2019-09-22T20:38:15+02:00]}</strong><br/><strong>2019/09/22 20:39:56 Worker A: extracting data..., JOB: map[client_time:2019-09-22T20:38:15+02:00]</strong><br/><strong>2019/09/22 20:39:58 Worker A: saving data to database..., JOB: 9dfbc374-a046-4b29-b6f8-5414a277aaa2</strong><br/><strong>2019/09/22 20:40:29 Workers received a message from the queue: {ac297c92-74ec-4fcb-b3e6-6dfb96eb45e0 B }</strong><br/><strong>2019/09/22 20:40:29 Worker B: performing some long running process..., JOB: ac297c92-74ec-4fcb-b3e6-6dfb96eb45e0</strong><br/><strong>2019/09/22 20:40:39 Worker B: posting the data back to the given callback..., JOB: ac297c92-74ec-4fcb-b3e6-6dfb96eb45e0</strong><br/><strong>2019/09/22 20:40:39 Workers received a message from the queue: {4ed59a6f-24d8-4179-8432-fe4adcdd4f51 C }</strong><br/><strong>2019/09/22 20:40:39 Worker C: sending the email..., JOB: 4ed59a6f-24d8-4179-8432-fe4adcdd4f51</strong><br/><strong>2019/09/22 20:40:41 Worker C: sent the email successfully, JOB: 4ed59a6f-24d8-4179-8432-fe4adcdd4f51</strong></pre>
<p>There is a two second delay in sending the mail, but the client is not blocked on that decision. This is how an asynchronous API works by design.</p>
<div class="packt_tip">Always prepare a design upfront for an asynchronous API. Since there is no silver bullet for a given problem, you have to explore various architectures, such as message queues.</div>
<p>Okay, but how can a client retrieve the status of a job, whether it is started, in progress, or done? To enable that feature, we have to store the state of a job somewhere. This can be a database or a temporary cache. Modern applications make a lot of read operations by polling the API for the job status. Redis is a good caching solution for these kinds of problems. We can extend this example with Redis to solve <kbd>find the status of a job ID</kbd>.</p>
<p>In the next section, we'll introduce Redis, which includes installing Redis and linking it to a Go program. After that, we'll construct an extended version of a long-running task with a job status.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Caching strategies for APIs</h1>
                </header>
            
            <article>
                
<p>Redis is a wonderful open source solution for caching high-read configuration/information. It is a key/value pair store and has faster reads thanks to its in-memory storage. An example of a key/value pair store is a media website where a few articles are set fixed on their home page for a few hours.</p>
<p>Instead of letting every reader hit their database to fetch a record, a media house can use Redis to store article content. That is one of many applications of Redis.</p>
<p>Job status is temporary information that becomes irrelevant once the job is finished and status is logged to log storage. Due to this, Redis is the best choice for implementing job status caching. We plan to do the following things:</p>
<ul>
<li>Write a job status</li>
<li>Read a job status</li>
</ul>
<p>Both actions are performed by our job server but at different times. The status can be in three forms:</p>
<ul>
<li>Started</li>
<li>In Progress</li>
<li>Done</li>
</ul>
<p>Redis provides a rich collection of data structures to hold information temporarily. Out of them, we use a simple <kbd>Key:String</kbd> for our job status. Job ID can be a key and status is its value. In simple notation, it looks like this:</p>
<pre>{ '4ed59a6f-24d8-4179-8432-fe4adcdd4f51': 'In Progress'</pre>
<p>We can easily run a Redis instance with Docker. Just run a Redis container and expose port <kbd>6379</kbd>:</p>
<pre>&gt;<strong> docker run --name some-redis -p 6379:6379 -d redis</strong></pre>
<p>The preceding command runs a Redis server on localhost on port <kbd>6379</kbd>. The process will be run as a daemon with the <kbd>-d</kbd> option. To check which container is for Redis, you can simply run the following Docker command:</p>
<pre><strong>&gt; docker ps</strong><br/><strong>CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                                                             NAMES</strong><br/><strong>2f0b2b457ed7        redis               "docker-entrypoint.sâ¦"   8 minutes ago       Up 8 minutes        0.0.0.0:6379-&gt;6379/tcp                                                            some-redis</strong><br/><strong>c3b2a0a0295d        rabbitmq:3          "docker-entrypoint.sâ¦"   6 weeks ago         Up 11 hours         4369/tcp, 0.0.0.0:5672-&gt;5672/tcp, 5671/tcp, 25672/tcp, 0.0.0.0:15672-&gt;15672/tcp   rabbitmq-server</strong></pre>
<p><kbd>redis-cli</kbd> is a tool that can be used to quickly inspect the Redis server. You don't have to install it separately. Your Redis Docker instance already has it built in. You just have to execute a command against the Redis container, like this:</p>
<pre>&gt;<strong> docker exec -i -t some-redis redis-cli</strong><br/><strong>127.0.0.1:6379&gt;</strong></pre>
<p>You can get all the available keys stored in Redis with the following command:</p>
<pre><strong> 127.0.0.1:6379&gt; KEYS *</strong></pre>
<p>You can also set a key to a value with an expiration date in the CLI, like this:</p>
<pre><strong>127.0.0.1:6379&gt; SET topic async<br/>OK</strong></pre>
<p>The preceding command sets a key called <kbd>topic</kbd> to <kbd>async</kbd>. The server returns <kbd>OK</kbd> for a successful insert. The CLI is easy to use, but in most cases, you can also access Redis from applications. In the next section, we'll learn how to do this from Go programs.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">go-redis, a Go client for communicating with Redis</h1>
                </header>
            
            <article>
                
<p>There is a widely used type-safe Go client that's used to talk to Redis servers called <kbd>go-redis</kbd>. We can use it to connect to a Redis server by creating a client similar to RabbitMQ. Let's look at the steps for doing this:</p>
<ol>
<li>First, we need to create a simple project called <kbd>redisIntro</kbd> for illustrating its basic usage:</li>
</ol>
<pre style="padding-left: 60px"><strong>mkdir -p $GOPATH/src/github.com/git-user/chapter9/redisIntro</strong></pre>
<ol start="2">
<li>Initialize the necessary dependencies and install the <kbd>go-redis</kbd> package using the <kbd>dep</kbd> tool from your project's root:</li>
</ol>
<pre style="padding-left: 60px"><strong>dep init<br/>dep ensure --add "github.com/go-redis/redis"</strong></pre>
<ol start="3">
<li>Now, create a small client that calls the default <kbd>PING</kbd> command and gets <kbd>PONG</kbd> back:</li>
</ol>
<pre style="padding-left: 60px"><strong>touch $GOPATH/src/github.com/git-user/chapter9/redisIntro/main.go</strong></pre>
<ol start="4">
<li>A client can be created using the <kbd>redis.NewClient</kbd> method from the <kbd>go-redis</kbd> package:</li>
</ol>
<pre style="padding-left: 60px">package main<br/><br/>import (<br/>    "fmt"<br/><br/>    "github.com/go-redis/redis"<br/>)<br/><br/>func main() {<br/>    client := redis.NewClient(&amp;redis.Options{<br/>        Addr:     "localhost:6379",<br/>        Password: "", // no password set<br/>        DB:       0,  // use default DB<br/>    })<br/><br/>    pong, _ := client.Ping().Result() // Ignoring error<br/>    fmt.Println(pong)<br/>}</pre>
<ol start="5">
<li>The Redis client can perform commands on the server. One such command is <kbd>PING</kbd>. A <kbd>SET</kbd> or <kbd>GET</kbd> command works the same way. Now, let's run the program:</li>
</ol>
<pre style="padding-left: 60px">&gt; <strong>go run $GOPATH/src/github.com/git-user/chapter9/redisIntro/<br/>main.go<br/>PONG</strong></pre>
<p>This prints out the <kbd>PONG</kbd> message, which is a response that's given by the Redis server. With this, we can confirm that our program is successfully connected to the server and that the queries are working fine.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Job status cache with Redis</h1>
                </header>
            
            <article>
                
<p>Now that we've introduced Redis and the Redis client for Go, let's quickly add the feature of job status to our previously designed asynchronous API. We need to make the following changes to that project:</p>
<ol>
<li>Add a new route to collect the job ID from a client</li>
<li>Add a new handler to fetch the job status from Redis</li>
<li>Whenever someone adds a new job, we need to write status to Redis in every stage of the job life cycle</li>
</ol>
<p>We'll create a new project for this feature. It has a similar structure to <kbd>longRunningTaskV1</kbd>, which we created previously. The code and files are the same. You can clone the project and rename it <kbd>longRunningTaskV2</kbd>.</p>
<p>Let's take a look at the implementation, which includes dependency installs and modifications we have to make to the previous project. We won't go through the complete code, to avoid any redundancy:</p>
<ol>
<li>To make sure you have all the necessary dependencies, run the <kbd>dep</kbd> command:</li>
</ol>
<pre style="padding-left: 60px"><strong>dep ensure</strong></pre>
<ol start="2">
<li>Add the Redis package to the cache in order to store/retrieve the status of a job:</li>
</ol>
<pre style="padding-left: 60px"><strong>dep ensure --add github.com/go-redis/redis</strong></pre>
<p style="padding-left: 60px">The first change is to add a route to access the job status. The status could be any one of these three:</p>
<ul>
<li style="padding-left: 60px"><kbd>STARTED</kbd></li>
<li style="padding-left: 60px"><kbd>IN PROGRESS</kbd></li>
<li style="padding-left: 60px"><kbd>DONE</kbd></li>
</ul>
<p>Â </p>
<ol start="3">
<li>Let's add one more property to the <kbd>JobServer</kbd> struct, called <kbd>redisClient</kbd>. This stores the client connection to the Redis container, which is already up and running:</li>
</ol>
<pre style="padding-left: 60px"><strong>vi $GOPATH/src/github.com/git-user/chapter9/longRunningTaskV2<br/>/handlers.go</strong></pre>
<ol start="4">
<li>Add the Redis package and modify its struct:</li>
</ol>
<pre style="padding-left: 60px">import (<br/>    ...<br/>    "github.com/go-redis/redis"<br/>)<br/><br/><br/>// JobServer holds handler functions<br/>type JobServer struct {<br/>    Queue       amqp.Queue<br/>    Channel     *amqp.Channel<br/>    Conn        *amqp.Connection<br/>    redisClient *redis.Client<br/>}</pre>
<ol start="5">
<li>Now, add a handler function that accepts a <kbd>UUID</kbd> as a parameter and constructs a response by fetching the job status from Redis:</li>
</ol>
<pre style="padding-left: 60px">...<br/>func (s *JobServer) statusHandler(w http.ResponseWriter,<br/>r *http.Request) {<br/>    queryParams := r.URL.Query()<br/>    // fetch UUID from query<br/>    uuid := queryParams.Get("uuid")<br/>    w.Header().Set("Content-Type", "application/json")<br/>    jobStatus := s.redisClient.Get(uuid)<br/>    status := map[string]string{"uuid": uuid, "status":<br/>     jobStatus.Val()}<br/>    response, err := json.Marshal(status)<br/>    handleError(err, "Cannot create response for client")<br/>    w.Write(response)<br/>}</pre>
<p style="padding-left: 60px">This handler uses the Redis client <kbd>Get</kbd> function to fetch the value of a key from the Redis server. After this happens, the HTTP JSON response is sent back to the client.</p>
<ol start="6">
<li>Now, change the <kbd>main.go</kbd> file and add a new route:</li>
</ol>
<pre style="padding-left: 60px"><br/>import (<br/>    ...<br/>    "github.com/go-redis/redis" // Add redis import<br/>)<br/><br/>func main() {<br/>    jobServer := getServer(queueName)<br/>    <br/>    // Create a client and attach to job server<br/>    jobServer.redisClient = redis.NewClient(&amp;redis.Options{<br/>        Addr:     "localhost:6379",<br/>        Password: "", // no password set<br/>        DB:       0,  // use default DB<br/>    })<br/><br/>    ...<br/>    router := mux.NewRouter()<br/>    // Attach handlers<br/>    router.HandleFunc("/job/database", jobServer.asyncDBHandler)<br/>    router.HandleFunc("/job/mail", jobServer.asyncMailHandler)<br/>    router.HandleFunc("/job/callback",<br/>     jobServer.asyncCallbackHandler)<br/>    <br/>    // Add a new route here<br/>    router.HandleFunc("/job/status", jobServer.statusHandler)<br/>}</pre>
<p style="padding-left: 60px">This imports the Redis package and creates a new Redis client. It also adds a new route for collecting UUID job strings from clients. The new route is <kbd>"job/status"</kbd>,Â and we attach the newly created handler,Â <kbd>statusHandler</kbd>, to it.</p>
<ol start="7">
<li>We can make an API call to get the status of a job, but the pending functionality is to write a job status in Redis whenever a new job is executed. For that, we have to modify our workers a bit. The file we'll be modifying is as follows:</li>
</ol>
<pre style="padding-left: 60px"><strong>vi $GOPATH/src/github.com/git-user/chapter9/longRunningTaskV2<br/>/worker.go</strong></pre>
<p style="padding-left: 60px">Here, we should change the worker struct so that it holds one more Redis connection so that it can write the statuses of jobs in the cache. Our plan is to store the job ID as a key and the status as a value.</p>
<ol start="8">
<li>Add the Redis package to import <kbd>NewClient</kbd>:</li>
</ol>
<pre style="padding-left: 60px">import (<br/>    ...<br/>    "github.com/go-redis/redis"<br/>}</pre>
<ol start="9">
<li>Modify the <kbd>Worker</kbd> struct to add <kbd>redisClient</kbd>. This will hold a new connection to the Redis server:</li>
</ol>
<pre style="padding-left: 60px">// Workers do the job. It holds connections<br/><br/>type Workers struct {<br/>    conn        *amqp.Connection<br/>    redisClient *redis.Client<br/>}</pre>
<ol start="10">
<li>In the <kbd>run</kbd> function, create a concrete connection to the Redis client:</li>
</ol>
<pre style="padding-left: 60px">func (w *Workers) run() {<br/>    ...<br/>    // Create a new connection<br/>    w.redisClient = redis.NewClient(&amp;redis.Options{<br/>        Addr:     "localhost:6379",<br/>        Password: "", // no password set<br/>        DB:       0,  // use default DB<br/>    })<br/>    ...<br/>}</pre>
<ol start="11">
<li>Modify the worker functions to add the status messages. For example, let's look at <kbd>dbWork</kbd>:</li>
</ol>
<pre style="padding-left: 60px">...<br/>func (w *Workers) dbWork(job models.Job) {<br/>    result := job.ExtraData.(map[string]interface{})<br/>    w.redisClient.Set(job.ID.String(), "STARTED", 0)<br/>    log.Printf("Worker %s: extracting data..., JOB: %s",<br/>     job.Type, result)<br/>    w.redisClient.Set(job.ID.String(), "IN PROGRESS", 0)<br/>    time.Sleep(2 * time.Second)<br/>    log.Printf("Worker %s: saving data to database..., JOB: %s",<br/>     job.Type, job.ID)<br/>    w.redisClient.Set(job.ID.String(), "DONE", 0)<br/>}<br/>...</pre>
<p>We are writing messages into a Redis key with the message as a value. The same key is overwritten when the process shifts to the next phase. This is achieved by calling the Redis <kbd>redisClient.Set()</kbd>. function.</p>
<p>If you're wondering why the third argument is provided, it's because it's the expiration time of a key on the Redis server. We can also set a key that lives only for some time. For now, we want to persist our keys, so the expiration is set to <kbd>zero</kbd>, which means no expiration in Redis.</p>
<p>We can apply the same process for the other two worker functions, that is,Â <kbd><span>callbackWork</span></kbd> and <kbd>emailWork</kbd>.</p>
<p>Now, it's time to test our new feature:</p>
<ol>
<li>Build the <kbd>longRunningTaskV2</kbd> project and call a job using curl. Now, find the status of that job using the new endpoint that we added:</li>
</ol>
<pre style="padding-left: 60px"><strong>go build .<br/><br/>./longRunningTaskV2</strong></pre>
<ol start="2">
<li>Create a new job, like this:</li>
</ol>
<pre style="padding-left: 60px"><strong>curl -X GET http://localhost:8000/job/database\?client_time\=1569177495</strong></pre>
<ol start="3">
<li>This returns the following JSON, which contains job details:</li>
</ol>
<pre style="padding-left: 60px"><strong>{"uuid":"07050695-ce75-4ae8-99d3-2ab068cafe9d","type":"A","extra_data":{"client_time":"2019-09-23T00:08:15+05:30"}}</strong></pre>
<ol start="4">
<li>Now, we can find the status of a job with <kbd>uuid</kbd>:</li>
</ol>
<pre style="padding-left: 60px"><strong>curl -X GET http://localhost:8000/job/status\?uuid\=07050695-ce75-4ae8-99d3-2ab068cafe9d</strong></pre>
<ol start="5">
<li>This returns the following status:</li>
</ol>
<pre style="padding-left: 60px"><strong>{"uuid":"07050695-ce75-4ae8-99d3-2ab068cafe9d","status":"DONE"}</strong></pre>
<p>This message varies according to when the client calls the API. But it is a transparent way to give the status of asynchronous jobs to clients.</p>
<p>There is one more category of API that realizes asynchronous behavior. That is known as the event-driven API. Servers and clients can listen to broadcasted events rather than explicitly requesting them. This approach is different from traditional asynchronous implementations. We'll take a look at this in the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Event-driven API</h1>
                </header>
            
            <article>
                
<p>The strategies we've explained so far are instances of the request/response protocol where the client makes an API call to execute a job. There are many other architectures like this, such as the event-driven API, where a system generates a series of events that other systems can listen to and receive updates from. For a client to receive events, they should be subscribed.</p>
<p>This is similar to callbacks in some languages, such as JavaScript, where an event loop runs continuously and collects events. This type of approach is good for non-blocking clients and servers.</p>
<p>A trivial example includes a client registering an HTTP endpoint with an API. The server can trigger the API as an event whenever some useful information is available. A few practical examples are as follows:</p>
<ul>
<li>A weather station sending a series of events to subscribed clients (for example, mobiles)</li>
<li>Amazon's <strong>Simple Notification ServiceÂ </strong>(<strong>SNS</strong>) publishing a message to an endpoint</li>
<li>A slack webhook that is registered to an API to get events; for example, a code pipeline failing</li>
</ul>
<p>A few protocols that implement the event-driven architecture are as follows:</p>
<ul>
<li>Publish/Subscribe</li>
<li>WebSocket communication</li>
<li>Webhooks/ REST hooks</li>
<li>Server push (SSE)</li>
</ul>
<p>These protocols are used in different places according to the use case at hand. We'll discuss Publish/Subscribe briefly in <a href="b5dafb13-8906-4c1a-b780-7f0356f95d61.xhtml">Chapter 11</a>, <em>Scaling our REST API Using Microservices</em>. There, we'll learn how to build an event-driven system, consume events from another party, and more.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we introduced the asynchronous API. First, we explained the key difference between a synchronous API and an asynchronous API. Then, we learned how multiple API requests lead to the fan-in or fan-out of services.</p>
<p>After that, we introduced a queuing system called RabbitMQ. A queue can hold jobs and allows servers to work on them. We learned how to create a queue and write a job into it. We also created a few RabbitMQ clients that can pick jobs from the queue and process them.</p>
<p>We also designed a long-running task with multiple workers and a queue. The workers always listen to the queue and accept jobs. We defined three kinds of workers: DB, Email, and Callback.</p>
<p>Redis is an in-memory database that stores key/value pairs. We can use it as a cache to store the status of jobs. We extended our long-running task to add status information by storing job statuses in Redis.</p>
<p>Finally, we introduced the event-driven API and learned that, using Publish/Subscribe and WebSockets, we can set up event-driven data exchange between clients and servers.</p>
<p>In the next chapter, we will take a look at the basics of GraphQL, as well as examples of writing a GraphQL client and a server in Go.</p>


            </article>

            
        </section>
    </body></html>