<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Graph-Based Data Processing</h1>
                </header>
            
            <article>
                
<div class="packt_quote">"Big data is at the foundation of all of the megatrends that are happening today, from social to mobile to the cloud to gaming."</div>
<div class="packt_quote CDPAlignRight CDPAlign"><span>- Chris Lynch</span></div>
<p>Ask any highly successful company out there and they will all unequivocally agree that data is a precious commodity. Companies use data to not only make informed short-term decisions that affect their day to day operations but also as a guide for shaping their strategy in the long term. In fact, in some industries (such as advertising), data <em>is</em> the product!</p>
<p>Nowadays, with the advent of cheap storage solutions, the collection of data has increased exponentially in comparison to the last few years. Furthermore, the rate of increase in storage requirements is expected to keep following an exponential curve well into the future.</p>
<p>While there are quite a few solutions for processing structured data (such as systems supporting map-reduce operations), they fall short when the data to be processed is organized as a <em>graph</em>. Running specialized algorithms against massive graphs is a fairly common use case for companies in the field of logistics or companies that operate social networks.</p>
<p>In this chapter, we will be focusing our attention on systems that process graphs at scale. More specifically, the following topics will be covered:</p>
<ul>
<li>Understanding the <strong>Bulk Synchronous Parallel</strong> (<strong>BSP</strong>) model for distributing computation across multiple nodes</li>
<li>Applying the BSP model principles to create our very own graph processing system in Go</li>
<li>Using the graph system as a platform for solving graph-based problems such as shortest path and graph coloring</li>
<li>Implementing an iterative version of the PageRank algorithm for the Links 'R' Us project</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>The full code for the topics that will be discussed in this chapter has been published in this book's GitHub repository under the <kbd>Chapter08</kbd> folder.</p>
<div class="packt_infobox">You can access this book's GitHub repository by visiting the following URL: <a href="https://github.com/PacktPublishing/Hands-On-Software-Engineering-with-Golang">https://github.com/PacktPublishing/Hands-On-Software-Engineering-with-Golang</a>.</div>
<p>To get you up and running as quickly as possible, each example project includes a <span>Makefile</span> <span>that defines the following set of targets:</span></p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td><strong>Makefile target</strong></td>
<td><strong>Description</strong></td>
</tr>
<tr class="odd">
<td><kbd>deps</kbd></td>
<td>Install any required dependencies</td>
</tr>
<tr class="even">
<td><kbd>test</kbd></td>
<td>Run all tests and report coverage</td>
</tr>
<tr class="odd">
<td><kbd>lint</kbd></td>
<td>Check for lint errors</td>
</tr>
</tbody>
</table>
<p> </p>
<p>As with all other chapters in this book, you will need a fairly recent version of Go, which you can download at <a href="https://golang.org/dl">https://golang.org/dl</a><em>.</em></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exploring the Bulk Synchronous Parallel model</h1>
                </header>
            
            <article>
                
<p>How can we efficiently run a graph algorithm against a massive graph? To be able to answer this question, we need to clarify what we mean by the word <em>massive</em>. Is a graph with 1 million nodes considered to be massive? How about 10 million, 100 million, or even 1 billion nodes? The real question we should be asking ourselves is whether the graph can actually <em>fit in memory</em>. If the answer is yes, then we can simply buy (or rent from a cloud provider) a server with a beefy CPU, max out the amount of installed memory, and execute our graph-processing code on a single node.</p>
<p>On the other hand, things get much more interesting when the answer to the preceding question is <em>no...</em> Congratulations; you can now claim that you work with big data! In such cases, traditional compute models are evidently inadequate; we need to start exploring alternative applications that are explicitly designed for out of core processing.</p>
<p>The BSP model is one of the most popular models for building systems that can process massive datasets by distributing calculations to a cluster of processing nodes. It was proposed in 1990 by Leslie Valiant <sup><span class="citation">[10]</span></sup> as a novel and elegant approach for bridging together parallel hardware and software.</p>
<p>At the heart of the BSP model lies the <strong>BSP computer</strong>. The BSP computer, which can be seen in the following diagram, is an abstract computer model made up of a collection of, potentially heterogeneous, processors that are interconnected via a computer network:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/2f23d84d-39d0-4ac5-83e6-a90dc0962c8d.png" style="width:54.42em;height:27.25em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>Figure 1: The components that comprise the BSP computer model</span></div>
<p><span>The BSP model itself is not particularly concerned with the network implementation details. In fact, the network is treated as a black box; the model can support any type of network as long as the network provides a mechanism for routing messages between processors.</span></p>
<p>Processors can not only access their own local memory, but they can also use the network link to exchange data with other processors. To this end, the BSP computer is effectively a <em>distributed memory</em> computer that can perform computations in parallel. However, this functionality comes with a catch! While access to local memory is fast, accessing a remote processor's memory is significantly slower as it involves an exchange of messages over the network link. Therefore, the BSP computer can be also characterized as a <strong>non-uniform memory access</strong> (<strong>NUMA</strong>) architecture.</p>
<p>So, what kinds of programs can we run on a BSP computer? Algorithms or data processing operations that can be expressed as a <em>sequence of iteration steps</em> are generally a good fit for the BSP model. The BSP model uses the term <em>super-step</em> to refer to the execution of a single iteration of a user-defined program.</p>
<p>One thing that differentiates the BSP model from other concurrent programming models is that BSP achieves parallelism through the use of a technique referred to as <strong>Single Program Multiple Data</strong> (<strong>SPMD</strong>). Software engineers who are interested in writing programs for the BSP computer can do so as if they were writing a program for a single-core machine. The program simply receives a set of data as input, applies a processing function to it, and emits some output. In other words, software engineers are completely oblivious to the existence of individual processors and the network that connects them.</p>
<p>Before commencing the execution of the user's program, the BSP computer transparently uploads the program to every single processor, splits the data to be processed into a set of partitions, and assigns each partition to one of the available processors. The model employs a rather cunning strategy to reduce computation latency: it breaks down each super-step into two phases or substeps: a <strong>compute</strong> step and a <strong>communication</strong> step. During the compute step, each processor executes a single iteration of the user's program using the data that was assigned to the processor as input. Once <em>all</em> <span>the</span> processors have completed their individual computations, they can communicate through the network and <span>–</span> depending on the use case <span>–</span> compare, exchange, or aggregate the results of their individual computations.</p>
<p>Given that each processor can perform computation work in parallel and independently from other processors, the BSP model makes use of <strong>blocking barriers</strong> to synchronize processors. <span>The following diagram summarizes the way in which the BSP computer model executes programs as a sequence of super-steps that are isolated from each other via write barriers:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/3c87d7d2-1148-4ae9-a9c8-29c43ae3efe4.png" style="width:55.42em;height:27.50em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>Figure 2: The BSP computer model executes programs as a sequence of super-steps that are isolated from each other via write barriers</span></div>
<p><span>In Go parlance, a blocking barrier is equivalent to a</span> <span><kbd>sync.WaitGroup</kbd></span><span>; the BSP computer waits for all the processors to reach the barrier before assigning them the next chunk of work.</span></p>
<p>In the last couple of years, interest in models such as BSP has spiked. This can largely be attributed to Google, which (excluding state-funded three-letter agencies) is the undisputed worldwide leader in big data processing. Google engineers incorporated several of the BSP model concepts into Pregel, an in-house solution for out-of-core graph processing. In 2010, Google published a paper <sup><span class="citation">[7]</span></sup> detailing the design decisions and architecture behind Pregel. This publication paved the way for creating open source equivalents such as Stanford's GPS <sup><span class="citation">[4]</span></sup> and Apache Giraph <sup>[1]</sup>. The latter is currently used at Facebook to analyze the social graph that's formed by the network's users and their connections.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building a graph processing system in Go</h1>
                </header>
            
            <article>
                
<p>There is no better way to gain a deeper understanding of the BSP model principles than to build, from scratch, our very own scalable Pregel-like graph processing system in Go.</p>
<p class="mce-root"/>
<p>Here are a few of the design requirements for the system we will be building:</p>
<ul>
<li>Graphs will be represented as a collection of vertices and directed edges. Each vertex will be assigned a unique ID. In addition, both vertices and edges can optionally store a user-defined value.</li>
<li>At every super-step, the system executes a user-defined compute function for <em>every</em> vertex in the graph.</li>
<li>Compute functions are allowed to inspect and modify the internal state of the vertex they are invoked on. They can also iterate the list of outgoing edges and exchange messages with other vertices.</li>
<li>Any outgoing messages that are produced during a super-step will be buffered and delivered to their intended recipients in the <em>following</em> super-step.</li>
<li>The system must be able to support both single- and multi-node (distributed) graph topologies. In a multi-node topology, each node is responsible for managing a subset of the graph vertices and their outgoing edges. While operating in a multi-node configuration, the system should provide a mechanism for relaying vertex messages between nodes (for example, over a network link).</li>
</ul>
<p><span>In the following sections, we will analyze each of these requirements in more detail and elaborate on how they can be implemented in Go.</span> You can find the fully documented source code and test suites for the graph processing system from this chapter in the <kbd>Chapter08/bspgraph</kbd> folder in this book's GitHub repository.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Queueing and delivering messages</h1>
                </header>
            
            <article>
                
<p>One of the core ideas of the BSP model is that graph components communicate with each other by exchanging messages. The fact that each vertex in the graph can potentially receive multiple messages mandates the introduction of some sort of abstraction for storing or queuing incoming messages until they are ready to be processed by the intended recipient.</p>
<p>In the three sections that follow, we will kick off our design discussion by defining the required interfaces for modeling messages and queues. Then, we will take a stab at implementing a simple, concurrent-safe in-memory queue.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Message interface</h1>
                </header>
            
            <article>
                
<p>It logically follows that the contents of messages that are exchanged between vertices heavily depend on the application or graph algorithm that we are trying to execute. Consequently, to avoid passing plain <kbd>interface{}</kbd> values around, we need to come up with a plausible interface for describing messages in a generic way. The <kbd>Message</kbd> interface, which lives in the <kbd>Chapter08/bspgraph/message</kbd> package, is an attempt at doing exactly that:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">type</span> Message <span class="kw">interface</span> {</a>
<a>    <span class="co">// Type returns the type of this Message.</span></a>
<a>    Type() <span class="dt">string</span></a>
<a>}</a></pre></div>
<p>At this point, you are probably dubious about the usefulness of having a <kbd>Type</kbd> method on this interface. Can this really be any better than simply using an <kbd>interface{}</kbd>?</p>
<p>If you recall our discussion of the BSP computer model, processors communicate with each other over network links. Before a message can be transmitted over the network, the sender must serialize it into a byte stream. On the receiving end, the byte stream is unserialized back into a message and delivered to the intended recipient.</p>
<p>The <kbd>Type</kbd> method is quite handy for supporting use cases where the sender and the receiver can exchange <em>different</em> types of messages over the same channel (for example, a TCP socket). At serialization time, the sender queries the type of the message and attaches this information as additional metadata to the serialized payload. The receiver can then decode the metadata and unserialize the payload's byte stream back to the appropriate type of message.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Queues and message iterators</h1>
                </header>
            
            <article>
                
<p>Queues serve as buffers for storing incoming messages and making them available for consumption by compute functions. Users of the graph processing system can either make use of the built-in in-memory queue (see the next section) or inject their application-specific queue implementation as long as it adheres to the <kbd>Queue</kbd> interface, whose definition is listed as follows:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">type</span> Queue <span class="kw">interface</span> {</a>
<a>    <span class="co">// Cleanly shutdown the queue.</span></a>
<a>    Close() <span class="dt">error</span></a>

<a>    <span class="co">// Enqueue inserts a message to the end of the queue.</span></a>
<a>    Enqueue(msg Message) <span class="dt">error</span></a>

<a>    <span class="co">// PendingMessages returns true if the queue contains any messages.</span></a>
<a>    PendingMessages() <span class="dt">bool</span></a>

<a>    <span class="co">// Flush drops all pending messages from the queue.</span></a>
<a>    DiscardMessages() <span class="dt">error</span></a>

<a>    <span class="co">// Messages returns an iterator for accessing the queued messages.</span></a>
<a>    Messages() Iterator</a>
<a>}</a></pre></div>
<p>The methods on the <kbd>Queue</kbd> interface are pretty standard for any type of queue system. A call to <kbd>PendingMessages</kbd> reveals whether the queue is currently empty, while a call to <kbd>DiscardMessages</kbd> can be used to flush any stored messages. The <kbd>Enqueue</kbd> method can be used to append a new <kbd>Message</kbd> to the queue, while the <kbd>Messages</kbd> method returns an <kbd>Iterator</kbd> for accessing the list of already enqueued messages. Since iterator implementations are typically coupled to the underlying queue system, <kbd>Iterator</kbd> is also defined as an interface:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">type</span> Iterator <span class="kw">interface</span> {</a>
<a>    <span class="co">// Next advances the iterator so that the next message can be retrieved</span></a>
<a>    <span class="co">// via a call to Message(). If no more messages are available or an</span></a>
<a>    <span class="co">// error occurs, Next() returns false.</span></a>
<a>    Next() <span class="dt">bool</span></a>

<a>    <span class="co">// Message returns the message currently pointed to by the iterator.</span></a>
<a>    Message() Message</a>

<a>    <span class="co">// Error returns the last error that the iterator encountered.</span></a>
<a>    Error() <span class="dt">error</span></a>
<a>}</a></pre></div>
<p>This interface follows exactly the same iterator pattern that you should be familiar with from the previous chapters. Calling <kbd>Next</kbd> advances the iterator and returns a Boolean value to indicate whether more messages are available. After a successful call to <kbd>Next</kbd>, the current message can be retrieved by calling <kbd>Message</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementing an in-memory, thread-safe queue</h1>
                </header>
            
            <article>
                
<p>For the majority of applications, using an in-memory queue implementation such as the one presented here should suffice. Implementing support for other types of queue systems (for example, Kafka, nats-streaming, or even plain files) is left as an exercise for you.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Let's start by defining the <kbd>inMemoryQueue</kbd> type and its constructor:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">type</span> inMemoryQueue <span class="kw">struct</span> {</a>
<a>    mu   sync.Mutex</a>
<a>    msgs []Message</a>

<a>    latchedMsg Message</a>
<a>}</a>

<a><span class="kw">func</span> NewInMemoryQueue() Queue {</a>
<a>    <span class="kw">return</span> <span class="bu">new</span>(inMemoryQueue)</a>
<a>}</a></pre></div>
<p>As you can see, the in-memory queue is nothing more than a slice of <kbd>Message</kbd> instances <span>–</span> a slot for storing the message that's being currently pointed to by an iterator and a <kbd>sync.Mutex</kbd> for serializing access to the list of messages.</p>
<p>Next, we will take a look at the implementation of <kbd>Enqueue</kbd> and <kbd>PendingMessages</kbd>:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (q *inMemoryQueue) Enqueue(msg Message) <span class="dt">error</span> {</a>
<a>    q.mu.Lock()</a>
<a>    q.msgs = <span class="bu">append</span>(q.msgs, msg)</a>
<a>    q.mu.Unlock()</a>
<a>    <span class="kw">return</span> <span class="ot">nil</span></a>
<a>}</a>

<a><span class="kw">func</span> (q *inMemoryQueue) PendingMessages() <span class="dt">bool</span> {</a>
<a>    q.mu.Lock()</a>
<a>    pending := <span class="bu">len</span>(q.msgs) != <span class="dv">0</span></a>
<a>    q.mu.Unlock()</a>
<a>    <span class="kw">return</span> pending</a>
<a>}</a></pre></div>
<p>To enqueue a new message, we acquire the lock and then append the messages to the list. In a similar fashion, checking for pending messages is facilitated by obtaining the lock and checking whether the message list is empty.</p>
<p>The last set of functions that we need to implement so that the type satisfies the <kbd>Queue</kbd> interface are as follows:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (q *inMemoryQueue) DiscardMessages() <span class="dt">error</span> {</a>
<a>    q.mu.Lock()</a>
<a>    q.msgs = q.msgs[:<span class="dv">0</span>]</a>
<a>    q.mu.Unlock()</a>
<a>    <span class="kw">return</span> <span class="ot">nil</span></a>
<a>}</a>

<a><span class="kw">func</span> (*inMemoryQueue) Close() <span class="dt">error</span> { <span class="kw">return</span> <span class="ot">nil</span> }</a>

<a><span class="kw">func</span> (q *inMemoryQueue) Messages() Iterator { <span class="kw">return</span> q }</a></pre></div>
<p>As you can see in the preceding code block, the implementation of the <kbd>DiscardMessages</kbd> method uses a nifty trick: the message list is purged via a slice operation that <em>retains</em> the already allocated slice capacity but resets its length to zero. This allows us to reduce the number of memory allocations that need to be performed and, by extension, reduce the pressure on the Go garbage collector.</p>
<p>Furthermore, the <kbd>Messages</kbd> <span>method body</span> is quite interesting in itself as the returned value implies that the <kbd>inMemoryQueue</kbd> type must <em>also</em> implement the <kbd>Iterator</kbd> interface! The following code shows the implementation of the relevant methods for satisfying the <kbd>Iterator</kbd> interface:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (q *inMemoryQueue) Next() <span class="dt">bool</span> {</a>
<a>    q.mu.Lock()</a>
<a>    qLen := <span class="bu">len</span>(q.msgs)</a>
<a>    <span class="kw">if</span> qLen == <span class="dv">0</span> {</a>
<a>        q.mu.Unlock()</a>
<a>        <span class="kw">return</span> <span class="ot">false</span></a>
<a>    }</a>
<a>    q.latchedMsg = q.msgs[qLen<span class="dv">-1</span>] <span class="co">// Dequeue message from the tail of the queue.</span></a>
<a>    q.msgs = q.msgs[:qLen<span class="dv">-1</span>]</a>
<a>    q.mu.Unlock()</a>
<a>    <span class="kw">return</span> <span class="ot">true</span></a>
<a>}</a>

<a><span class="kw">func</span> (q *inMemoryQueue) Message() Message {</a>
<a>    q.mu.Lock()</a>
<a>    msg := q.latchedMsg</a>
<a>    q.mu.Unlock()</a>
<a>    <span class="kw">return</span> msg</a>
<a>}</a></pre></div>
<p>While most queue implementations use FIFO semantics, as you can easily tell by the <kbd>Message</kbd> method's implementation, the in-memory queue follows <strong>last-in first-out</strong> (<strong>LIFO</strong>) semantics. This is intentional; if we were to dequeue from the head of the list (for example, <kbd>q.msgs = q.msgs[1:]</kbd>), its capacity would decrease and we wouldn't be able to reuse the already allocated memory to append new messages in the future.</p>
<p class="mce-root"/>
<p>As the graph system that we are building is not required to provide any guarantee about the order of incoming messages, our in-memory queue implementation can be used as-is without any issue. Now that we have a solution for storing messages, we can go ahead and define the necessary structures that will represent the vertices and edges of our graph.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Modeling the vertices and edges of graphs</h1>
                </header>
            
            <article>
                
<p>As we mentioned when we discussed the requirements for the graph processing system, we need to come up with a model for describing the vertices and edges that comprise a graph. Moreover, we need to provide an API that we can use to insert new vertices and edges into the graph.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Defining the Vertex and Edge types</h1>
                </header>
            
            <article>
                
<p>The <kbd>Vertex</kbd> type encapsulates the state of each vertex that is part of a <kbd>Graph</kbd> instance:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">type</span> Vertex <span class="kw">struct</span> {</a>
<a>    id       <span class="dt">string</span></a>
<a>    value    <span class="kw">interface</span>{}</a>
<a>    active   <span class="dt">bool</span></a>
<a>    msgQueue [<span class="dv">2</span>]message.Queue</a>
<a>    edges    []*Edge</a>
<a>}</a></pre></div>
<p>An interesting tidbit about the <kbd>Vertex</kbd> type definition is that we actually need to maintain two <kbd>message.Queue</kbd> instances. Any messages produced by compute function invocations while executing a super-step must be buffered so that they can be delivered to the intended recipient in the <em>following</em> super-step. To this end, our implementation will employ a double-buffering scheme. We will use one queue to hold the messages for the current super-step and another queue to buffer the messages for the next super-step. At the end of each super-step, we will swap the queues around so that the output queue from the previous super-step becomes the input queue for the following super-step and vice versa. To avoid having to physically swap the queue pointers for every vertex in the graph, we will rely on modulo arithmetic to select the input and output queues based on the current super-step number:</p>
<ul>
<li>The queue at index <kbd>super_step%2</kbd> holds the messages that should be consumed during the current super-step</li>
<li>The queue at index <kbd>(super_step+1)%2</kbd> buffers the messages for the next super-step</li>
</ul>
<p class="mce-root"/>
<p>Moving on, we shouldn't allow users of the <kbd>bspgraph</kbd> package to directly mutate the internal state of vertices. Therefore, none of the <kbd>Vertex</kbd> fields are exported outside of the <kbd>bspgraph</kbd> package. Instead, we will define the following set of helper methods so that we can access and/or safely manipulate the state of a vertex instance:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (v *Vertex) ID() <span class="dt">string</span> { <span class="kw">return</span> v.id }</a>

<a><span class="kw">func</span> (v *Vertex) Value() <span class="kw">interface</span>{} { <span class="kw">return</span> v.value }</a>

<a><span class="kw">func</span> (v *Vertex) SetValue(val <span class="kw">interface</span>{}) { v.value = val }<br/><br/></a><a><span class="kw">func</span> (v *Vertex) Freeze() { v.active = <span class="ot">false</span> }<br/><br/></a><a><span class="kw">func</span> (v *Vertex) Edges() []*Edge { <span class="kw">return</span> v.edges }</a> </pre></div>
<p>Each vertex is uniquely identified by a string-based ID that can be queried via a call to the <kbd>ID</kbd> method. In addition, vertices can optionally store a user-defined value that compute functions can read or write via the <kbd>Value</kbd> and <kbd>SetValue</kbd> methods.</p>
<p>What's more, a vertex can be in one of the following two states: <em>active</em> or <em>inactive</em> state. <span>All the vertices are initially marked as</span> <em>active. </em>To conserve compute resources, the graph framework will only invoke c<span>ompute functions on</span> <span>active</span> <span>vertices. If the compute method implementation decides that a particular vertex has reached a terminal state and no further calculations are required, it can opt to explicitly mark the vertex as inactive via a call to its</span> <kbd>Freeze</kbd> <span>method</span><em>.</em> <span>However, should an inactive vertex receive a new message during a super-step, the graph framework will automatically mark it as active at the next super-step.</span></p>
<p>Finally, the <kbd>Edges</kbd> method returns a slice of <kbd>Edge</kbd> objects that correspond to the outgoing, directed edges originating from a particular vertex. The following code shows the definition of the <kbd>Edge</kbd> type and its helper methods:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">type</span> Edge <span class="kw">struct</span> {</a>
<a>    value <span class="kw">interface</span>{}</a>
<a>    dstID <span class="dt">string</span></a>
<a>}</a>

<a><span class="kw">func</span> (e *Edge) DstID() <span class="dt">string</span> { <span class="kw">return</span> e.dstID }</a>

<a><span class="kw">func</span> (e *Edge) Value() <span class="kw">interface</span>{} { <span class="kw">return</span> e.value }</a>

<a><span class="kw">func</span> (e *Edge) SetValue(val <span class="kw">interface</span>{}) { e.value = val }</a></pre></div>
<p class="mce-root"/>
<p>Similar to the <kbd>Vertex</kbd> type, edges can also store an optional user-defined value that can be read/written to via the <kbd>Value</kbd> and <kbd>SetValue</kbd> methods. Every edge has a destination vertex whose ID can be obtained via a call to the <kbd>DstID</kbd> method. As we will see in the <em>Sending and receiving messages</em> section, the vertex ID is the only piece of information that we need to be aware of in order to send a message to a particular vertex.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Inserting vertices and edges into the graph</h1>
                </header>
            
            <article>
                
<p>The <kbd>Graph</kbd> type keeps track of all vertices that comprise the graph with the help of a map where keys are vertex IDs and values are <kbd>Vertex</kbd> instances. Besides the fact that the vertex map allows us to quickly lookup vertices by their ID <span>–</span> a very important feature for delivering incoming messages <span>–</span> it also provides an efficient mechanism (as opposed to using a slice) for <em>deleting</em> vertices if we ever wish to allow users to mutate the graph topology between super-steps.</p>
<p>New vertices can be inserted into the graph via the <kbd>AddVertex</kbd> method. It expects two arguments:</p>
<ul>
<li>A unique vertex ID</li>
<li>An initial value (which may also be <kbd>nil</kbd>):</li>
</ul>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (g *Graph) AddVertex(id <span class="dt">string</span>, initValue <span class="kw">interface</span>{}) {</a>
<a>    v := g.vertices[id]</a>
<a>    <span class="kw">if</span> v == <span class="ot">nil</span> {</a>
<a>        v = &amp;Vertex{</a>
<a>            id: id,</a>
<a>            msgQueue: [<span class="dv">2</span>]message.Queue{</a>
<a>                g.queueFactory(),</a>
<a>                g.queueFactory(),</a>
<a>            },</a>
<a>            active: <span class="ot">true</span>,</a>
<a>        }</a>
<a>        g.vertices[id] = v</a>
<a>    }</a>
<a>    v.SetValue(initValue)</a>
<a>}</a></pre></div>
<p>If a vertex with the same ID already exists, we simply override its stored initial value. Otherwise, a new <kbd>Vertex</kbd> instance must be allocated. The code populates its ID field, sets the vertex status to active, and invokes the configured (at graph construction time) queue factory to instantiate the two queues that we need in order to store incoming messages for the current and next super-steps. Finally, the new vertex instance is inserted into the map.</p>
<p>Similarly, the <kbd>AddEdge</kbd> method creates a new directed edge between two vertices:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (g *Graph) AddEdge(srcID, dstID <span class="dt">string</span>, initValue <span class="kw">interface</span>{}) <span class="dt">error</span> {</a>
<a>    srcVert := g.vertices[srcID]</a>
<a>    <span class="kw">if</span> srcVert == <span class="ot">nil</span> {</a>
<a>        <span class="kw">return</span> xerrors.Errorf(<span class="st">"create edge from %q to %q: %w"</span>, srcID, dstID, ErrUnknownEdgeSource)</a>
<a>    }</a>

<a>    srcVert.edges = <span class="bu">append</span>(srcVert.edges, &amp;Edge{</a>
<a>        dstID: dstID,</a>
<a>        value: initValue,</a>
<a>    })</a>
<a>    <span class="kw">return</span> <span class="ot">nil</span></a>
<a>}</a></pre></div>
<p>As we mentioned in a <em>Defining the Vertex and Edge types</em> section, edges are <em>owned</em> by the vertices they originate from. Ergo, the <kbd>AddEdge</kbd> implementation must check whether the <kbd>srcID</kbd> can be resolved to an existing vertex. If the source vertex cannot be located, then an error is returned to the caller. Otherwise, a new edge is created and appended to the edge list of the source vertex.</p>
<p>Note that while we expect the source vertex for the edge to be known locally, the same assumption cannot be made for the destination vertex. For instance, if the graph was spread across two nodes, the source vertex could be managed by the first node while the destination vertex could be managed by the second node.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sharing global graph state through data aggregation</h1>
                </header>
            
            <article>
                
<p>Aggregators are a key component for implementing several graph-based algorithms that rely on sharing global state between vertices. They are concurrent-safe primitives that apply an aggregation operator to a set of values and make the result available to <em>all</em> <span>the</span> vertices at the next super-step.</p>
<p>Any kind of operator can be used to create an aggregator as long as it is commutative and associative. Aggregators are commonly used to implement counters, accumulators, or for keeping track of the minimum and/or maximum value of some quantity.</p>
<p>In the upcoming sections, we will do the following:</p>
<ul>
<li>Define a generic interface for aggregators</li>
<li>Augment our Graph type with helper methods for registering and looking up <kbd>Aggregator</kbd> instances by name</li>
<li>Build an example aggregator that accumulates <kbd>float64</kbd> values</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Defining the Aggregator interface</h1>
                </header>
            
            <article>
                
<p>The <kbd>Aggregator</kbd> interface describes the set of methods that must be implemented by Go types so that they can be used with our graph processing framework for data aggregation purposes:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">type</span> Aggregator <span class="kw">interface</span> {</a>
<a>    <span class="co">// Type returns the type of this aggregator.</span></a>
<a>    Type() <span class="dt">string</span></a>

<a>    <span class="co">// Set the aggregator to the specified value.</span></a>
<a>    Set(val <span class="kw">interface</span>{})</a>

<a>    <span class="co">// Get the current aggregator value.</span></a>
<a>    Get() <span class="kw">interface</span>{}</a>

<a>    <span class="co">// Aggregate updates the aggregator's value based on the provided <br/>    // value.</span></a>
<a>    Aggregate(val <span class="kw">interface</span>{})</a>

<a>    <span class="co">// Delta returns the change in the aggregator's value since the last <br/>    // call to Delta. </span></a>
<a>    Delta() <span class="kw">interface</span>{}</a>
<a>}</a></pre></div>
<p>One of my pet peeves is that the methods in the preceding interface definition use <kbd>interface{}</kbd> values. Unfortunately, this is one of the few cases where we cannot actually avoid the use of <kbd>interface{}</kbd> since the types of values that can be aggregated are implementation-specific.</p>
<p>Whenever we want to apply the aggregation operation to a new value, we can do so by invoking the <kbd>Aggregate</kbd> method. Furthermore, the current value can be retrieved via a call to the <kbd>Get</kbd> method. On the other hand, if we want to set the aggregator to a <em>specific</em> value (for example, reset a counter to zero), we can invoke the <kbd>Set</kbd> method. The <kbd>Type</kbd> method provides an identifier for the aggregator's type that can be used for serialization purposes (for example, if we want to take a snapshot of the graph's state).</p>
<p class="mce-root"/>
<p>The <kbd>Delta</kbd> method returns the <em>change</em> in the aggregator's value since the <em>last</em> time that either <kbd>Delta</kbd> or <kbd>Set</kbd> was called. This method is meant to be used in a distributed graph computation scenario (see <a href="67abdf43-7d4c-4bff-a17e-b23d0a900759.xhtml">Chapter 12</a>, <em>Building Distributed Graph Processing Systems</em>) to reduce the values from individual local aggregators into a single global aggregated value.</p>
<p>To understand how the <kbd>Delta</kbd> method is used, let's picture a scenario where we deploy three nodes: a master and two workers. Our goal is to create a distributed counter whose value is synchronized with all the nodes prior to executing a new super-step. To achieve this, each node (including the master) defines a <em>local</em> aggregator instance that implements a simple counter. While executing a super-step, compute functions are only allowed access to the local counter of the worker they are executing on. The master node is not assigned any vertices. Instead, it is responsible for collecting the partial <em>deltas</em> from each worker, aggregating those into its own counter, and <em>broadcasting</em> the new total back to the workers. The workers then use the <kbd>Set</kbd> method to update their local counters to the new total.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Registering and looking up aggregators</h1>
                </header>
            
            <article>
                
<p>To facilitate efficient name-based aggregator lookups, <kbd>Graph</kbd> instances store aggregators in a map where the aggregator name is used as a key. New aggregator instances can be linked to a <kbd>Graph</kbd> instance through the <kbd>RegisterAggregator</kbd> method:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (g *Graph) RegisterAggregator(name <span class="dt">string</span>, aggr Aggregator) { </a>
<a>    g.aggregators[name] = aggr </a>
<a>}</a></pre></div>
<p>Compute functions that need access to a particular aggregator can invoke the <kbd>Aggregator</kbd> method to look up a registered aggregator instance by name:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (g *Graph) Aggregator(name <span class="dt">string</span>) Aggregator { </a>
<a>    <span class="kw">return</span> g.aggregators[name] </a>
<a>}</a></pre></div>
<p>In an effort to make it easier for clients to create snapshots of the graph's state, we will also be providing the auxiliary <kbd>Aggregators</kbd> method, which just returns a copy of the map that contains the complete set of registered aggregator instances.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementing a lock-free accumulator for float64 values</h1>
                </header>
            
            <article>
                
<p>In the <kbd>Chapter08/bspgraph/aggregator</kbd> package, you can find two concurrent-safe accumulator implementations that are designed to work with <kbd>int64</kbd> and <kbd>float64</kbd> values and can also double as distributed counters.</p>
<p class="mce-root"/>
<p>Instead of using a mutex to guarantee concurrent access, both accumulators are implemented using compare and swap instructions. The int64-based version is pretty straightforward and can easily be implemented with the help of the functions provided by the <kbd>sync/atomic</kbd> package. The float64-based version, which we will be dissecting here, is more challenging (and fun!) since the <kbd>sync/atomic</kbd> package offers no support for dealing with floating-point values. To work around this limitation, we will import the <kbd>unsafe</kbd> package and employ a few <em>creative value casting tricks</em> to roll our very own set of atomic functions that can work with <kbd>float64</kbd> values!</p>
<p>Let's begin by defining the <kbd>Float64Accumulator</kbd> type:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">type</span> Float64Accumulator <span class="kw">struct</span> {</a>
<a>    prevSum <span class="dt">float64</span></a>
<a>    curSum  <span class="dt">float64</span></a>
<a>}</a></pre></div>
<p>The <kbd>Float64Accumulator</kbd> type keeps track of two <kbd>float64</kbd> values: the first one holds the current sum while the latter keeps track of the last value that was reported by a call to the <kbd>Delta</kbd> method.</p>
<p>Now, let's define the necessary set of methods for satisfying the <kbd>Accumulator</kbd> interface. The first method that we will be defining is <kbd>Get</kbd>:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (a *Float64Accumulator) Get() <span class="kw">interface</span>{} {</a>
<a>    <span class="kw">return</span> loadFloat64(&amp;a.curSum)</a>
<a>}</a>

<a><span class="kw">func</span> loadFloat64(v *<span class="dt">float64</span>) <span class="dt">float64</span> {</a>
<a>    <span class="kw">return</span> math.Float64frombits(</a>
<a>        atomic.LoadUint64((*<span class="dt">uint64</span>)(unsafe.Pointer(v))),</a>
<a>    )</a>
<a>}</a></pre></div>
<p>Here, the <kbd>loadFloat64</kbd> helper function is where all the magic happens. The trick that we will be using is based on the observation that a <kbd>float64</kbd> value takes exactly the same space in memory (8 bytes) as a <kbd>uint64</kbd> value. With the help of the <kbd>unsafe</kbd> package, we can cast a <em>pointer</em> to the <kbd>float64</kbd> value we want to read into a <kbd>*uint64</kbd> <span>value</span> and use the <kbd>atomic.LoadUint64</kbd> function to read it atomically as a raw <kbd>uint64</kbd> value. Then, we can use the handy <kbd>Float64frombits</kbd> function from the built-in <kbd>math</kbd> package to <em>interpret</em> the raw <kbd>uint64</kbd> value as a <kbd>float64</kbd>.</p>
<p class="mce-root"/>
<p>Next, let's examine the implementation for <kbd>Aggregate</kbd>:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (a *Float64Accumulator) Aggregate(v <span class="kw">interface</span>{}) {</a>
<a>    <span class="kw">for</span> v64 := v.(<span class="dt">float64</span>); ; {</a>
<a>        oldV := loadFloat64(&amp;a.curSum)</a>
<a>        newV := oldV + v64</a>
<a>        <span class="kw">if</span> atomic.CompareAndSwapUint64(</a>
<a>            (*<span class="dt">uint64</span>)(unsafe.Pointer(&amp;a.curSum)),</a>
<a>            math.Float64bits(oldV),</a>
<a>            math.Float64bits(newV),</a>
<a>        ) {</a>
<a>            <span class="kw">return</span></a>
<a>        }</a>
<a>    }</a>
<a>}</a></pre></div>
<p>As you can see in the preceding code snippet, we enter an infinite <kbd>for</kbd> loop where we fetch the current aggregator value, add the <kbd>float64</kbd> value that was passed to the method, and keep trying to execute a compare and swap operation until we succeed. Like we did previously, we exploit the observation that <kbd>float64</kbd> values take the same space in memory as an <kbd>uint64</kbd> and use <kbd>atomic.CompareAndSwapUint64</kbd> to perform the swap. This function expects <kbd>uint64</kbd> values as arguments, so this time, we leverage the <kbd>math.Float64bits</kbd> function to convert the <kbd>float64</kbd> values that we are working with into raw <kbd>uint64</kbd> values for the compare-and-swap operation.</p>
<p>We can apply exactly the same methodology to implement the <kbd>Delta</kbd> method, as follows:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (a *Float64Accumulator) Delta() <span class="kw">interface</span>{} {</a>
<a>    <span class="kw">for</span> {</a>
<a>        curSum := loadFloat64(&amp;a.curSum)</a>
<a>        prevSum := loadFloat64(&amp;a.prevSum)</a>
<a>        <span class="kw">if</span> atomic.CompareAndSwapUint64(</a>
<a>            (*<span class="dt">uint64</span>)(unsafe.Pointer(&amp;a.prevSum)),</a>
<a>            math.Float64bits(prevSum),</a>
<a>            math.Float64bits(curSum),</a>
<a>        ) {</a>
<a>            <span class="kw">return</span> curSum - prevSum</a>
<a>        }</a>
<a>    }</a>
<a>}</a></pre></div>
<p>Once again, we enter an infinite for loop where we latch on to the current and previous values and then use a compare and swap operation to copy <kbd>curSum</kbd> to <kbd>prevSum</kbd>. Once the swap succeeds, we subtract the two latched values and return the result to the caller.</p>
<p class="mce-root"/>
<p>To complete the set of methods for implementing our accumulator, we also need to provide an implementation for <kbd>Set</kbd>, which, as you see in the following code listing, is slightly more complicated:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (a *Float64Accumulator) Set(v <span class="kw">interface</span>{}) {</a>
<a>    <span class="kw">for</span> v64 := v.(<span class="dt">float64</span>); ; {</a>
<a>        oldCur := loadFloat64(&amp;a.curSum)</a>
<a>        oldPrev := loadFloat64(&amp;a.prevSum)</a>
<a>        swappedCur := atomic.CompareAndSwapUint64(</a>
<a>            (*<span class="dt">uint64</span>)(unsafe.Pointer(&amp;a.curSum)),</a>
<a>            math.Float64bits(oldCur),</a>
<a>            math.Float64bits(v64),</a>
<a>        )</a>
<a>        swappedPrev := atomic.CompareAndSwapUint64(</a>
<a>            (*<span class="dt">uint64</span>)(unsafe.Pointer(&amp;a.prevSum)),</a>
<a>            math.Float64bits(oldPrev),</a>
<a>            math.Float64bits(v64),</a>
<a>        )</a>
<a>        <span class="kw">if</span> swappedCur &amp;&amp; swappedPrev {</a>
<a>            <span class="kw">return</span></a>
<a>        }</a>
<a>    }</a>
<a>}</a></pre></div>
<p>The extra complexity arises from the fact that we need to perform two sequential compare and swap operations, both of which must succeed before we can exit the <kbd>for</kbd> loop.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sending and receiving messages</h1>
                </header>
            
            <article>
                
<p>As we mentioned previously, vertices communicate with each other by exchanging messages. Sending the <em>same</em> message to all immediate neighbors of a particular vertex is an often recurring pattern in several graph algorithms. Let's define a convenience method for handling this fairly common use case:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (g *Graph) BroadcastToNeighbors(v *Vertex, msg message.Message) <span class="dt">error</span> {</a>
<a>    <span class="kw">for</span> _, e := <span class="kw">range</span> v.edges {</a>
<a>        <span class="kw">if</span> err := g.SendMessage(e.dstID, msg); err != <span class="ot">nil</span> {</a>
<a>            <span class="kw">return</span> err</a>
<a>        }</a>
<a>    }</a>

<a>    <span class="kw">return</span> <span class="ot">nil</span></a>
<a>}</a></pre></div>
<p class="mce-root"/>
<p class="mce-root"/>
<p><kbd>BroadcastToNeighbors</kbd> simply iterates the list of edges for a particular vertex and attempts to send the message to each neighbor with the help of the <kbd>SendMessage</kbd> method. With the help of <kbd>SendMessage</kbd>, compute functions can send a message to any vertex in the graph, provided that its ID is known to them (for example, discovered through the use of a gossip protocol).</p>
<p>Let's take a look at the implementation for <kbd>SendMessage</kbd>:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (g *Graph) SendMessage(dstID <span class="dt">string</span>, msg message.Message) <span class="dt">error</span> {</a>
<a>    dstVert := g.vertices[dstID]</a>
<a>    <span class="kw">if</span> dstVert != <span class="ot">nil</span> {</a>
<a>        queueIndex := (g.superstep + <span class="dv">1</span>) % <span class="dv">2</span></a>
<a>        <span class="kw">return</span> dstVert.msgQueue[queueIndex].Enqueue(msg)</a>
<a>    }</a>

<a>    <span class="kw">if</span> g.relayer != <span class="ot">nil</span> {</a>
<a>        <span class="kw">if</span> err := g.relayer.Relay(dstID, msg); !xerrors.Is(err, ErrDestinationIsLocal) {</a>
<a>            <span class="kw">return</span> err</a>
<a>        }</a>
<a>    }</a>
<a>    </a>
<a>    <span class="kw">return</span> xerrors.Errorf(<span class="st">"message cannot be delivered to %q: %w"</span>, dstID, ErrInvalidMessageDestination)</a>
<a>}</a></pre></div>
<p>First things first, we need to look up the destination vertex in the graph's vertex map. If the lookup yields a valid <kbd>Vertex</kbd> instance, then we can enqueue the message so that it can be delivered to the vertex in the following super-step.</p>
<p>Things get a bit more interesting when the vertex lookup fails… A failed lookup can occur because of two reasons:</p>
<ul>
<li>We are running in distributed mode and the vertex is managed by a <em>remote</em> graph instance</li>
<li>The vertex simply does not exist</li>
</ul>
<p>To handle vertices that are potentially hosted remotely, the <kbd>Graph</kbd> type allows users of the <kbd>bspgraph</kbd> package to register a helper that can relay messages between remote graph instances. More specifically, these helpers:</p>
<ul>
<li>Are aware of the topology of a distributed graph (that is, the vertex ID ranges that are managed by each node in a cluster)</li>
<li>Provide a mechanism for shuttling messages back and forth between the cluster nodes</li>
</ul>
<p class="mce-root"/>
<p>User-defined relay helpers must implement the <kbd>Relayer</kbd> interface and can be registered with a graph instance through the <kbd>RegisterRelayer</kbd> method:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">type</span> Relayer <span class="kw">interface</span> {</a>
<a>    <span class="co">// Relay a message to a vertex that is not known locally. Calls</span></a>
<a>    <span class="co">// to Relay must return ErrDestinationIsLocal if the provided dst value</span></a>
<a>    <span class="co">// is not a valid remote destination.</span></a>
<a>    Relay(dst <span class="dt">string</span>, msg message.Message) <span class="dt">error</span></a>
<a>}</a>

<a><span class="kw">func</span> (g *Graph) RegisterRelayer(relayer Relayer) { </a>
<a>    g.relayer = relayer </a>
<a>}</a></pre></div>
<p>To make it easier for users to provide functions or closures as a suitable <kbd>Relayer</kbd> implementation, let's also go ahead and define the <kbd>RelayerFunc</kbd> adapter, which converts a function with the appropriate signature into a <kbd>Relayer</kbd>:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">type</span> RelayerFunc <span class="kw">func</span>(<span class="dt">string</span>, message.Message) <span class="dt">error</span></a>

<a><span class="co">// Relay calls f(dst, msg).</span></a>
<a><span class="kw">func</span> (f RelayerFunc) Relay(dst <span class="dt">string</span>, msg message.Message) <span class="dt">error</span> {</a>
<a>    <span class="kw">return</span> f(dst, msg)</a>
<a>}</a></pre></div>
<p>If the destination vertex ID cannot be located by the graph and the user has registered a <kbd>Relayer</kbd> instance, <kbd>SendMessage</kbd> invokes its <kbd>Relay</kbd> method and checks the response for errors. <span>If we get an</span> <span>error</span> <em>other</em> <span>than</span> <kbd>ErrDestinationLocal</kbd><span>, we return the error as-is back to the caller.</span></p>
<p>If the relay helper detects that the destination vertex ID should, in fact, be managed by the local graph instance, it will fail with the typed <kbd>ErrDestinationIsLocal</kbd> <span>error to indicate this. In such a case, we</span> assume that the vertex ID is invalid and return the typed <kbd>ErrInvalidMessageDestination</kbd> error to the caller.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementing graph-based algorithms using compute functions</h1>
                </header>
            
            <article>
                
<p>In order for a compute function to be used with the <kbd>bspgraph</kbd> package, it must adhere to the following signature:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">type</span> ComputeFunc <span class="kw">func</span>(g *Graph, v *Vertex, msgIt message.Iterator) <span class="dt">error</span></a></pre></div>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The first argument to the compute function is a pointer to the <kbd>Graph</kbd> instance itself. This allows compute functions to use the graph API to query the current super-step number, look up aggregators, and send messages to vertices. The second argument is a pointer to the <kbd>Vertex</kbd> instance that the compute function is operating on, while the third and final argument is a <kbd>message.Iterator</kbd> for consuming the messages that were sent to the vertex during the <em>previous</em> super-step.</p>
<p>It is important to note that the system operates under the assumption that compute functions can be safely executed concurrently. The only runtime guarantee that's provided by the system is that at each super-step, compute functions will be executed for each vertex <em>exactly once</em>. Consequently, compute function implementations can use any of the <kbd>Vertex</kbd> methods without having to worry about data races and synchronization issues. Given that vertices effectively <em>own</em> the edges originating from them, the same data access principles also apply to any <kbd>Edge</kbd> instances that are obtained by invoking the <kbd>Edges</kbd> method on a vertex.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Achieving vertical scaling by executing compute functions in parallel</h1>
                </header>
            
            <article>
                
<p>Next, we will shift our focus to the mechanism that's used to execute compute functions. A rather simplistic approach would be to use a <kbd>for</kbd> loop construct to iterate the vertices in the graph and invoke the compute function for each vertex in a sequential fashion. While the approach would undoubtedly work as expected, it would be a rather inefficient use of the compute resources that are at our disposal. Running compute functions sequentially would only make use of a single CPU core; that would be quite a waste given that machines with up to 64 cores are readily available from the majority of cloud providers.</p>
<p>A much better alternative would be to fan out the execution of compute functions to a pool of workers. This way, compute functions can run in parallel and make full use of all the available CPU cores. The graph constructor initializes the pool of workers via a call to the <kbd>startWorkers</kbd> method, whose implementation is as follows:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (g *Graph) startWorkers(numWorkers <span class="dt">int</span>) {</a>
<a>    g.vertexCh = <span class="bu">make</span>(<span class="kw">chan</span> *Vertex)</a>
<a>    g.errCh = <span class="bu">make</span>(<span class="kw">chan</span> <span class="dt">error</span>, <span class="dv">1</span>)</a>
<a>    g.stepCompletedCh = <span class="bu">make</span>(<span class="kw">chan</span> <span class="kw">struct</span>{})</a>

<a>    g.wg.Add(numWorkers)</a>
<a>    <span class="kw">for</span> i := <span class="dv">0</span>; i &lt; numWorkers; i++ {</a>
<a>        <span class="kw">go</span> g.stepWorker()</a>
<a>    }</a>
<a>}</a></pre></div>
<p>The first thing that <kbd>startWorkers</kbd> does is create a set of channels that are needed to communicate with the workers in the pool. Let's briefly talk about each channel's purpose:</p>
<ul>
<li><kbd>vertexCh</kbd> is a channel that is polled by workers to obtain the next vertex to be processed.</li>
<li><kbd>errCh</kbd> is a buffered channel where workers publish any errors that may occur while invoking compute functions. The graph processing system implementation will treat all errors as <em>fatal</em>. Therefore, we only need room to store a single error value. When a worker detects an error, it will attempt to enqueue it to <kbd>errCh</kbd>; if the channel is full, another fatal error has already been written to it, so the new error can safely be ignored.</li>
<li>Since we are using a worker pool to execute compute functions in parallel, we need to introduce some sort of synchronization mechanism to detect when all the vertices have been processed. The <kbd>stepCompletedCh</kbd> channel allows workers to signal when the <em>last</em> enqueued vertex has been processed.</li>
</ul>
<p>The remainder of the <kbd>startWorkers</kbd> method is pretty straightforward: we start a go-routine for each worker and use a <kbd>sync.WaitGroup</kbd> to keep track of their completion status.</p>
<p>The <kbd>step</kbd> method, as shown in the following code, is responsible for executing a single super-step. If the super-step completes without an error, <kbd>step</kbd> returns the number of vertices that were active during the super-step:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (g *Graph) step() (activeInStep <span class="dt">int</span>, err <span class="dt">error</span>) {</a>
<a>    g.activeInStep, g.pendingInStep = <span class="dv">0</span>, <span class="dt">int64</span>(<span class="bu">len</span>(g.vertices))</a>
<a>    <span class="kw">if</span> g.pendingInStep == <span class="dv">0</span> {</a>
<a>        <span class="kw">return</span> <span class="dv">0</span>, <span class="ot">nil</span> <span class="co">// no work required</span></a>
<a>    }</a>
<a>    <span class="kw">for</span> _, v := <span class="kw">range</span> g.vertices {</a>
<a>        g.vertexCh &lt;- v</a>
<a>    }</a>
<a>    &lt;-g.stepCompletedCh</a>

<a>    <span class="kw">select</span> {</a>
<a>    <span class="kw">case</span> err = &lt;-g.errCh: <span class="co">// dequeued</span></a>
<a>    <span class="kw">default</span>: <span class="co">// no error available</span></a>
<a>    }</a>
<a>    <span class="kw">return</span> <span class="dt">int</span>(g.activeInStep), err</a>
<a>}</a></pre></div>
<p class="mce-root"/>
<p>The preceding block of code should be self-explanatory. First, we reset the <kbd>activeInStep</kbd> counter to zero and load the <kbd>pendingInStep</kbd> counter with the number of vertices in the graph. Then, the map that holds the set of the graph <kbd>Vertex</kbd> instances is iterated and each vertex value is written to <kbd>vertexCh</kbd> so that it can be picked up and processed by an idle worker.</p>
<p>Once all the vertices have been enqueued, <kbd>step</kbd> waits for all vertices to be processed by the worker pool by performing a blocking read on <kbd>stepCompletedCh</kbd>. Before returning, the code checks whether an error has been enqueued to the error channel. If that happens to be the case, the error is dequeued and returned to the caller.</p>
<p>Now, let's take a look at the <kbd>stepWorker</kbd> method's implementation:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">for</span> v := <span class="kw">range</span> g.vertexCh {</a>
<a>    buffer := g.superstep % <span class="dv">2</span></a>
<a>    <span class="kw">if</span> v.active || v.msgQueue[buffer].PendingMessages() {</a>
<a>        _ = atomic.AddInt64(&amp;g.activeInStep, <span class="dv">1</span>)</a>
<a>        v.active = <span class="ot">true</span></a>
<a>        <span class="kw">if</span> err := g.computeFn(g, v, v.msgQueue[buffer].Messages()); err != <span class="ot">nil</span> {</a>
<a>            tryEmitError(g.errCh, xerrors.Errorf(<span class="st">"running compute function for vertex %q failed: %w"</span>, v.ID(), err))</a>
<a>        } <span class="kw">else</span> <span class="kw">if</span> err := v.msgQueue[buffer].DiscardMessages(); err != <span class="ot">nil</span> {</a>
<a>            tryEmitError(g.errCh, xerrors.Errorf(<span class="st">"discarding unprocessed messages for vertex %q failed: %w"</span>, v.ID(), err))</a>
<a>        }</a>
<a>    }</a>
<a>    <span class="kw">if</span> atomic.AddInt64(&amp;g.pendingInStep, <span class="dv">-1</span>) == <span class="dv">0</span> {</a>
<a>        g.stepCompletedCh &lt;- <span class="kw">struct</span>{}{}</a>
<a>    }</a>
<a>}</a>
<a>g.wg.Done()</a></pre></div>
<p>The channel's <kbd>range</kbd> statement ensures that our worker will keep executing until the <kbd>vertexCh</kbd> is closed. After dequeuing the next vertex from <kbd>vertexCh</kbd>, the worker uses modulo arithmetic to select the message queue that contains the messages that should be consumed by the compute function during the current super-step.</p>
<p>Vertices are considered to be active if either their <kbd>active</kbd> flag is set or if their input message queue contains any undelivered messages. For any vertex deemed to be active, we set its <kbd>active</kbd> flag to <kbd>true</kbd> and atomically increment the <kbd>activeInStep</kbd> counter. As we will see in the following sections, several graph algorithms use the number of active vertices in a super-step as a predicate for deciding whether the algorithm has completed or not.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Next, we invoke the registered compute function and check for any errors. If an error occurs, we invoke the <kbd>tryEmitError</kbd> helper to enqueue the error to <kbd>errCh</kbd>:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> tryEmitError(errCh <span class="kw">chan</span>&lt;- <span class="dt">error</span>, err <span class="dt">error</span>) {</a>
<a>    <span class="kw">select</span> {</a>
<a>    <span class="kw">case</span> errCh &lt;- err: <span class="co">// queued error</span></a>
<a>    <span class="kw">default</span>: <span class="co">// channel already contains another error</span></a>
<a>    }</a>
<a>}</a></pre></div>
<p>The last bit of housekeeping that we need to do within the <kbd>stepWorker</kbd> method is to call the queue's <kbd>DiscardMessages</kbd> <span>method and</span> flush any messages that were not consumed by the compute function that we executed in the previous step. This ensures that the queue is always empty and ready to store incoming messages for <kbd>superstep+2</kbd>.</p>
<p>Regardless of whether the vertex is active or not, the worker invokes the <kbd>atomic.AddInt64</kbd> function to <em>decrement</em> the <kbd>pendingInStep</kbd> counter and check whether it has reached zero. When that occurs, all the vertices for the current super-step have been processed and the worker writes an empty <kbd>struct{}</kbd> value to <kbd>stepCompletedCh</kbd> to unblock the <kbd>step</kbd> method and allow it to return.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Orchestrating the execution of super-steps</h1>
                </header>
            
            <article>
                
<p>In the previous section, we performed a detailed analysis of the mechanism that's used by the <kbd>Graph</kbd> type to execute a single super-step. However, graph algorithms typically involve several super-steps. For the <kbd>bspgraph</kbd> package users to be able to run generic graph algorithms using the system we are building, they require more fine-grained control over the execution of a sequence of super-steps.</p>
<p>Before executing a super-step, we need to reset the value of one or more aggregators. Likewise, after a super-step completes, we might be interested in examining or modifying an aggregator's final value. Furthermore, each algorithm defines its own termination condition. For example, an algorithm might terminate when the following occurs:</p>
<ul>
<li>After a fixed number of steps</li>
<li>When all vertices in the graph become inactive</li>
<li>When the value of some aggregator exceeds a threshold</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>
<p>To cater to such requirements, we need to introduce a high-level API that provides an orchestration layer for governing the execution of a sequential list of super-steps. This API is provided by the <kbd>Executor</kbd> type, whose definition is as follows:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">type</span> Executor <span class="kw">struct</span> {</a>
<a>    g  *Graph</a>
<a>    cb ExecutorCallbacks</a>
<a>}</a></pre></div>
<p>An <kbd>Executor</kbd> wraps a <kbd>Graph</kbd> instance and is parameterized with a set of user-defined <kbd>ExecutorCallbacks</kbd>:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">type</span> ExecutorCallbacks <span class="kw">struct</span> {</a>
<a>    PreStep <span class="kw">func</span>(ctx context.Context, g *Graph) <span class="dt">error</span></a>
<a>    PostStep <span class="kw">func</span>(ctx context.Context, g *Graph, activeInStep <span class="dt">int</span>) <span class="dt">error</span></a>
<a>    PostStepKeepRunning <span class="kw">func</span>(ctx context.Context, g *Graph, activeInStep <span class="dt">int</span>) (<span class="dt">bool</span>, <span class="dt">error</span>)</a>
<a>}</a></pre></div>
<p>The <kbd>PreStep</kbd> and <kbd>PostStep</kbd> callbacks are invoked <span>–</span> if defined <span>–</span> before and after the execution of a new super-step. If the <kbd>PostStepKeepRunning</kbd> callback is defined, it will be automatically invoked by the <kbd>Executor</kbd> after <kbd>PostStep</kbd>. The callback is responsible for checking whether the termination condition for the algorithm has been met and to return <kbd>false</kbd> when no further super-steps need to be executed.</p>
<p>The <kbd>NewExecutor</kbd> function serves as a constructor for creating new <kbd>Executor</kbd> instances:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> NewExecutor(g *Graph, cb ExecutorCallbacks) *Executor {</a>
<a>    patchEmptyCallbacks(&amp;cb)</a>
<a>    g.superstep = <span class="dv">0</span></a>
<a>    <span class="kw">return</span> &amp;Executor{</a>
<a>        g:              g,</a>
<a>        cb:             cb,</a>
<a>    }</a>
<a>}</a></pre></div>
<p>To avoid nil pointer dereference errors when trying to invoke undefined callbacks, the constructor uses the following helper to patch missing callbacks with a dummy no-op stub:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> patchEmptyCallbacks(cb *ExecutorCallbacks) {</a>
<a>    <span class="kw">if</span> cb.PreStep == <span class="ot">nil</span> {</a>
<a>        cb.PreStep = <span class="kw">func</span>(context.Context, *Graph) <span class="dt">error</span> { <span class="kw">return</span> <span class="ot">nil</span> }</a>
<a>    }</a>
<a>    <span class="kw">if</span> cb.PostStep == <span class="ot">nil</span> {</a>
<a>        cb.PostStep = <span class="kw">func</span>(context.Context, *Graph, <span class="dt">int</span>) <span class="dt">error</span> { <span class="kw">return</span> <span class="ot">nil</span> }</a>
<a>    }</a>
<a>    <span class="kw">if</span> cb.PostStepKeepRunning == <span class="ot">nil</span> {</a>
<a>        cb.PostStepKeepRunning = <span class="kw">func</span>(context.Context, *Graph, <span class="dt">int</span>) (<span class="dt">bool</span>, <span class="dt">error</span>) { <span class="kw">return</span> <span class="ot">true</span>, <span class="ot">nil</span> }</a>
<a>    }</a>
<a>}</a></pre></div>
<p>The high-level interface that's exposed by the <kbd>Executor</kbd> consists of the following set of methods:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (ex *Executor) Graph() *Graph { <span class="kw">return</span> ex.g }</a>

<a><span class="kw">func</span> (ex *Executor) Superstep() <span class="dt">int</span> { <span class="kw">return</span> ex.g.Superstep() }</a>

<a><span class="kw">func</span> (ex *Executor) RunSteps(ctx context.Context, numSteps <span class="dt">int</span>) <span class="dt">error</span> {</a>
<a>    <span class="kw">return</span> ex.run(ctx, numSteps)</a>
<a>}</a>

<a><span class="kw">func</span> (ex *Executor) RunToCompletion(ctx context.Context) <span class="dt">error</span> {</a>
<a>    <span class="kw">return</span> ex.run(ctx, <span class="dv">-1</span>)</a>
<a>}</a></pre></div>
<p>The <kbd>Graph</kbd> method provides access to the <kbd>Graph</kbd> instance that's linked to the <kbd>Executor</kbd><span>,</span> while <kbd>Superstep</kbd> reports the <em>last</em> super-step that was executed. The <kbd>RunSteps</kbd> and <kbd>RunToCompletion</kbd> methods repeatedly execute super-steps until one of the following conditions is met:</p>
<ul>
<li>The context expires</li>
<li>An error occurs</li>
<li>The <kbd>PostStepKeepRunning</kbd> callback returns false</li>
<li>The maximum number of <kbd>numSteps</kbd> has been executed (only for <kbd>RunSteps</kbd>)</li>
</ul>
<p>Both of these functions are simply proxies for the <kbd>run</kbd> method, whose implementation is as follows:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (ex *Executor) run(ctx context.Context, maxSteps <span class="dt">int</span>) <span class="dt">error</span> {</a>
<a>    <span class="kw">var</span> activeInStep <span class="dt">int</span></a>
<a>    <span class="kw">var</span> err          <span class="dt">error</span></a>
<a>    <span class="kw">var</span> keepRunning  <span class="dt">bool</span></a>
<a>    <span class="kw">var</span> cb           = ex.cb</a>
<a>    <span class="kw">for</span> ; maxSteps != <span class="dv">0</span>; ex.g.superstep, maxSteps = ex.g.superstep+<span class="dv">1</span>, maxSteps<span class="dv">-1</span> {</a>
<a>        <span class="kw">if</span> err = ensureContextNotExpired(ctx); err != <span class="ot">nil</span> {</a>
<a>            <span class="kw">break</span></a>
<a>        } <span class="kw">else</span> <span class="kw">if</span> err = cb.PreStep(ctx, ex.g); err != <span class="ot">nil</span> {</a>
<a>            <span class="kw">break</span></a>
<a>        } <span class="kw">else</span> <span class="kw">if</span> activeInStep, err = ex.g.step(); err != <span class="ot">nil</span> {</a>
<a>            <span class="kw">break</span></a>
<a>        } <span class="kw">else</span> <span class="kw">if</span> err = cb.PostStep(ctx, ex.g, activeInStep); err != <span class="ot">nil</span> {</a>
<a>            <span class="kw">break</span></a>
<a>        } <span class="kw">else</span> <span class="kw">if</span> keepRunning, err = cb.PostStepKeepRunning(ctx, ex.g, activeInStep); !keepRunning || err != <span class="ot">nil</span> {</a>
<a>            <span class="kw">break</span></a>
<a>        }</a>
<a>    }</a>
<a>    <span class="kw">return</span> err</a>
<a>}</a></pre></div>
<p>The <kbd>run</kbd> method enters a <kbd>for</kbd> loop that keeps running until the caller-provided <kbd>maxSteps</kbd> <span>value</span> becomes equal to zero. At the end of each iteration, <kbd>maxSteps</kbd> is decremented while the graph's <kbd>superstep</kbd> counter is incremented. However, if the caller specifies a <em>negative</em> value for <kbd>maxSteps</kbd> when invoking <kbd>run</kbd>, then the preceding loop is functionally equivalent to an infinite loop.</p>
<p>The <kbd>Executor</kbd> begins a new iteration by checking whether the provided context has been canceled and then proceeds to invoke the <kbd>PreStep</kbd> callback. Then, it executes a new super-step by invoking the <kbd>step</kbd> method of the wrapped <kbd>Graph</kbd> instance. Following that, it invokes the <kbd>PostStep</kbd> and <kbd>PostStepKeepRunning</kbd> callbacks. If any of the callbacks or the <kbd>step</kbd> method returns an error, then we break out of the loop and return the error back to the caller.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating and managing Graph instances</h1>
                </header>
            
            <article>
                
<p>Our graph processing system is nearly complete! To finalize our implementation, we need to define a constructor that will create new <kbd>Graph</kbd> instances and some auxiliary methods that will manage the graph's life cycle.</p>
<p>As we saw in the previous sections, there are quite a few knobs for configuring <kbd>Graph</kbd> instances. Passing each individual configuration option as an argument to the graph's constructor is considered to be an anti-pattern <span>– n</span>ot to mention that we would have to bump the major version of our package every time we want to add a new configuration option; changing a constructor's signature is the very definition of a breaking change!</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>A much better solution is to define a typed configuration object and pass that as an argument to the constructor:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">type</span> GraphConfig <span class="kw">struct</span> {</a>
<a>    QueueFactory message.QueueFactory</a>
<a>    ComputeFn ComputeFunc</a>
<a>    ComputeWorkers <span class="dt">int</span></a>
<a>}</a></pre></div>
<p><kbd>QueueFactory</kbd> will be used by the <kbd>AddVertex</kbd> method to create the required message queue instances for each new vertex that is being added to the graph. The <kbd>ComputeFn</kbd> setting is used to specify the compute function that will be executed for each super-step. Finally, the <kbd>ComputeWorkers</kbd> option allows the end users of the package to fine-tune the size of the worker pool so that they can execute the provided compute function.</p>
<p>From the preceding list of configuration options, only <kbd>ComputeFn</kbd> is required. Let's create a validator helper to check a <kbd>GraphConfig</kbd> object and to populate missing fields with sane defaults:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (g *GraphConfig) validate() <span class="dt">error</span> {</a>
<a>    <span class="kw">var</span> err <span class="dt">error</span></a>
<a>    <span class="kw">if</span> g.QueueFactory == <span class="ot">nil</span> {</a>
<a>        g.QueueFactory = message.NewInMemoryQueue</a>
<a>    }</a>
<a>    <span class="kw">if</span> g.ComputeWorkers &lt;= <span class="dv">0</span> {</a>
<a>        g.ComputeWorkers = <span class="dv">1</span></a>
<a>    }</a>

<a>    <span class="kw">if</span> g.ComputeFn == <span class="ot">nil</span> {</a>
<a>        err = multierror.Append(err, xerrors.New(<span class="st">"compute function not specified"</span>))</a>
<a>    }</a>

<a>    <span class="kw">return</span> err</a>
<a>}</a></pre></div>
<p>If a nil <kbd>QueueFactory</kbd> <span>instance</span> is provided by the caller, the validator code will use the in-memory implementation as a sane default. Furthermore, if an invalid number of compute workers is specified, the validator will fall back to using a single worker. Of course, doing so would effectively turn processing graph vertices for every super-step into a <em>sequential</em> operation. Nevertheless, this might prove to be a useful feature when the end users wish to debug misbehaving compute functions.</p>
<p class="mce-root"/>
<p>A new <kbd>Graph</kbd> instance can be created via the <kbd>NewGraph</kbd> constructor, which is as follows:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> NewGraph(cfg GraphConfig) (*Graph, <span class="dt">error</span>) {</a>
<a>    <span class="kw">if</span> err := cfg.validate(); err != <span class="ot">nil</span> {</a>
<a>        <span class="kw">return</span> <span class="ot">nil</span>, xerrors.Errorf(<span class="st">"graph config validation failed: %w"</span>, err)</a>
<a>    }</a>

<a>    g := &amp;Graph{</a>
<a>        computeFn:    cfg.ComputeFn,</a>
<a>        queueFactory: cfg.QueueFactory,</a>
<a>        aggregators:  <span class="bu">make</span>(<span class="kw">map</span>[<span class="dt">string</span>]Aggregator),</a>
<a>        vertices:     <span class="bu">make</span>(<span class="kw">map</span>[<span class="dt">string</span>]*Vertex),</a>
<a>    }</a>
<a>    g.startWorkers(cfg.ComputeWorkers)</a>

<a>    <span class="kw">return</span> g, <span class="ot">nil</span></a>
<a>}</a></pre></div>
<p>The first thing that the constructor needs to do is run a validation check on the provided configuration options. With a valid configuration at hand, the code creates the <kbd>Graph</kbd> instance, plugs in the provided configuration options, and allocates the maps that are needed to hold the graph's <kbd>Vertex</kbd> and <kbd>Aggregator</kbd> instances. The last thing that the constructor needs to do before returning the new <kbd>Graph</kbd> instance to the caller is initialize the worker pool via a call to <kbd>startWorkers</kbd>.</p>
<p>After creating a new <kbd>Graph</kbd> instance, users can proceed with populating the graph vertices and edges, register aggregators, and make use of an <kbd>Executor</kbd> to orchestrate the execution of a particular graph-based algorithm. However, after a completed run, users may want to reuse a <kbd>Graph</kbd> instance to run the exact same algorithm again but this time to use a different graph layout. Let's provide them with a <kbd>Reset</kbd> method to reset the graph's internal state:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (g *Graph) Reset() <span class="dt">error</span> {</a>
<a>    g.superstep = <span class="dv">0</span></a>
<a>    <span class="kw">for</span> _, v := <span class="kw">range</span> g.vertices {</a>
<a>        <span class="kw">for</span> i := <span class="dv">0</span>; i &lt; <span class="dv">2</span>; i++ {</a>
<a>            <span class="kw">if</span> err := v.msgQueue[i].Close(); err != <span class="ot">nil</span> {</a>
<a>                <span class="kw">return</span> xerrors.Errorf(<span class="st">"closing message queue #%d for vertex %v: %w"</span>, i, v.ID(), err)</a>
<a>            }</a>
<a>        }</a>
<a>    }</a>
<a>    g.vertices = <span class="bu">make</span>(<span class="kw">map</span>[<span class="dt">string</span>]*Vertex)</a>
<a>    g.aggregators = <span class="bu">make</span>(<span class="kw">map</span>[<span class="dt">string</span>]Aggregator)</a>
<a>    <span class="kw">return</span> <span class="ot">nil</span></a>
<a>}</a></pre></div>
<p>As you may recall, every vertex is associated with two message queue instances. The <kbd>message.Queue</kbd> interface defines a <kbd>Close</kbd> method that we must call to release any resources (for example, file handles, sockets, and so on) that are used by the underlying queue implementation. Lastly, to completely reset the graph's internal state, we can simply reset the graph's super-step counter to zero and recreate the maps that store the graph's vertices and aggregator instances.</p>
<p>Given that the worker pool consists of a bunch of long-running go-routines, we must also provide a mechanism for managing their life cycle and, more importantly, to shut them down when we are done with the graph. The last method that we will be defining on the <kbd>Graph</kbd> type is <kbd>Close</kbd>:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (g *Graph) Close() <span class="dt">error</span> {</a>
<a>    <span class="bu">close</span>(g.vertexCh)</a>
<a>    g.wg.Wait()</a>

<a>    <span class="kw">return</span> g.Reset()</a>
<a>}</a></pre></div>
<p>To force the worker pool to cleanly shut down and all its workers to exit, the <kbd>Close</kbd> method implementation closes <kbd>vertexCh</kbd><span>,</span> which each worker polls for incoming vertex processing jobs. The code then blocks on a wait group until all the workers have exited. Before returning, we make a tail call to the <kbd>Reset</kbd> method to ensure that the per-vertex queue instances are properly closed.</p>
<p>This concludes the development of a framework that allows us to execute graph-based algorithms using the BSP computation model. Next, we will explore how we can leverage the framework to solve some real-world problems that involve graphs!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Solving interesting graph problems</h1>
                </header>
            
            <article>
                
<p>In this section, we will be examining three very popular graph-based problems that are good fits for the graph processing system we have just finished building.</p>
<p>After describing each problem in detail and listing some of its potential real-world applications, we will continue our discussion by presenting a <em>sequential</em> algorithm that can be used to solve it. Following that, we will come up with an equivalent parallel version of the same algorithm and encode it as a compute function that can be used with the <kbd>bspgraph</kbd> package.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Searching graphs for the shortest path</h1>
                </header>
            
            <article>
                
<p>If we look around, we are bound to encounter a plethora of quite challenging problems that essentially boil down to finding a path or set of paths within a graph that minimize a particular cost function. Pathfinding has a multitude of real-world use cases, ranging from building efficient computer networks to logistics and even games!</p>
<div class="packt_infobox">The definition of a suitable cost function and its interpretation is typically application-specific.<br/>
<br/>
For instance, in the context of a map service, the cost associated with a graph edge could reflect the distance between two points or the time that's required to drive from one point to another due to traffic congestion. On the other hand, if we were talking about packet routing application, cost could represent the amount of money that the network operator would need to pay in order to use a peering connection with another provider.</div>
<p>For simplicity, the sole focus of this section will be about finding the shortest paths within a graph. It goes without saying that the principles and algorithms we will be discussing can be applied, as-is, to any <em>type</em> of cost function as long as <em>lower</em> cost value for a graph edge indicates a <em>better</em> path through the graph.</p>
<p>Depending on how we define the path origin and destination, we can classify shortest path queries into three general categories:</p>
<ul>
<li><strong>Point to point</strong>: <span>In a</span> <em>point to point</em> <span>search query, we are interested in locating the shortest path that connects</span> <em>two points</em><span>. An interesting example of this type of search would be a real-time strategy game where the user selects a unit (the path origin) and subsequently clicks on the map location where they want the unit to move to (the path destination). The game engine searches for the shortest unobstructed path between the two points (typically by implementing an algorithm such as A*</span> <sup><span class="citation">[5]</span></sup><span>) and navigates the unit along the path.</span></li>
<li><strong>Point to multi-point</strong>: <span>A</span> <em>point to multi-point</em> <span>search query involves finding the shortest paths connecting a</span> <em>single</em> <span>graph vertex to</span> <em>multiple</em> <span><span>vertices. For example, a user of a map application might be interested in obtaining a list of coffee shops located within a particular radius from their current location sorted by distance. If we flip this query around, we can identify even more interesting use cases. For instance, a ride-hailing application is aware of both the users' and the drivers' locations. A multi-point to point query would allow the application to dispatch the nearest driver to a user's location and reduce the time-to-pickup. These types of queries can be efficiently answered using Dijkstra's algorithm, one of the most widely-known graph algorithms.</span></span></li>
<li><strong>Multi-point to multi-point</strong>: <span>The third, and most complicated, pathfinding query category consists of</span> <em>multi-point to multi-point</em> <span>queries where we are effectively seeking the shortest path from each vertex to</span> <em>all</em> <span>the</span> <span>other vertices in the graph. Arguably, we could answer this kind of query by running Dijkstra's algorithm for each vertex in the graph at the cost of a much longer total runtime, especially if the graph contains a large number of vertices. A much better alternative performance-wise for answering such queries would be to use a dynamic programming algorithm such as Floyd-Warshall</span> <sup><span class="citation">[3]</span></sup><span>.</span></li>
</ul>
<p>Let's take a stab at implementing Dijkstra's algorithm using the graph processing framework that we developed in the first half of this chapter. While the original version of Dijkstra's algorithm was meant to find the shortest path between two points, the variant that we will be working with is designed to locate the <em>shortest path tree</em>, that is, the shortest path from a point to all the other points in the graph.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The sequential Dijkstra algorithm</h1>
                </header>
            
            <article>
                
<p>Before we adapt Dijkstra's algorithm so that it works with our graph processing system, we need to have a clear idea of how the original algorithm works. The following snippet outlines an implementation of the sequential version of Dijkstra's algorithm in pseudocode form:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a>function Dikstra(Graph):</a>
<a>  <span class="kw">for</span> each vertex v in Graph:</a>
<a>      min_cost_via[v] = infinity</a>
<a>      prev[v] = <span class="ot">nil</span></a>
<a>  min_cost_via[src] = <span class="dv">0</span></a>
<a>  </a>
<a>  Q = set of all vertices in graph</a>
<a>  while Q is not empty:</a>
<a>    u = entry from Q with smallest min_cost_via[]</a>
<a>    remove u from Q</a>

<a>    <span class="kw">for</span> each neighbor v from u:</a>
<a>      cost_via_u = min_cost_via[u] + cost(u, v)</a>
<a>      <span class="kw">if</span> cost_via_u &lt; min_cost_via[v]:</a>
<a>        min_cost_via[v] = cost_via_u</a>
<a>        prev[v] = u</a></pre></div>
<p>The preceding implementation maintains two arrays, each one having a length equal to the number of vertices in the graph:</p>
<ul>
<li>The first array, <kbd>min_cost_via</kbd><span>,</span> tracks the minimum cost (distance) for reaching the source vertex from the <em>i<sub>th</sub></em> vertex in the graph.</li>
<li>The <kbd>prev</kbd> array keeps track of the previous vertex in the optimal path leading from the source vertex to the <em>i<sub>th</sub></em> vertex.</li>
</ul>
<p>At initialization time, we set all the entries in the <kbd>prev</kbd> array to <kbd>nil</kbd>. Additionally, all the entries in the <kbd>min_cost_via</kbd> array are initialized to a large number with the exception of the entry for the source vertex, whose entry is set to <kbd>0</kbd>. If we were implementing this algorithm in Go and path costs were <kbd>uint64</kbd> values, we would set the initial value to <kbd>math.MaxUint64</kbd>.</p>
<p>Dijkstra's algorithm is bootstrapped by placing all the graph vertices in a set called <kbd>Q</kbd>. The algorithm then executes a number of iterations equal to the number of vertices in the graph. At each iteration, we select vertex <kbd>u</kbd> from <kbd>Q</kbd> which has the <em>lowest</em> <kbd>min_cost_via</kbd> value and remove it from the set.</p>
<p>Then, the algorithm examines each neighbor <kbd>v</kbd> of the selected vertex <kbd>u</kbd>. If a lower cost path from <kbd>v</kbd> to the source vertex can be constructed by passing through <kbd>u</kbd><span>,</span> then we update the <kbd>min_cost_via</kbd> entry for <kbd>v</kbd> and make <kbd>u</kbd> the predecessor of the optimal path to <kbd>v</kbd>.</p>
<p>The algorithm completes when all the vertices in set <kbd>Q</kbd> have been processed. The shortest path from the source vertex to any other vertex in the graph can be reconstructed by starting at the destination vertex and following the <kbd>prev</kbd> array entries until we reach the source vertex.</p>
<p>What's more, we can slightly tweak the preceding algorithm to obtain the original variant that answers point to point queries. All we need to do is terminate the algorithm after processing the destination vertex for our query. Those of you who are familiar with, or have implemented, the A* algorithm in the past will definitely notice a lot of similarities between the two algorithms. In fact, Dijkstra's algorithm is a special case of the A* algorithm where no distance heuristic is used.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Leveraging a gossip protocol to run Dijkstra in parallel</h1>
                </header>
            
            <article>
                
<p>Dijkstra's algorithm is fairly straightforward to implement and its runtime can be sped up considerably with the introduction of specialized data structures (for example, min-heap or Fibonacci heap) for selecting the next vertex for each iteration. Let's take a look at how we can leverage the graph processing system that we have built to execute Dijkstra's algorithm in parallel.</p>
<p>To break the sequential nature of the original algorithm, we will swap out the next vertex selection step and replace it with a <em>gossip protocol</em>. Whenever a vertex identifies a better path to it via another vertex, it will <em>broadcast</em> this information to all its neighbors by sending them a <kbd>PathCostMessage</kbd>. The neighbors would then process these messages during the <em>next</em> super-step, update their own min-distance estimates, and broadcast any better paths, if found, to their own neighbors. The key concept here is to trigger a wavefront of path updates throughout the graph that can be processed by each vertex in parallel.</p>
<p>The first thing we need to do is to define the types for the following:</p>
<ul>
<li>The message that's exchanged by the vertices</li>
<li>Storing the state for each vertex</li>
</ul>
<p>Consider the following piece of code:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">type</span> PathCostMessage <span class="kw">struct</span> {</a>
<a>    <span class="co">// The ID of the vertex this cost announcement originates from.</span></a>
<a>    FromID <span class="dt">string</span></a>

<a>    <span class="co">// The cost of the path from this vertex to the source vertex via <br/>    // FromID.</span></a>
<a>    Cost <span class="dt">int</span></a>
<a>}</a>

<a><span class="kw">func</span> (pc PathCostMessage) Type() <span class="dt">string</span> { <span class="kw">return</span> <span class="st">"cost"</span> }</a>

<a><span class="kw">type</span> pathState <span class="kw">struct</span> {</a>
<a>    minDist    <span class="dt">int</span></a>
<a>    prevInPath <span class="dt">string</span></a>
<a>}</a></pre></div>
<p>The <kbd>pathState</kbd> struct encodes the same kind information as the <kbd>min_cost_via</kbd> and <kbd>prev</kbd> arrays from the sequential version of the algorithm. The only difference is that each vertex maintains its own <kbd>pathState</kbd> instance, which is stored as the vertex value.</p>
<p>Next, let's try to put together a compute function for the graph. As you may recall from the previous sections, compute functions receive the following input arguments: a pointer to the graph, the currently processed vertex, and an iterator for the messages that are sent to the vertex during the previous super-step. At super-step <em>0</em>, each vertex initializes its own internal state with the maximum possible distance value:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">if</span> g.Superstep() == <span class="dv">0</span> {</a>
<a>    v.SetValue(&amp;pathState{ minDist: <span class="dt">int</span>(math.MaxInt64) })</a>
<a>}</a></pre></div>
<p>Then, each vertex processes any path announcements from its neighbors and keeps track of the path announcement with the minimum cost:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a>minDist := <span class="dt">int</span>(math.MaxInt64)</a>
<a><span class="kw">if</span> v.ID() == c.srcID { <span class="co">// min cost from source to source is always 0</span></a>
<a>    minDist = <span class="dv">0</span></a>
<a>}</a>
<a><span class="kw">var</span> via <span class="dt">string</span></a>
<a><span class="kw">for</span> msgIt.Next() {</a>
<a>    m := msgIt.Message().(*PathCostMessage)</a>
<a>    <span class="kw">if</span> m.Cost &lt; minDist {</a>
<a>        minDist = m.Cost</a>
<a>        via = m.FromID</a>
<a>    }</a>
<a>}</a></pre></div>
<p>After all the messages have been processed, we compare the cost of the best path from all the announcements to the cost of the best path we've seen so far by this vertex. If the vertex is already aware of a better path with a lower cost, we don't really need to do anything. Otherwise, we update the local vertex state to reflect the new best path and send out a message to each of our neighbors:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a>st := v.Value().(*pathState)</a>
<a><span class="kw">if</span> minDist &lt; st.minDist {</a>
<a>    st.minDist = minDist</a>
<a>    st.prevInPath = via</a>
<a>    <span class="kw">for</span> _, e := <span class="kw">range</span> v.Edges() {</a>
<a>        costMsg := &amp;PathCostMessage{</a>
<a>            FromID: v.ID(),</a>
<a>            Cost:   minDist + e.Value().(<span class="dt">int</span>),</a>
<a>        }</a>
<a>        <span class="kw">if</span> err := g.SendMessage(e.DstID(), costMsg); err != <span class="ot">nil</span> {</a>
<a>            <span class="kw">return</span> err</a>
<a>        }</a>
<a>    }</a>
<a>}</a>
<a>v.Freeze()</a></pre></div>
<p>Each outgoing <kbd>PathCostMessage</kbd> includes the cost of reaching each neighbor through the current vertex and is calculated by adding the cost for the next hop (the value associated with the outgoing edge) to the new minimum cost for reaching the current vertex.</p>
<p>Regardless of whether the best path to a vertex was updated or not, we always invoke the <kbd>Freeze</kbd> method on each vertex and mark it as processed. This means that the vertex will not be reactivated in a future super-step unless it receives a message from its neighbors. Eventually, all the vertices will figure out the optimal path to the source vertex and stop broadcasting cost updates to their neighbors. When this happens, all the vertices will end up in a frozen state and the algorithm will terminate.</p>
<p>We could definitely argue that this particular approach requires much more effort compared to the traditional sequential version. However, contrary to the sequential version of the algorithm, the parallel version can run efficiently on massive graphs that can be potentially distributed across multiple compute nodes.</p>
<p><span>The full source code and tests for the shortest path calculator from this section can be found in this book's GitHub repository in the</span> <kbd>Chapter08/shortestpath</kbd> <span>folder.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Graph coloring</h1>
                </header>
            
            <article>
                
<p>The next graph-based problem that we will be trying to solve using our graph processing system is <strong>graph coloring</strong>. The idea behind graph coloring is to assign a color to each vertex in the graph so that no adjacent vertices have the same color. The following diagram illustrates an example graph whose vertices have been colored with the optimal (minimum possible) number of colors:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/111cf89d-f996-467e-8f83-8016d6d5c74d.png" style="width:25.33em;height:15.00em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>Figure 3: A graph with optimal coloring</span></div>
<p class="mce-root"/>
<p>Graph coloring has numerous real-world applications:</p>
<ul>
<li>It is frequently used by compilers to perform register allocation <sup><span class="citation">[2]</span></sup>.</li>
<li>Mobile operators use graph coloring as the means for solving the frequency assignment problem <sup><span class="citation">[9]</span></sup> where the goal is to assign frequencies from a limited frequency pool to a set of communication links so that there is no interference between links in the same vicinity.</li>
<li>Many popular puzzle games such as Sudoku can be modeled as a graph and solved with the help of a graph coloring variant where the allowed set of colors is fixed (k-color graph coloring).</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">A sequential greedy algorithm for coloring undirected graphs</h1>
                </header>
            
            <article>
                
<p>Calculating the optimal graph coloring is known to be NP-hard. Therefore, researchers have proposed greedy algorithms that produce good enough, but not necessarily optimal, solutions. The sequential greedy algorithm listed here works with undirected graphs and guarantees an upper bound of <em>d+1</em> colors where <em>d</em> is the maximum out-degree (number of outgoing edges) for all the vertices in the graph:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a>function assignColors(Graph):</a>
<a>  C holds the assigned color <span class="kw">for</span> each vertex</a>
<a>  <span class="kw">for</span> each vertex u in Graph:</a>
<a>    C[u] = <span class="dv">0</span></a>

<a>  <span class="kw">for</span> each vertex u in Graph:</a>
<a>    already_in_use is a <span class="kw">map</span> where keys indicate colors that are currently in use</a>
<a>    <span class="kw">for</span> each neighbor v of u:</a>
<a>      already_in_use[ C[v] ] = <span class="ot">true</span></a>

<a>    assigned_color = <span class="dv">1</span></a>
<a>    while already_in_use[ color ] is <span class="ot">true</span>:</a>
<a>     assigned_color = assigned_color + <span class="dv">1</span></a>

<a>    C[u] = assigned_color</a></pre></div>
<p>The algorithm maintains an array called <kbd>C</kbd> that holds the assigned color for each vertex in the graph. During initialization, we set each entry of the <kbd>C</kbd> array to the value <em>0</em> to indicate that no color has been assigned to any of the graph vertices.</p>
<p class="mce-root"/>
<p>For each vertex <kbd>u</kbd> in the graph, the algorithm iterates its neighbor list and inserts the colors that have been already assigned to each neighbor into a map using the color value as a key. Next, the <kbd>assigned_color</kbd> variable is set to the lowest possible color value (in this case, <em>1</em>) and the <kbd>already_in_use</kbd> map is consulted to check whether that color is currently in use. If that happens to be the case, we increment the <kbd>assigned_color</kbd> variable and repeat the same steps until we finally land on a color value that is not in use. The unused color value is assigned to vertex <kbd>u</kbd> and the process continues until all the vertices have been colored.</p>
<p>An interesting fact about the preceding algorithm is that we can tweak it slightly to add support for handling pre-colored graphs. In this type of graph, a subset of the vertices have been already assigned a color value and the goal is to assign non-conflicting colors to the remaining vertices. All we need to do is the following:</p>
<ul>
<li>Set <kbd>C[u]</kbd> to the already assigned color instead of <em>0</em> during initialization</li>
<li>When iterating the graph vertices, skip the ones that have already been colored</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exploiting parallelism for undirected graph coloring</h1>
                </header>
            
            <article>
                
<p>Parallel graph coloring algorithms are based on the observation that if we split the graph into multiple <em>independent sets of vertices</em>, we can color those in parallel without introducing any conflict.</p>
<div class="packt_infobox">An independent set is defined as the collection or set of vertices where no two vertices share an edge.</div>
<p>To develop a parallelized version of the sequential greedy graph coloring algorithm from the previous section, we will be relying on a simple, yet effective algorithm proposed by Jones and Plassmann <sup><span class="citation">[6]</span></sup>. Before diving into the implementation details, let's take a few minutes to explain how the algorithm generates independent sets and how can we guarantee that our compute function will avoid data races while accessing the graph.</p>
<p>At initialization time, each vertex is assigned a random token. During each super-step, every vertex that hasn't been colored yet compares its own token value to the value of every <em>uncolored</em> neighbor. In the highly unlikely case that two neighboring vertices have been assigned the same random token, we can use the vertex ID as an extra comparison predicate to break the tie. The vertex with the highest token value gets to choose the next color using the same steps as the sequential algorithm while the neighboring vertices remain idle, waiting for their turn.</p>
<p class="mce-root"/>
<p>The concept of using tokens to enforce a coloring order guarantees that, at every super-step, we only color exactly one vertex from <em>each</em> independent set. At the same time, since connected vertices wait for their turn before they can pick a color, no data races can occur.</p>
<p>Just like we did with the shortest path implementation, we will begin by defining a type for holding the state of each vertex and a type that describes the messages that are exchanged between neighboring vertices:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">type</span> vertexState <span class="kw">struct</span> {</a>
<a>    token <span class="dt">int</span></a>
<a>    color <span class="dt">int</span></a>
<a>    usedColors <span class="kw">map</span>[<span class="dt">int</span>]<span class="dt">bool</span></a>
<a>}</a>

<a><span class="kw">type</span> VertexStateMessage <span class="kw">struct</span> {</a>
<a>    ID    <span class="dt">string</span></a>
<a>    Token <span class="dt">int</span></a>
<a>    Color <span class="dt">int</span></a>
<a>}</a>

<a><span class="kw">func</span> (m *VertexStateMessage) Type() <span class="dt">string</span> { <span class="kw">return</span> <span class="st">"vertexStateMessage"</span> }</a></pre></div>
<p>The <kbd>vertexState</kbd> struct keeps track of the token and colors that are assigned to the vertex. Furthermore, the <kbd>usedColors</kbd> map tracks colors that have already been assigned to the vertex neighbors. Vertices broadcast their state to each of their neighbors by exchanging <kbd>VertexStateMessage</kbd> instances. In addition to the token and color value, these messages also include a vertex ID. As we mentioned previously, the vertex ID is required for breaking ties while comparing token values.</p>
<p><span>Now, let's break down the compute function for this algorithm into small chunks and examine each chunk in more detail:</span></p>
<div class="sourceCode">
<pre class="sourceCode go"><a>v.Freeze()</a>
<a>state := v.Value().(*vertexState)</a>

<a><span class="kw">if</span> g.Superstep() == <span class="dv">0</span> {</a>
<a>    <span class="kw">if</span> state.color == <span class="dv">0</span> &amp;&amp; <span class="bu">len</span>(v.Edges()) == <span class="dv">0</span> {</a>
<a>        state.color = <span class="dv">1</span></a>
<a>        <span class="kw">return</span> <span class="ot">nil</span></a>
<a>    }</a>
<a>    state.token = random.Int()</a>
<a>    state.usedColors = <span class="bu">make</span>(<span class="kw">map</span>[<span class="dt">int</span>]<span class="dt">bool</span>)</a>
<a>    <span class="kw">return</span> g.BroadcastToNeighbors(v, state.asMessage(v.ID()))</a>
<a>}</a></pre></div>
<p class="mce-root"/>
<p>First things first, each super-step iteration begins by marking <em>all</em> the vertices as inactive. This way, vertices will only be reactivated in subsequent super-steps when a neighbor gets to pick a color and broadcast its selection. Consequently, once the last remaining vertex has been colored, no further messages will be exchanged and all the vertices will be marked as inactive. This observation will serve as the termination condition for the algorithm.</p>
<p>Super-step <em>0</em> serves as an initialization step. During this step, we assign random tokens to all the vertices and have them <em>all</em> announce their initial state to their neighbors. If any of the vertices are pre-colored, their assigned colors will also be included in the broadcasted state update message. The <kbd>vertexState</kbd> type defines a handy helper method called <kbd>asMessage</kbd> which generates a <kbd>VertexStateMessage</kbd>, that can be sent to neighbors via the graph's <kbd>BroadcastToNeighbors</kbd> method:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (s *vertexState) asMessage(id <span class="dt">string</span>) *VertexStateMessage {</a>
<a>    <span class="kw">return</span> &amp;VertexStateMessage{</a>
<a>        ID:    id,</a>
<a>        Token: s.token,</a>
<a>        Color: s.color,</a>
<a>    }</a>
<a>}</a></pre></div>
<p>Of course, the input graph may potentially include vertices with no neighbors. If these vertices have not been already pre-colored, we simply assign them the first available color, which in our particular implementation is color <em>1</em>.</p>
<p>The next block of code processes state announcements from the vertex neighbors. Before iterating each state message, each vertex sets its local <kbd>pickNextColor</kbd> variable to <kbd>true</kbd>. Then, the message list is iterated and the following occurs:</p>
<ul>
<li>If a neighbor has been assigned a color, we insert it into the <kbd>usedColors</kbd> map for the local vertex.</li>
<li>If any of the neighbors has a higher token value or has the <em>same</em> token value but their ID string value is greater than the local vertex one, they have a higher priority for picking the next color. Therefore, the <kbd>pickNextColor</kbd> variable will be set to <kbd>false</kbd> for the local vertex.</li>
</ul>
<p>Once all state announcements have been processed, we check the value of the <kbd>pickNextColor</kbd> variable. If the vertex is not allowed to pick the next color, it simply broadcasts its current state and waits for the next super-step, as follows:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a>pickNextColor := <span class="ot">true</span></a>
<a>myID := v.ID()</a>
<a><span class="kw">for</span> msgIt.Next() {</a>
<a>    m := msgIt.Message().(*vertexStateMessage)</a>
<a>    <span class="kw">if</span> m.Color != <span class="dv">0</span> {</a>
<a>        state.usedColors[m.Color] = <span class="ot">true</span></a>
<a>    } <span class="kw">else</span> <span class="kw">if</span> state.token &lt; m.Token || (state.token == m.Token &amp;&amp; myID &lt; m.ID) {</a>
<a>        pickNextColor = <span class="ot">false</span></a>
<a>    }</a>
<a>}</a>

<a><span class="kw">if</span> !pickNextColor {</a>
<a>    <span class="kw">return</span> g.BroadcastToNeighbors(v, state.asMessage(v.ID()))</a>
<a>}</a></pre></div>
<p>Otherwise, the vertex gets to select the next color to be assigned to it:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a>    <span class="kw">for</span> nextColor := <span class="dv">1</span>; ; nextColor++ {</a>
<a>        <span class="kw">if</span> state.usedColors[nextColor] {</a>
<a>            <span class="kw">continue</span></a>
<a>        }</a>

<a>        state.color = nextColor</a>
<a>        <span class="kw">return</span> g.BroadcastToNeighbors(v, state.asMessage(myID))</a>
<a>    }</a></pre></div>
<p>Since some of the vertices in the graph might be pre-colored, our goal is to pick the <em>smallest</em> not used color for this vertex. To do this, we initialize a counter with the smallest allowed value and enter a loop: at each step, we check whether <kbd>usedColors</kbd> contains an entry for the <kbd>nextColor</kbd> value. If so, we increment the counter and try again. Otherwise, we assign <kbd>nextColor</kbd> to the vertex and broadcast our updated state to the neighbors.</p>
<p>In case you are having concerns about the space requirements for keeping track of the used colors on a per-vertex basis, we can actually do much better if we don't need to support potentially pre-colored graphs. If that happens to be the case, each vertex only needs to keep track of the <em>maximum</em> color value that's assigned to its neighbors. At color selection time, the vertex picks <kbd>maxColor + 1</kbd> as its own color.</p>
<p><span>The full source code and tests for the graph coloring implementation from this section can be found in this book's GitHub repository in the</span> <kbd>Chapter08/color</kbd> <span>folder.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Calculating PageRank scores</h1>
                </header>
            
            <article>
                
<p>Whenever someone hears the name Google, the first thing that would probably spring to mind is, of course, the widely popular search engine that made its appearance some time around 1997 and since then has consistently managed to eclipse all other competition in the search engine space.</p>
<p>The heart of Google's search engine technology is undoubtedly the patented PageRank algorithm, which was published in the 1999 paper by the Google co-founders, Larry Page and Sergey Brin <sup><span class="citation">[8]</span></sup>. Fortunately, the patent to the algorithm expired in June 2019; that's a great piece of news as it allows us to freely implement it for the Links 'R' Us project!</p>
<p>The PageRank algorithm treats all indexed web pages as a massive, directed graph. Each page is represented as a vertex in the graph, while outgoing links from each page are represented as directed edges. All the pages in the graph are assigned what is referred to as a <em>PageRank score</em>. PageRank scores express the importance (ranking) of every page compared to all the other pages in the graph. The key premise of this algorithm is that if we were to sort the results of a keyword-based search by <kbd>both</kbd> keyword match relevance and by their PageRank score, we would be able to increase the quality of the results that are returned to the user performing the search.</p>
<p>In the following sections, we will explore the formula for calculating PageRank scores and implement our very own PageRank calculator using the graph processing framework that we developed at the beginning of this chapter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The model of the random surfer</h1>
                </header>
            
            <article>
                
<p>To calculate the score for each vertex in the graph, the PageRank algorithm utilizes the model of the <strong>random surfer</strong>. Under this model, a user performs an initial search and lands on a page from the graph. From that point on, users randomly select one of the following two options:</p>
<ul>
<li>They can click any outgoing link from the current page and navigate to a new page. Users choose this option with a predefined probability that we will be referring to with the term <strong>damping factor</strong>.</li>
<li>Alternatively, they can decide to run a new search query. This decision has the effect of <em>teleporting</em> the user to a random page in the graph.</li>
</ul>
<p>The PageRank algorithm works under the assumption that the preceding steps are repeated in perpetuity. As a result, the model is equivalent to performing a random walk of the web page graph. PageRank score values reflect the <em>probability</em> that a surfer lands on a particular page. By this definition, we expect the following to occur:</p>
<ul>
<li>Each PageRank score should be a value in the <em>[0, 1]</em> range</li>
<li>The sum of all assigned PageRank scores should be exactly equal to 1</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">An iterative approach to PageRank score calculation</h1>
                </header>
            
            <article>
                
<p>To estimate the PageRank score for web page <em>P</em> from the graph, we need to take two factors into account:</p>
<ul>
<li>The number of links leading to <em>P</em></li>
<li>The quality of the pages linking to <em>P</em><span>,</span> as indicated by their own individual PageRank scores</li>
</ul>
<p>If we only took the number of links into account, we would allow malicious users to game the system and artificially boost the score of a particular target page by creating a large number of links pointing at it. One way that this could be achieved would be, for instance, by cross-posting the same link to online forums. On the other hand, if we were to use the PageRank scores of the source pages to <em>weight</em> the incoming link contributions to the target page, pages with just a few incoming links from reputable sources (for example, major news outlets) would get a much better score than pages with a greater number of links but from sources that are not as popular.</p>
<p>To figure out the score of a particular page, we need to be aware of the score of every page linking to it. To make matters even worse, pages might also link <em>back</em> to some or all pages that link to them. This sounds a bit like a chicken and egg problem! So, how does the calculation work? It turns out that we can actually calculate PageRank scores using an iterative algorithm that uses the following formula to calculate the PageRank score for page <em>P</em>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/02e1279c-48f0-482e-a68f-059961edf01f.png" style="width:36.58em;height:4.33em;"/></p>
<p>At step <em>0</em>, all the vertices in the graph are assigned an initial PageRank score of <em>1/N</em><span>,</span> where <em>N</em> is the number of vertices in the graph. For the <em>i<sub>th</sub></em> step, we calculate the PageRank score by taking the weighted sum of two terms:</p>
<ul>
<li>The first term encodes the PageRank score contribution from a random page in the graph due to a teleport operation. According to the random surfer model, users can decide to stop clicking outgoing links from the page they are currently visiting and instead run a new query which lands them on page <em>P</em>. This is equivalent to creating a <em>one-off</em> connection to <em>P.</em> As a result, it transfers <em>1/N</em> units of PageRank to <em>P</em>.</li>
<li>The second term encodes the score contributions for every page in the graph that has an outgoing link to <em>P</em>. In the preceding equation, <em>LT(P)</em> represents the set of pages that link to page <em>P</em>. For each page <em>J</em> in that set, we calculate the PageRank contribution to <em>P</em> by dividing its accumulated PageRank score from step <em>i-1</em> by the number of outgoing links. Essentially, at each step, each and every page <em>evenly distributes</em> its PageRank score to all outgoing links.</li>
</ul>
<p>Since the two terms refer to mutually exclusive events that occur with specific probabilities, we need to weigh each term by its respective probability to make sure that all PageRank scores add up to 1.0. Given that users click outgoing links with a probability equal to the damping factor <em>d</em>, we need to multiply the first term by <em>1-d</em> and the second term by <em>d</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Reaching convergence – when should we stop iterating?</h1>
                </header>
            
            <article>
                
<p>By virtue of the fact that we are using an iterative formula to calculate PageRank scores, the more steps we execute, the more accurate results we will get. This raises an interesting question: how many steps do we need to execute so as to reach a desired level of accuracy for the calculated scores?</p>
<p>To answer this question, we must come up with a suitable metric that will allow us to measure how close we are to reaching convergence. For this purpose, we will be calculating the <strong>sum of absolute differences</strong> (<strong>SAD</strong>) for PageRank scores between two subsequent iterations using the following formula:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/5cccbc92-40e8-42c5-be1b-e9cdbfe37570.png" style="width:19.33em;height:2.58em;"/></p>
<p>The intuition behind this metric is that while the first few iterations will cause significant, in absolute terms, changes to the PageRank scores, as we get closer to convergence, the magnitude of each subsequent change will keep decreasing and become zero as the number of iterations reaches infinity. Obviously, for our particular use case, we need to execute a finite number of steps. Consequently, we have to decide on a suitable threshold value (for example, 10<sup>-3</sup>) and keep iterating until the SAD score drops below the target threshold.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Web graphs in the real world – dealing with dead ends</h1>
                </header>
            
            <article>
                
<p>The preceding formula for calculating PageRank scores assumes that all the pages link to at <em>least</em> one page. In real life, this is not always the case! Let's consider the graph shown in the following diagram. Here, all the vertices are connected to each other with the exception of vertex <strong>D</strong><span>,</span> which has incoming links but no outgoing links. In other words, <strong>D</strong> is a dead end!</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/e434f76d-ba21-47d9-8c53-b2c0e9895099.png" style="width:16.83em;height:9.42em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>Figure 4: </span><span>An example graph where vertex D is a dead end</span></div>
<p>Would the presence of dead ends in the input graph cause problems with our PageRank score calculations? So far, we know that at each iteration of the PageRank algorithm, pages evenly distribute their currently accumulated PageRank score across all outgoing links. In the case of a dead-end scenario like the one shown in the preceding diagram, vertex <strong>D</strong> would keep receiving the PageRank scores from every other vertex in the graph but <em>never</em> distribute its own accumulated score since it has no outgoing links. Therefore, <strong>D</strong> will end up with a relatively high PageRank score while all the other vertices will end up with significantly lower scores.</p>
<p>One strategy for mitigating this issue is to pre-process the graph, identify vertices that are dead ends, and exclude them from our PageRank calculations. However, dead-end elimination is far from a trivial task: the removal of an existing dead end might cause some of the vertices that used to link to it to transform into dead ends that also need to be removed and so on. As a result, implementing this solution and scaling it up to work with large graphs would be quite costly in terms of the required compute power.</p>
<p>A much better alternative, and the one that we will be using for our Go implementation, would be to treat dead ends as having an implicit connection to <em>all</em> <span>the</span> other vertices in the graph. This approach mitigates the problem of skewed scores by distributing the accumulated PageRank scores from each dead end back to all the vertices in the graph.</p>
<p class="mce-root"/>
<p>The naive approach for implementing this strategy using our graph processing system would be to have each dead-end node broadcast a message that would transfer a quantity equal to <em>PR/N</em> to every other vertex in the graph. Obviously, this idea would never scale for large graphs, so we need to come up with something better… What if, instead of following a push-based approach, we switched to a pull-based approach? In fact, this is actually a great use case for leveraging the graph processing system's support for aggregators! Rather than have each vertex with no outgoing links distribute its PageRank to every other vertex in the graph by means of message broadcasting, they can simply add their per-node contribution (the <em>PR/N</em> quantity) into an accumulator. We can then extend the PageRank formula with an extra term to take this <em>residual</em> PageRank into account when performing our calculations:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/3f1dfb27-419a-4447-8a36-ea62f87005c5.png" style="width:41.58em;height:3.83em;"/></p>
<p>In the preceding formula, <kbd>ResPR(i)</kbd> returns the residual PageRank accumulated while executing the <em>i<sub>th</sub></em> step. Given that we treat dead ends as having outgoing links to every other node in the graph and that surfers click outgoing links with a probability equal to the damping factor <em>d</em>, we need to multiply the residual PageRank by the damping factor. This yields the preceding equation, which will form the basis for our PageRank score calculator.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Defining an API for the PageRank calculator</h1>
                </header>
            
            <article>
                
<p>Now, let's discuss how we can implement a PageRank calculator on top of the functionality provided by the graph processing framework we have built. The full source code and tests for the PageRank calculator can be found in this book's GitHub repository in the <kbd>Chapter08/pagerank</kbd> folder.</p>
<p>The <kbd>Calculator</kbd> type is nothing more than a container for a <kbd>bspgraph.Graph</kbd> instance and a bunch of configuration options:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">type</span> Calculator <span class="kw">struct</span> {</a>
<a>    g   *bspgraph.Graph</a>
<a>    cfg Config</a>

<a>    executorFactory bspgraph.ExecutorFactory</a>
<a>}</a></pre></div>
<p>The <kbd>executorFactory</kbd> points to the executor factory that will be used to create new <kbd>Executor</kbd> instances each time we want to execute the PageRank algorithm on a graph. By default, the <kbd>Calculator</kbd> constructor will use <kbd>bspgraph.NewExecutor</kbd> as the factory implementation, but users will be allowed to override it with a <kbd>SetExecutorFactory</kbd> helper method:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (c *Calculator) SetExecutorFactory(factory bspgraph.ExecutorFactory) {</a>
<a>    c.executorFactory = factory</a>
<a>}</a></pre></div>
<p>You might be curious why we allow the user to provide a custom factory for creating graph executors. The benefit of being able to specify a custom factory is that it permits us to intercept, inspect, and modify the <kbd>ExecutorCallbacks</kbd> object <em>before</em> it gets passed to the default factory. In <a href="67abdf43-7d4c-4bff-a17e-b23d0a900759.xhtml">Chapter 12</a>, <em>Building Distributed Graph Processing Systems</em>, we will be leveraging this functionality to build a distributed version of the PageRank calculator. We will do all of this <em>without changing a single line of code</em> in the calculator implementation... Sounds impossible? Keep reading and all will be revealed in due course!</p>
<p>The following is the definition of the <kbd>Config</kbd> type, which encapsulates all the required configuration options for executing the PageRank algorithm:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">type</span> Config <span class="kw">struct</span> {</a>
<a>    <span class="co">// DampingFactor is the probability that a random surfer will click on</span></a>
<a>    <span class="co">// one of the outgoing links on the page they are currently visiting</span></a>
<a>    <span class="co">// instead of visiting (teleporting to) a random page in the graph.</span></a>
<a>    DampingFactor <span class="dt">float64</span></a>

<a>    <span class="co">// The algorithm will keep executing until the aggregated SAD for all</span></a>
<a>    <span class="co">// vertices becomes less than MinSADForConvergence.</span></a>
<a>    MinSADForConvergence <span class="dt">float64</span></a>

<a>    <span class="co">// The number of workers to spin up for computing PageRank scores.</span></a>
<a>    ComputeWorkers <span class="dt">int</span></a>
<a>}</a></pre></div>
<p>The <kbd>validate</kbd> method, which is defined on the <kbd>Config</kbd> type, checks the validity of each configuration parameter and populates empty parameters with a sane default value:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (c *Config) validate() <span class="dt">error</span> {</a>
<a>    <span class="kw">var</span> err <span class="dt">error</span></a>
<a>    <span class="kw">if</span> c.DampingFactor &lt; <span class="dv">0</span> || c.DampingFactor &gt; <span class="dv">1</span><span class="fl">.0</span> {</a>
<a>        err = multierror.Append(err, xerrors.New(<span class="st">"DampingFactor must be in the range (0, 1]"</span>))</a>
<a>    } <span class="kw">else</span> <span class="kw">if</span> c.DampingFactor == <span class="dv">0</span> {</a>
<a>        c.DampingFactor = <span class="dv">0</span><span class="fl">.85</span></a>
<a>    }</a>
<a>    <span class="kw">if</span> c.MinSADForConvergence &lt; <span class="dv">0</span> || c.MinSADForConvergence &gt;= <span class="dv">1</span><span class="fl">.0</span> {</a>
<a>        err = multierror.Append(err, xerrors.New(<span class="st">"MinSADForConvergence must be in the range (0, 1)"</span>))</a>
<a>    } <span class="kw">else</span> <span class="kw">if</span> c.MinSADForConvergence == <span class="dv">0</span> {</a>
<a>        c.MinSADForConvergence = <span class="dv">0</span><span class="fl">.001</span></a>
<a>    }</a>
<a>    <span class="kw">if</span> c.ComputeWorkers &lt;= <span class="dv">0</span> {</a>
<a>        c.ComputeWorkers = <span class="dv">1</span></a>
<a>    }</a>
<a>    <span class="kw">if</span> c.ExecutorFactory == <span class="ot">nil</span> {</a>
<a>        c.ExecutorFactory = bspgraph.DefaultExecutor</a>
<a>    }</a>
<a>    <span class="kw">return</span> err</a>
<a>}</a></pre></div>
<p>To create new <kbd>Calculator</kbd> instances, the clients populate a <kbd>Config</kbd> object that invokes the <kbd>NewCalculator</kbd> constructor:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> NewCalculator(cfg Config) (*Calculator, <span class="dt">error</span>) {</a>
<a>    <span class="kw">if</span> err := cfg.validate(); err != <span class="ot">nil</span> {</a>
<a>        <span class="kw">return</span> <span class="ot">nil</span>, xerrors.Errorf(<span class="st">"PageRank calculator config validation failed: %w"</span>, err)</a>
<a>    }</a>

<a>    g, err := bspgraph.NewGraph(bspgraph.GraphConfig{</a>
<a>        ComputeWorkers: cfg.ComputeWorkers,</a>
<a>        ComputeFn:      makeComputeFunc(cfg.DampingFactor),</a>
<a>    })</a>
<a>    <span class="kw">if</span> err != <span class="ot">nil</span> {</a>
<a>        <span class="kw">return</span> <span class="ot">nil</span>, err</a>
<a>    }</a>

<a>    <span class="kw">return</span> &amp;Calculator{cfg: cfg, g: g, executorFactory: bspgraph.NewExecutor}, <span class="ot">nil</span></a>
<a>}</a></pre></div>
<p>Before proceeding any further, the constructor has to validate the provided set of configuration options. After the configuration object has been successfully validated, the next step is to create a new <kbd>bspgraph.Graph</kbd> instance and store it in a newly allocated <kbd>Calculator</kbd> instance. To instantiate the graph, we need to provide a compute function that is parameterized by the provided <kbd>DampingFactor</kbd> value. This is achieved with the help of the <kbd>makeComputeFunc</kbd> helper, which closes over the <kbd>dampingFactor</kbd> argument and makes it accessible by the returned closure:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> makeComputeFunc(dampingFactor <span class="dt">float64</span>) bspgraph.ComputeFunc {</a>
<a>    <span class="kw">return</span> <span class="kw">func</span>(g *bspgraph.Graph, v *bspgraph.Vertex, msgIt message.Iterator) <span class="dt">error</span> {</a>
<a>         <span class="co">// ....</span></a>
<a>    }</a>
<a>}</a></pre></div>
<p>Since the underlying <kbd>bspgraph.Graph</kbd> instance is encapsulated in the <kbd>Calculator</kbd> type, we also need to provide a set of convenience methods so that we can add vertices or edges to the graph and access the raw <kbd>bspgraph.Graph</kbd> instance:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (c *Calculator) AddVertex(id <span class="dt">string</span>) {</a>
<a>    c.g.AddVertex(id, <span class="dv">0</span><span class="fl">.0</span>)</a>
<a>}</a>

<a><span class="kw">func</span> (c *Calculator) AddEdge(src, dst <span class="dt">string</span>) <span class="dt">error</span> {</a>
<a>    <span class="co">// Don't allow self-links</span></a>
<a>    <span class="kw">if</span> src == dst {</a>
<a>        <span class="kw">return</span> <span class="ot">nil</span></a>
<a>    }</a>
<a>    <span class="kw">return</span> c.g.AddEdge(src, dst, <span class="ot">nil</span>)</a>
<a>}</a>

<a><span class="kw">func</span> (c *Calculator) Graph() *bspgraph.Graph {</a>
<a>    <span class="kw">return</span> c.g</a>
<a>}</a></pre></div>
<p>Of course, once the PageRank algorithm converges, users should be able to query the PageRank scores that have been assigned to each vertex in the graph. This is facilitated via a call to the <kbd>Scores</kbd> method. The method implementation invokes a user-defined visitor function for each vertex in the graph with the vertex ID and assigned PageRank score as arguments:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (c *Calculator) Scores(visitFn <span class="kw">func</span>(id <span class="dt">string</span>, score <span class="dt">float64</span>) <span class="dt">error</span>) <span class="dt">error</span> {</a>
<a>    <span class="kw">for</span> id, v := <span class="kw">range</span> c.g.Vertices() {</a>
<a>        <span class="kw">if</span> err := visitFn(id, v.Value().(<span class="dt">float64</span>)); err != <span class="ot">nil</span> {</a>
<a>            <span class="kw">return</span> err</a>
<a>        }</a>
<a>    }</a>

<a>    <span class="kw">return</span> <span class="ot">nil</span></a>
<a>}</a></pre></div>
<p class="mce-root"/>
<p>After creating a new <kbd>Calculator</kbd> instance and specifying the graph layout via calls to <kbd>AddVertex</kbd> and <kbd>AddEdge</kbd><span>,</span> we are ready to execute the PageRank algorithm. To do so, we need to obtain a <kbd>bspgraph.Executor</kbd> instance by invoking the calculator's <kbd>Executor</kbd> method:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (c *Calculator) Executor() bspgraph.Executor {</a>
<a>    c.registerAggregators()</a>
<a>    cb := bspgraph.ExecutorCallbacks{</a>
<a>        PreStep: <span class="kw">func</span>(_ context.Context, g *bspgraph.Graph) <span class="dt">error</span> {</a>
<a>            <span class="co">// Reset sum of abs differences and residual aggregators for next step.</span></a>
<a>            g.Aggregator(<span class="st">"SAD"</span>).Set(<span class="dv">0</span><span class="fl">.0</span>)</a>
<a>            g.Aggregator(residualOutputAccumName(g.Superstep())).Set(<span class="dv">0</span><span class="fl">.0</span>)</a>
<a>            <span class="kw">return</span> <span class="ot">nil</span></a>
<a>        },</a>
<a>        PostStepKeepRunning: <span class="kw">func</span>(_ context.Context, g *bspgraph.Graph, _ <span class="dt">int</span>) (<span class="dt">bool, error)</span> {</a>
<a>            <span class="co">// Super-steps 0 and 1 are part of the algorithm initialization; predicate should only be evaluated for super-steps &gt;1</span></a>
<a>            sad := c.g.Aggregator(<span class="st">"SAD"</span>).Get().(<span class="dt">float64</span>)</a>
<a>            <span class="kw">return</span> !(g.Superstep() &gt; <span class="dv">1</span> &amp;&amp; sad &lt; c.cfg.MinSADForConvergence), nil</a>
<a>        },</a>
<a>    }</a>
<a>    <span class="kw">return</span> c.executorFactory(c.g, cb)</a>
<a>}</a></pre></div>
<p>The first task of the <kbd>Executor</kbd> method is to call the <kbd>registerAggregators</kbd> helper. This helper, whose implementation is outlined in the following code, is responsible for registering a set of aggregators that will be used by both the PageRank compute function and the executor callbacks that we will be defining next:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (c *Calculator) registerAggregators() {</a>
<a>    c.g.RegisterAggregator(<span class="st">"page_count"</span>, <span class="bu">new</span>(aggregator.IntAccumulator))</a>
<a>    c.g.RegisterAggregator(<span class="st">"residual_0"</span>, <span class="bu">new</span>(aggregator.Float64Accumulator))</a>
<a>    c.g.RegisterAggregator(<span class="st">"residual_1"</span>, <span class="bu">new</span>(aggregator.Float64Accumulator))</a>
<a>    c.g.RegisterAggregator(<span class="st">"SAD"</span>, <span class="bu">new</span>(aggregator.Float64Accumulator))</a>
<a>}</a></pre></div>
<p class="mce-root"/>
<p>Let's take a closer look at the role of each of these aggregators:</p>
<ul>
<li><kbd>link_count</kbd> keeps track of the total number of vertices in the graph.</li>
<li><kbd>residual_0</kbd> and <kbd>residual_1</kbd> accumulate the residual PageRank quantities for even and odd super-steps. In case you are wondering, the reason why we need two accumulators is that, while calculating the PageRank scores for the <em>i<sub>th</sub></em> step, we need to add the residual PageRank from the <em>previous</em> step and at the same time accumulate the residual PageRank for the <em>next</em> step. While executing the i<sub>th</sub> step, the compute function will read from the accumulator at index <kbd>i%2</kbd> and write to the accumulator at index <kbd>(i+1)%2</kbd>.</li>
<li><kbd>SAD</kbd> is yet another accumulator that tracks the sum of absolute PageRank score differences between two sequential super-steps. The algorithm will keep executing while the accumulator's value is greater than the <kbd>MinSADForConvergence</kbd> configuration option.</li>
</ul>
<p>The second responsibility of the <kbd>Executor</kbd> method is to define the appropriate set of callbacks for executing the PageRank algorithm and invoke the configured <kbd>ExecutorFactory</kbd> to obtain a new <kbd>bspgraph.Executor</kbd> instance, which is then returned to the caller.</p>
<p>The <kbd>PreStep</kbd> callback ensures that each of the required accumulators is set to a zero value prior to executing a new step. The handy <kbd>residualOutputAccName</kbd> helper function returns the name of the accumulator that will store the residual PageRank score to be used as input by the <em>next</em> super-step, as shown here:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> residualOutputAccName(superstep <span class="dt">int</span>) <span class="dt">string</span> {</a>
<a>    <span class="kw">if</span> superstep%<span class="dv">2</span> == <span class="dv">0</span> {</a>
<a>        <span class="kw">return</span> <span class="st">"residual_0"</span></a>
<a>    }</a>
<a>    <span class="kw">return</span> <span class="st">"residual_1"</span></a>
<a>}</a></pre></div>
<p>Once the executor successfully runs the compute function for each vertex in the graph, it invokes the <kbd>PreStepKeepRunning</kbd> callback, whose purpose is to decide whether a new super-step needs to be executed. The registered callback looks up the <kbd>SAD</kbd> aggregator's value, compares it to the configured threshold, and terminates the algorithm's execution once the value becomes less than the threshold.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementing a compute function to calculate PageRank scores</h1>
                </header>
            
            <article>
                
<p>Now that we have completed our brief tour of the <kbd>Calculator</kbd> API, it's time to shift our focus to the most important part of the implementation: the <em>compute function</em>.</p>
<p>At the end of each super-step, vertices are expected to evenly distribute their PageRank score to their neighbors. Under our graph processing model, this task is facilitated by broadcasting a message. The <kbd>IncomingScoreMessage</kbd> type describes the payload for the exchanged messages:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">type</span> IncomingScoreMessage <span class="kw">struct</span> {</a>
<a>    Score <span class="dt">float64</span></a>
<a>}</a>

<a><span class="kw">func</span> (pr IncomingScoreMessage) Type() <span class="dt">string</span> { <span class="kw">return</span> <span class="st">"score"</span> }</a></pre></div>
<p>To bootstrap the calculator, we need to set the initial PageRank score for every vertex in the graph to the value <em>1/N</em><span>,</span> where <em>N</em> is the number of vertices (pages) in the graph. An easy way to calculate <em>N</em> is to simply access the graph and count the number of vertices (for example, <kbd>len(g.Vertices())</kbd>). However, keep in mind that the end goal is to run the algorithm in a distributed fashion. In distributed mode, each worker node would only have access to a <em>subset</em> of the graph vertices. As a result, simply counting the vertices in the <em>local</em> graph instance would not produce a correct result.</p>
<p>On the other hand, aggregators provide an elegant solution to our vertex counting problem that works for both single- and multi-node scenarios. Super-step <em>0</em> serves as our initialization step: every compute function invocation increments the value of the <kbd>page_count</kbd> aggregator. At the end of the super-step, the counter will contain the total number of vertices in the graph:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a>superstep := g.Superstep()</a>
<a>pageCountAgg := g.Aggregator(<span class="st">"page_count"</span>)</a>

<a><span class="kw">if</span> superstep == <span class="dv">0</span> {</a>
<a>    pageCountAgg.Aggregate(<span class="dv">1</span>)</a>
<a>    <span class="kw">return</span> <span class="ot">nil</span></a>
<a>}</a></pre></div>
<p>For every other super-step, we apply the PageRank formula to estimate the new PageRank score for the current vertex:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a>pageCount := <span class="dt">float64</span>(pageCountAgg.Get().(<span class="dt">int</span>))</a>
<a><span class="kw">var</span> newScore  <span class="dt">float64</span></a>
<a><span class="kw">switch</span> superstep {</a>
<a><span class="kw">case</span> <span class="dv">1</span>:</a>
<a>    newScore = <span class="dv">1</span><span class="fl">.0</span> / pageCount</a>
<a><span class="kw">default</span>:</a>
<a>    <span class="co">// Process incoming messages and calculate new score.</span></a>
<a>    dampingFactor := c.cfg.DampingFactor</a>
<a>    newScore = (<span class="dv">1</span><span class="fl">.0</span> - dampingFactor) / pageCount</a>
<a>    <span class="kw">for</span> msgIt.Next() {</a>
<a>        score := msgIt.Message().(IncomingScoreMessage).Score</a>
<a>        newScore += dampingFactor * score</a>
<a>    }</a>
<a>    <span class="co">// Add accumulated residual page rank from any dead-ends encountered during the previous step.</span></a>
<a>    resAggr := g.Aggregator(residualInputAccName(superstep))</a>
<a>    newScore += dampingFactor * resAggr.Get().(<span class="dt">float64</span>)</a>
<a>}</a></pre></div>
<p>Before storing the new PageRank estimate for the current vertex, we calculate the absolute difference from the previous value and add it to the <kbd>SAD</kbd> aggregator, whose role is to track the <em>sum</em> of absolute score differences for the current super-step:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a>absDelta := math.Abs(v.Value().(<span class="dt">float64</span>) - newScore)</a>
<a>g.Aggregator(<span class="st">"SAD"</span>).Aggregate(absDelta)</a>

<a>v.SetValue(newScore)</a></pre></div>
<p>If the vertex has no neighbors (that is, it is a dead end), our model assumes that it is <em>implicitly</em> connected to every other node in the graph. To ensure that the PageRank score for the vertex is evenly distributed to every other vertex in the graph, we add a quantity equal to <kbd>newScore</kbd>/<kbd>pageCount</kbd> to the residual PageRank aggregator that will be used as input in the following super-step. Otherwise, we need to evenly distribute the calculated PageRank score to the existing vertex neighbors. To achieve this, we send out a series of <kbd>IncomingScore</kbd> messages that contribute a quantity equal to <kbd>newScore</kbd>/<kbd>numOutLinks</kbd> to every neighbor at the next super-step:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="co">// Check if this is a dead-end</span></a>
<a>numOutLinks := <span class="dt">float64</span>(<span class="bu">len</span>(v.Edges()))</a>
<a><span class="kw">if</span> numOutLinks == <span class="dv">0</span><span class="fl">.0</span> {</a>
<a>    g.Aggregator(residualOutputAccName(superstep)).Aggregate(newScore / pageCount)</a>
<a>    <span class="kw">return</span> <span class="ot">nil</span></a>
<a>}</a>

<a><span class="co">// Otherwise, evenly distribute this node's score to all its neighbors.</span></a>
<a><span class="kw">return</span> g.BroadcastToNeighbors(v, IncomingScoreMessage{newScore / numOutLinks})</a></pre></div>
<p class="mce-root"/>
<p>That's basically it! The graph processing system we have developed made it quite easy to construct a fully functioning and vertically scalable PageRank calculator that can properly handle dead ends. All that remains is to hook it up to the link graph and text indexer components that we created in <a href="ce489d62-aaa3-4fbb-b239-c9de3daa9a8f.xhtml">Chapter 6</a>, <em>Building a Persistence Layer</em>, and we are in business!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>We began this chapter by presenting the BSP model for building systems that can support out-of-core processing for massive datasets. Then, we applied the key principles of the BSP model so that we could create our own graph processing system that can execute user-defined compute functions for every vertex in the graph in parallel while taking advantage of all the available CPU cores.</p>
<p>In the second half of this chapter, we explored a variety of graph-related problems and came up with parallel algorithms that can be efficiently executed against graphs of any size. In the last part of this chapter, we described the theory behind Google's PageRank algorithm and outlined the formulas for calculating PageRank scores in an iterative way. We leveraged the graph processing system to build a fully-fledged PageRank calculator that will form the basis for implementing the PageRank component for the Links 'R' Us project.</p>
<p>As we are getting closer and closer to completing the required components for our project, we need to plan ahead and design some APIs so that our components can exchange information between them. This is the main focus of the next chapter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Further reading</h1>
                </header>
            
            <article>
                
<ol>
<li>Apache Giraph: An iterative graph processing system built for high scalability. URL: <a href="https://giraph.apache.org/">https://giraph.apache.org/</a>.</li>
<li><span class="smallcaps">Chaitin, G. J.</span>: <em>Register Allocation &amp; Spilling via Graph Coloring.</em> In: Proceedings of the 1982 SIGPLAN Symposium on Compiler Construction, SIGPLAN '82. New York, NY, USA : ACM, 1982 — ISBN <a href="https://worldcat.org/isbn/0-89791-074-5">0-89791-074-5</a>, S. 98–105.</li>
<li><span class="smallcaps">Floyd, Robert W.</span>: <em>Algorithm 97: Shortest Path.</em> In: Commun. ACM Bd. 5. New York, NY, USA, ACM (1962), Nr. 6, S. 345</li>
<li>GPS: A graph processing system. URL: <a href="http://infolab.stanford.edu/gps">http://infolab.stanford.edu/gps</a>.</li>
</ol>
<ol start="5">
<li><span class="smallcaps">Hart, P. E.</span> ; <span class="smallcaps">Nilsson, N. J.</span> ; <span class="smallcaps">Raphael, B.</span>: <em>A Formal Basis for the Heuristic Determination of Minimum Cost Paths.</em> In: IEEE Transactions on Systems Science and Cybernetics Bd. 4 (1968), Nr. 2, S. 100–107.</li>
<li><span class="smallcaps">Jones, Mark T.</span> ; <span class="smallcaps">Plassmann, Paul E.</span>: <em>A Parallel Graph Coloring Heuristic.</em> In: SIAM J. Sci. Comput. Bd. 14. Philadelphia, PA, USA, Society for Industrial; Applied Mathematics (1993), Nr. 3, S. 654–669.</li>
<li><span class="smallcaps">Malewicz, Grzegorz</span> ; <span class="smallcaps">Austern, Matthew H.</span> ; <span class="smallcaps">Bik, Aart J. C</span> ; <span class="smallcaps">Dehnert, James C.</span> ; <span class="smallcaps">Horn, Ilan</span> ; <span class="smallcaps">Leiser, Naty</span> ; <span class="smallcaps">Czajkowski, Grzegorz</span>: Pregel: <em>A System for Large-scale Graph Processing.</em> In: Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data, SIGMOD '10. New York, NY, USA : ACM, 2010 — ISBN <a href="https://worldcat.org/isbn/978-1-4503-0032-2">978-1-4503-0032-2</a>, S. 135–146.</li>
<li><span class="smallcaps">Page, Lawrence</span> ; <span class="smallcaps">Brin, Sergey</span> ; <span class="smallcaps">Motwani, Rajeev</span> ; <span class="smallcaps">Winograd, Terry</span>: <em>The PageRank Citation Ranking: Bringing Order to the Web.</em>(Technical Report Nr. 1999-66) : Stanford InfoLab; Stanford InfoLab, 1999. <span>–</span> Previous number = SIDL-WP-1999-0120.</li>
<li><span class="smallcaps">Park, Taehoon</span> ; <span class="smallcaps">Lee, Chae Y.</span>: <em>Application of the graph coloring algorithm to the frequency assignment problem.</em> In: Journal of the Operations Research Society of Japan Bd. 39 (1996), Nr. 2, S. 258–265.</li>
<li><span class="smallcaps">Valiant, Leslie G.</span>: <em>A Bridging Model for Parallel Computation.</em> In: Commun. ACM Bd. 33. New York, NY, USA, ACM (1990), Nr. 8, S. 103–111.</li>
</ol>


            </article>

            
        </section>
    </body></html>