["```go\ntype Message interface {\n // Type returns the type of this Message.\n Type() string\n}\n```", "```go\ntype Queue interface {\n // Cleanly shutdown the queue.\n Close() error\n\n // Enqueue inserts a message to the end of the queue.\n Enqueue(msg Message) error\n\n // PendingMessages returns true if the queue contains any messages.\n PendingMessages() bool\n\n // Flush drops all pending messages from the queue.\n DiscardMessages() error\n\n // Messages returns an iterator for accessing the queued messages.\n Messages() Iterator\n}\n```", "```go\ntype Iterator interface {\n // Next advances the iterator so that the next message can be retrieved\n // via a call to Message(). If no more messages are available or an\n // error occurs, Next() returns false.\n Next() bool\n\n // Message returns the message currently pointed to by the iterator.\n Message() Message\n\n // Error returns the last error that the iterator encountered.\n Error() error\n}\n```", "```go\ntype inMemoryQueue struct {\n mu   sync.Mutex\n msgs []Message\n\n latchedMsg Message\n}\n\nfunc NewInMemoryQueue() Queue {\n return new(inMemoryQueue)\n}\n```", "```go\nfunc (q *inMemoryQueue) Enqueue(msg Message) error {\n q.mu.Lock()\n q.msgs = append(q.msgs, msg)\n q.mu.Unlock()\n return nil\n}\n\nfunc (q *inMemoryQueue) PendingMessages() bool {\n q.mu.Lock()\n pending := len(q.msgs) != 0\n q.mu.Unlock()\n return pending\n}\n```", "```go\nfunc (q *inMemoryQueue) DiscardMessages() error {\n q.mu.Lock()\n q.msgs = q.msgs[:0]\n q.mu.Unlock()\n return nil\n}\n\nfunc (*inMemoryQueue) Close() error { return nil }\n\nfunc (q *inMemoryQueue) Messages() Iterator { return q }\n```", "```go\nfunc (q *inMemoryQueue) Next() bool {\n q.mu.Lock()\n qLen := len(q.msgs)\n if qLen == 0 {\n q.mu.Unlock()\n return false\n }\n q.latchedMsg = q.msgs[qLen-1] // Dequeue message from the tail of the queue.\n q.msgs = q.msgs[:qLen-1]\n q.mu.Unlock()\n return true\n}\n\nfunc (q *inMemoryQueue) Message() Message {\n q.mu.Lock()\n msg := q.latchedMsg\n q.mu.Unlock()\n return msg\n}\n```", "```go\ntype Vertex struct {\n id       string\n value    interface{}\n active   bool\n msgQueue [2]message.Queue\n edges    []*Edge\n}\n```", "```go\nfunc (v *Vertex) ID() string { return v.id }\n\nfunc (v *Vertex) Value() interface{} { return v.value }\n\nfunc (v *Vertex) SetValue(val interface{}) { v.value = val } func (v *Vertex) Freeze() { v.active = false } func (v *Vertex) Edges() []*Edge { return v.edges } \n```", "```go\ntype Edge struct {\n value interface{}\n dstID string\n}\n\nfunc (e *Edge) DstID() string { return e.dstID }\n\nfunc (e *Edge) Value() interface{} { return e.value }\n\nfunc (e *Edge) SetValue(val interface{}) { e.value = val }\n```", "```go\nfunc (g *Graph) AddVertex(id string, initValue interface{}) {\n v := g.vertices[id]\n if v == nil {\n v = &Vertex{\n id: id,\n msgQueue: [2]message.Queue{\n g.queueFactory(),\n g.queueFactory(),\n },\n active: true,\n }\n g.vertices[id] = v\n }\n v.SetValue(initValue)\n}\n```", "```go\nfunc (g *Graph) AddEdge(srcID, dstID string, initValue interface{}) error {\n srcVert := g.vertices[srcID]\n if srcVert == nil {\n return xerrors.Errorf(\"create edge from %q to %q: %w\", srcID, dstID, ErrUnknownEdgeSource)\n }\n\n srcVert.edges = append(srcVert.edges, &Edge{\n dstID: dstID,\n value: initValue,\n })\n return nil\n}\n```", "```go\ntype Aggregator interface {\n // Type returns the type of this aggregator.\n Type() string\n\n // Set the aggregator to the specified value.\n Set(val interface{})\n\n // Get the current aggregator value.\n Get() interface{}\n\n // Aggregate updates the aggregator's value based on the provided \n    // value.\n Aggregate(val interface{})\n\n // Delta returns the change in the aggregator's value since the last \n    // call to Delta. \n Delta() interface{}\n}\n```", "```go\nfunc (g *Graph) RegisterAggregator(name string, aggr Aggregator) { \n g.aggregators[name] = aggr \n}\n```", "```go\nfunc (g *Graph) Aggregator(name string) Aggregator { \n return g.aggregators[name] \n}\n```", "```go\ntype Float64Accumulator struct {\n prevSum float64\n curSum  float64\n}\n```", "```go\nfunc (a *Float64Accumulator) Get() interface{} {\n return loadFloat64(&a.curSum)\n}\n\nfunc loadFloat64(v *float64) float64 {\n return math.Float64frombits(\n atomic.LoadUint64((*uint64)(unsafe.Pointer(v))),\n )\n}\n```", "```go\nfunc (a *Float64Accumulator) Aggregate(v interface{}) {\n for v64 := v.(float64); ; {\n oldV := loadFloat64(&a.curSum)\n newV := oldV + v64\n if atomic.CompareAndSwapUint64(\n (*uint64)(unsafe.Pointer(&a.curSum)),\n math.Float64bits(oldV),\n math.Float64bits(newV),\n ) {\n return\n }\n }\n}\n```", "```go\nfunc (a *Float64Accumulator) Delta() interface{} {\n for {\n curSum := loadFloat64(&a.curSum)\n prevSum := loadFloat64(&a.prevSum)\n if atomic.CompareAndSwapUint64(\n (*uint64)(unsafe.Pointer(&a.prevSum)),\n math.Float64bits(prevSum),\n math.Float64bits(curSum),\n ) {\n return curSum - prevSum\n }\n }\n}\n```", "```go\nfunc (a *Float64Accumulator) Set(v interface{}) {\n for v64 := v.(float64); ; {\n oldCur := loadFloat64(&a.curSum)\n oldPrev := loadFloat64(&a.prevSum)\n swappedCur := atomic.CompareAndSwapUint64(\n (*uint64)(unsafe.Pointer(&a.curSum)),\n math.Float64bits(oldCur),\n math.Float64bits(v64),\n )\n swappedPrev := atomic.CompareAndSwapUint64(\n (*uint64)(unsafe.Pointer(&a.prevSum)),\n math.Float64bits(oldPrev),\n math.Float64bits(v64),\n )\n if swappedCur && swappedPrev {\n return\n }\n }\n}\n```", "```go\nfunc (g *Graph) BroadcastToNeighbors(v *Vertex, msg message.Message) error {\n for _, e := range v.edges {\n if err := g.SendMessage(e.dstID, msg); err != nil {\n return err\n }\n }\n\n return nil\n}\n```", "```go\nfunc (g *Graph) SendMessage(dstID string, msg message.Message) error {\n dstVert := g.vertices[dstID]\n if dstVert != nil {\n queueIndex := (g.superstep + 1) % 2\n return dstVert.msgQueue[queueIndex].Enqueue(msg)\n }\n\n if g.relayer != nil {\n if err := g.relayer.Relay(dstID, msg); !xerrors.Is(err, ErrDestinationIsLocal) {\n return err\n }\n }\n\n return xerrors.Errorf(\"message cannot be delivered to %q: %w\", dstID, ErrInvalidMessageDestination)\n}\n```", "```go\ntype Relayer interface {\n // Relay a message to a vertex that is not known locally. Calls\n // to Relay must return ErrDestinationIsLocal if the provided dst value\n // is not a valid remote destination.\n Relay(dst string, msg message.Message) error\n}\n\nfunc (g *Graph) RegisterRelayer(relayer Relayer) { \n g.relayer = relayer \n}\n```", "```go\ntype RelayerFunc func(string, message.Message) error\n\n// Relay calls f(dst, msg).\nfunc (f RelayerFunc) Relay(dst string, msg message.Message) error {\n return f(dst, msg)\n}\n```", "```go\ntype ComputeFunc func(g *Graph, v *Vertex, msgIt message.Iterator) error\n```", "```go\nfunc (g *Graph) startWorkers(numWorkers int) {\n g.vertexCh = make(chan *Vertex)\n g.errCh = make(chan error, 1)\n g.stepCompletedCh = make(chan struct{})\n\n g.wg.Add(numWorkers)\n for i := 0; i < numWorkers; i++ {\n go g.stepWorker()\n }\n}\n```", "```go\nfunc (g *Graph) step() (activeInStep int, err error) {\n g.activeInStep, g.pendingInStep = 0, int64(len(g.vertices))\n if g.pendingInStep == 0 {\n return 0, nil // no work required\n }\n for _, v := range g.vertices {\n g.vertexCh <- v\n }\n <-g.stepCompletedCh\n\n select {\n case err = <-g.errCh: // dequeued\n default: // no error available\n }\n return int(g.activeInStep), err\n}\n```", "```go\nfor v := range g.vertexCh {\n buffer := g.superstep % 2\n if v.active || v.msgQueue[buffer].PendingMessages() {\n _ = atomic.AddInt64(&g.activeInStep, 1)\n v.active = true\n if err := g.computeFn(g, v, v.msgQueue[buffer].Messages()); err != nil {\n tryEmitError(g.errCh, xerrors.Errorf(\"running compute function for vertex %q failed: %w\", v.ID(), err))\n } else if err := v.msgQueue[buffer].DiscardMessages(); err != nil {\n tryEmitError(g.errCh, xerrors.Errorf(\"discarding unprocessed messages for vertex %q failed: %w\", v.ID(), err))\n }\n }\n if atomic.AddInt64(&g.pendingInStep, -1) == 0 {\n g.stepCompletedCh <- struct{}{}\n }\n}\ng.wg.Done()\n```", "```go\nfunc tryEmitError(errCh chan<- error, err error) {\n select {\n case errCh <- err: // queued error\n default: // channel already contains another error\n }\n}\n```", "```go\ntype Executor struct {\n g  *Graph\n cb ExecutorCallbacks\n}\n```", "```go\ntype ExecutorCallbacks struct {\n PreStep func(ctx context.Context, g *Graph) error\n PostStep func(ctx context.Context, g *Graph, activeInStep int) error\n PostStepKeepRunning func(ctx context.Context, g *Graph, activeInStep int) (bool, error)\n}\n```", "```go\nfunc NewExecutor(g *Graph, cb ExecutorCallbacks) *Executor {\n patchEmptyCallbacks(&cb)\n g.superstep = 0\n return &Executor{\n g:              g,\n cb:             cb,\n }\n}\n```", "```go\nfunc patchEmptyCallbacks(cb *ExecutorCallbacks) {\n if cb.PreStep == nil {\n cb.PreStep = func(context.Context, *Graph) error { return nil }\n }\n if cb.PostStep == nil {\n cb.PostStep = func(context.Context, *Graph, int) error { return nil }\n }\n if cb.PostStepKeepRunning == nil {\n cb.PostStepKeepRunning = func(context.Context, *Graph, int) (bool, error) { return true, nil }\n }\n}\n```", "```go\nfunc (ex *Executor) Graph() *Graph { return ex.g }\n\nfunc (ex *Executor) Superstep() int { return ex.g.Superstep() }\n\nfunc (ex *Executor) RunSteps(ctx context.Context, numSteps int) error {\n return ex.run(ctx, numSteps)\n}\n\nfunc (ex *Executor) RunToCompletion(ctx context.Context) error {\n return ex.run(ctx, -1)\n}\n```", "```go\nfunc (ex *Executor) run(ctx context.Context, maxSteps int) error {\n var activeInStep int\n var err          error\n var keepRunning  bool\n var cb           = ex.cb\n for ; maxSteps != 0; ex.g.superstep, maxSteps = ex.g.superstep+1, maxSteps-1 {\n if err = ensureContextNotExpired(ctx); err != nil {\n break\n } else if err = cb.PreStep(ctx, ex.g); err != nil {\n break\n } else if activeInStep, err = ex.g.step(); err != nil {\n break\n } else if err = cb.PostStep(ctx, ex.g, activeInStep); err != nil {\n break\n } else if keepRunning, err = cb.PostStepKeepRunning(ctx, ex.g, activeInStep); !keepRunning || err != nil {\n break\n }\n }\n return err\n}\n```", "```go\ntype GraphConfig struct {\n QueueFactory message.QueueFactory\n ComputeFn ComputeFunc\n ComputeWorkers int\n}\n```", "```go\nfunc (g *GraphConfig) validate() error {\n var err error\n if g.QueueFactory == nil {\n g.QueueFactory = message.NewInMemoryQueue\n }\n if g.ComputeWorkers <= 0 {\n g.ComputeWorkers = 1\n }\n\n if g.ComputeFn == nil {\n err = multierror.Append(err, xerrors.New(\"compute function not specified\"))\n }\n\n return err\n}\n```", "```go\nfunc NewGraph(cfg GraphConfig) (*Graph, error) {\n if err := cfg.validate(); err != nil {\n return nil, xerrors.Errorf(\"graph config validation failed: %w\", err)\n }\n\n g := &Graph{\n computeFn:    cfg.ComputeFn,\n queueFactory: cfg.QueueFactory,\n aggregators:  make(map[string]Aggregator),\n vertices:     make(map[string]*Vertex),\n }\n g.startWorkers(cfg.ComputeWorkers)\n\n return g, nil\n}\n```", "```go\nfunc (g *Graph) Reset() error {\n g.superstep = 0\n for _, v := range g.vertices {\n for i := 0; i < 2; i++ {\n if err := v.msgQueue[i].Close(); err != nil {\n return xerrors.Errorf(\"closing message queue #%d for vertex %v: %w\", i, v.ID(), err)\n }\n }\n }\n g.vertices = make(map[string]*Vertex)\n g.aggregators = make(map[string]Aggregator)\n return nil\n}\n```", "```go\nfunc (g *Graph) Close() error {\n close(g.vertexCh)\n g.wg.Wait()\n\n return g.Reset()\n}\n```", "```go\nfunction Dikstra(Graph):\n for each vertex v in Graph:\n min_cost_via[v] = infinity\n prev[v] = nil\n min_cost_via[src] = 0\n\n Q = set of all vertices in graph\n while Q is not empty:\n u = entry from Q with smallest min_cost_via[]\n remove u from Q\n\n for each neighbor v from u:\n cost_via_u = min_cost_via[u] + cost(u, v)\n if cost_via_u < min_cost_via[v]:\n min_cost_via[v] = cost_via_u\n prev[v] = u\n```", "```go\ntype PathCostMessage struct {\n // The ID of the vertex this cost announcement originates from.\n FromID string\n\n // The cost of the path from this vertex to the source vertex via \n    // FromID.\n Cost int\n}\n\nfunc (pc PathCostMessage) Type() string { return \"cost\" }\n\ntype pathState struct {\n minDist    int\n prevInPath string\n}\n```", "```go\nif g.Superstep() == 0 {\n v.SetValue(&pathState{ minDist: int(math.MaxInt64) })\n}\n```", "```go\nminDist := int(math.MaxInt64)\nif v.ID() == c.srcID { // min cost from source to source is always 0\n minDist = 0\n}\nvar via string\nfor msgIt.Next() {\n m := msgIt.Message().(*PathCostMessage)\n if m.Cost < minDist {\n minDist = m.Cost\n via = m.FromID\n }\n}\n```", "```go\nst := v.Value().(*pathState)\nif minDist < st.minDist {\n st.minDist = minDist\n st.prevInPath = via\n for _, e := range v.Edges() {\n costMsg := &PathCostMessage{\n FromID: v.ID(),\n Cost:   minDist + e.Value().(int),\n }\n if err := g.SendMessage(e.DstID(), costMsg); err != nil {\n return err\n }\n }\n}\nv.Freeze()\n```", "```go\nfunction assignColors(Graph):\n C holds the assigned color for each vertex\n for each vertex u in Graph:\n C[u] = 0\n\n for each vertex u in Graph:\n already_in_use is a map where keys indicate colors that are currently in use\n for each neighbor v of u:\n already_in_use[ C[v] ] = true\n\n assigned_color = 1\n while already_in_use[ color ] is true:\n assigned_color = assigned_color + 1\n\n C[u] = assigned_color\n```", "```go\ntype vertexState struct {\n token int\n color int\n usedColors map[int]bool\n}\n\ntype VertexStateMessage struct {\n ID    string\n Token int\n Color int\n}\n\nfunc (m *VertexStateMessage) Type() string { return \"vertexStateMessage\" }\n```", "```go\nv.Freeze()\nstate := v.Value().(*vertexState)\n\nif g.Superstep() == 0 {\n if state.color == 0 && len(v.Edges()) == 0 {\n state.color = 1\n return nil\n }\n state.token = random.Int()\n state.usedColors = make(map[int]bool)\n return g.BroadcastToNeighbors(v, state.asMessage(v.ID()))\n}\n```", "```go\nfunc (s *vertexState) asMessage(id string) *VertexStateMessage {\n return &VertexStateMessage{\n ID:    id,\n Token: s.token,\n Color: s.color,\n }\n}\n```", "```go\npickNextColor := true\nmyID := v.ID()\nfor msgIt.Next() {\n m := msgIt.Message().(*vertexStateMessage)\n if m.Color != 0 {\n state.usedColors[m.Color] = true\n } else if state.token < m.Token || (state.token == m.Token && myID < m.ID) {\n pickNextColor = false\n }\n}\n\nif !pickNextColor {\n return g.BroadcastToNeighbors(v, state.asMessage(v.ID()))\n}\n```", "```go\n for nextColor := 1; ; nextColor++ {\n if state.usedColors[nextColor] {\n continue\n }\n\n state.color = nextColor\n return g.BroadcastToNeighbors(v, state.asMessage(myID))\n }\n```", "```go\ntype Calculator struct {\n g   *bspgraph.Graph\n cfg Config\n\n executorFactory bspgraph.ExecutorFactory\n}\n```", "```go\nfunc (c *Calculator) SetExecutorFactory(factory bspgraph.ExecutorFactory) {\n c.executorFactory = factory\n}\n```", "```go\ntype Config struct {\n // DampingFactor is the probability that a random surfer will click on\n // one of the outgoing links on the page they are currently visiting\n // instead of visiting (teleporting to) a random page in the graph.\n DampingFactor float64\n\n // The algorithm will keep executing until the aggregated SAD for all\n // vertices becomes less than MinSADForConvergence.\n MinSADForConvergence float64\n\n // The number of workers to spin up for computing PageRank scores.\n ComputeWorkers int\n}\n```", "```go\nfunc (c *Config) validate() error {\n var err error\n if c.DampingFactor < 0 || c.DampingFactor > 1.0 {\n err = multierror.Append(err, xerrors.New(\"DampingFactor must be in the range (0, 1]\"))\n } else if c.DampingFactor == 0 {\n c.DampingFactor = 0.85\n }\n if c.MinSADForConvergence < 0 || c.MinSADForConvergence >= 1.0 {\n err = multierror.Append(err, xerrors.New(\"MinSADForConvergence must be in the range (0, 1)\"))\n } else if c.MinSADForConvergence == 0 {\n c.MinSADForConvergence = 0.001\n }\n if c.ComputeWorkers <= 0 {\n c.ComputeWorkers = 1\n }\n if c.ExecutorFactory == nil {\n c.ExecutorFactory = bspgraph.DefaultExecutor\n }\n return err\n}\n```", "```go\nfunc NewCalculator(cfg Config) (*Calculator, error) {\n if err := cfg.validate(); err != nil {\n return nil, xerrors.Errorf(\"PageRank calculator config validation failed: %w\", err)\n }\n\n g, err := bspgraph.NewGraph(bspgraph.GraphConfig{\n ComputeWorkers: cfg.ComputeWorkers,\n ComputeFn:      makeComputeFunc(cfg.DampingFactor),\n })\n if err != nil {\n return nil, err\n }\n\n return &Calculator{cfg: cfg, g: g, executorFactory: bspgraph.NewExecutor}, nil\n}\n```", "```go\nfunc makeComputeFunc(dampingFactor float64) bspgraph.ComputeFunc {\n return func(g *bspgraph.Graph, v *bspgraph.Vertex, msgIt message.Iterator) error {\n // ....\n }\n}\n```", "```go\nfunc (c *Calculator) AddVertex(id string) {\n c.g.AddVertex(id, 0.0)\n}\n\nfunc (c *Calculator) AddEdge(src, dst string) error {\n // Don't allow self-links\n if src == dst {\n return nil\n }\n return c.g.AddEdge(src, dst, nil)\n}\n\nfunc (c *Calculator) Graph() *bspgraph.Graph {\n return c.g\n}\n```", "```go\nfunc (c *Calculator) Scores(visitFn func(id string, score float64) error) error {\n for id, v := range c.g.Vertices() {\n if err := visitFn(id, v.Value().(float64)); err != nil {\n return err\n }\n }\n\n return nil\n}\n```", "```go\nfunc (c *Calculator) Executor() bspgraph.Executor {\n c.registerAggregators()\n cb := bspgraph.ExecutorCallbacks{\n PreStep: func(_ context.Context, g *bspgraph.Graph) error {\n // Reset sum of abs differences and residual aggregators for next step.\n g.Aggregator(\"SAD\").Set(0.0)\n g.Aggregator(residualOutputAccumName(g.Superstep())).Set(0.0)\n return nil\n },\n PostStepKeepRunning: func(_ context.Context, g *bspgraph.Graph, _ int) (bool, error) {\n // Super-steps 0 and 1 are part of the algorithm initialization; predicate should only be evaluated for super-steps >1\n sad := c.g.Aggregator(\"SAD\").Get().(float64)\n return !(g.Superstep() > 1 && sad < c.cfg.MinSADForConvergence), nil\n },\n }\n return c.executorFactory(c.g, cb)\n}\n```", "```go\nfunc (c *Calculator) registerAggregators() {\n c.g.RegisterAggregator(\"page_count\", new(aggregator.IntAccumulator))\n c.g.RegisterAggregator(\"residual_0\", new(aggregator.Float64Accumulator))\n c.g.RegisterAggregator(\"residual_1\", new(aggregator.Float64Accumulator))\n c.g.RegisterAggregator(\"SAD\", new(aggregator.Float64Accumulator))\n}\n```", "```go\nfunc residualOutputAccName(superstep int) string {\n if superstep%2 == 0 {\n return \"residual_0\"\n }\n return \"residual_1\"\n}\n```", "```go\ntype IncomingScoreMessage struct {\n Score float64\n}\n\nfunc (pr IncomingScoreMessage) Type() string { return \"score\" }\n```", "```go\nsuperstep := g.Superstep()\npageCountAgg := g.Aggregator(\"page_count\")\n\nif superstep == 0 {\n pageCountAgg.Aggregate(1)\n return nil\n}\n```", "```go\npageCount := float64(pageCountAgg.Get().(int))\nvar newScore  float64\nswitch superstep {\ncase 1:\n newScore = 1.0 / pageCount\ndefault:\n // Process incoming messages and calculate new score.\n dampingFactor := c.cfg.DampingFactor\n newScore = (1.0 - dampingFactor) / pageCount\n for msgIt.Next() {\n score := msgIt.Message().(IncomingScoreMessage).Score\n newScore += dampingFactor * score\n }\n // Add accumulated residual page rank from any dead-ends encountered during the previous step.\n resAggr := g.Aggregator(residualInputAccName(superstep))\n newScore += dampingFactor * resAggr.Get().(float64)\n}\n```", "```go\nabsDelta := math.Abs(v.Value().(float64) - newScore)\ng.Aggregator(\"SAD\").Aggregate(absDelta)\n\nv.SetValue(newScore)\n```", "```go\n// Check if this is a dead-end\nnumOutLinks := float64(len(v.Edges()))\nif numOutLinks == 0.0 {\n g.Aggregator(residualOutputAccName(superstep)).Aggregate(newScore / pageCount)\n return nil\n}\n\n// Otherwise, evenly distribute this node's score to all its neighbors.\nreturn g.BroadcastToNeighbors(v, IncomingScoreMessage{newScore / numOutLinks})\n```"]