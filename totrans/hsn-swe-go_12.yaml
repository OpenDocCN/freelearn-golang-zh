- en: Communicating with the Outside World
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '"An API that isn''t comprehensible isn''t usable."'
  prefs: []
  type: TYPE_NORMAL
- en: '- James Gosling'
  prefs: []
  type: TYPE_NORMAL
- en: All software systems eventually need to exchange data with the outside world.
    In many cases, this is achieved via an API. This chapter provides a comparison
    between the REST and RPC patterns for building APIs and discusses some common
    API issues such as authentication, versioning, and security. The rest of this
    chapter explores the gRPC ecosystem in depth and concludes with a gRPC-based API
    implementation for the Links 'R' Us project.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Basic principles of RESTful APIs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Strategies for securing APIs and pitfalls that you should avoid
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Approaches for API versioning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: gRPC as an alternative to building high-performance services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Describing messages and RPC services using the protocol buffers definition language
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The different RPC modes (unary, client, server-streaming, and bi-directional
    streaming)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Locking down gRPC APIs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The full code for the topics discussed that will be within this chapter have
    been published to this book's GitHub repository in the `Chapter09` folder.
  prefs: []
  type: TYPE_NORMAL
- en: You can access this book's GitHub repository, which contains the code and all
    the required resources for each of this book's chapters, by pointing your web
    browser to the following URL: [https://github.com/PacktPublishing/Hands-On-Software-Engineering-with-Golang](https://github.com/PacktPublishing/Hands-On-Software-Engineering-with-Golang).
  prefs: []
  type: TYPE_NORMAL
- en: 'To get you up and running as quickly as possible, each example project includes
    a Makefile that defines the following set of targets:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Makefile target** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| deps | Install any required dependencies |'
  prefs: []
  type: TYPE_TB
- en: '| test | Run all tests and report coverage |'
  prefs: []
  type: TYPE_TB
- en: '| lint | Check for lint errors |'
  prefs: []
  type: TYPE_TB
- en: As with all the other chapters in this book, you will need a fairly recent version
    of Go, which you can download at [https://golang.org/dl](https://golang.org/dl).
  prefs: []
  type: TYPE_NORMAL
- en: Designing robust, secure, and backward-compatible REST APIs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Whenever an engineer hears the word API, **REST**, the acronym for **Representational
    State Transfer**, is undoubtedly one of the first words that springs to mind.
    Indeed, the vast majority of online services and applications that people use
    on a daily basis are using a REST API to communicate with the backend servers.
  prefs: []
  type: TYPE_NORMAL
- en: 'The proliferation of what we commonly refer to as RESTful APIs is indeed not
    coincidental. REST, as an architectural style for building applications for the
    web, offers quite a few enticing advantages over alternatives such as the **Simple
    Object Access Protocol** (**SOAP**):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ease of interaction**: A web browser or a command tool such as `curl` is
    all that is required to interact with REST endpoints'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The majority of programming languages ship with built-in support for performing
    HTTP requests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is quite easy to intercept HTTP requests (for example, via a proxy) and provided
    canned responses for testing purposes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By virtue of the fact that RESTful APIs are built on top of HTTP, clients (for
    example, web browsers) can opt to cache large HTTP GET responses locally, query
    the remote server to figure out whether the cached data has become stale, and
    needs to be refreshed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'REST APIs are built around the concept of accessing and mutating resources.
    A resource represents any piece of application data (for example, a product, user,
    order, collection of documents, and so on) that clients can operate on. A typical
    RESTful API exposes a set of endpoints that allow clients to **create**, **read**,
    **update**, and **delete** (**CRUD**) resources of a particular type. Each one
    of these actions maps to an HTTP verb, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: A new resource can be created via a POST request
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Existing resources can be retrieved via a GET request
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Resources can be fully or partially updated via a PUT or PATCH request
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A resource can be deleted via a DELETE request
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While the REST architecture does not dictate the use of a particular data format
    for delivering data to clients, nowadays, JSON has become the de facto standard
    for implementing REST APIs. This can be largely attributed to the fact that it
    is lightweight, human-readable, and easy to compress. Having said that, you can
    still find several organizations out there (banks and payment processing gateways
    are a typical example) that provide RESTful APIs that expect and produce XML payloads.
  prefs: []
  type: TYPE_NORMAL
- en: Using human-readable paths for RESTful resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the key ideas, and something that clients would typically expect when
    dealing with a RESTful API, is that each resource instance can be individually
    addressed via a **Uniform Resource Identi****fier** (**URI**). Since the format
    of URIs plays a significant role in conveying the API's resource model to the
    clients that will be consuming it, software engineers should always strive to
    come up with consistent URI naming schemes when designing new APIs or introducing
    new resource types to existing APIs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following opinionated set of conventions for naming resources can help
    you design APIs that are easier for end users to understand and work with:'
  prefs: []
  type: TYPE_NORMAL
- en: Resource names must always be nouns and never verbs or verb-like expressions.
    Verbs can be used as suffixes to indicate an action to be performed on a particular
    resource. For example, `/basket/checkout` triggers the checkout flow for the current
    user's basket.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As an exception to the previously mentioned guideline, verbs related to CRUD
    operations should not be included as part of the resource URI; they can be inferred
    by the HTTP verb that's used when performing requests. In other words, instead
    of using a URI such as `/users/123/delete` to delete a user, clients should perform
    an HTTP **DELETE** request to `/users/123` instead.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When referring to a specific resource instance by name, a singular noun must
    be used. For instance,` /user/account` returns the account details for the currently
    logged-on user. While it might be tempting to use the singular noun pattern to
    refer to a particular item within a collection (for example, `/user/123`), it
    is recommended to avoid this practice as it tends to create inconsistent paths
    for CRUD operations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A plural noun must be used when referring to a collection of resources or a
    specific resource instance within a collection. For example, `order/123/items` would
    return the list of items in order with ID `123`, while `/users/789` would return
    information about the user with ID `789`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid appending trailing forward slashes (/) to the end of URIs. Doing so does
    not provide any additional information to clients and could lead to confusion;
    that is, is the URI complete or does it lack a portion of its path?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RFC3986 ^([6]) defines URIs as being case-sensitive. Therefore, for consistency purposes,
    it's good practice to stick to lowercase characters for URI paths. What's more,
    the use of hyphens (-) to separate long path segments can oftentimes result in
    paths that are much easier to read. Arguably, `/archived-resource` is much easier
    to read than `/archivedresource`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following table summarizes the combination of HTTP verbs and URI patterns
    for performing CRUD operations against a collection of products. The set of HTTP
    verbs and resource paths for working with a `products` resource are given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **HTTP Verb** | **Path** | **Expects (JSON)** | **Returns (JSON)** | **HTTP
    Status** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| POST | `/products` | A product entry | The new product entry including its
    ID | 200 (success) or 201 (created) | Create a new product |'
  prefs: []
  type: TYPE_TB
- en: '| GET | `/products` | Nothing | An array with product entries | 200 (success)
    | Get a list of products |'
  prefs: []
  type: TYPE_TB
- en: '| GET | `/products/:id` | Nothing | The product with the specified ID | 200
    (success) or 404 (not found) | Get product by ID |'
  prefs: []
  type: TYPE_TB
- en: '| PUT | `/products/:id` | A product entry | The updated product entry | 200
    (success) or 404 (not found) | Update product by ID |'
  prefs: []
  type: TYPE_TB
- en: '| PATCH | `/products/:id` | A partial product entry | The updated product entry
    | 200 (success) or 404 (not found) | Update individual fields for a product by
    ID |'
  prefs: []
  type: TYPE_TB
- en: '| DELETE | `/products/:id` | Nothing | Nothing | 200 (success) or 404 (not
    found) | Delete product by ID |'
  prefs: []
  type: TYPE_TB
- en: As you can probably surmise, the aforementioned patterns can also be applied
    to address resources that form hierarchies. For instance, to retrieve the set
    of permissions that have been assigned to the user with ID `123` within a security
    group with ID `789`, `/security-groups/789/users/123/permissions` can be used
    as a path. In this example, the use of a forward slash to separate the security
    group and user resources implies the existence of a hierarchical relationship
    between them.
  prefs: []
  type: TYPE_NORMAL
- en: Controlling access to API endpoints
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After defining the endpoints for referring to resources, the next logical step
    is to implement a mechanism for enforcing access control. For instance, while `/orders/123` and `orders/789` are
    both valid resource paths, they might belong to different users; obviously, we
    would expect that each user should only be able to access their own orders.
  prefs: []
  type: TYPE_NORMAL
- en: In a different scenario, a user might be able to list the users that belong
    to a particular security group by performing a GET request to `/security-groups/123/users`,
    but only an administrator would be allowed to add or remove users from that group
    (for example, by performing POST and DELETErequests to the same endpoint). A fairly
    common pattern for achieving this kind of granular access to resources is **Role-Based
    Access Control** (**RBAC**).
  prefs: []
  type: TYPE_NORMAL
- en: To apply this pattern, we need to define a list of roles (for example, normal
    user, administrator, and so on) and associate each role with a set of access permissions.
    Each user of the system is assigned to one or more roles that the system consults
    when considering whether it should grant access to a particular resource or not.
  prefs: []
  type: TYPE_NORMAL
- en: Before we can go ahead and implement RBAC, we need to establish a mechanism
    for authenticating users prior to them attempting to access non-public API endpoints.
  prefs: []
  type: TYPE_NORMAL
- en: A lot of people tend to conflate the terms authentication and authorization when,
    in fact, they cannot be used interchangeably.
  prefs: []
  type: TYPE_NORMAL
- en: 'To avoid any confusion, let''s spend a bit of time properly defining the two
    terms:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Authentication**: This proves that a particular entity (for example, a client
    making API requests) is who they claim to be by providing some form of credential.
    This is akin to displaying your passport when going through security at an airport.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Authorization**: This proves that an entity has a right to access a particular
    resource. For instance, a metro ticket grants you access to a train platform without
    you having to disclose your identity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the following two sections, we will be examining two popular approaches to
    handling authentication, namely, basic HTTP authentication over TLS and authorization to
    an external service provider via **OAuth2**.
  prefs: []
  type: TYPE_NORMAL
- en: Basic HTTP authentication
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Basic HTTP authentication is probably the easiest and simplest way to implement
    an authentication layer for any API. Each client is provided either with a username
    and password tuple or with an API key. The latter approach is generally preferred
    as it allows application developers to generate multiple access keys that are
    tied to the same user account but can be independently managed, metered, and even
    revoked, should the need arise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Whenever clients need to perform an authenticated API request, they have to
    encode their access credentials and attach them to the outgoing request by means
    of the standard HTTP authorization header. Clients construct the content of the
    header field in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: Concatenate the username and password with a colon separator. So, if the username
    is `foo` and the password is `bar`, the concatenated result would be `foo:bar`.
    On the other hand, if the client is only provided with an API key, they need to
    use it as the username and concatenate it with a blank password. In other words,
    if the API key is `abcdefg`, then the concatenated result would be `abcdefg:`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The concatenated credentials are then base64-encoded. For the username and password
    scenario we mentioned previously, the encoded output for `foo:bar` becomes `Zm9vOmJhcg==`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The authorization method (basic) followed by a space character is prepended to
    the encoded credentials to yield the final header value, that is, `Authorization:
    Basic Zm9vOmJhcg==`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The obvious caveat of this approach is that the client's credentials are transmitted
    in plaintext over the wire. Therefore, in order to avoid credential leaks, API
    requests need to be transmitted over a secure channel. In principle, this is achieved
    by establishing a TLS session between the client and the server.
  prefs: []
  type: TYPE_NORMAL
- en: Securing TLS connections from eavesdropping
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is also important to note that while TLS sessions do offer a secure channel
    for exchanging data, TLS encryption is not a panacea; it is still possible for
    a malicious adversary to intercept and decode TLS traffic by using a proxy to
    perform a **man-in-the-middle** (**MITM**) attack:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/77f12f87-d575-49a2-91a9-5766ec1b9f14.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1: Using a MITM attack to intercept TLS traffic
  prefs: []
  type: TYPE_NORMAL
- en: The preceding diagram illustrates a scenario where **Alice** uses her bank's
    application on her mobile phone to query the balance in her bank account. **Eve**
    is a malicious actor trying to intercept the API calls between the application
    running on **Alice's** phone and the bank backend servers.
  prefs: []
  type: TYPE_NORMAL
- en: To achieve this, **Eve** needs to install a MITM proxy that will intercept and
    record outgoing connection requests from **Alice's** phone and either proxy them
    to the intended server or return fake responses. However, as we mentioned previously,
    the bank's server uses TLS-based encryption, so the bank application will not
    complete the TLS handshake steps unless the server provides a valid TLS certificate
    for the bank's domain.
  prefs: []
  type: TYPE_NORMAL
- en: In order for the MITM attack to succeed, the proxy server needs to be able to
    provide forged TLS certificates to Alice, which not only matches the bank's domain
    but is also signed by one of the globally trusted **Certificate Authorities**
    (**CAs**) that are preinstalled on **Alice's** phone.
  prefs: []
  type: TYPE_NORMAL
- en: Given that **Eve** does not have access to the private keys of any global CA,
    a prerequisite for forging certificates is for **Eve** to install a custom certificate
    authority on **Alice's** phone. This can be achieved either by exploiting a security
    hole via social engineering or simply by forcing **Alice** to do so if **Eve**
    happens to be a state actor.
  prefs: []
  type: TYPE_NORMAL
- en: 'With **Eve''s** CA certificate in place, the interception process works as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Alice** tries to connect to a website, for example, `https://www.bank.com`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Eve** intercepts the request and establishes a TCP socket with **Alice**.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Alice** initiates the TLS handshake. The handshake headers include a** Server
    Name Indication **(**SNI**) entry, which indicates the domain name it is trying
    to reach.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Eve opens a connection to the real `https://www.bank.com` server and initiates
    a TLS handshake, making sure to pass the same SNI entry as **Alice**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The bank server responds with its TLS certificate that also includes information
    about the server **Common Name** (**CN**), which in this case would normally be `www.bank.com` or `bank.com`.
    The certificate may also include a **Subject Alternative Name** (**SAN**) entry,
    which enumerates a list of additional domains that are also secured by the same
    certificate.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Eve** forges a new TLS certificate that matches the information from the
    bank''s TLS certificate and signs it with the private keys that correspond to
    the custom CA cert installed on **Alice''s** phone. The forged certificate is
    returned to **Alice**.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Alice** successfully verifies the forged TLS certificate, that is, it has
    the correct SNI and its parent certificate chain can be fully traced back to a
    trusted root CA. At this point, **Alice** completes the TLS handshake and sends
    out an API request to the bank API, which includes her access credentials.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Alice''s** request is encrypted with the forged TLS certificate. **Eve** decrypts
    the request and makes a record of it. Acting as a proxy, she opens a connection
    to the real bank server and sends **Alice''s** request through.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Eve** records the response from the bank server and sends it back to **Alice**.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that we are fully aware of the extent of damage that can be potentially
    caused by MITM attacks, what steps can we actually take to make our APIs more
    resistant to attacks like this? One approach to mitigating the issue of forged
    TLS certificates is to employ a technique known as public key pinning.
  prefs: []
  type: TYPE_NORMAL
- en: Each time we release a new client for our application, we embed the fingerprint of
    the public key that corresponds to the TLS certificate that's used to secure the
    API gateway. After completing the TLS handshake, the client calculates the public
    key fingerprint for the certificates that are presented by the server and compares
    it to the embedded value. If a mismatch is detected, the client immediately aborts
    the connection attempt and notifies the user that a potential MITM attack might
    be in progress.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's look at how we can implement public key pinning in our Go applications.
    The full source code for the following example is available in the `Chapter09/pincert/dialer` package of
    this book's GitHub repository. Go's `http.Transport` type is a low-level primitive
    that is used by `http.Client` to perform HTTP and HTTPS requests. When creating
    a new `http.Transport` instance, we can override its `DialTLS` field with a custom
    function that will be invoked each time a new TLS connection needs to be established.
    This sounds like the perfect spot to implement the public key fingerprint verification
    logic.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `WithPinnedCertVerification` helper, whose listing is shown in the following
    code, returns a dialer function that can be assigned to the `DialTLS` field of `http.Transport`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The returned dialer attempts to establish a TLS connection by invoking the `tls.Dial`
    function with the caller-provider network, destination address, and `tls.Config`
    parameters as arguments. Note that the `tls.Dial` call will also automatically
    handle the validation of the TLS certificate chain that''s presented by the remote
    server for us. After successfully establishing a TLS connection, the dialer delegates
    the verification of the pinned certificate to the `verifyPinnedCert` helper function,
    which is shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The `verifyPinnedCert` implementation iterates the list of X509 certificates
    presented by the remote server and calculates the SHA256 hash for each certificate's
    public key. Each calculated fingerprint is then compared to the pinned certificate's
    fingerprint. If a match is found, then `verifyPinnedCert` returns without an error
    and the TLS connection can be safely used to make API calls. On the other hand,
    an error will be returned if no match was found. In the latter case, the dialer
    will terminate the connection and propagate the error back to the caller.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using this dialer to improve the security of your API clients is quite easy.
    All you need to do is create your own `http.Client` instance, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: You can now use this client instance to perform HTTPS requests to your backend
    servers, just like you would normally do, but with the added benefit that your
    code can now detect MITM attack attempts. A complete end-to-end example of using
    this dialer to perform public key pinning can be found in the `Chapter09/pincert` package
    of this book's GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: Authenticating to external service providers using OAuth2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OAuth is an open standard for authorization that was initially proposed as an
    alternative to the basic authentication pattern that we examined in the previous
    section.
  prefs: []
  type: TYPE_NORMAL
- en: OAuth was designed to solve the following problem: let's assume that we have
    two services, A and B, which are typically unrelated to each other. As end users
    of service A, we wish to grant it access to some of our personal data that is
    hosted by service B. However, we want to avoid having to divulge our credentials
    so that we can access service B from service A.
  prefs: []
  type: TYPE_NORMAL
- en: 'Common use cases for using OAuth are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Using a third-party service as a **single sign-on** (**SSO**) provider instead
    of creating individual accounts for each service we are interested in using. The
    login with *X* buttons that you commonly see when attempting to sign in to online
    services is a great example of this pattern. Furthermore, SSO providers often
    provide a dashboard where users can examine the list of services that they have
    granted access to and revoke their access at any point in time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Allowing a service to use another service's API on behalf of a particular user.
    For instance, a user can log in to a **Continuous Integration** (**CI**) service
    with their GitHub account and allow the CI service to use GitHub's API to query
    the user's repositories or to set up webhooks that will trigger CI runs when a
    pull request is created.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So, how does this work under the hood and how can we integrate the OAuth framework
    into our Go applications? For the remainder of this section, we will be focusing
    on the three-legged OAuth2 flow, which can facilitate data exchange between applications
    without sharing user credentials.
  prefs: []
  type: TYPE_NORMAL
- en: 'The three-legged OAuth2 flow involves the following four parties:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The Resource Owner**: This is the user who wants to give access to their
    data that''s hosted by service B to service A without sharing their credentials.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The OAuth client**: In our scenario, service A wants to leverage an API offered
    by service B to obtain the user''s data or to execute some action on behalf of
    the user.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The Resource Server**: In our scenario, service B hosts the user data that
    service A attempts to access.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The Authorization Server**: This is a part of service B and acts as the key
    component in this particular OAuth flow. It generates the appropriate set of access
    tokens that allow service A to access a specific subset of the user data hosted
    by service B.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram illustrates the three-legged OAuth2 flow:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/40e0989f-d149-4afa-bcfb-41183ec7c649.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2: The steps in the three-legged OAuth2 flow
  prefs: []
  type: TYPE_NORMAL
- en: In order for service A to be able to trigger the three-legged OAuth2 flow, it
    needs to be registered with the authorization server for service B. Upon registering,
    service A will be assigned a unique client ID and client secret token. The client
    ID is a public token that allows the authorization server to identify the application
    that requires access. On the other hand, the client secret is private and is used
    to authenticate the OAuth client whenever it needs to contact the authorization
    server.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s examine what happens during the three-legged OAuth2 flow:'
  prefs: []
  type: TYPE_NORMAL
- en: The user visits the website for service A and clicks the login with the B button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The backend server for service A is configured with the API endpoints of the
    authorization server for service B. It returns an authorization URL to the user
    that embeds the following pieces of information:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The client ID token that is used by the authorization server to identify the
    service requesting access
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A set of granular access permissions (grants) to be granted to service A
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A URL hosted by service A, which the user will be redirected to by the authorization
    server once they consent to give access
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A nonce value, which is to be used as a unique identifier for the authorization
    request
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The user visits the authorization URL using their web browser.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The authorization server renders a consent page providing details (name, author,
    and so on) about the application that requires access to the user's data, as well
    as a description for the types of grants that can be requested.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'An example of a consent page for authorizing access to a user''s GitHub account
    can be seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b75ddae0-8177-4df1-9195-effaa6cf2798.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3: An example consent page for granting access to a user's GitHub account
  prefs: []
  type: TYPE_NORMAL
- en: Once the user reviews and authorizes the list of permissions that have been
    requested by service A and authorizes them, their web browser will be redirected
    to the URL included in the authorization request URL that was generated in *step
    2*. The authorization server appends two additional values to that URL – the nonce
    value from the authorization request and an access code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After receiving the access code and matching the incoming nonce value to the
    one included in the authorization request, the OAuth client contacts the server
    and attempts to exchange the obtained access co de with an access token.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The authorization server returns two tokens: a short-lived access token that
    can be used to access data on the resource server and a long-lived refresh token that
    the OAuth client can use to refresh expired access tokens.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The OAuth client contacts the resource server and obtains the required data
    using the access token.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In a similar fashion to the basic authentication mechanism we discussed previously,
    all outgoing requests to the resource server include an HTTP authorization header
    that the client populates with the obtained access token. The only difference
    is that instead of specifying a basic authorization method, this time, the client
    specifies `bearer` as the authorization method, that is, the transmitted header
    looks like `Authorization: Bearer ACCESS_TOKEN`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Fortunately, most of the plumbing that''s needed for implementing the three-legged
    OAuth flow in our applications is already provided by the `golang.org/x/oauth2` package.
    All we need to do is implement the redirect handling logic we described in *step
    5*. Let''s begin by creating a new type called `Flow` to encapsulate the logic
    for our OAuth implementation. The `type` definition lives in the `Chapter09/oauthflow/auth` package
    and contains the following set of fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The `cfg` field holds a `oauth2.Config` value, which describes the OAuth provider''s
    endpoints for:'
  prefs: []
  type: TYPE_NORMAL
- en: Authorizing requests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Obtaining access tokens
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refreshing access tokens when they expire
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `srvListener` field stores the `net.Listener` instance, which is where our
    implementation will listen for incoming OAuth redirects, while the `pendingRequests
    map` keeps track of all authorization attempts that are currently in flight. A
    `sync.Mutex` guards the access to both these variables and ensures that our implementation
    is safe for concurrent use.
  prefs: []
  type: TYPE_NORMAL
- en: 'To work with our package, users must create a new `Flow` instance by invoking
    the `NewOAuthFlow` constructor, whose implementation is shown in the following
    code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The constructor expects three arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: An `oauth2.Config` instance for the provider that the user wishes to authenticate
    against.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A local address so that it can listen for incoming redirect requests. If not
    specified, the implementation will bind to the default address, `127.0.0.1:8080`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A redirect URL that is sent to the remote server as part of the three-legged
    OAuth flow. If not specified, the implementation will use the address that the
    listener has bound to.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You might be wondering why users need to specify both the listen address and
    the redirect URL. When we are testing our application locally, these two values
    will always be the same. In fact, we can leave both parameters blank and our application
    will work just fine with the default values!
  prefs: []
  type: TYPE_NORMAL
- en: In this scenario, once we log in to the remote service, the OAuth server will
    redirect our browser to a loopback address that the browser can successfully connect
    to, given that it executes on the same machine as our OAuth redirect listener.
  prefs: []
  type: TYPE_NORMAL
- en: In a production deployment, our code would run on an isolated virtual machine
    hosted by a cloud provider. While our OAuth-handling code would still be listening
    to a loopback address, the users' browsers would only be able to connect to it
    through a load balancer with a public IP address. In such a case, the only way
    to make the three-legged OAuth flow work correctly is to provide a redirect URL
    whose DNS record resolves to the IP of the external load balancer.
  prefs: []
  type: TYPE_NORMAL
- en: Going back to the constructor implementation, the first thing that we need to
    do is bind a new `net.Listener` to the requested address and populate the value
    of the `redirectHost` parameter (if it's not been specified). Next, we overwrite
    the `RedirectURL` field of the user-provided OAuth configuration object with a
    URL that is generated by concatenating the value of the `redirectHost` parameter
    with a known static path (in this example, `/oauth/redirect`). Before returning
    the newly allocated `Flow` instance, the code spawns a go-routine and starts an
    HTTP server for processing incoming redirects from the remote authorization server.
  prefs: []
  type: TYPE_NORMAL
- en: 'After obtaining a new `Flow` instance, users can trigger a three-legged OAuth
    flow by invoking its `Authenticate` method, whose source is displayed in the following
    code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: From the preceding code snippet, to distinguish between concurrent authentication
    requests, the `Authenticate` method generates a unique nonce value and associates
    it with every pending request. The generated nonce is then passed to the OAuth
    configuration's `AuthCodeURL` method to generate an authorization URL (pointing
    at the remote service) where the end user can log in using their web browser and
    consent to the grants that have been requested by our application.
  prefs: []
  type: TYPE_NORMAL
- en: The remaining steps of the OAuth flow happen asynchronously. To this end, the
    code allocates a buffered `Result` channel, appends it to the `pendingRequests` map
    while using the generated nonce as a key, and returns both the authorization URL
    and the result channel to the caller. The application must then redirect the end
    user's browser to the generated URL and block until a `Result` instance can be
    read off the returned channel.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Result` type encapsulates the result of an authorization attempt and is
    defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Once the user completes the authorization process, the remote OAuth server will
    redirect their browser to the HTTP server that we launched in the `Flow` type's
    constructor. Next, we will examine the implementation of the `handleAuthRedirect` HTTP
    handler.
  prefs: []
  type: TYPE_NORMAL
- en: In the following code snippets, the `r` variable refers to an `http.Request` instance,
    while the `w` variable refers to an `http.ResponseWriter` instance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first task of the HTTP handler is to parse and validate the parameters
    that were sent to us by the authorization server using the following block of
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `ParseForm` method of the `http.Request` object is quite flexible in that
    it is able to decode parameters both from the URL (if this is a **GET** request)
    and the HTTP request body (if this is a **POST** request). If the call returns
    without an error, we use the handy `FormValue` method to extract the state parameter,
    which contains the nonce value that we embedded in our initial authorization request
    URL, and the code value, which contains the access code that was returned by the
    authorization server.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, the handler acquires the lock and indexes the `pendingRequests` map using
    the provided nonce value in an attempt to look up the result channel for the pending
    request. If no match is found, we print out a simple warning message that will
    be displayed to the user''s browser and exit the handler. Otherwise, we remove
    the pending result channel from the map and publish a `Result` instance to it.
    The following block of code illustrates how the aforementioned steps are implemented:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the HTTP handler writes the `Result` value to the channel, the application
    waiting on the channel unblocks and can invoke the result''s `Client` method to
    obtain an `http.Client` instance so that it can make authenticated calls to the
    remote service. The returned `http.Client` instance is specially configured to
    automatically inject the obtained access token into all outgoing requests and
    transparently refresh it when it expires. The complete implementation for this
    method is outlined in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: As shown in the preceding code snippet, we complete the three-legged OAuth flow
    by exchanging the short-lived authentication code that's sent back to us by the
    authorization server with a long-lived access token. Finally, we pass the `OAuth`
    access token to the similarly-named `Client` method of the stored `oauth2.Config` value
    to create a token-aware `http.Client` instance, which is then returned to the
    caller.
  prefs: []
  type: TYPE_NORMAL
- en: To understand how all the pieces of the puzzle fit together, you can take a
    look at the `Chapter09/oauthflow` package in this book's GitHub repository. It
    contains a complete, end-to-end example of a simple CLI application that uses
    the code from this section to gain access to GitHub's API and to print out a user's
    login name.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with API versions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once a public API for a particular service gets published and third parties
    begin using it, API developers need to be very careful to avoid introducing any
    changes that could cause third-party applications to stop working.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine that we are building a payment processor similar to PayPal, Stripe,
    or Adyen. The core business value proposition of such a service is to provide
    a solid and easy-to-use API for handling payments. To this end, we expect hundreds
    or thousands of application instances (e-commerce sites, recurring subscription
    services, and so on) to be tightly coupled to our payment processor's public API.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing new API endpoints would be a relatively trivial task; after all,
    none of the applications that depend on the service API will be using the new
    endpoints, so we can't really break something. On the other hand, changing existing
    or removing old API endpoints cannot be done without giving advance notice to
    all the users of our API.
  prefs: []
  type: TYPE_NORMAL
- en: The problem is compounded even further by the fact that each application integrator
    moves at a different pace; some may update their applications in a relatively
    short amount of time, while others may take months to come up with an update.
    Likewise, application integrators can also go out of business, leaving end users
    with no channel for receiving updates for already deployed application instances.
  prefs: []
  type: TYPE_NORMAL
- en: So, what if we were in complete control of both the server and the client? Would
    it be easier to introduce breaking changes if we were building, for instance,
    a mobile application and opted to use a proprietary API for communicating with
    the backend servers? The answer is still no! To figure out why this is the case,
    let's pretend that we are the operator that's responsible for running a ride-hailing
    application.
  prefs: []
  type: TYPE_NORMAL
- en: One strategy that we can use to our advantage is to ship our mobile application
    with a built-in force-update mechanism. When the application starts, it can contact
    our API servers and check whether an update must be installed before continuing.
    If that happens to be the case, the application can nag the user until they agree
    to update it. That would definitely work... unless, of course, our users were
    standing in the pouring rain on a Saturday night, desperately trying to get a
    taxi.
  prefs: []
  type: TYPE_NORMAL
- en: In such a scenario, displaying a "please upgrade the application to continue"
    message is definitely a sign of bad UX and would probably trigger many users to
    immediately switch to a competitor's application. In addition, some of our users
    might be owners of older phone models that cannot be upgraded to a newer version
    of our application because they either run on older hardware or because the phone
    manufacturer revoked the keys that are used to sign applications for OS versions
    that are not supported anymore.
  prefs: []
  type: TYPE_NORMAL
- en: In hindsight, the evolution of APIs is inevitable. Therefore, we need to come
    up with some kind of versioning mechanism for the RESTful APIs that would allow
    us to introduce breaking changes while at the same time still being able to handle
    requests from legacy API clients.
  prefs: []
  type: TYPE_NORMAL
- en: Including the API version as a route prefix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The most popular approach for implementing API versioning is for clients to
    include the requested API version as part of the requested API endpoint paths.
    For instance, `/v1/account` and `/v2/account` are versioned endpoints for retrieving
    the user's account details. However, the `/account` endpoint, when mounted under
    the `v2` prefix, might return a completely different payload than the one mounted
    under the `v1` prefix.
  prefs: []
  type: TYPE_NORMAL
- en: 'The choice of the version naming scheme is totally arbitrary and is up to the
    API designer to decide on. Common versioning schemes include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Numeric values; for example, `v4`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: API release dates; for example, `20200101`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Season names that coincide with new API releases; for example, `spring2020`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is important to be aware that this particular versioning approach violates
    the principle that URIs should refer to unique resources. Clearly, in the previous
    example, `/v1/account` and `/v2/account` both refer to the same resource. What's
    more, a limitation of this approach is that we cannot version individual API endpoints.
  prefs: []
  type: TYPE_NORMAL
- en: Negotiating API versions via HTTP Accept headers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The version as part of the route approach works fine if we assume that the API
    server is always supporting the latest API version. In this scenario, the client
    can simply select the highest version that it can work with without any concern
    about the server hosting the API. What if this assumption does not hold?
  prefs: []
  type: TYPE_NORMAL
- en: Let's say that we are developing a chat server that users can download and deploy
    on their own infrastructure. Besides the chat server package, we also develop
    and maintain the official client for connecting to the chat server. The chat server
    exposes an API endpoint with a `/messages/:channel` path, which clients can invoke
    to obtain a list of messages for a particular channel.
  prefs: []
  type: TYPE_NORMAL
- en: 'In version 1 of the API, each returned message includes two fields: the name
    of the user who sent the message and the message itself. In version 2 of the API,
    the message payload is augmented with two additional fields, namely, a timestamp
    and a link to the user''s avatar image.'
  prefs: []
  type: TYPE_NORMAL
- en: Given that the version of the server that gets deployed is ultimately controlled
    by the end user, clients that connect to the server have no means of knowing which
    API version they can safely use. Granted, we could provide a dedicated API endpoint
    that clients could use to query the server version and then select the API version
    based on the server response. However, this approach is not really elegant and
    cannot really scale if we want to version specific endpoints but not the entire
    API.
  prefs: []
  type: TYPE_NORMAL
- en: Clearly, we need to introduce a sort of negotiation protocol that would allow
    the client and server to select the maximum common supported API version that
    is understood by both parties. As it turns out, the HTTP protocol already comes
    with such functionality baked in.
  prefs: []
  type: TYPE_NORMAL
- en: The client can use the HTTP Accept header to specify the API versions that it
    supports when it invokes the `/messages/:channel` endpoint. The contents of the Accept header
    must follow the media type specification format defined in RFC6838 ^([9]). For
    JSON-based APIs, the `application/vnd.apiVersion+json` template is typically used.
  prefs: []
  type: TYPE_NORMAL
- en: The `vnd` part indicates a vendor-specific media type. The `apiVersion` part
    is used to specify the supported version number, while the `+json` part indicates
    that the client expects a well-formed JSON document to be returned by the server.
    The media type syntax also allows clients to specify multiple media types as a
    comma-separated list. For the scenario we are currently discussing, a client that
    supports both API versions but prefers to use version 2 of the API would populate
    the header with the value `application/vnd.v2+json,application/vnd.v1+json`.
  prefs: []
  type: TYPE_NORMAL
- en: The server parses the header value, locates the highest supported API version,
    and routes the request to it or returns an error if none of the proposed client
    API versions are supported. When responding to the client with the payload, the
    server sets the value of the `Content-Type` header to indicate the API version
    that was actually used to process the request. The client parses this information
    and uses it to correctly unmarshal and handle the response payload.
  prefs: []
  type: TYPE_NORMAL
- en: Building RESTful APIs in Go
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Nowadays, building RESTful APIs in Go is a fairly streamlined process. If you
    don't mind a little bit of elbow grease (for example, using regular expressions
    to manually extract parameters from request paths), you can build your very own HTTP
    router by leveraging the functionality offered by `http.Mux`, a component that
    ships with the Go standard library.
  prefs: []
  type: TYPE_NORMAL
- en: While building your own router from scratch would undoubtedly be a great learning
    experience, you should probably save quite a bit of time (and effort) and simply
    use one of the popular, battle-tested router packages such as gorilla-mux ^([5]) or
    HttpRouter ^([3]).
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, if fully-fledged web frameworks (combining a router, middleware,
    and perhaps an ORM into a single package) are your cup of tea, you will be positively
    surprised to find out that there are a plethora of packages to choose from! An
    indicative list of popular (based on the number of stars on GitHub) web framework
    packages would definitely include buffalo ^([1]), revel ^([4]), and gin-gonic ^([10]).
  prefs: []
  type: TYPE_NORMAL
- en: 'All of these packages have one thing in common: they are all built on top of
    the net/http package. If you happen to be building APIs that can potentially receive
    a large (that is, more than one million requests per server) volume of concurrent
    requests, you may find that the net/http package actually becomes a bottleneck
    that caps your API''s throughput.'
  prefs: []
  type: TYPE_NORMAL
- en: If you ever find yourself in this predicament and don't mind programming against
    a slightly different API than the one offered by the net/http package, you should
    take a look at the fasthttp ^([8]) package.
  prefs: []
  type: TYPE_NORMAL
- en: Building RPC-based APIs with the help of gRPC
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: gRPC ^([2]) is a modern open source framework that was created by Google to
    assist the process of implementing APIs that are based on the **Remote Procedure
    Call** (**RPC**) paradigm. In contrast to the REST architecture, which is more
    suited for connecting web-based clients such as browsers to backend services,
    gRPC was proposed as a cross-platform and cross-language alternative for building
    low-latency and highly scalable distributed systems.
  prefs: []
  type: TYPE_NORMAL
- en: Do you know what the letter g in gRPC stands for? A lot of people naturally
    think that it stands for Google, a reasonable assumption given that gRPC was released
    by Google in the first place. Others believe that **gRPC** is a recursive acronym,
    that is, **gRPC Remote Procedure Calls**.
  prefs: []
  type: TYPE_NORMAL
- en: The fun fact is that both interpretations are wrong! According to the gRPC documentation
    on GitHub, the meaning of the letter g changes with every new gRPC release ^([11]).
  prefs: []
  type: TYPE_NORMAL
- en: While the construction of high-performance APIs to link together microservices
    is the bread and butter of gRPC, as we will see in the following sections, it
    can also be used as a replacement for existing REST APIs.
  prefs: []
  type: TYPE_NORMAL
- en: Comparing gRPC to REST
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While using REST as an architecture for building APIs provides several benefits,
    it also comes with a few caveats attached. Let's examine these caveats in more
    detail.
  prefs: []
  type: TYPE_NORMAL
- en: REST APIs are typically implemented on top of the HTTP/1.x protocol, which lacks
    proper support for managing and reusing connections. As a result, clients must
    establish a new TCP connection with the backend server and perform a complete
    TLS handshake every time they wish to invoke an API endpoint. This requirement
    not only incurs additional latency to API calls but also increases the load on
    backend servers (or load balancers, if you are doing TLS termination at the edge)
    since TLS handshaking comes with a non-insignificant computation cost.
  prefs: []
  type: TYPE_NORMAL
- en: In an attempt to mitigate this issue, HTTP/1.1 introduced the model of HTTP
    pipelining. In this connection-management mode, the client opens a single TCP
    socket to the server and sends a batch of successive requests through. The server
    processes the batch of requests and sends back a batch of responses that match
    the order of the requests sent in by the client. One limitation of this model
    is that it can only be applied to idempotent requests (HEAD, GET, PUT, and DELETE).
    Furthermore, it is susceptible to head-of-line blocking, that is, a request that
    takes a long time to execute will delay the processing of subsequent requests
    in the same batch.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, gRPC is built on top of HTTP/2, which defines a new connection
    management model, that is, multiplexed streams. With this model, gRPC can support
    bi-directional streams that are interleaved and transmitted over a single TCP
    connection. This approach avoids the head-of-line blocking problem altogether
    and also allows the server to send push notifications back to the client.
  prefs: []
  type: TYPE_NORMAL
- en: The text-based nature of the HTTP/1.x protocol and the choice of JSON as the dominant serialization
    format for requests and responses makes RESTful APIs a bit too verbose to work
    with in use cases where the goal is to maximize throughput. While JSON payloads
    can definitely be compressed (for example, using gzip), we wouldn't be able to
    achieve the same efficiency as protocol buffers, the binary format that gRPC uses
    to compactly encode messages exchanged between the client and the server.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, RESTful APIs do not mandate a particular structure for requests and
    response payloads. It's up to the client and server to correctly unmarshal JSON
    payloads and coerce the payload values to the correct type for the language they
    are written in. This approach could lead to errors or, even worse, data corruption.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if the server tries to unmarshal a 64-bit integer into a 32-bit
    integer variable, the value might be truncated if the original value cannot be
    coerced into 32 bits. On the other hand, gRPC uses strongly-typed messages, which
    always unmarshal to the correct types, regardless of the programming language
    that's used by the client or the server.
  prefs: []
  type: TYPE_NORMAL
- en: Defining messages using protocol buffers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Protocol buffers are language- and platform-neutral mechanisms for serializing
    structured data in a very efficient manner. To achieve language neutrality, protocol
    buffers describe both messages and RPC services in a high-level **interface definition
    language** (**IDL**).
  prefs: []
  type: TYPE_NORMAL
- en: To start working with protocol buffers, we need to install the protoc compiler
    for our development environment. You can do this by compiling from source or by
    installing a pre-built binary release for your platform from [https://github.com/protocolbuffers/protobuf/releases](https://github.com/protocolbuffers/protobuf/releases).
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, you will also need to install the Go output generator for the
    protoc compiler and the Go packages that are required for working with protocol
    buffers and the gRPC framework by executing the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Protocol buffer message definitions typically live in files with a `.proto` extension.
    They are processed by specialized tools that compile the definitions into language-specific
    types that we can use to build our applications. For Go, the protoc compiler is
    generally invoked as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The `--go_out` argument instructs the protoc compiler to enable the Go output
    generator. It expects a comma-delimited list of options that end with a colon
    character. In the aforementioned example, the option list includes a plugin option
    to enable the gRPC plugin. The argument after the colon character specifies the
    location for any file that's generated by the compiler. Here, we set it to the
    current working directory.
  prefs: []
  type: TYPE_NORMAL
- en: The `-I` argument can be used to specify additional include paths that the compiler
    scans when resolving include directives. In this example, we add the current working
    directory to the include path.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the last argument to the protoc compiler is the name of the `.proto`
    file to be compiled.
  prefs: []
  type: TYPE_NORMAL
- en: Defining messages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So, what does a protocol buffer message definition look like? Here is a short
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding definition, the first line announces the version of the protocol
    buffer format that's going to be used for the rest of the file to the compiler.
    In this example, we are using version 3, which is the latest version and the one
    should be used for any new projects. The second line defines the name of the package,
    which will be used as a container for the generated protocol buffer definitions.
    As you can probably guess, the use of packages avoids conflicts between projects
    that define messages with the same names.
  prefs: []
  type: TYPE_NORMAL
- en: 'Message definitions begin with the `message` keyword, which is followed by
    the message name and a list of (field type, field name) tuples. Protocol buffer
    compilers recognize the following set of built-in types ^([7]):'
  prefs: []
  type: TYPE_NORMAL
- en: '| **.proto Type** | **Equivalent Go Type** | **Notes** |'
  prefs: []
  type: TYPE_TB
- en: '| `double` | `float64` |  |'
  prefs: []
  type: TYPE_TB
- en: '| `float` | `float32` |  |'
  prefs: []
  type: TYPE_TB
- en: '| `int32` | `int32` | Uses variable-length encoding |'
  prefs: []
  type: TYPE_TB
- en: '| `int64` | `int64` | Uses variable-length encoding |'
  prefs: []
  type: TYPE_TB
- en: '| `uint32` | `uint32` | Uses variable-length encoding |'
  prefs: []
  type: TYPE_TB
- en: '| `uint64` | `uint64` | Uses variable-length encoding |'
  prefs: []
  type: TYPE_TB
- en: '| `sint32` | `int32` | More efficient for storing negative integer values than
    `int32` |'
  prefs: []
  type: TYPE_TB
- en: '| `sint64` | `int64` | More efficient for storing negative integer values than
    `int64` |'
  prefs: []
  type: TYPE_TB
- en: '| `fixed32` | `uint32` | Always 4 bytes; more efficient for values > 228 than
    `uint32` |'
  prefs: []
  type: TYPE_TB
- en: '| `fixed64` | `uint64` | Always 8 bytes; more efficient for values > 256 than
    `uint64` |'
  prefs: []
  type: TYPE_TB
- en: '| `sfixed32` | `int32` | Always 4 bytes |'
  prefs: []
  type: TYPE_TB
- en: '| `sfixed64` | `int64` | Always 8 bytes |'
  prefs: []
  type: TYPE_TB
- en: '| `bool` | `bool` |  |'
  prefs: []
  type: TYPE_TB
- en: '| `string` | `string` |  |'
  prefs: []
  type: TYPE_TB
- en: '| `bytes` | `[]byte` |  |'
  prefs: []
  type: TYPE_TB
- en: As we mentioned in the previous sections, protocol buffers try to encode messages
    into a compact and space-efficient format. To this end, integers are generally
    serialized using variable-length encoding. Since this approach does not work that
    well for negative values, protocol buffers also define auxiliary types for (mostly)
    negative values (for example, `sint32` and `sint64`), which are encoded in a different
    and more space-efficient way.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, we are not limited to just the built-in types. We can use already-defined
    message types as field types too! In fact, these definitions might even live in
    a separate `.proto` file that we include in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Another interesting feature of protocol buffers is enumerations, which allow
    us to define fields that can only be assigned a value from a fixed, predefined
    list of values. The following code expands the `Address` message definition so
    that it includes a type field to help us identify the address type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The `enum` block defines the list of constants that can be assigned to the newly
    introduced type field. One important thing to keep in mind is that every enumeration
    list must include a constant that maps to the zero value as its first element.
    This serves as the default value for the field.
  prefs: []
  type: TYPE_NORMAL
- en: Versioning message definitions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Each field in a protocol buffer message is assigned a unique ID. The most common
    pattern is to assign IDs in an incremental fashion, starting from 1\. When a field
    is serialized to the wire format, the serializer emits a small header that contains
    information about the field type, its size (for variable-sized fields), and its
    ID.
  prefs: []
  type: TYPE_NORMAL
- en: The receiver scans the header and checks whether a field with that ID is present
    in its local message definition. If so, the field value is unserialized from the
    stream to the appropriate field. Otherwise, the receiver uses the information
    in the header to skip over any fields it does not recognize.
  prefs: []
  type: TYPE_NORMAL
- en: This feature is extremely important as it forms the basis for versioning message
    definitions. Since message definitions evolve over time, new fields can be added
    or existing fields may be reordered without breaking existing consumers who are
    working with messages that have been compiled from older `.proto` files.
  prefs: []
  type: TYPE_NORMAL
- en: Representing collections
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'What''s more, protocol buffers can also model two types of collections, namely,
    lists and maps. To create a list of items, all we need to do is add the `repeated` keyword
    as a prefix of the field''s type. On the other hand, maps are defined with a special
    notation, that is, `map<K, V>`, where `K` and `V` represent the types for the
    map keys and values. The following snippet is an example of defining collections:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: When compiled to Go code, the fields for the `Users` message will be mapped
    to a `[]User` type and a `map[string]User` type, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Modeling field unions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One frequent requirement for many kinds of applications is the ability to model unions.
    A union is a special kind of value that can have multiple representations, all
    of which point to the same location in memory. The use of shared memory implies
    that every time we write a value to a particular union field, any attempt to read
    one of the other union fields will result in garbled data.
  prefs: []
  type: TYPE_NORMAL
- en: The concept of unions extends quite nicely to protocol buffers. If you are working
    with messages that contain multiple fields where, at most, one field can be set
    at any given time, you can reduce the amount of required memory by grouping all
    these fields in a union.
  prefs: []
  type: TYPE_NORMAL
- en: 'A union definition begins with the `oneof` keyword, followed by the field name
    and a list of fields that comprise the union. The following snippet shows a simple
    example that demonstrates a very common API use case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: In this example, all the responses have an associated correlation ID value.
    However, depending on the outcome of the API call invocation, the response payload
    will either contain an `Account` or an `Error`.
  prefs: []
  type: TYPE_NORMAL
- en: 'After compiling the aforementioned message definition, the protoc compiler
    will generate two special types, namely, `CreateAccountResponse_Account` and `CreateAccountResponse_Error`,
    that can be assigned to the `Payload` field of the `CreateAccountResponse` type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'To prevent other types from being assigned to the `Payload` field, the protoc
    compiler uses an interesting trick: it defines a private interface with an unexported
    dummy method and arranges it so that only the previous two type definitions implement
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The protoc compiler specifies the interface mentioned in the preceding code
    snippet as the type of the `Payload` field, thus making it a compile-time error
    to assign any other type to the field. Moreover, to facilitate the retrieval of
    the union values, the compiler will also generate `GetAccount` and `GetError` helpers
    on the `CreateAccountResponse` type. These helpers peek into the `Payload` field's
    contents and either return the assigned value (`Account` or `Error`) or `nil` if
    no value of that type has been assigned to the union field.
  prefs: []
  type: TYPE_NORMAL
- en: The Any type
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When building event-driven systems, a common pattern is to define a top-level
    message that acts as an envelope for different event payloads. Since new event
    types may be added (or removed) at any point in time, using a union is simply
    not going to suffice. Furthermore, the following are from the standpoint of event
    consumers:'
  prefs: []
  type: TYPE_NORMAL
- en: Consumers might ship with older `.proto` versions than the event producers do.
    It is quite possible for them to encounter an event payload that they don't really
    know how to decode.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some consumers may only be interested in processing a *subset* of the events.
    In such a scenario, consumers should only decode the messages they care about
    and skip over all other messages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To cater for such cases, we can use the `Any` type to define our envelope message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The `Any` type, as the name implies, can store any protocol buffer message.
    Internally, this is achieved by storing a serialized version of the message, as
    well as a string identifier that describes the type of message stored within.
    The type identifier has the form of a URL and is constructed by concatenating `type.googleapis.com/` with
    the message name. The `ptypes` package (you can find it at [www.github.com/golang/protobuf/ptypes](http://www.github.com/golang/protobuf/ptypes))
    provides several useful helpers for dealing with `Any` messages.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code is an example of how we would populate an `Envelope` instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The `MarshalAny` helper takes any value that implements the `proto.Message` interface
    and serializes it into an `Any` message, which we then assign to the `Payload` field
    of the `Envelope` type.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the consumer end, we can use the following block of code to process incoming
    envelopes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Essentially, the handler switches on the message type and uses the `UnmarshalAny` helper
    to unserialize and handle supported messages. On the other hand, if the message
    type is unknown or not one that the consumer is interested in, they can either
    skip it or return an error, which is what is happening in the preceding code.
  prefs: []
  type: TYPE_NORMAL
- en: After defining the set of messages that we want to use in our application using
    the protocol buffer definition language, the next logical step is to create RPCs
    that make use of them! In the following section, we will explore how we can enable
    the *grpc* plugin and have the protoc compiler automatically generate the required
    code stubs for our RPCs.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing RPC services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The gRPC framework leverages the stream multiplexing capabilities of `HTTP/2`
    so that it can handle both synchronous and asynchronous RPCs. The protoc compiler,
    when invoked with the *grpc* plugin enabled, will generate the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Client and server **interfaces** for every RPC service definition in the compiled
    `.proto` file. For a service named `Foo`, the compiler will generate a `FooServer` and
    a `FooClient` interface. This is quite a useful feature as it allows us to inject
    mocked clients into our code at test time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Complete client implementation for each service that adheres to the generated
    client interface.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A helper function to register our service implementation with a gRPC server
    instance. Once again, for a service called `Foo`, the compiler will generate a
    function with a signature similar to `RegisterFooServer(*grpc.Server, FooServer)`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following short code snippet demonstrates how we can create a new gRPC
    server, register our implementation for the `Foo` service, and start serving incoming
    RPCs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: In the following four sections, we will examine the different types of RPC modes
    that are supported by the gRPC framework.
  prefs: []
  type: TYPE_NORMAL
- en: Unary RPCs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A unary RPC is equivalent to the request-response model that''s used in traditional
    RESTful APIs. In the following example, we are defining a service with the name `AccountService` that
    exposes a `CreateAccount` method that receives `CreateAccountRequest` as input
    and returns a `CreateAccountResponse` to the caller:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Defining the server handler is also quite similar to a regular RESTful API.
    Consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: To be able to register our server implementation with gRPC, we need to implement
    the `AccountServiceServer` interface. The server-side implementation in the listing
    (given in the preceding code snippet) receives a `CreateAccountRequest` message
    as an argument. It invokes the `createAccount` helper, which validates the request,
    creates the new account record, and returns its ID. Then, a new `CreateAccountResponse` instance is
    created and returned to the client.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the client side, things are also quite simple. The following code shows
    that the `accountAPI` type simply offers a friendly API for abstracting the RPC
    call to the server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The method receives a model instance that describes the account to be created,
    converts it into `CreateAccountInstance`, and sends it to the server via the `AccountServiceClient` instance
    that was injected at construction time. Upon receiving a response, the client
    extracts the ID that was assigned to the new account and returns it to the caller.
  prefs: []
  type: TYPE_NORMAL
- en: Server-streaming RPCs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a server-streaming RPC scenario, the client initiates an RPC on the server
    and receives a stream of responses. Clients block reading on the stream until
    new data becomes available or the server closes the stream. In the latter case,
    the client read request will return an `io.EOF` error to indicate that no more
    data is available.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we are defining a service that streams price updates
    for a particular cryptocurrency:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code shows the server-side implementation for the `StreamCryptoPrice`
    RPC:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The `StreamCryptoPrice` signature shown in the preceding code snippet is different
    than the unary RPC signature we examined in the previous section. Besides the
    incoming request, the handler also receives a helper type that the protoc compiler
    created for us to deal with the streaming aspects of this particular RPC call.
  prefs: []
  type: TYPE_NORMAL
- en: 'The server handler calls out to the `priceStreamFor` helper (implementation
    omitted) to obtain a channel where price updates for the requested currency type
    are posted. Once a new price has been received, the server code invokes the `Send` method
    on the provided stream helper to stream a new response to the client. Once the
    server handler returns (for example, when the price stream channel closes), gRPC
    will automatically shut down the stream and send an `io.EOF` error to the client,
    whose implementation is shown in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The client API wrapper uses the injected `PriceServiceClient` instance to initiate
    the RPC and obtain a stream where price updates can be read from. The client then
    enters an infinite `for` loop where it blocks on the stream's `Recv` method until
    a new price update (or an error) is received.
  prefs: []
  type: TYPE_NORMAL
- en: Client-streaming RPCs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Client-streaming RPCs are the opposite of server-streaming RPCs. In this case,
    it's the client that streams data to the server. Once the server has received
    *all* the data, it replies with a *single* response.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we are defining a service that receives a stream
    of metric values from the client and responds with a set of aggregated statistics
    (`count`, `min`, `max`, and `avg` value) for the entire batch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The following block of code builds on top of the functionality offered by the
    RPC client for this service and exposes an API for calculating the statistics
    for a stream of values that are read off a caller-provided Go channel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'As shown in the preceding code snippet, the `GetStats` implementation initially
    makes a call to the underlying RPC client''s `CalculateStats` method and obtains
    a (client-side) stream helper. With the help of a `range`loop, each value from
    the provided `valueCh` is wrapped into a new `Observation` message and transmitted
    to the server for processing. Once the client has sent all observed values to
    the server, it invokes the `CloseAndRecv` method, which performs two tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: It notifies the server that no more data is available
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It blocks until the server returns a `StatsResponse`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, we will take a look at the server-side implementation for the aforementioned
    RPC:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The server reads incoming `Observation` instances from the stream that's passed
    as an argument to `CalculateStats` and appends them to a slice. Once the server
    detects (via the presence of an `io.EOF` error) that the client has transmitted
    all data, it passes the collected observations slice to the `calcStats` helper,
    which calculates the statistics for the batch and returns them as a `StatsResponse` message that
    the server forwards to the client.
  prefs: []
  type: TYPE_NORMAL
- en: Bi-directional streaming RPCs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The last RPC mode that we will explore is bi-directional streaming. This mode
    combines client- and server-side streaming and provides us with two independent
    channels where the client and server can *asynchronously* publish and consume
    messages.
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand how this mode works, let''s examine the definition for an asynchronous
    `Echo` service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The server-side logic for the echo service is not that interesting. As shown
    in the following code snippet, the server runs a `for` loop where it reads the
    next message from the client and echoes it back. The server''s `for` loop keeps
    executing until the client terminates the RPC:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s take a look at the client implementation, which turns out to be
    a bit more convoluted since we need to deal with two asynchronous streams. In
    a typical bi-directional RPC implementation, we would spin up a go-routine to
    handle each end of the streams. However, to keep this example as simple as possible,
    we will only use a go-routine to process echo responses from the server, as shown
    in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: As shown in the preceding code snippet, the client invokes the `Echo` method
    on the echo service client and obtains a helper object (assigned to a variable
    called `stream`) to assist us with sending and receiving streaming data to and
    from the server. We then spin up a go-routine to execute `processEcho`, which
    is the function that's responsible for handling incoming echo responses. The function
    receives the `stream` object we obtained as an argument and a buffered error channel
    for reporting received errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows the implementation of `processEcho`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: The receiving end is almost identical to the server-side implementation. We
    keep reading echo messages from the stream until we get an error. If the `Recv` method
    returns an error other than `io.EOF`, we write it to the error channel prior to
    returning it.
  prefs: []
  type: TYPE_NORMAL
- en: Note that, in the preceding code snippet, the error channel is *always closed* when
    the function returns. The `Echo` method exploits this behavior so that it blocks
    until `processEcho` returns and dequeues emitted errors by using a `for` loop
    to range on `errCh`.
  prefs: []
  type: TYPE_NORMAL
- en: 'While the `processEcho` function is running in the background, the code calls
    out to `sendEcho`, a *synchronous* function that sends out `msgCount` echo requests
    and then returns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: So, how do we terminate this RPC? The call to the `CloseSend` method terminates
    the upstream channel to the server and causes the `Recv` method in the *server-side* code
    to return an `io.EOF` error. This triggers the server handler to exit and subsequently
    close its downstream channel to the client.
  prefs: []
  type: TYPE_NORMAL
- en: The `sendEcho` function returns to `Echo`, which then waits for `processEcho` to
    exit. As soon as the server terminates the downstream channel, the `Recv` call
    in `processEcho` will also return an `io.EOF` error and cause the `processEcho` go-routine
    to return. This last step unblocks the `Echo` call, which can now return to its
    caller.
  prefs: []
  type: TYPE_NORMAL
- en: Security considerations for gRPC APIs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The constructor for each of the RPC clients that the protoc compiler generated
    for you expects a `grpc.Connection` argument. This is intentional as a single
    remote server might expose multiple RPC services. Given that HTTP/2 supports request
    multiplexing, it makes sense to instantiate a single connection to the server
    and share it between the various RPC clients.
  prefs: []
  type: TYPE_NORMAL
- en: So, how can we obtain a `grpc.Connection` instance? The `grpc` package provides
    a convenience helper called `Dial`, which handles all the low-level details for
    establishing a connection to a gRPC server. The `Dial` function expects the address
    of the gRPC server we want to connect to and a variadic list of `grpc.DialOption` values.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, it is important to note that the gRPC dialer assumes that the
    remote server will be secured with TLS and will fail to establish a connection
    if this happens not to be the case. We can definitely come up with scenarios where
    the use of TLS might not be required:'
  prefs: []
  type: TYPE_NORMAL
- en: We might be running a local gRPC server on our development machine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We might spin up a gRPC server as part of a test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of our backend services might be running in a private subnet that can't
    be reached from the internet
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To cater for such use cases, we can force gRPC to establish connections to non-TLS
    servers by providing the `grpc.WithInsecure()` dial option to the `Dial` function.
  prefs: []
  type: TYPE_NORMAL
- en: If you do opt for the recommended approach and use TLS everywhere, you will
    be pleasantly surprised to find that the methods for securing RESTful APIs that
    we discussed at the beginning of this chapter can also be applied to gRPC! The
    gRPC framework allows you to configure security at two different levels, namely,
    at the **connection** and at the **application** level.
  prefs: []
  type: TYPE_NORMAL
- en: At the connection level, gRPC allows us to manually configure the options for
    the TLS handshake with the help of the `grpc.WithTransportCredentials` dial option,
    which takes a `credentials.TransportCredentials` argument. The `grpc/credentials` package
    contains helpers that produce `TransportCredentials` from certificates (if you
    wish to implement client authentication via provisioned TLS certificates) and `tls.Config` instances
    (for implementing server certificate pinning).
  prefs: []
  type: TYPE_NORMAL
- en: As far as application-level security is concerned, gRPC offers the `grpc.WithPerRPCCredentials` dial
    option. This option accepts a `credentials.PerRPCCredentials` instance and allows
    gRPC clients to automatically inject the provided set of credentials into every
    outgoing RPC. The `grpc/credentials/oauth` package provides helpers for dealing
    with different authorization mechanisms. For instance, the `oauth.NewOauthAccess` function
    allows us to use an `oauth2.Token` instance that we have obtained via a three-legged
    OAuth2 flow with our RPCs.
  prefs: []
  type: TYPE_NORMAL
- en: On the other end, the server uses specialized middleware (gRPC refers to middleware
    with the term *request interceptors*) to access the credentials provided by clients
    and control access to RPC methods.
  prefs: []
  type: TYPE_NORMAL
- en: Decoupling Links 'R' Us components from the underlying data stores
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Both the link-crawler component that we created in [Chapter 7](51dcc0d4-2ba3-4db9-83f7-fcf73a33aa74.xhtml), *Data-Processing
    Pipelines*, and the PageRank calculator component that we built in [Chapter 8](c505ec2d-0bd8-4edd-97e1-d06de2b326a5.xhtml),
    *Graph-Based Data Processing*, were designed to work with one of the data store
    implementations from [Chapter 6](ce489d62-aaa3-4fbb-b239-c9de3daa9a8f.xhtml),
    *Building a Persistence Layer*.
  prefs: []
  type: TYPE_NORMAL
- en: 'To this end, when configuring these components, we are expected to provide
    suitable concrete data store implementations that satisfy the `graph.Graph` and `index.Indexer` interfaces.
    If we were building a monolithic application, we would normally be performing
    this bit of initialization inside the `main` package, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Import the package with the data store drivers we want to use in our application
    (for example, the **CockroachDB **backed link-graph and the **Elasticsearch **backed
    text indexer).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create new driver instances and configure them accordingly with a static or
    externally provided driver-specific set of settings (for example, the endpoints
    for the CockroachDB or Elasticsearch cluster).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialize the link-crawler and PageRank calculator components using the data
    store instances we just created. This works out of the box as all datastore implementations
    from [Chapter 6](ce489d62-aaa3-4fbb-b239-c9de3daa9a8f.xhtml), *Building a Persistence
    Layer**,* satisfy the aforementioned interfaces and can be directly assigned to
    the configuration objects that are passed as arguments to the component constructors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As we will see in the next chapter, we can make our application a bit more flexible
    by having our code import the packages for all the supported link-graph and text-indexer
    provider implementations and dynamically instantiate one of them at runtime after
    consulting the value of a command-line flag.
  prefs: []
  type: TYPE_NORMAL
- en: One of the issues with this approach is that it introduces a strong coupling
    to a particular data store implementation. What if our design requirements involve
    the creation of multiple applications that all need to use the same datastore
    providers?
  prefs: []
  type: TYPE_NORMAL
- en: To apply the aforementioned steps, we would need to duplicate the same initialization
    logic across all our applications. That would violate the **Don't Repeat Yourself**
    (**DRY**) principle and make our code base harder to maintain. Moreover, think
    about the amount of effort that would be required if we are asked to add support
    for a new data store implementation. We would essentially need to modify and recompile
    all our applications!
  prefs: []
  type: TYPE_NORMAL
- en: Given the list of problems related to having a strong coupling between applications
    and data stores, what options do we, as software engineers, have to reduce or
    ideally eliminate this coupling when designing new systems? An elegant solution
    would be to create a standalone proxy service that provides access to a particular
    data store implementation through a REST or (preferably) gRPC-based API. This
    pattern allows us to effectively switch to a different data store at any point
    in time without having to recompile any of our applications that consume the API.
  prefs: []
  type: TYPE_NORMAL
- en: In the last part of this chapter, we will apply what we have learned so far
    and build gRPC-based APIs so that we can access the link-graph and text-indexer
    components over the network. To keep things as consistent as possible, both the
    RPC names and the field list of the messages that are exchanged between the client
    and the server will *mimic* the signatures of the methods defined by the `graph.Graph`
    and `index.Indexer` interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: In accordance with the instructions from the previous sections, we will be using
    the protocol buffer definition language to specify the RPCs for our APIs.
  prefs: []
  type: TYPE_NORMAL
- en: Defining RPCs for accessing a remote link-graph instance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first API that we will be designing will grant our project''s applications
    access to any concrete link-graph implementation that satisfies the `graph.Graph`
    interface over a network link. The following snippet outlines the protocol buffer
    definitions for the RPC endpoints that we will need:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The `UpsertLink` call inserts a new link to the graph or updates the details
    of an existing link. The call receives and returns a `Link` message, whose definition
    is shown in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Link` message includes the following bits of information:'
  prefs: []
  type: TYPE_NORMAL
- en: The UUID of the link. Given that protocol buffers do not offer a native type
    for storing UUIDs (16-byte values), we will be representing them as a *byte slice*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The link's URL.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The timestamp when the link was last retrieved by the crawler.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `UpsertEdge` call inserts a new edge to the graph or updates the details
    of an existing edge. The call receives and returns an `Edge` message with the
    following definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Each `Edge` message includes the following bits of information:'
  prefs: []
  type: TYPE_NORMAL
- en: The UUID of the edge
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The UUIDs of the source and destination vertices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A timestamp indicating when the edge was last updated by the crawler
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The next call on our list is `RemoveStaleEdges`. As you may recall from [Chapter
    7](51dcc0d4-2ba3-4db9-83f7-fcf73a33aa74.xhtml), *Data-Processing Pipelines*, this
    call is required by the web-crawler component to discard missing (stale) edges
    every time it retrieves the latest contents of a web page in the link-graph.
  prefs: []
  type: TYPE_NORMAL
- en: What's interesting about this particular RPC is that while it accepts a `RemoveStaleEdgesQuery` message
    as input, it doesn't really need to return a result to the caller. However, since
    gRPC mandates that all RPCs return some message to the caller, we will use `google.protobuf.Empty`
    (a placeholder type for an empty/void message) as the RPC's return type.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a quick look at the definition of the `RemoveStaleEdgesQuery` message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: The last two methods on our RPC list are `Links` and `Edges`. Both calls expect
    the client to provide a `Range` message as input. This message allows clients
    to specify the set of arguments that the server will pass through to the similarly-named
    method of the underlying concrete link-graph implementation, namely, the UUID
    range for selecting the set of entities (links or edges) to return and a cutoff
    timestamp for filtering entities with a more recent last retrieved/updated value.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following snippet outlines the definition of the `Range` message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Up to this point, all the RPCs that we have examined are unary. However, the `Links` and `Edges` calls
    differ in that they are declared as *server-streaming* RPCs. The use of streaming
    allows clients to process the returned list of links and edges more efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will examine the RPC definitions for accessing the text-indexer.
  prefs: []
  type: TYPE_NORMAL
- en: Defining RPCs for accessing a text-indexer instance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The second API that we will be designing will grant our project''s applications
    access to any concrete link-graph implementation that satisfies the `index.Indexer` interface
    over a network link. The following snippet outlines the protocol buffer definitions
    for the RPC endpoints that we will need:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Index` method inserts a document into the search index or triggers a reindexing
    operation if the document already exists. As you can see by its method definition,
    the call expects and returns a `Document` message, which is shown in the following
    code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: A successful call to `Index` will return the same `Document` that was passed
    as input. However, the document will also have the `indexed_at` field populated/updated
    by the remote server.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next call that we will be examining is `UpdateScore`. This call will be
    used by the PageRank calculator component to set the PageRank score for a particular
    document. The call accepts an `UpdateScoreRequest` message and returns nothing
    (hence the use of the `google.protobuf.Empty` placeholder message):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The last, and more interesting, RPC method that we will be discussing is `Search`.
    Calls to `Search` accept a `Query` message as input and return a *stream* of `QueryResult` responses:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the message definitions for `Query` and `QueryResult` are a
    bit more complicated. To begin with, the `Query` message defines a nested enumeration
    for specifying the type of query to be executed. By default, the query expression
    is treated as a regular keyword-based search (`MATCH` is the default value for
    the `type` field).
  prefs: []
  type: TYPE_NORMAL
- en: However, the caller can also request a phrase-based search by specifying `PHRASE`
    as the value of the `type` field. Furthermore, callers are also allowed to specify
    an offset and instruct the server to skip a number of results from the top of
    the returned result set. This mechanism can be used by clients to implement pagination.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `QueryResult` message uses the **one-of** feature of protocol buffers.
    This message can either contain a `uint64` value that describes the total number
    of documents matched by the query or the next `Document` from the result set.
    Our server implementation will use the following simple protocol to stream results
    to the client:'
  prefs: []
  type: TYPE_NORMAL
- en: The *first* message in the result stream will *always* describe the total number
    of results for the search. If no documents matched the search query, the server
    will indicate this by setting the `doc_count` field to the value `0`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each subsequent message will push the `Document` that matches the client.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating high-level clients for accessing data stores over gRPC
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The *protoc* compiler, given the RPC definitions from the previous two sections
    as input, will generate a client and the required server stubs for the data store
    proxy service.
  prefs: []
  type: TYPE_NORMAL
- en: 'From the perspective of the API server, each RPC method is nothing more than
    a wrapper for invoking the similarly-named method of the underlying concrete store
    implementation that we configured the server to use. More specifically, to implement
    the RPC method called **X**, we perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Convert the fields of the RPC's input message (where required) into the values
    expected by the wrapped method, *X.*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Invoke X while watching out for any errors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Convert and pack the output of X into the appropriate return message for the
    RPC.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Return the generated response to the client.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As you can probably tell, our server implementation will mostly consist of boring
    boilerplate code that uses the recipe we just described as a template. To conserve
    some space, we will omit the implementation details from this book. However, you
    can take a look at the full source code for the two API servers by examining the
    `server.go` files in the `Chapter09/linksrus/linkgraphapi` and `Chapter09/linksrus/textindexerapi`
    packages, which can be found in this book's GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: With the RPC server in place, our applications can establish a connection to
    it and use the gRPC client that the *protoc* compiler generated for us to access
    the link-graph and text-indexer components on the other end. An unfortunate caveat
    of our current implementation is that since the auto-generated gRPC clients do
    not implement the `graph.Graph` and `index.Indexer` interfaces, we cannot use
    them as drop-in replacements for configuring the crawler and PageRank calculator
    components.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, there is an elegant way to work around this inconvenience! The
    package for each API will also need to define a *high-level* client that *wraps* the
    gRPC client that the protoc compiler generated for us and implements, depending
    on the API, either the `graph.Graph` interface or the `index.Indexer` interface.
  prefs: []
  type: TYPE_NORMAL
- en: Behind the scenes, the high-level client will transparently handle all interactions
    with the remote gRPC server. While this approach does require additional development
    effort, it makes the high-level client appear as yet another graph or indexer
    implementation that we can inject into the **Links 'R' Us components** without
    requiring any code changes. In [Chapter 11](dfb5c555-2534-4bac-b661-34cb9e7a3da8.xhtml),
    *Splitting Monoliths into Microservices,* we will be exploiting this trick to
    split the Links 'R' Us project into a set of microservices!
  prefs: []
  type: TYPE_NORMAL
- en: In a similar fashion to the server implementation, the high-level client also
    consists of quite a bit of repetitive boilerplate code, so in the interest of
    brevity, we will also omit its listing from this chapter. The full source code
    for the two high-level clients can be found in a file called `client.go`, which
    is in the same location as the server implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the first part of this chapter, we discussed the key principles behind RESTful
    APIs. We focused on effective strategies for handling hot topics such as security
    and versioning. Then, we analyzed the pros and cons of RESTful APIs compared to
    the RPC-base paradigm used by the gRPC framework and highlighted the key differences
    that make gRPC more suitable for building high-performance services.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you're at the end of this chapter, you should be familiar with the
    protocol buffer definition language and know how to leverage the various features
    supported by the gRPC framework for building high-performance secure APIs based
    on the RPC pattern.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will find out how we can perform hermetic builds of
    our software, package it as a container image, and deploy it on a Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Describe the CRUD endpoints for a user entity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Explain how basic authentication over TLS can help us secure APIs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Are TLS connections immune to eavesdropping?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Describe the steps in the three-legged OAuth2 flow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the benefit of using protocol buffers compared to JSON for request/response
    payloads?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Describe the different RPC modes that are supported by gRPC.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*A Go web development eco-system, designed to make your life easier;* refer
    to the following link for more information: [https://github.com/gobuffalo/buffalo](https://github.com/gobuffalo/buffalo).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*A high performance, open-source universal RPC framework;* refer to the following
    link for more information: [https://www.grpc.io](https://www.grpc.io).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*A high-performance HTTP request router that scales well*; refer to the following
    link for more information: [https://github.com/julienschmidt/httprouter](https://github.com/julienschmidt/httprouter).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*A high productivity, full-stack web framework for the Go language; *refer
    to the following link for more information: [https://github.com/revel/revel](https://github.com/revel/revel).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*A powerful HTTP router and URL matcher for building Go web servers;* refer
    to the following link for more information: [https://github.com/gorilla/mux](https://github.com/gorilla/mux).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Berners-Lee, T.; Fielding, R.; Masinter, L.: RFC 3986, **Uniform Resource Identifier**
    (**URI**): Generic Syntax.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Developer guide for protocol buffer v3;* refer to the following link for more
    information: [https://developers.google.com/protocol-buffers/docs/proto3](https://developers.google.com/protocol-buffers/docs/proto3).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Fast HTTP package for Go. Tuned for high performance. Zero memory allocations
    in hot paths. Up to 10x faster than net/http*; refer to the following link for
    more information: [https://github.com/valyala/fasthttp](https://github.com/valyala/fasthttp).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Media Type Specifications and Registration Procedures;* refer to the following
    link for more information: [https://tools.ietf.org/html/rfc6838](https://tools.ietf.org/html/rfc6838).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*The fastest full-featured web framework for Go; *refer to the following link
    for more information:[https://github.com/gin-gonic/gin](https://github.com/gin-gonic/gin).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*The meaning of the letter g in gRPC;* refer to the following link for more
    information: [https://github.com/grpc/grpc/blob/master/doc/g_stands_for.md](https://github.com/grpc/grpc/blob/master/doc/g_stands_for.md).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
