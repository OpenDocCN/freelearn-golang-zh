<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Splitting Monoliths into Microservices</h1>
                </header>
            
            <article>
                
<div class="packt_quote">"If the components do not compose cleanly (when migrating to microservices), then all you are doing is shifting the complexity from inside a component to the connections between components. This does not just move complexity around; it moves it to a place that's less explicit and harder to control."</div>
<div class="packt_quote CDPAlignRight CDPAlign"><span>– Martin Fowler and James Lewis</span></div>
<p>This chapter introduces the concept of <strong>Service-Oriented Architecture</strong> (<strong>SOA</strong>) and compares it with the traditional monolithic design pattern. This will help us discuss the various challenges of microservices such as logging, tracing, and service introspection, and provides advice for reducing the pain points from moving to an SOA.</p>
<p>Toward the end of this chapter, we will be breaking down the monolithic Links 'R' Us implementation from the previous chapter into several microservices and deploying them to Kubernetes.</p>
<p>The following topics will be covered in this chapter:</p>
<ul>
<li>When is a good time to switch from monolithic design to a microservice-based architecture?</li>
<li>Common anti-patterns for microservice implementations and how to work around them</li>
<li>Tracing requests through distributed systems</li>
<li>Best practices for logging and pitfalls to avoid</li>
<li>Introspection of live Go services</li>
<li>Breaking down the Links 'R' Us monolith into microservices and deploying them to Kubernetes</li>
<li>Locking down access to microservices using Kubernetes network policies</li>
</ul>
<p><span>By leveraging the knowledge you will have obtained in this chapter, you will be able to horizontally scale your own projects so as to better handle spikes in incoming traffic.  </span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>The full code for the topics that will be discussed in this chapter has been published to this book's GitHub repository under the<span> </span><kbd>Chapter11</kbd> folder.</p>
<div class="packt_infobox">You can access this book's GitHub repository, which contains the code and all the required resources for each chapter in this book, by pointing your web browser to the following URL: <a href="https://github.com/PacktPublishing/Hands-On-Software-Engineering-with-Golang">https://github.com/PacktPublishing/Hands-On-Software-Engineering-with-Golang</a>.</div>
<p>To get you up and running as quickly as possible, each example project includes a<span> Makefile</span><span> </span><span>that defines the following set of targets:</span></p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td><strong>Makefile target</strong></td>
<td><strong>Description</strong></td>
</tr>
<tr class="odd">
<td><kbd>deps</kbd></td>
<td>Installs any required dependencies</td>
</tr>
<tr class="even">
<td><kbd>test</kbd></td>
<td>Runs all tests and report coverage</td>
</tr>
<tr class="odd">
<td><kbd>lint</kbd></td>
<td>Checks for lint errors</td>
</tr>
</tbody>
</table>
<p> </p>
<p>As with all the other chapters in this book, you will need a fairly recent version of Go, which you can download at<span> <a href="https://golang.org/dl/">https://golang.org/dl/</a></span><em>.</em></p>
<p>To run some of the code examples in this chapter, you will need to have a working Docker <sup>[4]</sup> installation on your machine.</p>
<p>Furthermore, a subset of the examples are designed to run on Kubernetes. If you don't have access to a Kubernetes cluster for testing, you can simply follow the instructions laid out in the following sections to set up a small cluster on your laptop or workstation.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Monoliths versus service-oriented architectures</h1>
                </header>
            
            <article>
                
<p>In the last couple of years, more and more organizations, especially in the start up scene, have been actively embracing the SOA paradigm either for building new systems or for modernizing existing legacy systems.</p>
<div class="packt_infobox">SOA is an architectural approach to creating systems that have been built from autonomous services that may be written in different programming languages and communicate with each other over a network link.</div>
<p>In the following sections, we will examine this architectural pattern in more detail and highlight some best practices for migrating from a monolithic application to microservices. At the same time, we will explore some common anti-patterns that can impede the transition to a microservice-based architecture.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Is there something inherently wrong with monoliths?</h1>
                </header>
            
            <article>
                
<p>Before you decide to take the plunge and convert your monolithic application into an SOA, you should take a small pause and ask yourself: is a microservice-based design the right model for my application<span> </span><em>at this point in time</em>?</p>
<div class="packt_tip">Try not to be influenced by the hype surrounding microservices! Just because this kind of model works at a massive scale for companies such as Google, Netflix, or Twitter, it doesn't mean that it also will for your particular use case.<br/>
<br/>
Monolithic system designs have been around for much longer and have proven themselves time and time again when it comes to supporting business-critical systems. As the saying goes: if it's good enough for banks and airlines, it's probably adequate for your next start up idea!</div>
<p>In many cases, the decision to transition to a microservice-based architecture is driven purely by necessity; scaling large, monolithic systems to deal with irregular spikes in traffic can prove to be quite costly and can oftentimes lead to underutilization of the resources available at our disposal. This is a great example where switching to microservices would most probably have both an observable and measurable effect.</p>
<p>On the other hand, if you are building a new product or a <strong>minimum viable product</strong> (<strong>MVP</strong>), it is always much easier to begin with a monolithic design and introduce the right abstractions from the start to facilitate an easier transition path to microservices, if and when that is required.</p>
<p>Lots of new start-ups get trapped in the mentality that microservices are the next best thing since sliced bread and forget about the hidden cost of such an architecture: increased complexity, which directly translates to increased demand for DevOps. As a result, engineering teams tend to spend a significant chunk of their development time debugging communication issues or setting up elaborate schemes for monitoring microservices instead of focusing their efforts on building and developing their core product.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Microservice anti-patterns and how to deal with them</h1>
                </header>
            
            <article>
                
<p>Now, let's take a look at some anti-patterns that you might encounter when working with microservice-based projects and explore alternative ways of dealing with them.</p>
<p><em>Sharing a database</em><span> </span>is probably the biggest mistake that engineers new to the microservice pattern make when they attempt to split a monolith into microservices for the first time. As a rule of thumb, each microservice must be provisioned with its own, private data store (assuming it needs one) and expose an API so that other microservices can access it. This pattern provides us with the flexibility to select the most suitable technology (for example, NoSQL, relational) for the needs of each particular microservice.</p>
<p>Communication between microservices might fail for a variety of reasons (for example, a service crash, network partition, or lost packets). A correct microservice implementation should operate under the assumption that outbound calls can fail at any time. Instead of immediately bailing out with an error when things go wrong, microservices should always implement some sort of<span> </span><em>retry logic</em>.</p>
<p>A corollary to the preceding statement is that when a connection to a remote microservice drops before receiving a reply, the client cannot be sure whether the remote server actually managed to process the request. Based on the preceding recommendation, the client will typically retry the call. Consequently, every microservice that exposes an API must be written in such a way so that requests are always<span> </span><em>idempotent</em>.</p>
<p>Another common anti-pattern is to allow a service to become a<span> </span><em>single point of failure</em><span> </span>for the entire system. Imagine a scenario where you have three services that all depend on a piece of data that's been exposed by a fourth, downstream service. If the latter service is underprovisioned, a sudden request in traffic to the three upstream services might cause requests to the downstream service to time out. The upstream services would then retry their requests, increasing the load on the downstream service even further, up to the point where it becomes unresponsive or crashes. As a result, the upstream services now begin experiencing elevated error rates that affect calls that are made to them by other upstream services, and so on and so forth.</p>
<p>To avoid situations like this, microservices can implement the circuit breaker pattern: when the number of errors from a particular downstream service exceeds a particular threshold, the circuit breaker is tripped and all future requests automatically fail with an error. Periodically, the circuit breaker lets some requests go through and after a number of successful responses, the circuit breaker switches back to the open position, allowing all requests to go through.</p>
<p>By implementing this pattern into your microservices, we allow downstream services to recover from load spikes or crashes. Moreover, some services might be able to respond with cached data when downstream services are not available, thus ensuring that the system remains functional, even in the presence of problems.</p>
<p>As we have already explained, microservice-based architectures are inherently complex as they consist of a large number of moving parts. The biggest mistake that we can make is switching to this kind of architecture before laying down the necessary infrastructure for collecting the log output of each microservice and monitoring its health. Without this infrastructure in place, we are effectively flying blind. In the next section, we will explore a few different approaches to microservice instrumentation and monitoring.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Monitoring the state of your microservices</h1>
                </header>
            
            <article>
                
<p>In the following sections, we will be analyzing an array of different approaches for monitoring the state of a microservice deployment:</p>
<ul>
<li>Request tracing</li>
<li>Log collection and aggregation</li>
<li>Introspection of live Go services with the help of <kbd>pprof</kbd></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Tracing requests through distributed systems</h1>
                </header>
            
            <article>
                
<p>In a world where you might have distributed systems with hundreds or thousands of microservices running, request tracing is an invaluable tool for figuring out bottlenecks, understanding the dependencies between individual services, and figuring out the root cause of issues that affect production systems.</p>
<p>The idea behind tracing is to tag an incoming (usually external) request with a unique identifier and keep track of it as it propagates through the system, hopping from one microservice to the next until it eventually exits the system.</p>
<p>The concept of a distributed tracing system is definitely not new. In fact, systems such as Google's Dapper<span> </span><sup><span class="citation">[17]</span></sup><span> </span>and Twitter's Zipkin<span> </span><sup><span class="citation">[16]</span></sup><span> </span>have been around for almost a decade. So, why isn't everyone jumping on the wagon and implementing it for their code bases? The reason is simple: up until now, updating your entire code base to support request tracing used to be a daunting task.</p>
<p>Imagine a system where the components communicate with each other via different types of transports, that is, some microservices use REST, others use gRPC, and others perhaps exchange events over WebSockets. Ensuring that request IDs get injected into all outgoing requests and unmarshaled on the receiving end requires quite a bit of effort to implement across all microservices. What's more, if you were to go down this route, you would be expected to do a bit of research, select a tracing<span> </span><em>vendor</em><span> </span>to use, and finally integrate with their (typically proprietary) API, which would effectively lock you into their offering.</p>
<p>There's got to be a better way to implement request tracing!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The OpenTracing project</h1>
                </header>
            
            <article>
                
<p>The OpenTracing<span> </span><sup><span class="citation">[18]</span></sup><span> </span>project was created to solve exactly the set of problems that we outlined in the previous section. It provides a standardized, vendor-neutral API that software engineers can use to instrument their code base to enable support for request tracing. Moreover, OpenTracing not only dictates the appropriate encoding for transferring trace contexts<span> </span><em>across service boundaries</em>,<span> </span>but also provides APIs to facilitate the exchange of tracing context over REST and gRPC transports.</p>
<p>Before we continue, let's spend some time explaining a term that we will be using quite a lot in the following sections. A request trace is comprised of a sequence of<span> </span><strong>spans</strong>. A span represents a timed unit of work that executes inside a microservice. In a typical scenario, a new span begins when the service receives a request and ends when the service returns a response.</p>
<p>Furthermore, spans can also be nested. If service<span> </span><em>A</em><span> </span>needs to contact downstream services<span> </span><em>B</em><span> </span>and<span> </span><em>C</em><span> </span>for additional data before it can send back a response, then the spans from<span> </span><em>B</em><span> </span>and<span> </span><em>C</em><span> </span>can be added as children of<span> </span><em>A</em>'s span. Consequently, a request trace can be thought of as a<span> </span><em>tree of spans</em><span> </span>whose root is the service that received the initial request.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Stepping through a distributed tracing example</h1>
                </header>
            
            <article>
                
<p>To understand how distributed tracing works, let's build a small demo application that simulates a system for collecting price quotes for a particular SKU from a variety of vendors. You can find the full source code for this demo in the<span> </span><kbd>Chapter11/tracing</kbd><span> </span>folder of this book's GitHub repository.</p>
<p>Our system will feature three types of services, all of which will be built on top of gRPC:</p>
<ul>
<li>The<span> </span><strong>provider</strong><span> </span>service returns price quotes for a single vendor. For our example scenario, we will be spinning up multiple provider instances to simulate different vendor systems.</li>
<li>An<span> </span><strong>aggregator</strong><span> </span>service that sends incoming queries to a list of downstream services (providers or other aggregators) collects the responses and returns the aggregated results.</li>
<li>An<span> </span><strong>API gateway</strong><span> </span>service, which will serve as the root of the captured request traces. In the real world, the API gateway would handle requests from a frontend application running on the users' browser.</li>
</ul>
<p>Let's begin by listing the protocol buffer and RPC definitions for the services:</p>
<div class="sourceCode">
<pre class="sourceCode proto"><a><span class="kw">message</span> QuotesRequest {</a>
<a>  <span class="dt">string</span> SKU = <span class="dv">1</span>;</a>
<a>}</a>

<a><span class="kw">message</span> QuotesResponse {</a>
<a>  <span class="kw">repeated</span> Quote quotes = <span class="dv">1</span>;</a>
<a>}</a>

<a><span class="kw">message</span> Quote {</a>
<a>  <span class="dt">string</span> vendor = <span class="dv">1</span>;</a>
<a>  <span class="dt">double</span> price = <span class="dv">2</span>;</a>
<a>}</a>

<a>service QuoteService {</a>
<a>  rpc GetQuote(QuotesRequest) returns (QuotesResponse);</a>
<a>}</a></pre></div>
<p>As you can see, we define a single RPC named<span> </span><kbd>GetQuote</kbd><span> </span>that receives a<span> </span><kbd>QuotesRequest</kbd><span> </span>and returns a<span> </span><kbd>QuotesResponse</kbd>. The response is simply a collection to<span> </span><kbd>Quote</kbd><span> </span>objects, with each one consisting of a<span> </span><kbd>vendor</kbd><span> </span>and a<span> </span><kbd>price</kbd><span> </span>field.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The provider service</h1>
                </header>
            
            <article>
                
<p>The first and easiest service to implement is <kbd>Provider</kbd>. The following is the definition for the<span> </span><kbd>Provider</kbd> type and its constructor:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">type</span> Provider <span class="kw">struct</span> {</a>
<a>    vendorID <span class="dt">string</span></a>
<a>}</a>

<a><span class="kw">func</span> NewProvider(vendorID <span class="dt">string</span>) *Provider {</a>
<a>    <span class="kw">return</span> &amp;Provider{ vendorID: vendorID }</a>
<a>}</a></pre></div>
<p>Next, we will implement the<span> </span><kbd>GetQuote</kbd><span> </span>method, as specified in the preceding protocol buffer definitions. To keep our example as simple as possible, we will provide a dummy implementation that returns a single quote with a random price value and the<span> </span><kbd>vendorID</kbd><span> </span><span>value that was passed as an argument to the</span><span> </span><kbd>NewProvider</kbd><span> </span><span>constructor:</span></p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (p *Provider) GetQuote(ctx context.Context, req *proto.QuotesRequest) (*proto.QuotesResponse, <span class="dt">error</span>) {</a>
<a>    <span class="kw">return</span> &amp;proto.QuotesResponse{</a>
<a>        Quotes: []*proto.Quote{</a>
<a>            &amp;proto.Quote{ Vendor: p.vendorID, Price:  <span class="dv">100</span><span class="fl">.0</span> * rand.Float64() },</a>
<a>        },</a>
<a>    }, <span class="ot">nil</span></a>
<a>}</a></pre></div>
<p>To simulate a microservice architecture, our main file will start multiple instances of this service. Each service instance will create its own gRPC server and bind it to a random port. Let's implement this functionality for the<span> </span><kbd>Provider</kbd><span> </span>type:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (p *Provider) Serve(ctx context.Context) (<span class="dt">string</span>, <span class="dt">error</span>) {</a>
<a>    <span class="kw">return</span> doServe(ctx, p, tracer.MustGetTracer(p.vendorID))</a>
<a>}</a></pre></div>
<p>The<span> </span><kbd>tracer</kbd><span> </span>package encapsulates the required logic for creating tracer instances that satisfy the<span> </span><kbd>opentracing.Tracer</kbd><span> </span>interface. The obtained tracer will be used for each of the services that we will be creating so that it can collect and report spans. In the following sections, we will explore the implementation of this package when we select a suitable tracing provider for our example.</p>
<p>After obtaining a tracer, the<span> </span><kbd>Serve</kbd><span> </span>method calls out to<span> </span><kbd>doServe</kbd><span>, </span>whose task is to expose a gRPC server to a random available port and return its listen address. The<span> </span><kbd>doServe</kbd><span> </span>code, which is listed in the following code block, has been intentionally extracted since we will be using this to implement the aggregator service:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> doServe(ctx context.Context, srv proto.QuoteServiceServer, tracer opentracing.Tracer) (<span class="dt">string</span>, <span class="dt">error</span>) {</a>
<a>    l, err := net.Listen(<span class="st">"tcp"</span>, <span class="st">":0"</span>)</a>
<a>    <span class="kw">if</span> err != <span class="ot">nil</span> {</a>
<a>        <span class="kw">return</span> <span class="st">""</span>, err</a>
<a>    }</a>
<a>    tracerOpt := grpc.UnaryInterceptor(otgrpc.OpenTracingServerInterceptor(tracer))</a>
<a>    gsrv := grpc.NewServer(tracerOpt)</a>
<a>    proto.RegisterQuoteServiceServer(gsrv, srv)</a>
<a>    <span class="kw">go</span> <span class="kw">func</span>() {</a>
<a>        <span class="kw">go</span> <span class="kw">func</span>() { _ = gsrv.Serve(l) }()</a>
<a>        &lt;-ctx.Done()</a>
<a>        gsrv.Stop()</a>
<a>        _ = l.Close()</a>
<a>    }()</a>
<a>    <span class="kw">return</span> l.Addr().String(), <span class="ot">nil</span></a>
<a>}</a></pre></div>
<p>The first lines in the preceding function ask the<span> </span><kbd>net</kbd><span> </span>package to listen to a random free port by passing<span> </span><kbd>:0</kbd><span> </span>as the listen address. The next line is where the real magic happens! The<span> </span><kbd>grpc-opentracing</kbd><span> </span><sup><span class="citation">[10]</span></sup><span> </span>package provides gRPC interceptors that decode tracing-related information from incoming gRPC requests and<span> </span><em>embed</em><span> </span>them into the request context that is passed to the RPC method implementations.</p>
<div class="packt_infobox">A gRPC interceptor is a kind of middleware that wraps an RPC call and provides additional functionality. Depending on the type of call that is being wrapped, interceptors are classified as unary or streaming.<br/>
<br/>
Moreover, interceptors can be applied on the server- or client-side. On the server-side, interceptors are typically used to implement features such as authentication, logging, and metrics collection. Client-side interceptors can be used to implement patterns such as circuit breakers or retries.</div>
<p>Since our service only defines a unary RPC, we need to create a unary interceptor and pass it to the<span> </span><kbd>grpc.NewServer</kbd><span> </span>function. Then, we register the RPC implementation with the server and spin up a goroutine so that we can start serving requests until the provided context expires. While the goroutine is running, the function returns with the address of the server listener.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The aggregator service</h1>
                </header>
            
            <article>
                
<p>The next service that we will be implementing is the<span> </span><kbd>Aggregator</kbd> type. As shown in the following code snippet, it stores a vendor ID, a list of provider addresses to query, and a list of gRPC clients for those addresses:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">type</span> Aggregator <span class="kw">struct</span> {</a>
<a>    vendorID      <span class="dt">string</span></a>
<a>    providerAddrs []<span class="dt">string</span></a>
<a>    clients       []proto.QuoteServiceClient</a>
<a>}</a>

<a><span class="kw">func</span> NewAggregator(vendorID <span class="dt">string</span>, providerAddrs []<span class="dt">string</span>) *Aggregator {</a>
<a>    <span class="kw">return</span> &amp;Aggregator{</a>
<a>        vendorID:      vendorID,</a>
<a>        providerAddrs: providerAddrs,</a>
<a>    }</a>
<a>}</a></pre></div>
<p>The gRPC clients are lazily created when the<span> </span><kbd>Serve</kbd><span> </span>method is invoked:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (a *Aggregator) Serve(ctx context.Context) (<span class="dt">string</span>, <span class="dt">error</span>) {</a>
<a>    tracer := tracer.MustGetTracer(a.vendorID)</a>
<a>    tracerClientOpt := grpc.WithUnaryInterceptor(otgrpc.OpenTracingClientInterceptor(tracer))</a>

<a>    <span class="kw">for</span> _, addr := <span class="kw">range</span> a.providerAddrs {</a>
<a>        conn, err := grpc.Dial(addr, grpc.WithInsecure(), tracerClientOpt)</a>
<a>        <span class="kw">if</span> err != <span class="ot">nil</span> {</a>
<a>            <span class="kw">return</span> <span class="st">""</span>, xerrors.Errorf(<span class="st">"dialing provider at %s: %w"</span>, addr, err)</a>
<a>        }</a>
<a>        a.clients = <span class="bu">append</span>(a.clients, proto.NewQuoteServiceClient(conn))</a>
<a>    }</a>

<a>    <span class="kw">return</span> doServe(ctx, a, tracer)</a>
<a>}</a></pre></div>
<p>This time, we create a<span> </span><strong>client</strong><span> </span>unary interceptor and pass it as an option to each client connection that we dial. Then, we invoke the<span> </span><kbd>doServe</kbd><span> </span>helper that we examined in the previous section so that we can start our server. The use of interceptors for both the server<span> </span><strong>and</strong><span> </span>the client ensures that the trace context information that we receive from incoming requests gets<span> </span><strong>automatically</strong><span> </span>injected into any outgoing gRPC request without us having to do anything.</p>
<p>Finally, let's examine how the<span> </span><kbd>GetQuote</kbd><span> </span>method is implemented for the<span> </span><kbd>Aggregator</kbd><span> </span>type:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (a *Aggregator) GetQuote(ctx context.Context, req *proto.QuotesRequest) (*proto.QuotesResponse, <span class="dt">error</span>) {</a>
<a>    <span class="co">// Run requests in parallel and aggregate results</span></a>
<a>    aggRes := <span class="bu">new</span>(proto.QuotesResponse)</a>
<a>    <span class="kw">for</span> quotes := <span class="kw">range</span> a.sendRequests(ctx, req) {</a>
<a>        aggRes.Quotes = <span class="bu">append</span>(aggRes.Quotes, quotes...)</a>
<a>    }</a>
<a>    <span class="kw">return</span> aggRes, <span class="ot">nil</span></a>
<a>}</a></pre></div>
<p>This method is quite straightforward. All it does is allocate a new<span> </span><kbd>QuotesResponse</kbd>, invoke the<span> </span><kbd>sendRequests</kbd><span> </span>helper, flatten the results into a list, and return it to the caller. The<span> </span><kbd>sendRequests</kbd><span> </span>method queries the downstream providers in parallel and returns a channel where the quotes are posted:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (a *Aggregator) sendRequests(ctx context.Context, req *proto.QuotesRequest) &lt;-<span class="kw">chan</span> []*proto.Quote {</a>
<a>    <span class="kw">var</span> wg sync.WaitGroup</a>
<a>    wg.Add(<span class="bu">len</span>(a.clients))</a>
<a>    resCh := <span class="bu">make</span>(<span class="kw">chan</span> []*proto.Quote, <span class="bu">len</span>(a.clients))</a>
<a>    <span class="kw">for</span> _, client := <span class="kw">range</span> a.clients {</a>
<a>        <span class="kw">go</span> <span class="kw">func</span>(client proto.QuoteServiceClient) {</a>
<a>            <span class="kw">defer</span> wg.Done()</a>
<a>            <span class="kw">if</span> res, err := client.GetQuote(ctx, req); err == <span class="ot">nil</span> {</a>
<a>                resCh &lt;- res.Quotes</a>
<a>            }</a>
<a>        }(client)</a>
<a>    }</a>
<a>    <span class="kw">go</span> <span class="kw">func</span>() {</a>
<a>        wg.Wait()</a>
<a>        <span class="bu">close</span>(resCh)</a>
<a>    }()</a>
<a>    <span class="kw">return</span> resCh</a>
<a>}</a></pre></div>
<p>Notice how the request context argument from<span> </span><kbd>GetQuote</kbd><span> </span>is passed along to the<span> </span><kbd>client.GetQuote</kbd><span> </span>calls. This is all we need to do to associate the span from this service with the spans of the downstream services. Easy, right?</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The gateway</h1>
                </header>
            
            <article>
                
<p>The gateway service is nothing more than a wrapper on top of a gRPC client. The interesting bit of its implementation is the<span> </span><kbd>CollectQuotes</kbd><span> </span>method, which is what our main package will invoke to<span> </span><em>begin a new trace</em>:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> (gw *Gateway) CollectQuotes(ctx context.Context, SKU <span class="dt">string</span>) (<span class="kw">map</span>[<span class="dt">string</span>]<span class="dt">float64</span>, <span class="dt">error</span>) {</a>
<a>    span, ctx := opentracing.StartSpanFromContext(ctx, <span class="st">"CollectQuotes"</span>)</a>
<a>    <span class="kw">defer</span> span.Finish()</a>

<a>    res, err := gw.client.GetQuote(ctx, &amp;proto.QuotesRequest{SKU: SKU})</a>
<a>    <span class="kw">if</span> err != <span class="ot">nil</span> {</a>
<a>        <span class="kw">return</span> <span class="ot">nil</span>, err</a>
<a>    }</a>

<a>    quoteMap := <span class="bu">make</span>(<span class="kw">map</span>[<span class="dt">string</span>]<span class="dt">float64</span>, <span class="bu">len</span>(res.Quotes))</a>
<a>    <span class="kw">for</span> _, quote := <span class="kw">range</span> res.Quotes {</a>
<a>        quoteMap[quote.Vendor] = quote.Price</a>
<a>    }</a>
<a>    <span class="kw">return</span> quoteMap, <span class="ot">nil</span></a>
<a>}</a></pre></div>
<p>Here, we use <kbd>StartSpanFromContext</kbd><span> </span>to create a new<span> </span><em>named</em><span> </span>span and embed its trace details into a new context that wraps the one that was provided as an argument to the method.</p>
<p>The rest of the code is pretty self-explanatory: we invoke the<span> </span><kbd>GetQuote</kbd><span> </span>method on the embedded client instance, collect the responses, and place them in a map that we then return to the caller.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Putting it all together</h1>
                </header>
            
            <article>
                
<p>The main file prepares a microservice deployment environment via a call to the<span> </span><kbd>deployServices</kbd><span> </span>helper function. The idea here is to string together the services in such a manner so that tracing a request through the system will yield an interesting trace graph. Let's see how this is done.</p>
<p>First, the helper starts three<span> </span><kbd>Provider</kbd><span> </span>instances and keeps track of their addresses:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">var</span> err <span class="dt">error</span></a>
<a>providerAddrs := <span class="bu">make</span>([]<span class="dt">string</span>, <span class="dv">3</span>)</a>
<a><span class="kw">for</span> i := <span class="dv">0</span>; i &lt; <span class="bu">len</span>(providerAddrs); i++ {</a>
<a>    provider := service.NewProvider(fmt.Sprintf(<span class="st">"vendor-%d"</span>, i))</a>
<a>    <span class="kw">if</span> providerAddrs[i], err = provider.Serve(ctx); err != <span class="ot">nil</span> {</a>
<a>        <span class="kw">return</span> <span class="ot">nil</span>, err</a>
<a>    }</a>
<a>}</a></pre></div>
<p>Then, it starts an<span> </span><kbd>Aggregator</kbd><span> </span>instance and sets it up to connect to providers<span> </span><em>1</em><span> </span>and<span> </span><em>2</em><span> </span>from the preceding list:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a>aggr1 := service.NewAggregator(<span class="st">"aggr-1"</span>, providerAddrs[<span class="dv">1</span>:])</a>
<a>aggr1Addr, err := aggr1.Serve(ctx)</a>
<a><span class="kw">if</span> err != <span class="ot">nil</span> {</a>
<a>    <span class="kw">return</span> <span class="ot">nil</span>, err</a>
<a>}</a></pre></div>
<p>Following that, it instantiates yet another<span> </span><kbd>Aggregator</kbd><span> type </span>and connects it to provider<span> </span><em>0</em><span> </span>and the aggregator we just created:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a>aggr0 := service.NewAggregator(<span class="st">"aggr-0"</span>, []<span class="dt">string</span>{providerAddrs[<span class="dv">0</span>], aggr1Addr})</a>
<a>aggr0Addr, err := aggr0.Serve(ctx)</a>
<a><span class="kw">if</span> err != <span class="ot">nil</span> {</a>
<a>    <span class="kw">return</span> <span class="ot">nil</span>, err</a>
<a>}</a></pre></div>
<p>Finally, a<span> </span><kbd>Gateway</kbd><span> instance </span>is created with the preceding aggregator as its target and returned to the caller:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">return</span> service.NewGateway(<span class="st">"api-gateway"</span>, aggr0Addr)</a></pre></div>
<p>The<span> </span><kbd>Gateway</kbd><span> </span>instance that's returned by the<span> </span><kbd>deployServices</kbd><span> </span>function is used by<span> </span><kbd>runMain</kbd><span> </span>to trigger the execution of a quote query that marks the beginning of a new request trace:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> runMain(ctx context.Context) <span class="dt">error</span> {</a>
<a>    gw, err := deployServices(ctx)</a>
<a>    <span class="kw">if</span> err != <span class="ot">nil</span> {</a>
<a>        <span class="kw">return</span> err</a>
<a>    }</a>
<a>    <span class="kw">defer</span> <span class="kw">func</span>() { _ = gw.Close() }()</a>

<a>    res, err := gw.CollectQuotes(ctx, <span class="st">"example"</span>)</a>
<a>    <span class="kw">if</span> err != <span class="ot">nil</span> {</a>
<a>        <span class="kw">return</span> err</a>
<a>    }</a>
<a>    fmt.Printf(<span class="st">"Collected the following quotes:</span><span class="ch">\n</span><span class="st">"</span>)</a>
<a>    <span class="kw">for</span> k, v := <span class="kw">range</span> res {</a>
<a>        fmt.Printf(<span class="st">"  %q: %3.2f</span><span class="ch">\n</span><span class="st">"</span>, k, v)</a>
<a>    }</a>
<a>    <span class="kw">return</span> <span class="ot">nil</span></a>
<a>}</a></pre></div>
<p>In the following section, we will be hooking up a tracer implementation to our code so that we can capture and visualize the request traces that our code generates.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Capturing and visualizing traces using Jaeger</h1>
                </header>
            
            <article>
                
<p>In the previous sections, we saw how OpenTracing allows us to create and propagate span information across microservice boundaries. But,<span> </span><em>how </em>and, more importantly,<span> </span><em>where</em><span> </span>is this information collected and processed? After all, having this information available without the means to slice and dice it greatly diminishes its value.</p>
<p>As we mentioned previously, one of the key design goals of the OpenTracing framework is to avoid vendor lock-in. To this end, when it comes to span collection and visualization, you can either select an open source solution such as Uber's Jaeger<span> </span><sup><span class="citation">[11]</span></sup><span> </span>or Elastic's APM<span> </span><sup><span class="citation">[5]</span></sup>, which you host yourself. Alternatively, you can use one of the several available <strong>Software as a Service</strong> (<strong>SaaS</strong>) solutions<span> </span><sup>[19]</sup>.</p>
<p>As far as our open tracing example is concerned, we will be using Jaeger<span> </span><sup><span class="citation">[11]</span></sup><span> </span>as our tracer implementation. Jaeger is simple to install and integrate with the code we have already written so far. It is written in Go and can also be used as a drop-in replacement for Zipkin<span> </span><sup><span class="citation">[16]</span></sup>. A Jaeger deployment typically consists of two components:</p>
<ul>
<li>A local span collection agent is normally deployed as a sidecar container alongside your application. It collects spans that are published by the application over UDP, applies<span> </span><em>configurable</em><span> </span>probabilistic sampling so that it can select a subset of the spans to be sent upstream, and transmits them to the Jaeger collector service.</li>
<li>The collector service aggregates the spans that are transmitted by the various Jaeger agent instances and persists them to a data store. Depending on the rate at which new spans are produced, collectors can be configured to work in either<span> </span><em>direct-to-storage</em><span> </span>mode, where they interface directly with the DB, or in<span> </span><em>streaming</em><span> </span>mode, where a Kafka instance is used as a buffer between the collectors and another process that ingests, indexes, and stores the data in the DB.</li>
</ul>
<p>For our testing purposes, we will use the official all-in-one Docker image, which includes an agent and collector (backed by an in-memory store) instance, as well as the Jaeger UI. We can start the container using the following command:</p>
<pre class="shell">docker run -d --name jaeger \
  -p 6831:6831/udp \
  -p 16686:16686 \
  jaegertracing/all-in-one:1.14</pre>
<p>Port<span> </span><kbd>6831</kbd><span> </span>is where the Jaeger agent listens for spans that our instrumented services will publish over UDP. On the other hand, port<span> </span><kbd>16686</kbd><span> </span>exposes the Jaeger UI where we can browse, search, and visualize captured request traces.</p>
<p>As we mentioned in the previous sections, the<span> </span><kbd>tracer</kbd><span> </span>package will encapsulate the logic for instantiating new Jaeger tracer instances.</p>
<p>Let's take a look at the<span> </span><kbd>GetTracer</kbd><span> </span>function's implementation. The<span> </span><kbd>MustGetTracer</kbd><span> </span>function that our services invoke calls<span> </span><kbd>GetTracer</kbd><span> </span>and panics in case of an error, as shown here:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> GetTracer(serviceName <span class="dt">string</span>) (opentracing.Tracer, <span class="dt">error</span>) {</a>
<a>    cfg, err := jaegercfg.FromEnv()</a>
<a>    <span class="kw">if</span> err != <span class="ot">nil</span> {</a>
<a>        <span class="kw">return</span> <span class="ot">nil</span>, err</a>
<a>    }</a>
<a>    cfg.ServiceName = serviceName</a>
<a>    cfg.Sampler = &amp;jaegercfg.SamplerConfig{ </a>
<a>        Type: jaeger.SamplerTypeConst, </a>
<a>        Param: <span class="dv">1</span>, <span class="co">// Sample all traces generated by our demo</span></a>
<a>    }</a>
<a>    tracer, closer, err := cfg.NewTracer()</a>
<a>    <span class="kw">if</span> err == <span class="ot">nil</span> {</a>
<a>        <span class="co">// Omitted: keep track of closer so we can close all tracers when exiting</span></a>
<a>        <span class="kw">return</span> tracer, <span class="ot">nil</span></a>
<a>    }</a>
<a>    <span class="kw">return</span> err</a>
<a>}</a></pre></div>
<p>The Go client for Jaeger provides several convenience helpers for creating new tracers. The approach we chose here was to instantiate a tracer from a configuration object that we can obtain via the<span> </span><kbd>FromEnv</kbd><span> </span>helper.<span> </span><kbd>FromEnv</kbd><span> </span>initializes a configuration object with a set of sane defaults and then examines the environment for the presence of Jaeger-specific variables that override the default values. For instance, <kbd>JAEGER_AGENT_HOST</kbd> and <kbd>JAEGER_AGENT_PORT</kbd> can be used to specify the address where the Jaeger agent is listening for incoming spans. By default, the agent is expected to listen at<span> </span><kbd>localhost:6831</kbd><span>, </span>which matches the port that was exposed by the Docker container we just launched.</p>
<p>Next, we need to configure a sampling strategy for the tracer. It stands to reason that if we were operating a deployment with very high throughput, we wouldn't necessarily want to trace every single request as that would generate an enormous amount of data that would need to be stored and indexed. To this end, Jaeger allows us to configure different sampling strategies, depending on our particular application requirements:</p>
<ul>
<li>A<span> </span><strong>constant</strong><span> </span>sampler always makes the same decision for each trace. This is the strategy we are using for our example to ensure that traces are always persisted each time we run our demo.</li>
<li>A<span> </span><strong>probabilistic</strong><span> </span>sampler retains traces with a specific probability (for example, 10% of traces).</li>
<li>The <strong>rate-limiting</strong> sampler ensures that traces are sampled at a particular rate (for example, 10 traces per second).</li>
</ul>
<p>The following screenshot<span> </span>shows a detailed view of a captured trace that was generated by running the example application that we just built:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/5b467669-f51f-4cd5-814b-a858b23ca7ab.png" style="width:67.92em;height:33.67em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Figure 1: Visualizing a request trace in Jaeger's UI</div>
<p>The first row represents the<span> </span><em>total</em><span> </span>time spent in the <kbd>api-gateway</kbd> waiting for a response to the outgoing quote request. The rows beneath it contain the nested spans that correspond to other requests that were executing in parallel. Here is a brief overview of the events that occurred:</p>
<ol type="1">
<li>The gateway makes a request to<span> </span><span class="packt_screen">aggr-0</span><span> </span>and blocks waiting for a response.</li>
<li><span class="packt_screen">aggr-0 </span>makes two requests in parallel: one to<span> </span><span class="packt_screen">vendor-0</span><span> </span>and one to<span> </span><span class="packt_screen">aggr-1</span>. Then, it blocks waiting for the downstream responses before returning a response to the gateway.</li>
<li><span class="packt_screen">aggr-1</span><span> </span>makes two requests in parallel: one to<span> </span><span class="packt_screen">vendor-1</span><span> </span>and one to<span> </span><span class="packt_screen">vendor-2</span>. It blocks waiting for the downstream responses before returning a response to<span> </span><span class="packt_screen">aggr-0</span>.</li>
</ol>
<p>One other very cool feature of the Jaeger UI is that it can display the dependencies between services as a <strong>directed acyclic graph</strong> (<strong>DAG</strong>). The following screenshot shows the DAG for our example microservice deployment, which matches the preceding event sequence:</p>
<div class="packt_figref CDPAlignCenter CDPAlign"><img src="assets/7d15b395-ac88-4aa6-b842-875f68077f81.png" style="width:34.17em;height:24.67em;"/></div>
<p class="mce-root"/>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>Figure 2: Visualizing the dependencies between services</span></div>
<p>In conclusion, request tracing is a great tool for gaining a deeper insight into the internals of modern, complex microservice-based systems. I would strongly recommend considering it for your next large-scale project.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Making logging your trusted ally</h1>
                </header>
            
            <article>
                
<p>Time and time again, logging always proves to be an invaluable resource for investigating the root cause of a problem in contemporary computer software. However, in the context of a microservice-based architecture, where requests cross service boundaries, being able to collect, correlate, and search the log entries that are emitted by each individual service is of paramount importance.</p>
<p>In the following sections, we will focus on the best practices for writing succinct log entries that are easily searchable and highlight some common pitfalls that you definitely want to avoid. Furthermore, we will discuss solutions for collecting and shipping the logs from your Kubernetes pods (or dockerized services) to a central location where they can be indexed.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Logging best practices</h1>
                </header>
            
            <article>
                
<p>The first item on our best practice checklist is<span> </span><strong>leveled logging</strong>. When using leveled logging, there are two aspects you need to consider:</p>
<ul>
<li><strong>Selecting the appropriate log level to use for each message</strong>: The majority of logging packages for Go applications support at least the<span> </span><em>DEBUG</em>,<span> </span><em>INFO, </em>and<span> </span><em>ERROR</em><span> </span>levels. However, your preferred logging solution might also support more granular log levels, such as <em>TRACE</em>,<span> </span><em>DEBUG</em><span>, </span>and<span> </span><em>WARNING</em>.</li>
<li><strong>Deciding which log levels to actually output</strong>: For instance, perhaps you want your application to only output messages at the<span> </span><em>INFO</em><span> </span>and<span> </span><em>ERROR</em><span> </span>levels to reduce the volume of produced logs.</li>
</ul>
<p>When debugging an application, it makes sense to also include <em>DEBUG</em> or <em>TRACE</em><span> </span>messages in the logs so that you can get a better understanding of what's going on. It stands to reason that you shouldn't have to recompile and redeploy an application just to change its log level! To this end, it's good practice to implement some sort of hook to allow you to dynamically change the active log level of an application while it is executing. Here are a few suggestions you can try:</p>
<ul>
<li>Toggle between the configured log level and the<span> </span><em>DEBUG</em><span> </span>level when the application receives a particular signal (for example, SIGHUP). If your application reads the initial log level from a config file, you could use the same signal-based approach to force a reload of the config file.</li>
<li>Expose an HTTP endpoint to change the log level.</li>
<li>Store the per-application log level setting in a distributed key-value store such as etcd<span> </span><sup><span class="citation">[6]</span></sup><span>, </span>which allows clients to watch a key for changes. If you are running multiple instances of your application, this is an effective way to change the log level for all the instances in a single step.</li>
</ul>
<p>If you haven't already done so, you can step up your logging game simply by switching to<span> </span><strong>structured</strong><span> </span>logging. While the good old way of extracting timestamps and messages from logs using regular expressions certainly does work, updating your applications to output logs in a format that is easily parsed by the service that indexes them goes a long way toward increasing the volume of logs that can be ingested per unit of time. Consequently, application logs become searchable in real time or near real-time fashions, allowing you to diagnose problems much quicker. There are quite a few Go packages out there that implement structured loggers. If we had to single out some, our list would definitely include<span> </span><kbd>sirupsen/logrus</kbd><span> </span><sup><span class="citation">[14]</span></sup>,<span> </span><kbd>uber-go/zap</kbd><span> </span><sup><span class="citation">[20]</span></sup>,<span> </span><kbd>rs/zerolog</kbd><span> </span><sup><span class="citation">[21]</span></sup><span>, </span>and<span> </span><kbd>gokit/log</kbd><span> </span><sup><span class="citation">[9]</span></sup>.</p>
<p>So, what does a structured log entry look like? The following screenshot demonstrates how the<span> </span><kbd>sirupsen/logrus</kbd><span> </span>package formats and prints the same set of logs using two of its built-in text formatters. The Terminal at the top uses a text-based formatter that is more suited for running applications on your development machine, while the Terminal at the bottom displays the same output as JSON. As you can see, each log entry consists, as a minimum, of a level, a timestamp, and a message. In addition, log entries can contain a variable number of key-value pairs:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/3c81a9c9-55fc-4aaf-a356-489e3f2f0cb9.png" style="width:64.92em;height:19.83em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>Figure 3:</span><span> </span>Example log output produced by logrus</div>
<p>When the log ingestion platform consumes such a log entry, it will also index the key-value pairs and make them available for searching. Consequently, you can compose highly targeted queries by slicing and dicing the log entries by multiple attributes (for example, a customer ID, service name, and data center location).</p>
<div class="packt_tip">Always make sure that the<span> </span><em>message</em><span> </span>portion of your log entries never includes<span> </span><em>variable</em><span> </span>parts. To explain why not adhering to this advice could lead to problems, let's take a look at two equivalent error messages that are produced by a service whose task is to redirect users:
<ul>
<li><kbd>level=error message="cannot connect to server: dial tcp4: lookup invalid.host: no such host" service=redirector customer-id=42</kbd></li>
<li><kbd>level=error message="cannot connect to server" err="dial tcp4: lookup invalid.host: no such host" host=invalid.host service=redirector customer-id=42</kbd></li>
</ul>
The first message embeds the error that's returned by the Go dialer into the log message. Given that the<span> </span><em>no such host</em><span> </span>error will most probably change for each request, adding it to the log message introduces a variable component that makes searching harder. What if we want to find the logs for<span> </span><em>all</em><span> </span>failed connection attempts? The only way to do that would be to use a regular expression, which would be quite slow since the log search engine would need to perform a full table scan and apply the regular expression to each entry.<br/>
<br/>
On the other hand, the second message uses a constant message for errors of a particular<span> </span><em>class</em><span> </span>and includes the error details and hostname as key-value pairs. Searching for this type of error is much easier: the log search engine can probably answer this type of query quickly and efficiently using an index. What's more, we can keep slicing the data further, for example, count failed attempts by the host. Answering this type of query for the first message would be nearly impossible!</div>
<p>We have already argued about the usefulness of structured logging. At this point, you might be wondering whether there's a list of fields that should always be included in your log messages. I would definitely recommend including at least the following bits of information:</p>
<ul>
<li>The application/service<span> </span><strong>name</strong>. Having this value present allows you to answer one of the most common queries out there: "display the logs for application <em>foo</em>".</li>
<li>The<span> </span><strong>hostname</strong><span> </span>where the application is executing. When your log storage is centralized, having this field available is quite handy if you need to figure out which machine (or container, if you're using Kubernetes) produced the log.</li>
<li>The<span> </span><strong>SHA</strong><span> </span>of the git (or your preferred VCS) branch that's used to compile the binary for the application. If your organization is a fan of the <em>ship frequently</em> mantra, adding the SHA to your logs makes it easy to link an error to a particular snapshot of the code base.</li>
</ul>
<p>Imagine that, against your better judgment, you decided to ignore the <em>never deploy on a Friday</em> rule and push a set of seemingly innocent changes to some of the microservices in production; after all, the code was thoroughly reviewed and all the tests passed. What could possibly go wrong, right? You come back to work on Monday and your mailbox is full of tickets that have been opened by the support team. According to the tickets, several users experienced issues adding products to their carts. To assist you with tracking down the problem, the support team has included both the affected user IDs and the approximate time when they were accessing the service in the tickets.</p>
<p>You fire up your log search tool, plug in the timestamp and user details, and receive a list of logs for the API gateway, which is the first microservice that users hit when they request something from their web browser. The gateway service makes several calls to downstream services that, unfortunately,<span> </span><em>do not</em><span> </span>have access to the user ID and therefore don't show up in the logs... Good luck tracking down the cause of the problem!</p>
<p>To avoid hairy situations like this, it's good practice to also include a<span> </span><strong>correlation ID</strong><span> </span>in your log entries. In this particular scenario, the API gateway would generate a unique correlation ID for incoming requests and inject it into requests to downstream services (which then include it in their own log entries), and so on and so forth. This approach is quite similar to request tracing, but instead of tracking spans and time-related request details, it allows us to correlate logs across service boundaries.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The devil is in the (logging) details</h1>
                </header>
            
            <article>
                
<p>When using structured logging, it is very easy to get carried away and try to stuff as much information as possible into the key-value pairs. Unfortunately, this can often prove to be dangerous security-wise! Take a look at the following code snippet, which retrieves a user's data from a URL they have provided to us:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">func</span> fetchUserData(url *url.URL) (*user.Data, <span class="dt">error</span>) {</a>
<a>    tick := time.Now()</a>
<a>    res, err := http.Get(url.String())</a>
<a>    <span class="kw">if</span> err != <span class="ot">nil</span> {</a>
<a>        <span class="kw">return</span> <span class="ot">nil</span>, err</a>
<a>    }</a>
<a>    <span class="kw">defer</span> <span class="kw">func</span>() { _ = res.Body.Close() }()</a>

<a>    logrus.WithFields(logrus.Fields{</a>
<a>        <span class="st">"url"</span>:  url,</a>
<a>        <span class="st">"time"</span>: time.Since(tick).String(),</a>
<a>    }).Info(<span class="st">"retrieved user data"</span>)</a>

<a>    <span class="co">// omitted: read and unmarshal user data</span></a>
<a>}</a></pre></div>
<p>Whenever we succeed in fetching the data, we log an<span> </span><em>INFO</em><span> </span>message with the URL and the time it took to retrieve it. This code looks pretty innocent, right? Wrong! The following screenshot shows the log output from this function:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/5eed49c9-147a-4af6-85fb-01f742041256.png" style="width:70.00em;height:7.42em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>Figure 4:</span><span> </span>Forgetting to properly sanitize log output can lead to credential leaks</div>
<p>Yikes! We just splatted the user's credentials all over our logs... We have to be very careful not to leak any credentials or any other bits of sensitive information (for example, credit card, bank account, or SSN numbers) to the logs. But how can we achieve this without having to audit every single log line in our code base? Most logging frameworks allow you to provide an<span> </span><kbd>io.Writer</kbd><span> </span>instance for receiving the logger output. You can leverage this capability to implement a filtering mechanism that uses a set of regular expressions to either mask or strip away sensitive information that adheres to specific patterns.</p>
<p>Another pitfall that you must be aware of is<span> </span><strong>synchronous</strong><span> </span>logging. The golden rule here is that logging should always be considered as an auxiliary function and should never interfere with the normal operation of your service. If you are using a synchronous logger and the output stream blocks (that is, it cannot keep up with the volume of generated logs), your service would also block and cause noticeable delays for upstream services depending on it. Whenever possible, try to use an<span> </span><strong>asynchronous</strong><span> </span>logger implementation <span>–</span> ideally, one that uses a leaky bucket abstraction to drop messages when it cannot keep up with the load.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Shipping and indexing logs inside Kubernetes</h1>
                </header>
            
            <article>
                
<p>If you have been following the guidelines from the previous sections, your applications will now emit clean and succinct logs in a format that makes them suitable for ingestion by a log aggregation system. The only missing piece of the puzzle is how we can collect the individual logs from each application instance running on a Kubernetes cluster and ship them either to a self-hosted or SaaS log indexing solution.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running a log collector on each Kubernetes node</h1>
                </header>
            
            <article>
                
<p>This option uses a Kubernetes<span> </span><em>DaemonSet</em><span> </span>to install a log collection daemon on each node of the Kubernetes cluster. Besides being relatively easy to implement, the main benefit of this particular approach is that it is totally transparent to running applications.</p>
<div class="packt_infobox">A DaemonSet is a special type of Kubernetes resource that ensures that all cluster nodes run a copy of a particular pod. Using daemon sets is a quite common pattern for the following reasons:
<ul>
<li>Running cluster storage daemons (for example, ceph or glusterd)</li>
<li>Collecting and shipping logs</li>
<li>Monitoring nodes and transmitting node-specific metrics (for example, load, memory, or disk space usage)</li>
</ul>
</div>
<p>When a pod executes, Kubernetes will capture its standard output and error streams and redirect them to a pair of log files. When you run the<span> </span><kbd>kubectl logs</kbd><span> </span>command, the<span> </span><kbd>kubelet</kbd><span> instance </span>running on the worker node streams the logs by reading off those files.</p>
<p>The log collector pod that's shown in the following diagram digests the captured log files for each executing pod, transforms them (if necessary) into the format expected by the log indexing service, and optionally augments them with additional information such as the Kubernetes namespace and container hostname. Depending on the log ingesting solution in use, logs can be either directly uploaded for ingestion or written to a message queue such as Kafka:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/92219a31-af22-4046-82da-5417d9a16c2a.png" style="width:46.83em;height:17.08em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>Figure 5: Running a log collector using a DaemonSet</span></div>
<p>The two most popular log collection daemons out there are Fluent Bit<span> </span><sup><span class="citation">[8]</span></sup><span>, </span>which is written in C, and Logstash<span> </span><sup><span class="citation">[15]</span></sup><span>, </span>which is written in Ruby. Quite often, logs will be shipped to an Elasticsearch cluster for indexing, and a frontend such as Kibana<span> </span><sup><span class="citation">[12]</span></sup><span> </span>will be used to browse and search the logs. You will hear this type of setup commonly referred to as an EFK or ELK stack, depending on which log collection daemon is being used.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using a sidecar container to collect logs</h1>
                </header>
            
            <article>
                
<p>The second option when it comes to collecting logs is to run a sidecar container for each application, as shown in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/d0e6746c-fe4f-41c6-8c54-0f05ec18eb97.png" style="width:33.42em;height:19.17em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>Figure 6: Running a log collector as a sidecar container</span></div>
<p>While this approach might feel a bit more cumbersome compared to using the infrastructure already built into Kubernetes, it can work quite nicely in cases where the following happens:</p>
<ul>
<li>The application writes to multiple log files. For example, a web server such as Apache or Nginx might be configured to write error logs to a different location than access logs. In such a case, you would add a sidecar container for each log file that you want to scrape.</li>
<li>Applications use non-standard log formats that need to be transformed on a<span> </span><strong>per-application</strong><span> </span>basis.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Shipping logs directly from the application</h1>
                </header>
            
            <article>
                
<p>The last log shipping strategy that we will be examining is to actually embed the log shipping logic into each application. As shown in the following diagram, the application is sending its logs directly to a log repository:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/9b319765-f4d7-485f-8e9c-671bc457d949.png" style="width:27.83em;height:18.25em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>Figure 7: Shipping logs directly from within the application</span></div>
<p>An interesting use case for this strategy is to integrate with an external, third-party SaaS offering that requires applications to import and use a vendor-specific software development kit.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introspecting live Go services</h1>
                </header>
            
            <article>
                
<p>After a long journey transitioning from a monolithic application into one based on microservices, you have reached a point where all your new and shiny services are happily running in production. At this stage, you will probably start becoming more and more curious about their operation in the long run:</p>
<ul>
<li>How much memory are they using?</li>
<li>How many goroutines are currently running?</li>
<li>Are there any leaks (memory or goroutines) that can eventually force the service to crash?</li>
<li>How often does the Go garbage collector run and how much time does each run actually take?</li>
</ul>
<p>If you are using a container orchestration framework such as Kubernetes, crashing services are not normally a big concern; just bump the number of instances and Kubernetes will take care of restarting them when they crash. However, if the root cause of the crash is a memory leak or an unbounded explosion in the number of running goroutines, crashes will become more and more frequent as the traffic to your system increases. This pattern will inevitably lead to service disruption.</p>
<p>Fortunately, the Go runtime exposes a heap of information that we can use to answer these questions. All we need to do is extract, export, and aggregate this information. In <a href="56c5302a-2c1a-4937-bb65-1b280f27ebed.xhtml">Chapter 13</a>, <em>Metrics Collection and Visualization</em>, where we will be discussing the SRE aspects of operating microservice architectures, we will explore metrics collection systems such as Prometheus, which let us not only collect this information but also act on it by creating alerts that can eventually turn into page calls for the SRE team.</p>
<p>In some cases, however, we might want to dig a bit deeper... Here are a few interesting examples:</p>
<ul>
<li>A service suddenly became unresponsive but the Go deadlock detector is not complaining about any deadlocks. The service still accepts requests but never sends out any reply and we need to find out why.</li>
<li>Our metrics dashboard indicates that instance<span> </span><em>X</em><span> </span>of service<span> </span><em>Y</em><span> </span>is using quite a lot of heap memory. But how can we inspect the heap's contents and see what is taking up all that memory? Perhaps we are leaking file handles (for example, forgot to close the response body off from the HTTP calls we are making) or maintain unneeded references to objects that prevent the Go garbage collector from freeing them.</li>
<li>A data ingestion service unexpectedly pegs the CPU, but only when running in production! So far, you have been unable to replicate this issue on your local development machine.</li>
</ul>
<p>To debug issues such as the ones described in the first example, we can SSH into the container that the service executes in and send it a<span> </span><em>SIGQUIT</em><span> </span>signal. This will force the Go runtime to dump a stack trace for each running goroutine and exit. Then, we can examine the log stream and figure out where exactly the service got stuck.</p>
<div class="packt_tip">If your Go application, which seemingly appears to be stuck, is running on the foreground, instead of looking for its pid so that you can send it a<span> </span><em>SIGQUIT</em><span> </span>signal, you can force it to dump the stack trace for every executing goroutine by pressing <em>CTRL+\</em> .<br/>
<br/>
Note that, behind the scenes, this key combination actually sends a<span> </span><em>SIGQUIT</em><span> </span>to the running process and will cause it to exit.</div>
<p>However, the obvious caveat of this trick is that our application or service will effectively crash. What's more, it doesn't really allow us to introspect its internal state, which is more or less required for dealing with situations such as the ones from the other examples.</p>
<p>Fortunately, Go allows us to embed<span> the </span><kbd>pprof</kbd><span> package </span>into our services and expose a frontend to it over HTTP. You might be worried that shipping what is effectively a sampling profiler with your code will undoubtedly make it run slower. In principle, this is not really the case as you can ask <kbd>pprof</kbd> to capture various kinds of profiles on demand, thus allowing it to stay out of the way until you need it. As the following code snippet shows, all you need to do is import the<span> </span><kbd>net/http/pprof</kbd><span> </span>package and launch an HTTP server:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="kw">import</span> (</a>
<a>    <span class="st">"log"</span></a>
<a>    <span class="st">"net/http"</span></a>
<a>    _ <span class="st">"net/http/pprof"</span> <span class="co">// import for side-effects</span></a>
<a>)</a>

<a><span class="kw">func</span> exposeProfile() {</a>
<a>    <span class="kw">go</span> <span class="kw">func</span>() {</a>
<a>        log.Println(http.ListenAndServe(<span class="st">"localhost:6060"</span>, <span class="ot">nil</span>))</a>
<a>    }()</a>
<a>}</a></pre></div>
<p>The<span> </span><kbd>net/http/pprof</kbd><span> </span>function defines an<span> </span><kbd>init</kbd><span> </span>function, which registers various pprof-related route handlers to the default<span> </span><kbd>http.ServeMux</kbd>. Therefore, the package is typically imported only for its side effects. After spinning up an HTTP server, you can simply point your web browser to<span> </span><kbd>http://localhost:6060/debug/pprof</kbd><span> </span>and access a minimalistic frontend for capturing <kbd>pprof</kbd> profiles and make them available for download so that they can be processed offline via the<span> </span><kbd>pprof</kbd><span> </span>tool.</p>
<p>The following screenshot is e<span>xposing a <kbd>pprof</kbd> frontend to introspect running applications:</span></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><img src="assets/a4ce5dc0-34b4-474a-9792-702bdf5c084f.png" style="width:62.25em;height:24.33em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>Figure 8: Exposing a pprof frontend to introspect running applications</span></div>
<p>As shown in the preceding screenshot, the <kbd>pprof</kbd> UI allows you to capture the following profile types on-demand:</p>
<ul>
<li><strong>allocs</strong>: A sampling of all past memory allocations</li>
<li><strong>block</strong>: Stack traces that led to blocking on synchronization primitives</li>
<li><strong>cmdline</strong>: The command-line invocation of the current program</li>
<li><strong>goroutine</strong>: Stack traces of all current goroutines</li>
<li><strong>heap</strong>: A sample of the memory allocations of live objects</li>
<li><strong>mutex</strong>: Stack traces of holders of contended mutexes</li>
<li><strong>profile</strong>: CPU profile</li>
<li><strong>threadcreate</strong>: Stack traces that led to the creation of new OS threads</li>
<li><strong>trace</strong>: A trace of the execution of the current program</li>
</ul>
<div class="packt_tip">If your application/service already spins up its own HTTP server that can potentially be exposed to the outside world (for example, via a Kubernetes ingress), make sure you bind its routes to a<span> </span><strong>new mux</strong><span> </span>instance and expose the <kbd>pprof</kbd> routes using the<span> </span><strong>default mux</strong><span> </span>via a second HTTP server running on a different (internal) port.<br/>
<br/>
This way, you don't run the risk of allowing unauthorized access to your introspection endpoints.</div>
<p class="mce-root">I would strongly recommend enabling <kbd>pprof</kbd> support for your production services using the approaches we discussed in this section. It only requires a little bit of effort on your end to set up but will prove to be a great asset if you ever need to debug a live application.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building a microservice-based version of Links 'R' Us</h1>
                </header>
            
            <article>
                
<p>In the last part of this chapter, we will take the monolithic Links 'R' Us application that we built and deployed in the previous chapter and apply <em>everything</em> we have learned so far to break it down into a bunch of microservices. The following diagram illustrates the expected state of our cluster after we've made all the necessary changes:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/5ecc62e1-e8b4-4f04-87ce-f626803d6ab0.png" style="width:64.83em;height:22.33em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref"><span>Figure 9: Breaking down the Links 'R' Us monolith into microservices</span></div>
<p>The Kubernetes manifest files that we will be using for the microservice-based version of Links 'R' Us are available under the<span> </span><kbd>Chapter11/k8s</kbd><span> </span>folder of this book's GitHub repository.</p>
<p>If you haven't already set up a Minikube cluster and whitelisted its private registry, you can either take a quick break and manually follow the step-by-step instructions from <a href="bd9d530b-f50e-4b81-a6c1-95b31e79b8c6.xhtml">Chapter 10</a>, <em>Building, Packaging, and Deploying Software</em>, or simply run<span> </span><kbd>make bootstrap-minikube</kbd><span>, </span>which will take care of everything for you. On the other hand, if you have already deployed the monolithic version of Links 'R' Us from the previous chapter, make sure to run<span> </span><kbd>kubectl delete namespace linksrus</kbd><span> </span>before proceeding. By deleting the<span> </span><strong>linksrus</strong><span> </span>namespace, Kubernetes will get rid of all pods, services, and ingresses for Links 'R' Us but leave the data stores (which live in the<span> </span><strong>linksrus-data</strong><span> </span>namespace) intact.</p>
<div class="packt_tip">To deploy the various Links 'R' Us components that we will be defining in the following sections, you will need to build and push a handful of Docker images. To save you some time, the Makefile in the<span> </span><kbd>Chapter11/k8s</kbd><span> </span>folder provides two handy build targets to get you up and running as quickly as possible:
<ul>
<li><kbd>make dockerize-and-push</kbd><span> </span>will build all required Docker images and push them to Minikube's private registry</li>
<li><kbd>make deploy</kbd><span> </span>will ensure that all the necessary data stores have been provisioned and apply all the manifests for deploying the microservice-based version of Links 'R' Us in one go</li>
</ul>
</div>
<p>Before we can start breaking down our monolith into microservices, there is one small task we need to take care of first: removing the coupling between our service and the underlying data stores. The next section explores how this can be achieved using the knowledge we acquired in <a href="b3edd7bf-fd1d-4203-bd96-9113cdbb2422.xhtml">Chapter 9</a>, <em>Communicating with the Outside World</em>. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Decoupling access to the data stores</h1>
                </header>
            
            <article>
                
<p>One fundamental issue with the monolithic implementation from the previous chapter is that our application was talking directly to the Elasticsearch and CockroachDB clusters. We have effectively introduced a tight coupling between the application and the data store implementations.</p>
<p>Now that it's time to create the microservice-based version of Links 'R' Us, we need to take a few steps to rectify this problem. To this end, the first two services that we will be creating as part of our refactoring work will serve as a kind of proxy for facilitating access to the underlying data stores. The<span> </span><strong>text-indexer</strong><span> </span>and<span> </span><strong>link-graph</strong><span> </span>services will be deployed in the<span> </span><strong>linksrus-data</strong><span> </span>namespace and allow other services to interact with the data stores through the gRPC-based APIs that we defined in <a href="b3edd7bf-fd1d-4203-bd96-9113cdbb2422.xhtml">Chapter 9</a><span>, </span><em>Communicating with the Outside World</em>.</p>
<p>An important benefit of introducing an indirection layer between the services and the data stores is that we gain the ability to change the data store implementation<span> </span><em>at any moment</em><span> </span>without having to change, update, or otherwise reconfigure any of the other Links 'R' Us services.</p>
<p>In terms of service implementation, things are surprisingly simple. Each service binary receives the URI of the data store to connect to as an argument. Then, it creates a gRPC server on port <kbd>8080</kbd> and exposes the <kbd>pprof</kbd> debug endpoints on port 6060. All the boilerplate code fits nicely into a single main file, which you can find in the<span> </span><kbd>Chapter11/linksrus/linkgraph</kbd><span> </span>and<span> </span><kbd>Chapter11/linksrus/textindexer</kbd><span> </span>folders of this book's GitHub repository.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Breaking down the monolith into distinct services</h1>
                </header>
            
            <article>
                
<p>In this section, we will extract the individual services from the Links 'R' Us monolith and build a standalone service binary for each one. This is also the point where you will probably realize that our clean, interface-based design that we have been preaching about since the beginning of this book finally begins to pay off.</p>
<p>As it turns out, we can take the service-specific code from <a href="bd9d530b-f50e-4b81-a6c1-95b31e79b8c6.xhtml">Chapter 10</a>, <em>Building, Packaging, and Deploying Software</em>, and use it as is with a few minor changes. For each service, we will create a <kbd>main</kbd> package that performs the following set of tasks:</p>
<ul>
<li>Creates a logger instance for each service</li>
<li>Exposes the <kbd>pprof</kbd> debug endpoints on a configurable port</li>
<li>Instantiates the gRPC clients for accessing the link-graph and text-indexer</li>
<li>Populates the configuration object for each service with the appropriate settings</li>
<li>Runs the service main loop and cleanly shuts down the application upon receiving a signal</li>
</ul>
<p>All of this boilerplate code is more or less the same for each service, so we will omit it for brevity. However, if you want to, you can extract the common parts into a separate package and make the<span> </span><kbd>main.go</kbd><span> </span>files for each service a bit leaner.</p>
<p>The configuration of each service is one of the places where we will be deviating slightly compared to the monolithic implementation from the previous chapter. We want our services to be configured either via command-line flags or via environment variables. The latter offers us the flexibility to define all the configuration options in a shared Kubernetes ConfigMap and inject them into our service manifests. Since the built-in<span> </span><kbd>flags</kbd><span> </span>package does not support this kind of functionality, we will be switching to the<span> </span><kbd>urfave/cli</kbd><span> </span><sup><span class="citation">[1]</span></sup><span> </span>package for our flag parsing needs. This package supports an elegant way of defining typed flags, which also allows us to (optionally) specify the name of an environment variable that can be set to override each flag value:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a>app.Flags = []cli.Flag{</a>
<a>    cli.StringFlag{</a>
<a>        Name:   <span class="st">"link-graph-api"</span>,</a>
<a>        EnvVar: <span class="st">"LINK_GRAPH_API"</span>,</a>
<a>        Usage:  <span class="st">"The gRPC endpoint for connecting to the link graph"</span>,</a>
<a>    },</a>
<a>    cli.StringFlag{</a>
<a>        Name:   <span class="st">"text-indexer-api"</span>,</a>
<a>        EnvVar: <span class="st">"TEXT_INDEXER_API"</span>,</a>
<a>        Usage:  <span class="st">"The gRPC endpoint for connecting to the text indexer"</span>,</a>
<a>    },</a>
<a>    <span class="co">// omitted: additional flags</span></a>
<a>}</a></pre></div>
<p>Each of our new services will need to access both the link-graph and the text-indexer data stores. Both of these stores are exposed over gRPC via the two services we described in the previous section. The following code snippet shows how to obtain a high-level (see <a href="b3edd7bf-fd1d-4203-bd96-9113cdbb2422.xhtml">Chapter 9</a>, <em>Communicating with the Outside World</em>) client instance for each of the two services:</p>
<div class="sourceCode">
<pre class="sourceCode go"><a><span class="co">// Obtain high-level client for link graph.</span></a>
<a>dialCtx, cancelFn := context.WithTimeout(ctx, <span class="dv">5</span>*time.Second)</a>
<a><span class="kw">defer</span> cancelFn()</a>
<a>linkGraphConn, err := grpc.DialContext(dialCtx, linkGraphAPI, grpc.WithInsecure(), grpc.WithBlock())</a>
<a><span class="kw">if</span> err != <span class="ot">nil</span> {</a>
<a>    <span class="kw">return</span> <span class="ot">nil</span>, <span class="ot">nil</span>, xerrors.Errorf(<span class="st">"could not connect to link graph API: %w"</span>, err)</a>
<a>}</a>
<a>graphCli := linkgraphapi.NewLinkGraphClient(ctx, linkgraphproto.NewLinkGraphClient(linkGraphConn))</a>

<a><span class="co">// Obtain high-level client for text-indexer.</span></a>
<a>dialCtx, cancelFn := context.WithTimeout(ctx, <span class="dv">5</span>*time.Second)</a>
<a><span class="kw">defer</span> cancelFn()</a>
<a>indexerConn, err := grpc.DialContext(dialCtx, textIndexerAPI, grpc.WithInsecure(), grpc.WithBlock())</a>
<a><span class="kw">if</span> err != <span class="ot">nil</span> {</a>
<a>    <span class="kw">return</span> <span class="ot">nil</span>, <span class="ot">nil</span>, xerrors.Errorf(<span class="st">"could not connect to text indexer API: %w"</span>, err)</a>
<a>}</a>
<a>indexerCli := textindexerapi.NewTextIndexerClient(ctx, textindexerproto.NewTextIndexerClient(indexerConn))</a></pre></div>
<p>As you may recall, back in <a href="b3edd7bf-fd1d-4203-bd96-9113cdbb2422.xhtml">Chapter 9</a>, <em>Communicating with the Outside</em> <em>World</em>, we meticulously designed the high-level clients so that they implement a subset of the<span> </span><kbd>graph.Graph</kbd><span> </span>and<span> </span><kbd>index.Indexer</kbd><span> </span>interfaces. This makes it possible to use the clients as a<span> </span><em>drop-in replacement</em><span> </span>for the concrete graph and indexer store implementations that are used in the monolithic Links 'R' Us version. This is a testament to the benefits of applying the SOLID design principles to make our code more modular and easier to interface with.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deploying the microservices that comprise the Links 'R' Us project</h1>
                </header>
            
            <article>
                
<p>Now that we have built standalone binaries for each of the new Links 'R' Us services, it's time to deploy them on Kubernetes! Let's take a quick look at the required Kubernetes resources for deploying each individual service.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deploying the link-graph and text-indexer API services</h1>
                </header>
            
            <article>
                
<p>For the link-graph and text-indexer API services, we will be using a Kubernetes deployment resource to spin up two replicas for each service in the<span> </span><strong>linksrus-data</strong><span> </span>namespace.</p>
<p>To allow clients from the<span> </span><strong>linksrus</strong><span> </span>namespace to access the API, we will be creating a Kubernetes service to load balance traffic to the pods that we will be spinning up.</p>
<p>Clients can then access the data stores by connecting their gRPC clients to the following endpoints:</p>
<ul>
<li><kbd>linksrus-textindexer.linksrus-data:8080</kbd></li>
<li><kbd>linksrus-linkgraph.linksrus-data:8080</kbd></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deploying the web crawler</h1>
                </header>
            
            <article>
                
<p>The crawler service deployment will use the same partition detection logic that the monolithic implementation from the previous chapter did. Consequently, we will be deploying two instances of the crawler service as a Kubernetes Stateful set, which guarantees that each pod will be assigned a predictable hostname that includes the pod's ordinal in the set.</p>
<p>In addition, we will be creating a<span> </span><strong>headless</strong><span> </span>Kubernetes service that will populate the SRV records for the crawler pods and allow the partition detection code to query the total number of available pods.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deploying the PageRank service</h1>
                </header>
            
            <article>
                
<p>The PageRank service is still subject to the same constraints and limitations that we discussed in the previous chapter. As a result, we will only run a<span> </span><em>single</em><span> </span>instance of the service by creating a Kubernetes deployment with the replica count set to<span> </span><em>one</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deploying the frontend service</h1>
                </header>
            
            <article>
                
<p>The last service that we will be deploying is the frontend. As with most other services in our cluster, we will create a Kubernetes deployment with the required number of replicas for the frontend.</p>
<p>Just as we did in the previous chapter, we will define a Kubernetes service to load balance traffic to the frontend pods and then expose it outside the cluster with the help of a Kubernetes ingress resource.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Locking down access to our Kubernetes cluster using network policies</h1>
                </header>
            
            <article>
                
<p>As the number of microservices begins to increase, it is probably a good time to start thinking more actively about security. Do we really want each and every pod in our cluster to be able to access every other pod across all namespaces? Truth be told, for our current deployment, it is not that important. However, for larger projects, that's definitely a question that you need to answer.</p>
<p>Kubernetes offers a special type of resource called<span> </span><strong>NetworkPolicy</strong><span> </span>to assist us with the creation of fine-grained rules for governing access to namespaces and pods. A prerequisite to creating and enforcing network policies is for your cluster to run with the<span> </span><em>cni</em><span> </span>network plugin enabled and to use a network provider implementation that is compliant with the <strong>Container Networking Interface</strong> (<strong>CNI</strong>). Examples of such providers include Calico<span> </span><sup><span class="citation">[2]</span></sup>, Cilium<span> </span><sup><span class="citation">[3]</span></sup><span>, </span>and Flannel<span> </span><sup><span class="citation">[7]</span></sup>.</p>
<div class="mce-root packt_tip">If you have bootstrapped a Minikube cluster using the <kbd>make bootstrap-minikube</kbd> target from the Makefile in either the <kbd>Chapter10/k8s</kbd> or the <kbd>Chapter11/k8s</kbd> folder, Calico has already been installed for you.<br/>
<br/>
Alternatively, you can manually install Calico to your test cluster by running the following command:<br/>
<br/>
<kbd>kubectl apply -f \ https://docs.projectcalico.org/v3.10/manifests/calico.yaml</kbd><strong><br/>
<br/></strong> The installation might take a few moments. You can monitor the status of the deployment by running <kbd>kubectl -n kube-system get pods -lk8s-app=calico-node -w</kbd> and waiting for the pod status to show up as <em>running</em>.</div>
<p>What would be a good example of a network policy for our Links 'R' Us deployment? Since the various pods in the<span> </span><strong>linksrus</strong><span> </span>namespace are now expected to access the data stores over gRPC, it would be good practice to specify a network policy that would block access to any other pod in the<span> </span><strong>linksrus-data</strong><span> </span>namespace from other namespaces.</p>
<p>A really cool thing about Kubernetes network policies is that we can combine multiple policies to construct more elaborate policies. For our use case, we will start with a<span> </span><strong>DENY ALL</strong><span> </span>policy:</p>
<div class="sourceCode">
<pre class="sourceCode yaml"><a><span class="fu">kind:</span><span class="at"> NetworkPolicy</span></a>
<a><span class="fu">apiVersion:</span><span class="at"> networking.k8s.io/v1</span></a>
<a><span class="fu">metadata:</span></a>
<a>  <span class="fu">namespace:</span><span class="at"> linksrus-data</span></a>
<a>  <span class="fu">name:</span><span class="at"> deny-from-other-namespaces</span></a>
<a><span class="fu">spec:</span></a>
<a>  <span class="fu">podSelector:</span></a>
<a>    <span class="fu">matchLabels:</span></a>
<a>  <span class="fu">ingress:</span></a>
<a>  <span class="kw">-</span> <span class="fu">from:</span></a>
<a>    <span class="kw">-</span> <span class="fu">podSelector:</span><span class="at"> </span><span class="kw">{}</span></a></pre></div>
<p>Each policy has two sections:</p>
<ul>
<li>The destination is where we specify the set of pods that we want to control access to. In this example, we are using a<span> </span><kbd>podSelector</kbd> block with an empty<span> </span><kbd>matchLabels</kbd> selector to match<span> </span><em>all</em><span> </span>pods in the namespace.</li>
<li>The traffic origin, which is where we specify the set of pods that are subject to the policy when attempting to access a pod in the destination list.</li>
</ul>
<p>So, the preceding policy can be interpreted as <em><strong>deny</strong><span> </span>access to any pod in the<span> </span><strong>linksrus-data</strong><span> </span>namespace from any pod in another namespace</em>. Moving on, we will define a second network policy that will explicitly whitelist the pods that we want to grant access to:</p>
<div class="sourceCode">
<pre class="sourceCode yaml"><a><span class="fu">kind:</span><span class="at"> NetworkPolicy</span></a>
<a><span class="fu">apiVersion:</span><span class="at"> networking.k8s.io/v1</span></a>
<a><span class="fu">metadata:</span></a>
<a>  <span class="fu">namespace:</span><span class="at"> linksrus-data</span></a>
<a>  <span class="fu">name:</span><span class="at"> allow-access-to-data-apis</span></a>
<a><span class="fu">spec:</span></a>
<a>  <span class="fu">podSelector:</span></a>
<a>    <span class="fu">matchLabels:</span></a>
<a>      <span class="fu">role:</span><span class="at"> data-api</span></a>
<a>  <span class="fu">ingress:</span></a>
<a>  <span class="kw">-</span> <span class="fu">from:</span></a>
<a>    <span class="kw">-</span> <span class="fu">namespaceSelector:</span></a>
<a>        <span class="fu">matchLabels:</span><span class="at"> </span></a>
<a>          <span class="fu">role:</span><span class="at"> linksrus-components</span></a></pre></div>
<p>The pods for the two gRPC services have been tagged with a<span> </span><kbd>role: data-api</kbd><span> </span>label, which the preceding policy uses to explicitly target the pods we are interested in. On the other hand, the pods running in the<span> </span><strong>linksrus</strong><span> </span>namespace have been tagged with a<span> </span><kbd>role: linksrus-components</kbd><span> </span>label, which allows us to specify them as part of the ingress selector. This rule is interpreted as<span> </span><em><strong>allow</strong><span> </span>access from<span> </span><strong>all</strong><span> </span>pods with a<span> </span><strong>linksrus-components</strong><span> </span>role to pods with a<span> </span><strong>data-api</strong><span> </span>role in the<span> </span><strong>linksrus-data</strong><span> </span>namespace</em>.</p>
<p>Let's apply these rules by running<span> </span><kbd>kubectl apply -f 08-net-policy.yaml</kbd><span> </span>and verify that they work as expected by connecting to the pods in both namespaces and running the<span> </span><em>nc</em><span> </span>command to check whether we are allowed to connect to the pods protected by the two network policies. The following screenshot shows us how to <span>verify that our network policies work as expected:</span></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><img src="assets/cf41a1ea-2f1a-4850-ba36-6494e660adea.png" style="width:55.92em;height:23.17em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>Figure 10: Verifying that our network policies work as expected</span></div>
<p>Success! As shown in the preceding screenshot, attempting to connect from one of the crawler pods in the<span> </span><strong>linksrus</strong><span> </span>namespace to the CockroachDB cluster times out, while attempts to connect to the text indexer API succeed. On the other hand, the connection attempt to CockroachDB succeeds when the same command is executed inside a pod running in the<span> </span><strong>linksrus-data</strong><span> </span>namespace.</p>
<p>Of course, this brief introduction to Kubernetes network policies barely scratches the surface. The Kubernetes documentation contains several other match rules that you can use to formulate the appropriate network policies for your particular use case. For those of you who are interested in exploring the different types of policies that you can implement further, I would strongly recommend taking a look at the <em>Kubernetes network policy recipes</em><span> </span><sup><span class="citation">[13]</span></sup><span> </span>GitHub repository.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we focused on the process of splitting a monolithic application into a series of microservices. We identified some common anti-patterns for building microservices and elaborated on ways for working around them.</p>
<p>In the second part of this chapter, we examined some interesting approaches for tracing requests through distributed systems, as well as collecting, aggregating, and searching logs. In the last part of this chapter, we split the monolithic Links 'R' Us project from the previous chapter into a series of microservices and deployed them to our test Kubernetes cluster.</p>
<p>In the next chapter, we will discuss building fault-tolerant systems and build a distributed version of the PageRank calculator using the master/slave pattern.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<ol type="1">
<li>Explain why using the microservices pattern for an MVP or <strong>proof of concept</strong> (<strong>PoC</strong>) project is often considered to be a bad idea.</li>
<li>Describe how the circuit breaker pattern works.</li>
<li>List some of the benefits of being able to trace requests as they travel through the system.</li>
<li>Why is it important to sanitize log output?</li>
<li>Briefly describe the three strategies for collecting logs from the pods running inside a Kubernetes cluster.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Further reading</h1>
                </header>
            
            <article>
                
<div class="references">
<div>
<ol>
<li>A simple, fast, and fun package for building command-line apps in Go:<span> </span><a href="https://github.com/urfave/cli">https://github.com/urfave/cli</a></li>
<li><strong>Calico</strong>: Secure networking for the cloud-native era:<span> </span><a href="https://www.projectcalico.org">https://www.projectcalico.org</a></li>
<li><strong>Cilium</strong>: API-aware networking and security:<span> </span><a href="https://cilium.io">https://cilium.io</a></li>
<li><strong>Docker</strong>: Enterprise container platform:<span> </span><a href="https://www.docker.com">https://www.docker.com</a></li>
</ol>
<ol start="5">
<li><strong>Elastic APM</strong>: Open source application performance monitoring:<span> </span><a href="https://www.elastic.co/products/apm">https://www.elastic.co/products/apm</a></li>
<li><strong>etcd</strong>: A distributed, reliable key-value store for the most critical data of a distributed system:<span> </span><a href="https://etcd.io">https://etcd.io</a></li>
<li><strong>Flannel</strong>: A network fabric for containers, designed for Kubernetes:<span> </span><a href="https://github.com/coreos/flannel">https://github.com/coreos/flannel</a></li>
<li><strong>Fluent Bit</strong>: A cloud-native log forwarder:<span> </span><a href="https://fluentbit.io">https://fluentbit.io</a></li>
<li><strong>gokit/log</strong>: A minimal interface for structured logging in services:<span> </span><a href="https://github.com/go-kit/kit/tree/master/log">https://github.com/go-kit/kit/tree/master/log</a></li>
<li><strong>grpc-opentracing</strong>: A package for enabling distributed tracing in gRPC clients via the OpenTracing project:<span> </span><a href="https://github.com/grpc-ecosystem/grpc-opentracing">https://github.com/grpc-ecosystem/grpc-opentracing</a></li>
<li><strong>Jaeger</strong>: For open source, end-to-end distributed tracing: <a href="https://jaegertracing.io">https://jaegertracing.io</a></li>
<li><strong>kibana</strong>: Your window into the Elastic Stack:<span> </span><a href="https://www.elastic.co/products/kibana">https://www.elastic.co/products/kibana</a></li>
<li>Kubernetes Network Policy Recipes:<span> </span><a href="https://github.com/ahmetb/kubernetes-network-policy-recipes">https://github.com/ahmetb/kubernetes-network-policy-recipes</a></li>
<li><strong>logrus</strong>: Structured, pluggable logging for Go:<span> </span><a href="https://github.com/sirupsen/logrus">https://github.com/sirupsen/logrus</a></li>
<li><strong>Logstash</strong>: Centralize, transform, and stash your data:<span> </span><a href="https://www.elastic.co/products/logstash">https://www.elastic.co/products/logstash</a></li>
<li><strong>OpenZipkin</strong>: A distributed tracing system:<span> </span><a href="https://zipkin.io">https://zipkin.io</a></li>
<li>Sigelman, Benjamin H.<span>;</span><span> </span><span class="smallcaps">Barroso, Luiz André</span><span>;</span><span> </span><span class="smallcaps">Burrows, Mike</span><span>;</span><span> </span><span class="smallcaps">Stephenson, Pat</span><span>;</span><span> </span><span class="smallcaps">Plakal, Manoj</span><span>;</span><span> </span><span class="smallcaps">Beaver, Donald</span><span>;</span><span> </span><span class="smallcaps">Jaspan, Saul</span><span>;</span><span> </span><span class="smallcaps">Shanbhag, Chandan</span><span>:</span><span> </span><em>Dapper, a Large-Scale Distributed Systems Tracing Infrastructure</em><span>. Google, Inc., 2010.</span></li>
<li><strong>The OpenTracing project</strong>:<span> </span><a href="https://opentracing.io">https://opentracing.io</a></li>
<li><strong>The OpenTracing project: Supported tracers</strong>:<span> </span><a href="https://opentracing.io/docs/supported-tracers">https://opentracing.io/docs/supported-tracers</a></li>
<li><strong>zap</strong>: Blazing fast, structured, leveled logging in Go:<span> </span><a href="https://github.com/uber-go/zap">https://github.com/uber-go/zap</a></li>
<li><strong>zerolog</strong>: Zero allocation JSON logger:<span> </span><a href="https://github.com/rs/zerolog">https://github.com/rs/zerolog</a></li>
</ol>
</div>
</div>


            </article>

            
        </section>
    </body></html>