["```go\nservice JobQueue {\n  rpc JobStream(stream WorkerPayload) returns (stream MasterPayload);\n}\n```", "```go\nmessage WorkerPayload {\n oneof payload {\n Step step = 1;\n RelayMessage relay_message = 2;\n }\n}\n```", "```go\nmessage Step {\n  Type type = 1;\n  map<string, google.protobuf.Any> aggregator_values = 2;\n  int64 activeInStep = 3;\n\n  enum Type {\n    INVALID = 0;\n    PRE = 1;\n    POST = 2;\n    POST_KEEP_RUNNING = 3;\n    EXECUTED_GRAPH = 4;\n    PESISTED_RESULTS = 5;\n    COMPLETED_JOB = 6;\n  }\n}\n```", "```go\nmessage RelayMessage {\n  string destination = 1;\n  google.protobuf.Any message = 2;\n}\n```", "```go\nmessage MasterPayload {\n  oneof payload {\n    JobDetails job_details = 1;\n    Step step = 2;\n    RelayMessage relay_message = 3;\n  }\n}\n```", "```go\nmessage JobDetails {\n  string job_id = 1;\n  google.protobuf.Timestamp created_at = 2;\n\n  // The [from, to) UUID range assigned to the worker. Note that from is \n  // inclusive and to is exclusive.\n  bytes partition_from_uuid = 3;\n  bytes partition_to_uuid = 4;\n}\n```", "```go\ntype remoteWorkerStream struct {\n    stream proto.JobQueue_JobStreamServer\n    recvMsgCh chan *proto.WorkerPayload\n    sendMsgCh chan *proto.MasterPayload\n    sendErrCh chan error\n\n    mu sync.Mutex\n    onDisconnectFn func()\n    disconnected bool\n}\n```", "```go\nfunc (s *remoteWorkerStream) RecvFromWorkerChan() <-chan *proto.WorkerPayload {\n    return s.recvMsgCh\n}\n\nfunc (s *remoteWorkerStream) SendToWorkerChan() chan<- *proto.MasterPayload {\n    return s.sendMsgCh\n}\n\nfunc (s *remoteWorkerStream) Close(err error) {\n    if err != nil {\n        s.sendErrCh <- err\n    }\n    close(s.sendErrCh)\n}\n```", "```go\nfunc (s *remoteWorkerStream) SetDisconnectCallback(cb func()) {\n    s.mu.Lock()\n    s.onDisconnectFn = cb\n    if s.disconnected {\n        s.onDisconnectFn()\n    }\n    s.mu.Unlock()\n}\n```", "```go\nfunc newRemoteWorkerStream(stream proto.JobQueue_JobStreamServer) *remoteWorkerStream {\n    return &remoteWorkerStream{\n        stream: stream,\n        recvMsgCh: make(chan *proto.WorkerPayload, 1),\n        sendMsgCh: make(chan *proto.MasterPayload, 1),\n        sendErrCh: make(chan error, 1),\n    }\n}\n```", "```go\nfunc (s *remoteWorkerStream) HandleSendRecv() error {\n    ctx, cancelFn := context.WithCancel(context.Background())\n    defer cancelFn()\n    go s.handleRecv(ctx, cancelFn)\n    for {\n        select {\n        case mPayload := <-s.sendMsgCh:\n            if err := s.stream.Send(mPayload); err != nil {\n                return err\n            }\n        case err, ok := <-s.sendErrCh:\n            if !ok { // signalled to close without an error\n                return nil\n            }\n            return status.Errorf(codes.Aborted, err.Error())\n        case <-ctx.Done():\n            return status.Errorf(codes.Aborted, errJobAborted.Error())\n        }\n    }\n}\n```", "```go\nfunc (s *remoteWorkerStream) handleRecv(ctx context.Context, cancelFn func()) {\n    for {\n        wPayload, err := s.stream.Recv()\n        if err != nil {\n            s.handleDisconnect()\n            cancelFn()\n            return\n        }\n\n        select {\n        case s.recvMsgCh <- wPayload:\n        case <-ctx.Done():\n            return\n        }\n    }\n}\n```", "```go\nfunc (s *remoteWorkerStream) handleDisconnect() {\n    s.mu.Lock()\n    if s.onDisconnectFn != nil {\n        s.onDisconnectFn()\n    }\n    s.disconnected = true\n    s.mu.Unlock()\n}\n```", "```go\ntype remoteMasterStream struct {\n    stream proto.JobQueue_JobStreamClient\n    recvMsgCh chan *proto.MasterPayload\n    sendMsgCh chan *proto.WorkerPayload\n\n    ctx context.Context\n    cancelFn func()\n\n    mu sync.Mutex\n    onDisconnectFn func()\n    disconnected bool\n}\n```", "```go\nfunc newRemoteMasterStream(stream proto.JobQueue_JobStreamClient) *remoteMasterStream {\n    ctx, cancelFn := context.WithCancel(context.Background())\n\n    return &remoteMasterStream{\n        ctx: ctx,\n        cancelFn: cancelFn,\n        stream: stream,\n        recvMsgCh: make(chan *proto.MasterPayload, 1),\n        sendMsgCh: make(chan *proto.WorkerPayload, 1),\n    }\n}\n```", "```go\nfunc (s *remoteMasterStream) RecvFromMasterChan() <-chan *proto.MasterPayload {\n    return s.recvMsgCh\n}\n\nfunc (s *remoteMasterStream) SendToMasterChan() chan<- *proto.WorkerPayload {\n    return s.sendMsgCh\n}\n```", "```go\nfunc (s *remoteMasterStream) HandleSendRecv() error {\n    defer func() {\n        s.cancelFn()\n        _ = s.stream.CloseSend()\n    }()\n    go s.handleRecv()\n    for {\n        select {\n        case wPayload := <-s.sendMsgCh:\n            if err := s.stream.Send(wPayload); err != nil && !xerrors.Is(err, io.EOF) {\n                return err\n            }\n        case <-s.ctx.Done():\n            return nil\n        }\n    }\n}\n```", "```go\nfunc (s *remoteMasterStream) handleRecv() {\n    for {\n        mPayload, err := s.stream.Recv()\n        if err != nil {\n            s.handleDisconnect()\n            s.cancelFn()\n            return\n        }\n        select {\n        case s.recvMsgCh <- mPayload:\n        case <-s.ctx.Done():\n            return\n        }\n    }\n}\n```", "```go\nfunc (s *remoteMasterStream) Close() {\n    s.cancelFn()\n}\n```", "```go\nfunc barrier(numWorkers int) {\n    var wg sync.WaitGroup\n    wg.Add(numWorkers)\n\n    for i := 0; i < numWorkers; i++ {\n        go func() {\n            wg.Done()\n            fmt.Printf(\"Entered the barrier; waiting for other goroutines to join\")\n            wg.Wait()\n            fmt.Printf(\"Exited the barrier\")\n        }()\n    }\n\n    wg.Wait()\n}\n```", "```go\ntype workerStepBarrier struct {\n    ctx context.Context\n    stream *remoteMasterStream\n    waitCh map[proto.Step_Type]chan *proto.Step\n}\n```", "```go\nfunc newWorkerStepBarrier(ctx context.Context, stream *remoteMasterStream) *workerStepBarrier {\n    waitCh := make(map[proto.Step_Type]chan *proto.Step)\n    for stepType := range proto.Step_Type_name {\n        if proto.Step_Type(stepType) == proto.Step_INVALID {\n            continue\n        }\n        waitCh[proto.Step_Type(stepType)] = make(chan *proto.Step)\n    }\n\n    return &workerStepBarrier{\n        ctx: ctx,\n        stream: stream,\n        waitCh: waitCh,\n    }\n}\n```", "```go\nfunc (b *workerStepBarrier) Wait(step *proto.Step) (*proto.Step, error) {\n    ch, exists := b.waitCh[step.Type]\n    if !exists {\n        return nil, xerrors.Errorf(\"unsupported step type %q\", proto.Step_Type_name[int32(step.Type)])\n    }\n    select {\n    case b.stream.SendToMasterChan() <- &proto.WorkerPayload{Payload: &proto.WorkerPayload_Step{Step: step}}:\n    case <-b.ctx.Done():\n        return nil, errJobAborted\n    }\n\n    select {\n    case step = <-ch:\n        return step, nil\n    case <-b.ctx.Done():\n        return nil, errJobAborted\n    }\n}\n```", "```go\nfunc (b *workerStepBarrier) Notify(step *proto.Step) error {\n    ch, exists := b.waitCh[step.Type]\n    if !exists {\n        return xerrors.Errorf(\"unsupported step type %q\", proto.Step_Type_name[int32(step.Type)])\n    }\n\n    select {\n    case ch <- step:\n        return nil\n    case <-b.ctx.Done():\n        return errJobAborted\n    }\n}\n```", "```go\ntype masterStepBarrier struct {\n    ctx context.Context\n    numWorkers int\n    waitCh map[proto.Step_Type]chan *proto.Step\n    notifyCh map[proto.Step_Type]chan *proto.Step\n}\n```", "```go\nfunc newMasterStepBarrier(ctx context.Context, numWorkers int) *masterStepBarrier {\n    waitCh := make(map[proto.Step_Type]chan *proto.Step)\n    notifyCh := make(map[proto.Step_Type]chan *proto.Step)\n    for stepType := range proto.Step_Type_name {\n        if proto.Step_Type(stepType) == proto.Step_INVALID {\n            continue\n        }\n        waitCh[proto.Step_Type(stepType)] = make(chan *proto.Step)\n        notifyCh[proto.Step_Type(stepType)] = make(chan *proto.Step)\n    }\n\n    return &masterStepBarrier{\n        ctx: ctx,\n        numWorkers: numWorkers,\n        waitCh: waitCh,\n        notifyCh: notifyCh,\n    }\n}\n```", "```go\nfunc (b *masterStepBarrier) Wait(step *proto.Step) (*proto.Step, error) {\n    waitCh, exists := b.waitCh[step.Type]\n    if !exists {\n        return nil, xerrors.Errorf(\"unsupported step type %q\", proto.Step_Type_name[int32(step.Type)])\n    }\n    select {\n    case waitCh <- step:\n    case <-b.ctx.Done():\n        return nil, errJobAborted\n    }\n    select {\n    case step = <-b.notifyCh[step.Type]:\n        return step, nil\n    case <-b.ctx.Done():\n        return nil, errJobAborted\n    }\n}\n```", "```go\nfunc (b *masterStepBarrier) WaitForWorkers(stepType proto.Step_Type) ([]*proto.Step, error) {\n    waitCh, exists := b.waitCh[stepType]\n    if !exists {\n        return nil, xerrors.Errorf(\"unsupported step type %q\", proto.Step_Type_name[int32(stepType)])\n    }\n\n    collectedSteps := make([]*proto.Step, b.numWorkers)\n    for i := 0; i < b.numWorkers; i++ {\n        select {\n        case step := <-waitCh:\n            collectedSteps[i] = step\n        case <-b.ctx.Done():\n            return nil, errJobAborted\n        }\n    }\n    return collectedSteps, nil\n}\n```", "```go\nfunc (b *masterStepBarrier) NotifyWorkers(step *proto.Step) error {\n    notifyCh, exists := b.notifyCh[step.Type]\n    if !exists {\n        return xerrors.Errorf(\"unsupported step type %q\", proto.Step_Type_name[int32(step.Type)])\n    }\n\n    for i := 0; i < b.numWorkers; i++ {\n        select {\n        case notifyCh <- step:\n        case <-b.ctx.Done():\n            return errJobAborted\n        }\n    }\n    return nil\n}\n```", "```go\ntype ExecutorFactory func(*bspgraph.Graph, bspgraph.ExecutorCallbacks) *bspgraph.Executor\n```", "```go\nfunc newWorkerExecutorFactory(serializer Serializer, barrier *workerStepBarrier) bspgraph.ExecutorFactory {\n    f := &workerExecutorFactory{ serializer: serializer, barrier: barrier }\n    return func(g *bspgraph.Graph, cb bspgraph.ExecutorCallbacks) *bspgraph.Executor {\n        f.origCallbacks = cb\n        patchedCb := bspgraph.ExecutorCallbacks{\n            PreStep: f.preStepCallback,\n            PostStep: f.postStepCallback,\n            PostStepKeepRunning: f.postStepKeepRunningCallback,\n        }\n        return bspgraph.NewExecutor(g, patchedCb)\n    }\n}\n```", "```go\ntype Serializer interface {\n    Serialize(interface{}) (*any.Any, error)\n    Unserialize(*any.Any) (interface{}, error)\n}\n```", "```go\nfunc (f *workerExecutorFactory) preStepCallback(ctx context.Context, g *bspgraph.Graph) error {\n    if _, err := f.barrier.Wait(&proto.Step{Type: proto.Step_PRE}); err != nil {\n        return err\n    }\n\n    if f.origCallbacks.PreStep != nil {\n        return f.origCallbacks.PreStep(ctx, g)\n    }\n    return nil\n}\n```", "```go\nfunc (f *workerExecutorFactory) postStepCallback(ctx context.Context, g *bspgraph.Graph, activeInStep int) error {\n    aggrDeltas, err := serializeAggregatorDeltas(g, f.serializer)\n    if err != nil {\n        return xerrors.Errorf(\"unable to serialize aggregator deltas\")\n    }\n    stepUpdateMsg, err := f.barrier.Wait(&proto.Step{\n        Type: proto.Step_POST,\n        AggregatorValues: aggrDeltas,\n    })\n    if err != nil {\n        return err\n    } else if err = setAggregatorValues(g, stepUpdateMsg.AggregatorValues, f.serializer); err != nil {\n        return err\n    } else if f.origCallbacks.PostStep != nil {\n        return f.origCallbacks.PostStep(ctx, g, activeInStep)\n    }\n    return nil\n}\n```", "```go\nfunc (f *workerExecutorFactory) postStepKeepRunningCallback(ctx context.Context, g *bspgraph.Graph, activeInStep int) (bool, error) {\n    stepUpdateMsg, err := f.barrier.Wait(&proto.Step{\n        Type: proto.Step_POST_KEEP_RUNNING,\n        ActiveInStep: int64(activeInStep),\n    })\n    if err != nil {\n        return false, err\n    }\n\n    if f.origCallbacks.PostStepKeepRunning != nil {\n        return f.origCallbacks.PostStepKeepRunning(ctx, g, int(stepUpdateMsg.ActiveInStep))\n    }\n    return true, nil\n}\n```", "```go\nfunc (f *masterExecutorFactory) preStepCallback(ctx context.Context, g *bspgraph.Graph) error {\n    if _, err := f.barrier.WaitForWorkers(proto.Step_PRE); err != nil {\n        return err\n    } else if err := f.barrier.NotifyWorkers(&proto.Step{Type: proto.Step_PRE}); err != nil {\n        return err\n    }\n\n    if f.origCallbacks.PreStep != nil {\n        return f.origCallbacks.PreStep(ctx, g)\n    }\n    return nil\n}\n```", "```go\nfunc (f *masterExecutorFactory) postStepCallback(ctx context.Context, g *bspgraph.Graph, activeInStep int) error {\n    workerSteps, err := f.barrier.WaitForWorkers(proto.Step_POST)\n    if err != nil {\n        return err\n    }\n    for _, workerStep := range workerSteps {\n        if err = mergeWorkerAggregatorDeltas(g, workerStep.AggregatorValues, f.serializer); err != nil {\n            return xerrors.Errorf(\"unable to merge aggregator deltas into global state: %w\", err)\n        }\n    }\n    globalAggrValues, err := serializeAggregatorValues(g, f.serializer, false)\n    if err != nil {\n        return xerrors.Errorf(\"unable to serialize global aggregator values: %w\", err)\n    } else if err := f.barrier.NotifyWorkers(&proto.Step{ Type: proto.Step_POST, AggregatorValues: globalAggrValues }); err != nil {\n        return err\n    } else if f.origCallbacks.PostStep != nil {\n        return f.origCallbacks.PostStep(ctx, g, activeInStep)\n    }\n    return nil\n}\n```", "```go\nfunc (f *masterExecutorFactory) postStepKeepRunningCallback(ctx context.Context, g *bspgraph.Graph, activeInStep int) (bool, error) {\n    workerSteps, err := f.barrier.WaitForWorkers(proto.Step_POST_KEEP_RUNNING)\n    if err != nil {\n        return false, err\n    }\n    for _, workerStep := range workerSteps {\n        activeInStep += int(workerStep.ActiveInStep)\n    }\n    if err := f.barrier.NotifyWorkers(&proto.Step{ Type: proto.Step_POST_KEEP_RUNNING, ActiveInStep: int64(activeInStep) }); err != nil {\n        return false, err\n    } else if f.origCallbacks.PostStepKeepRunning != nil {\n        return f.origCallbacks.PostStepKeepRunning(ctx, g, activeInStep)\n    }\n    return true, nil\n}\n```", "```go\ntype Runner interface {\n    StartJob(Details, bspgraph.ExecutorFactory) (*bspgraph.Executor, error)\n    CompleteJob(Details) error\n    AbortJob(Details)\n}\n```", "```go\ntype Details struct {\n    JobID string\n    CreatedAt time.Time\n    PartitionFromID uuid.UUID\n    PartitionToID uuid.UUID\n}\n```", "```go\ntype workerJobCoordinatorConfig struct {\n    jobDetails job.Details\n    masterStream *remoteMasterStream\n    jobRunner job.Runner\n    serializer Serializer\n}\n\nfunc newWorkerJobCoordinator(ctx context.Context, cfg workerJobCoordinatorConfig) *workerJobCoordinator {\n    jobCtx, cancelJobCtx := context.WithCancel(ctx)\n    return &workerJobCoordinator{\n        jobCtx: jobCtx, cancelJobCtx: cancelJobCtx,\n        barrier: newWorkerStepBarrier(jobCtx, cfg.masterStream),\n        cfg: cfg,\n    }\n}\n```", "```go\nfunc (c *workerJobCoordinator) RunJob() error {\n    // ...\n}\n```", "```go\nexecFactory := newWorkerExecutorFactory(c.cfg.serializer, c.barrier)\nexecutor, err := c.cfg.jobRunner.StartJob(c.cfg.jobDetails, execFactory)\nif err != nil {\n    c.cancelJobCtx()\n    return xerrors.Errorf(\"unable to start job on worker: %w\", err)\n}\n\ngraph := executor.Graph()\ngraph.RegisterRelayer(bspgraph.RelayerFunc(c.relayNonLocalMessage))\n```", "```go\nvar wg sync.WaitGroup\nwg.Add(1)\ngo func() {\n defer wg.Done()\n c.cfg.masterStream.SetDisconnectCallback(c.handleMasterDisconnect)\n c.handleMasterPayloads(graph)\n}()\n```", "```go\nif err = c.runJobToCompletion(executor); err != nil {\n c.cfg.jobRunner.AbortJob(c.cfg.jobDetails)\n if xerrors.Is(err, context.Canceled) {\n err = errJobAborted\n }\n if c.asyncWorkerErr != nil {\n err = c.asyncWorkerErr\n }\n}\n\nc.cancelJobCtx()\nwg.Wait() // wait for any spawned goroutines to exit before returning.\nreturn err\n```", "```go\nfunc (c *workerJobCoordinator) runJobToCompletion(executor *bspgraph.Executor) error {\n if err := executor.RunToCompletion(c.jobCtx); err != nil {\n return err\n } else if _, err := c.barrier.Wait(&proto.Step{Type: proto.Step_EXECUTED_GRAPH}); err != nil {\n return errJobAborted\n } else if err := c.cfg.jobRunner.CompleteJob(c.cfg.jobDetails); err != nil {\n return err\n } else if _, err = c.barrier.Wait(&proto.Step{Type: proto.Step_PESISTED_RESULTS}); err != nil {\n return errJobAborted\n }\n\n _, _ = c.barrier.Wait(&proto.Step{Type: proto.Step_COMPLETED_JOB})\n return nil\n}\n```", "```go\nfunc (c *workerJobCoordinator) handleMasterDisconnect() {\n select {\n case <-c.jobCtx.Done(): // job already aborted or completed\n default:\n c.cancelJobCtx()\n }\n}\n```", "```go\nfunc (c *workerJobCoordinator) handleMasterPayloads(graph *bspgraph.Graph) {\n defer c.cancelJobCtx()\n var mPayload *proto.MasterPayload\n for {\n select {\n case mPayload = <-c.cfg.masterStream.RecvFromMasterChan():\n case <-c.jobCtx.Done():\n return\n }\n if mPayload == nil {\n return\n } \n\n // omitted: process payload depending on its type\n }\n}\n```", "```go\nif relayMsg := mPayload.GetRelayMessage(); relayMsg != nil {\n if err := c.deliverGraphMessage(graph, relayMsg); err != nil {\n c.mu.Lock()\n c.asyncWorkerErr = err\n c.mu.Unlock()\n c.cancelJobCtx()\n return\n }\n} else if stepMsg := mPayload.GetStep(); stepMsg != nil {\n if err := c.barrier.Notify(stepMsg); err != nil {\n return\n }\n}\n```", "```go\nfunc (c *workerJobCoordinator) relayNonLocalMessage(dst string, msg message.Message) error {\n serializedMsg, err := c.cfg.serializer.Serialize(msg)\n if err != nil {\n return xerrors.Errorf(\"unable to serialize message: %w\", err)\n }\n wMsg := &proto.WorkerPayload{Payload: &proto.WorkerPayload_RelayMessage{\n RelayMessage: &proto.RelayMessage{\n Destination: dst,\n Message:     serializedMsg,\n },\n }}\n select {\n case c.cfg.masterStream.SendToMasterChan() <- wMsg:\n return nil\n case <-c.jobCtx.Done():\n return errJobAborted\n }\n}\n```", "```go\nfunc (c *workerJobCoordinator) deliverGraphMessage(graph *bspgraph.Graph, relayMsg *proto.RelayMessage) error {\n payload, err := c.cfg.serializer.Unserialize(relayMsg.Message)\n if err != nil {\n return xerrors.Errorf(\"unable to decode relayed message: %w\", err)\n }\n\n graphMsg, ok := payload.(message.Message)\n if !ok {\n return xerrors.Errorf(\"unable to relay message payloads that do not implement message.Message\")\n }\n\n return graph.SendMessage(relayMsg.Destination, graphMsg)\n}\n```", "```go\ntype masterJobCoordinatorConfig struct {\n jobDetails job.Details\n workers    []*remoteWorkerStream\n jobRunner  job.Runner\n serializer Serializer\n logger     *logrus.Entry\n}\n\ntype masterJobCoordinator struct {\n jobCtx       context.Context\n cancelJobCtx func()\n\n barrier   *masterStepBarrier\n partRange *partition.Range\n cfg       masterJobCoordinatorConfig\n}\n```", "```go\nfunc newMasterJobCoordinator(ctx context.Context, cfg masterJobCoordinatorConfig) (*masterJobCoordinator, error) {\n partRange, err := partition.NewRange(cfg.jobDetails.PartitionFromID, cfg.jobDetails.PartitionToID, len(cfg.workers))\n if err != nil {\n return nil, err\n }\n\n jobCtx, cancelJobCtx := context.WithCancel(ctx)\n return &masterJobCoordinator{\n jobCtx:       jobCtx,\n cancelJobCtx: cancelJobCtx,\n barrier:      newMasterStepBarrier(jobCtx, len(cfg.workers)),\n partRange:    partRange,\n cfg:          cfg,\n }, nil\n}\n```", "```go\nexecFactory := newMasterExecutorFactory(c.cfg.serializer, c.barrier)\nexecutor, err := c.cfg.jobRunner.StartJob(c.cfg.jobDetails, execFactory)\nif err != nil {\n c.cancelJobCtx()\n return xerrors.Errorf(\"unable to start job on master: %w\", err)\n}\n\nfor assignedPartition, w := range c.cfg.workers {\n w.SetDisconnectCallback(c.handleWorkerDisconnect)\n if err := c.publishJobDetails(w, assignedPartition); err != nil {\n c.cfg.jobRunner.AbortJob(c.cfg.jobDetails)\n c.cancelJobCtx()\n return err\n }\n}\n```", "```go\nvar wg sync.WaitGroup\nwg.Add(len(c.cfg.workers))\ngraph := executor.Graph()\nfor workerIndex, worker := range c.cfg.workers {\n go func(workerIndex int, worker *remoteWorkerStream) {\n defer wg.Done()\n c.handleWorkerPayloads(workerIndex, worker, graph)\n }(workerIndex, worker)\n}\n```", "```go\nif err = c.runJobToCompletion(executor); err != nil {\n c.cfg.jobRunner.AbortJob(c.cfg.jobDetails)\n if xerrors.Is(err, context.Canceled) {\n err = errJobAborted\n }\n}\n\nc.cancelJobCtx()\nwg.Wait() // wait for any spawned goroutines to exit before returning.\nreturn err\n}\n```", "```go\nfunc (c *masterJobCoordinator) runJobToCompletion(executor *bspgraph.Executor) error {\n if err := executor.RunToCompletion(c.jobCtx); err != nil {\n return err\n } else if _, err := c.barrier.WaitForWorkers(proto.Step_EXECUTED_GRAPH); err != nil {\n return err\n } else if err := c.barrier.NotifyWorkers(&proto.Step{Type: proto.Step_EXECUTED_GRAPH}); err != nil {\n return err\n } else if err := c.cfg.jobRunner.CompleteJob(c.cfg.jobDetails); err != nil {\n return err\n } else if _, err := c.barrier.WaitForWorkers(proto.Step_PESISTED_RESULTS); err != nil {\n return err\n } else if err := c.barrier.NotifyWorkers(&proto.Step{Type: proto.Step_PESISTED_RESULTS}); err != nil {\n return err\n } else if _, err := c.barrier.WaitForWorkers(proto.Step_COMPLETED_JOB); err != nil {\n return err\n }\n return nil\n}\n```", "```go\nfunc (c *masterJobCoordinator) handleWorkerPayloads(workerIndex int, worker *remoteWorkerStream, graph *bspgraph.Graph) {\n    var wPayload *proto.WorkerPayload\n    for {\n        select {\n        case wPayload = <-worker.RecvFromWorkerChan():\n        case <-c.jobCtx.Done():\n            return\n        }\n\n        if relayMsg := wPayload.GetRelayMessage(); relayMsg != nil {\n            c.relayMessageToWorker(workerIndex, relayMsg)\n        } else if stepMsg := wPayload.GetStep(); stepMsg != nil {\n            updatedStep, err := c.barrier.Wait(stepMsg)\n            if err != nil {\n                c.cancelJobCtx()\n                return\n            }\n\n            c.sendToWorker(worker, &proto.MasterPayload{\n                Payload: &proto.MasterPayload_Step{Step: updatedStep},\n            })\n        }\n    }\n}\n```", "```go\ntype Range struct {\n start       uuid.UUID\n rangeSplits []uuid.UUID\n}\n```", "```go\nfunc (r *Range) PartitionForID(id uuid.UUID) (int, error) {\n partIndex := sort.Search(len(r.rangeSplits), func(n int) bool {\n return bytes.Compare(id[:], r.rangeSplits[n][:]) < 0\n })\n\n if bytes.Compare(id[:], r.start[:]) < 0 || partIndex >= len(r.rangeSplits) {\n return -1, xerrors.Errorf(\"unable to detect partition for ID %q\", id)\n }\n return partIndex, nil\n}\n```", "```go\nfunc (c *masterJobCoordinator) relayMessageToWorker(srcWorkerIndex int, relayMsg *proto.RelayMessage) {\n dstUUID, err := uuid.Parse(relayMsg.Destination)\n if err != nil {\n c.cancelJobCtx()\n return\n }\n\n partIndex, err := c.partRange.PartitionForID(dstUUID)\n if err != nil || partIndex == srcWorkerIndex {\n c.cancelJobCtx()\n return\n }\n\n c.sendToWorker(c.cfg.workers[partIndex], &proto.MasterPayload{\n Payload: &proto.MasterPayload_RelayMessage{RelayMessage: relayMsg},\n })\n}\n```", "```go\ntype Worker struct {\n masterConn *grpc.ClientConn\n masterCli  proto.JobQueueClient\n cfg WorkerConfig\n}\n```", "```go\nfunc (w *Worker) Dial(masterEndpoint string, dialTimeout time.Duration) error {\n var dialCtx context.Context\n if dialTimeout != 0 {\n var cancelFn func()\n dialCtx, cancelFn = context.WithTimeout(context.Background(), dialTimeout)\n defer cancelFn()\n }\n conn, err := grpc.DialContext(dialCtx, masterEndpoint, grpc.WithInsecure(), grpc.WithBlock())\n if err != nil {\n return xerrors.Errorf(\"unable to dial master: %w\", err)\n }\n\n w.masterConn = conn\n w.masterCli = proto.NewJobQueueClient(conn)\n return nil\n}\n```", "```go\nstream, err := w.masterCli.JobStream(ctx)\nif err != nil {\n return err\n}\n\nw.cfg.Logger.Info(\"waiting for next job\")\njobDetails, err := w.waitForJob(stream)\nif err != nil {\n return err\n}\n```", "```go\nmasterStream := newRemoteMasterStream(stream)\njobLogger := w.cfg.Logger.WithField(\"job_id\", jobDetails.JobID)\ncoordinator := newWorkerJobCoordinator(ctx, workerJobCoordinatorConfig{\n jobDetails:   jobDetails,\n masterStream: masterStream,\n jobRunner:    w.cfg.JobRunner,\n serializer:   w.cfg.Serializer,\n logger:       jobLogger,\n})\n```", "```go\nvar wg sync.WaitGroup\nwg.Add(1)\ngo func() {\n defer wg.Done()\n if err := masterStream.HandleSendRecv(); err != nil {\n coordinator.cancelJobCtx()\n }\n}()\n```", "```go\nif err = coordinator.RunJob(); err != nil {\n jobLogger.WithField(\"err\", err).Error(\"job execution failed\")\n} else {\n jobLogger.Info(\"job completed successfully\")\n}\nmasterStream.Close()\nwg.Wait()\nreturn err\n```", "```go\nfunc NewMaster(cfg MasterConfig) (*Master, error) {\n if err := cfg.Validate(); err != nil {\n return nil, xerrors.Errorf(\"master config validation failed: %w\", err)\n }\n return &Master{\n cfg:        cfg,\n workerPool: newWorkerPool(),\n }, nil\n}\n```", "```go\nfunc (m *Master) Start() error {\n var err error\n if m.srvListener, err = net.Listen(\"tcp\", m.cfg.ListenAddress); err != nil {\n return xerrors.Errorf(\"cannot start server: %w\", err)\n }\n\n gSrv := grpc.NewServer()\n proto.RegisterJobQueueServer(gSrv, &masterRPCHandler{\n workerPool: m.workerPool,\n logger:     m.cfg.Logger,\n })\n m.cfg.Logger.WithField(\"addr\", m.srvListener.Addr().String()).Info(\"listening for worker connections\")\n go func(l net.Listener) { _ = gSrv.Serve(l) }(m.srvListener)\n\n return nil\n}\n```", "```go\nfunc (h *masterRPCHandler) JobStream(stream proto.JobQueue_JobStreamServer) error {\n extraFields := make(logrus.Fields)\n if peerDetails, ok := peer.FromContext(stream.Context()); ok {\n extraFields[\"peer_addr\"] = peerDetails.Addr.String()\n }\n\n h.logger.WithFields(extraFields).Info(\"worker connected\")\n\n workerStream := newRemoteWorkerStream(stream)\n h.workerPool.AddWorker(workerStream)\n return workerStream.HandleSendRecv()\n}\n```", "```go\nfunc (m *Master) RunJob(ctx context.Context, minWorkers int, workerAcquireTimeout time.Duration) error {\n // implementation omitted\n}\n```", "```go\nvar acquireCtx = ctx\nif workerAcquireTimeout != 0 {\n var cancelFn func()\n acquireCtx, cancelFn = context.WithTimeout(ctx, workerAcquireTimeout)\n defer cancelFn()\n}\nworkers, err := m.workerPool.ReserveWorkers(acquireCtx, minWorkers)\nif err != nil {\n return ErrUnableToReserveWorkers\n}\n```", "```go\njobID := uuid.New().String()\ncreatedAt := time.Now().UTC().Truncate(time.Millisecond)\njobDetails := job.Details{\n JobID:           jobID,\n CreatedAt:       createdAt,\n PartitionFromID: minUUID, // 00000000-00000000-00000000-00000000\n PartitionToID:   maxUUID, // ffffffff-ffffffff-ffffffff-ffffffff\n}\n```", "```go\ncoordinator, err := newMasterJobCoordinator(ctx, masterJobCoordinatorConfig{\n jobDetails: jobDetails,\n workers:    workers,\n jobRunner:  m.cfg.JobRunner,\n serializer: m.cfg.Serializer,\n logger:     logger,\n})\nif err != nil {\n err = xerrors.Errorf(\"unable to create job coordinator: %w\", err)\n for _, w := range workers {\n w.Close(err)\n }\n return err\n}\n```", "```go\nif err = coordinator.RunJob(); err != nil {\n for _, w := range workers {\n w.Close(err)\n }\n return err\n}\n\nfor _, w := range workers {\n w.Close(nil)\n}\nreturn nil\n}\n```", "```go\ntype IncomingScoreMessage struct {\n Score float64\n}\n```", "```go\n// need to run the PageRank calculation algorithm.\nfunc (c *Calculator) registerAggregators() {\n c.g.RegisterAggregator(\"page_count\", new(aggregator.IntAccumulator))\n c.g.RegisterAggregator(\"residual_0\", new(aggregator.Float64Accumulator))\n c.g.RegisterAggregator(\"residual_1\", new(aggregator.Float64Accumulator))\n c.g.RegisterAggregator(\"SAD\", new(aggregator.Float64Accumulator))\n}\n```", "```go\nfunc (serializer) Serialize(v interface{}) (*any.Any, error) {\n scratchBuf := make([]byte, binary.MaxVarintLen64)\n switch val := v.(type) {\n case int:\n nBytes := binary.PutVarint(scratchBuf, int64(val))\n return &any.Any{TypeUrl: \"i\", Value: scratchBuf[:nBytes]}, nil\n case float64:\n nBytes := binary.PutUvarint(scratchBuf, math.Float64bits(val))\n return &any.Any{TypeUrl: \"f\", Value: scratchBuf[:nBytes]}, nil\n case pr.IncomingScoreMessage:\n nBytes := binary.PutUvarint(scratchBuf, math.Float64bits(val.Score))\n return &any.Any{TypeUrl: \"m\", Value: scratchBuf[:nBytes]}, nil\n default:\n return nil, xerrors.Errorf(\"serialize: unknown type %#+T\", val)\n }\n}\n```", "```go\nfunc (serializer) Unserialize(v *any.Any) (interface{}, error) {\n switch v.TypeUrl {\n case \"i\":\n val, _ := binary.Varint(v.Value)\n return int(val), nil\n case \"f\":\n val, _ := binary.Uvarint(v.Value)\n return math.Float64frombits(val), nil\n case \"m\":\n val, _ := binary.Uvarint(v.Value)\n return pr.IncomingScoreMessage{\n Score: math.Float64frombits(val),\n }, nil\n default:\n return nil, xerrors.Errorf(\"unserialize: unknown type %q\", v.TypeUrl)\n }\n}\n```", "```go\ntype Runner interface {\n StartJob(Details, bspgraph.ExecutorFactory) (*bspgraph.Executor, error)\n CompleteJob(Details) error\n AbortJob(Details)\n}\n```", "```go\nfunc (n *MasterNode) StartJob(_ job.Details, execFactory bspgraph.ExecutorFactory) (*bspgraph.Executor, error) {\n if err := n.calculator.Graph().Reset(); err != nil {\n return nil, err\n }\n\n n.jobStartedAt = n.cfg.Clock.Now()\n n.calculator.SetExecutorFactory(execFactory)\n return n.calculator.Executor(), nil\n}\n```", "```go\nfunc (n *MasterNode) AbortJob(_ job.Details) {}\n\nfunc (n *MasterNode) CompleteJob(_ job.Details) error {\n n.cfg.Logger.WithFields(logrus.Fields{\n \"total_link_count\": n.calculator.Graph().Aggregator(\"page_count\").Get(),\n \"total_pass_time\":  n.cfg.Clock.Now().Sub(n.jobStartedAt).String(),\n }).Info(\"completed PageRank update pass\")\n return nil\n}\n```", "```go\nfunc (n *WorkerNode) StartJob(jobDetails job.Details, execFactory bspgraph.ExecutorFactory) (*bspgraph.Executor, error) {\n n.jobStartedAt = time.Now()\n if err := n.calculator.Graph().Reset(); err != nil {\n return nil, err\n } else if err := n.loadLinks(jobDetails.PartitionFromID, jobDetails.PartitionToID, jobDetails.CreatedAt); err != nil {\n return nil, err\n } else if err := n.loadEdges(jobDetails.PartitionFromID, jobDetails.PartitionToID, jobDetails.CreatedAt); err != nil {\n return nil, err\n }\n n.graphPopulateTime = time.Since(n.jobStartedAt)\n\n n.scoreCalculationStartedAt = time.Now()\n n.calculator.SetExecutorFactory(execFactory)\n return n.calculator.Executor(), nil\n}\n```", "```go\nfunc (n *WorkerNode) CompleteJob(_ job.Details) error {\n scoreCalculationTime := time.Since(n.scoreCalculationStartedAt)\n tick := time.Now()\n if err := n.calculator.Scores(n.persistScore); err != nil {\n return err\n }\n scorePersistTime := time.Since(tick)\n n.cfg.Logger.WithFields(logrus.Fields{\n \"local_link_count\":       len(n.calculator.Graph().Vertices()),\n \"total_link_count\":       n.calculator.Graph().Aggregator(\"page_count\").Get(),\n \"graph_populate_time\":    n.graphPopulateTime.String(),\n \"score_calculation_time\": scoreCalculationTime.String(),\n \"score_persist_time\":     scorePersistTime.String(),\n \"total_pass_time\":        time.Since(n.jobStartedAt).String(),\n }).Info(\"completed PageRank update pass\")\n return nil\n}\n```", "```go\nfunc (n *WorkerNode) persistScore(vertexID string, score float64) error {\n linkID, err := uuid.Parse(vertexID)\n if err != nil {\n return err\n }\n return n.cfg.IndexAPI.UpdateScore(linkID, score)\n}\n```"]