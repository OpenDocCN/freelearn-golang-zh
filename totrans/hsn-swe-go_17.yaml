- en: Metrics Collection and Visualization
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指标收集和可视化
- en: '"What''s measured improves."'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '"衡量的是改进的。"'
- en: '- Peter Drucker'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '- 彼得·德鲁克'
- en: 'In the previous chapters, we converted our initial monolithic application into
    a set of microservices that are now running distributed inside our Kubernetes
    cluster. This paradigm shift introduced a new item to our list of project requirements:
    as system operators, we must be able to monitor the health of each individual
    service and be notified when problems arise.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们将我们的初始单体应用程序转换为一组微服务，这些服务现在正在我们的 Kubernetes 集群内部运行。这种范式转变向我们的项目需求列表中引入了一个新项目：作为系统操作员，我们必须能够监控每个单独服务的健康状况，并在出现问题时收到通知。
- en: We will begin this chapter by comparing the strengths and weaknesses of popular
    systems for capturing and aggregating metrics. Then we will focus our attention
    on Prometheus, a popular metrics collection system written entirely in Go. We
    will explore approaches for instrumenting our code to facilitate the efficient
    collection and export of metrics. In the last part of this chapter, we will investigate
    the use of Grafana for visualizing our metrics and the Alertmanager for handling,
    grouping, deduplicating, and routing incoming alerts to a set of notification
    system integrations.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将本章从比较流行的指标捕获和聚合系统的优缺点开始。然后我们将关注 Prometheus，这是一个完全用 Go 编写的流行指标收集系统。我们将探讨为我们的代码添加仪表的方法，以促进指标的高效收集和导出。在本章的最后部分，我们将研究使用
    Grafana 可视化我们的指标以及使用 Alertmanager 处理、分组、去重并将传入警报路由到一组通知系统集成。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Explaining the differences between essential SRE terms such as SLIs, SLOs, and
    SLAs
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释 SRE 术语（如 SLIs、SLOs 和 SLAs）之间的区别
- en: Comparison of push- and pull-based systems for metrics collection and an analysis
    of the pros and cons of each approach
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指标收集基于推送和拉取的系统比较以及每种方法的优缺点分析
- en: Setting up Prometheus and learning how to instrument your Go applications for
    collecting and exporting metrics
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置 Prometheus 并学习如何为收集和导出指标仪表化您的 Go 应用程序
- en: Running Grafana as the visualization frontend for our metrics
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行 Grafana 作为我们的指标的可视化前端
- en: Using the Prometheus ecosystem tools to define and handle alerts
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Prometheus 生态系统工具来定义和处理警报
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The full code for the topics that will be discussed in this chapter has been
    published in this book's GitHub repository under the `Chapter13` folder.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将要讨论的主题的完整代码已发布在本书的 GitHub 仓库中的 `Chapter13` 文件夹下。
- en: You can access this book's GitHub repository, which contains all the code and
    required resources for the chapters in this book, by pointing your web browser
    to the following URL: [https://github.com/PacktPublishing/Hands-On-Software-Engineering-with-Golang](https://github.com/PacktPublishing/Hands-On-Software-Engineering-with-Golang).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过将您的网络浏览器指向以下 URL 来访问本书的 GitHub 仓库，该仓库包含本书各章节的所有代码和所需资源：[https://github.com/PacktPublishing/Hands-On-Software-Engineering-with-Golang](https://github.com/PacktPublishing/Hands-On-Software-Engineering-with-Golang)。
- en: 'To get you up and running as quickly as possible, each example project includes
    a Makefile that defines the following set of targets:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让您尽快开始，每个示例项目都包含一个 Makefile，它定义了以下目标集：
- en: '| **Makefile target** | **Description** |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| **Makefile 目标** | **描述** |'
- en: '| `deps` | Install any required dependencies |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| `deps` | 安装所需的任何依赖项 |'
- en: '| `test` | Run all tests and report coverage |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| `test` | 运行所有测试并报告覆盖率 |'
- en: '| `lint` | Check for lint errors |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| `lint` | 检查 lint 错误 |'
- en: As with the other chapters in this book, you will need a fairly recent version
    of Go, which you can download from [https://golang.org/dl](https://golang.org/dl)*.*
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 与本书中的其他章节一样，您需要一个相当新的 Go 版本，您可以从 [https://golang.org/dl](https://golang.org/dl)*.*
    下载。
- en: To run some of the code in this chapter, you will need to have a working Docker ^([3]) installation
    on your machine.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行本章中的一些代码，您需要在您的机器上安装一个可工作的 Docker ^([3]) 安装。
- en: Monitoring from the perspective of a site reliability engineer
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从站点可靠性工程师的角度进行监控
- en: As we saw in [Chapter 1](5ef11f50-0620-4132-8bfe-c30d6c79f2f5.xhtml), *A Bird's-Eye
    View of Software Engineering*, monitoring the state and performance of software
    systems is one of the key responsibilities associated with the role of a **site
    reliability engineer** (**SRE**). Before we delve deeper into the topic of monitoring
    and alerting, we should probably take a few minutes and clarify some of the SRE-related
    terms that we will be using in the following sections.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第1章](5ef11f50-0620-4132-8bfe-c30d6c79f2f5.xhtml)“软件工程鸟瞰”中看到的，监控软件系统的状态和性能是与**站点可靠性工程师**（SRE）角色相关联的关键职责之一。在我们深入探讨监控和警报的主题之前，我们可能需要花几分钟时间澄清以下章节中将要使用的某些SRE相关术语。
- en: Service-level indicators (SLIs)
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务级别指标（SLIs）
- en: 'An SLI is a type of metric that allows us to quantify the perceived quality
    of a service from the perspective of the end user. Let''s take a look at some
    common types of SLIs that can be applied to cloud-based services:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: SLI是一种指标类型，允许我们从最终用户的角度量化服务的感知质量。让我们看看一些可以应用于基于云服务的常见SLI类型：
- en: '**Availability** is defined as the ratio of two quantities: the time that the
    service can be used by the end user/customer and the total time that the service
    is deployed (including any downtime). For example, if we were operating a service
    that was offline for maintenance for about *53* minutes over the course of the *last
    year*, we could claim that the service had **99.99%** availability for the same
    period.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可用性**定义为两个数量的比率：服务可供最终用户/客户使用的时间和服务的总部署时间（包括任何停机时间）。例如，如果我们运营的服务在过去一年中因维护而离线约*53*分钟，我们可以说该服务在同一期间具有**99.99%**的可用性。'
- en: '**Throughput** is defined as the number of requests that a service processes
    in a given time period (for example, requests per second).'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**吞吐量**定义为在给定时间段内服务处理请求数量（例如，每秒请求数）。'
- en: '**Latency** is yet another interesting SLI and is defined as the time it takes
    for the server to process an incoming request and return a response to the client.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**延迟**是另一个有趣的SLI，定义为服务器处理传入请求并返回响应给客户端所需的时间。'
- en: Service-level objectives (SLOs)
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务级别目标（SLOs）
- en: Back in [Chapter 5](6e4047ad-1fc1-4c3e-b90a-f27a62d06f17.xhtml), *The Links
    'R' Us Project*, where the Links 'R' Us project was first introduced, we briefly
    discussed the concept of SLOs and even provided some example SLOs for the system
    we would be working on.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第5章](6e4047ad-1fc1-4c3e-b90a-f27a62d06f17.xhtml)“链接之用”项目中，我们首次介绍了链接之用项目，我们简要讨论了服务级别目标（SLOs）的概念，并为我们将要工作的系统提供了一些示例SLOs。
- en: An SLO is defined as the range of values for an SLI that allows us to deliver
    a particular level of service to an end user or customer.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: SLO被定义为SLI的值范围，它允许我们向最终用户或客户提供特定水平的服务。
- en: Depending on the underlying SLI, SLOs can either be specified either as a lower
    bound (SLI >= target), an upper bound (SLI <= target), or both (lower-bound <=
    SLI >= upper bound).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 根据基础服务级别指标（SLI），SLOs可以是下限（SLI >= 目标），上限（SLI <= 目标），或者两者（下限 <= SLI >= 上限）。
- en: 'SLO definitions generally consist of three parts: a description of the thing
    that we are measuring (the SLI), the expected service level expressed as a percentage,
    and the period where the measurement takes place. Let''s take a quick look at
    some SLO examples:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: SLO定义通常包括三个部分：我们正在测量的东西的描述（SLI）、以百分比表示的预期服务级别，以及测量发生的期间。让我们快速看一下一些SLO示例：
- en: The system's uptime, when measured in a period of a single month, must be at
    least 99%
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当在单月期间测量时，系统的正常运行时间必须至少为99%。
- en: The response time for 95% of service requests to X, when measured in a period
    of a year, must not exceed 100 ms
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当在一年期间内测量时，对X的95%服务请求的响应时间不得超过100毫秒。
- en: The CPU utilization for the database, when measured in a period of a day, must
    be in the range [40%, 70%]
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当在一天期间测量时，数据库的CPU利用率必须在[40%，70%]范围内。
- en: Service-level agreements (SLAs)
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务级别协议（SLAs）
- en: An SLA is an implicit or explicit contract between a service provider and one
    or more service consumers. The SLA outlines a set of SLOs that have to be met
    and the consequences for both meeting and failing to meet them.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: SLA是服务提供商与一个或多个服务消费者之间的一种隐式或显式合同。SLA概述了必须满足的一组SLOs以及满足和未能满足这些SLOs的后果。
- en: Note that, depending on the type of service being offered, the role of the consumer
    can be fulfilled either by an external third party or an internal company stakeholder.
    In the former case, an SLA would typically define a list of financial penalties
    for failing to meet the agreed SLOs. In the latter case, SLA terms can be less
    strict but must nevertheless be factored in when authoring SLAs for other downstream
    services.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，根据提供的服务类型，消费者的角色可以由外部第三方或内部公司利益相关者承担。在前一种情况下，SLA通常会定义一个因未能达到协议中的SLO而应受的财务处罚清单。在后一种情况下，SLA条款可能不那么严格，但无论如何，在编写其他下游服务的SLA时必须考虑这一点。
- en: Having understood these SRE-related terms, let's move on to metrics.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 理解了这些与SRE相关的术语后，让我们继续讨论指标。
- en: Exploring options for collecting and aggregating metrics
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索收集和汇总指标的选择
- en: The sheer complexity and level of customization that is inherent in modern,
    microservice-based systems has led to the development of specialized tooling to
    facilitate the collection and aggregation of metrics.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现代基于微服务的系统固有的复杂性和定制化水平，导致了专门工具的发展，以促进指标的收集和汇总。
- en: In this section, we will be briefly discussing a few popular pieces of software
    for achieving this task.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将简要讨论一些用于完成此任务的流行软件。
- en: Comparing push versus pull systems
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 比较推送与拉取系统
- en: 'Monitoring and metrics aggregation systems can be classified into two broad
    categories based on the entity that initiates the data collection:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 根据启动数据收集的实体，可以将监控和指标汇总系统分为两大类：
- en: In a **push-based** system, the client (for example, the application or a data
    collection service running on a node) is responsible for transmitting the metrics
    data to the metrics aggregation system. Examples of such systems include StatsD ^([11]),
    Graphite ^([5]), and InfluxDB ^([6]).
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在**基于推送**的系统中，客户端（例如，运行在节点上的应用程序或数据收集服务）负责将指标数据传输到指标汇总系统。此类系统的例子包括StatsD ^([11])、Graphite
    ^([5]) 和 InfluxDB ^([6])。
- en: In a **pull-based** system, metrics collection is the responsibility of the
    metrics aggregation system. In an operation commonly referred to as *scraping*,
    the metrics system initiates a connection to the metrics producers and retrieves
    the set of available metrics. Examples of such systems include Nagios ^([7]) and
    Prometheus ^([10]). We will be exploring Prometheus in more detail in the following
    section.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在**基于拉取**的系统中，指标收集是指标汇总系统的责任。在通常被称为*抓取*的操作中，指标系统启动与指标生产者的连接，并检索可用的指标集。此类系统的例子包括Nagios
    ^([7]) 和 Prometheus ^([10])。在下一节中，我们将更详细地探讨Prometheus。
- en: 'Push- and pull-based systems come with their own set of pros and cons. From
    a software engineer''s perspective, push systems are oftentimes considered to
    be easier to interface with. All of the aforementioned push system implementations
    support a text-based protocol for submitting metrics. You can simply open a socket
    (TCP or UDP) connection to the metrics collector and start submitting metric values.
    As a matter of fact, if we were using either StatsD or Graphite and wanted to
    increment a counter named `requests`, we could do so using nothing more than the
    standard Unix command-line tools, like so:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 基于推送和拉取的系统各有其优缺点。从软件工程师的角度来看，推送系统通常被认为更容易接口。上述所有推送系统实现都支持基于文本的协议来提交指标。您只需打开一个套接字（TCP或UDP）连接到指标收集器，并开始提交指标值。实际上，如果我们使用StatsD或Graphite并想增加一个名为`requests`的计数器，我们可以仅使用标准的Unix命令行工具来完成，如下所示：
- en: '[PRE0]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The lack of a proper flow control mechanism is one of the caveats associated
    with push-based systems. If the rate of metrics production suddenly spikes beyond
    the collector's ability to process, roll up, and/or index incoming metrics, it
    is quite possible that the collector will eventually become unavailable or respond
    to queries with severe lag.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 缺乏适当的流量控制机制是推送系统相关的一个注意事项。如果指标生产的速率突然激增，超出了收集器处理、汇总和/或索引传入指标的能力，那么收集器最终可能变得不可用，或者以严重的延迟响应查询。
- en: On the other hand, in a pull-based system, the ingestion rate for metrics is
    under the control of the collector. Collectors can react to sudden spikes in metric
    production rates by adjusting their scrape rates to compensate.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，在**基于拉取**的系统中，指标的摄取速率由收集器控制。收集器可以通过调整其抓取速率来补偿，从而对指标生产速率的突然激增做出反应。
- en: Pull-based systems are generally considered to be more scalable than their push-based
    counterparts.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 拉取式系统通常被认为比基于推送的系统更具可扩展性。
- en: For some anecdotal evidence on how a system such as Prometheus can be scaled
    up to support scraping a large number of nodes, I would definitely recommend checking
    out Mathew Campbell's fascinating talk on some of the strategies that are used
    by DigitalOcean to collect metrics at scale ^([1]).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何将Prometheus这样的系统扩展以支持抓取大量节点的一些轶事证据，我强烈建议查看Mathew Campbell关于DigitalOcean如何收集大规模指标的某些策略的引人入胜的演讲^([1])。
- en: Of course, pull-based systems come with their own set of cons. To begin with,
    in a pull-based system, the collector needs to be provided with a list of endpoints
    to scrape! This implies either the need for an operator to manually configure
    these endpoints or alludes to the availability of some kind of discovery mechanism
    for automating this process.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，拉取式系统也有其自身的缺点。首先，在拉取式系统中，收集器需要提供要抓取的端点列表！这意味着需要操作员手动配置这些端点，或者暗示存在某种发现机制来自动化此过程。
- en: Secondly, this model assumes that the collector can **always** establish a connection
    to the various endpoints. However, this may not always be possible! Consider a
    scenario where we want to scrape a service that has been deployed to a private
    subnet. That particular subnet is pretty much locked down and does not allow ingress
    traffic from the subnet that the collector is deployed to. In such a case, our
    only option would be to use a push-based mechanism to get the metrics out (while
    ingress traffic is blocked, egress traffic is typically allowed).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，这种模型假设收集器可以**始终**与各种端点建立连接。然而，这并不总是可能的！考虑这样一个场景，我们想要抓取部署到私有子网的服务。那个特定的子网几乎被完全锁定，不允许来自收集器部署的子网的入站流量。在这种情况下，我们唯一的选项就是使用基于推送的机制来获取指标（当入站流量被阻止时，出站流量通常是被允许的）。
- en: Capturing metrics using Prometheus
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Prometheus捕获指标
- en: 'Prometheus is a pull-based metrics collection system that was created at SoundCloud
    and subsequently released as open source. The following illustration (extracted
    from the official Prometheus documentation) describes the basic components that
    comprise the Prometheus ecosystem:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus是一个在SoundCloud创建的基于拉取的指标收集系统，随后作为开源软件发布。以下插图（摘自官方Prometheus文档）描述了构成Prometheus生态系统的基本组件：
- en: '![](img/953555ee-d13c-451e-a8d9-1a0da0b63260.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/953555ee-d13c-451e-a8d9-1a0da0b63260.png)'
- en: Figure 1: The Prometheus architecture
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：Prometheus架构
- en: 'Let''s briefly describe the role of each component shown in the preceding diagram:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 简要描述一下前面图中展示的每个组件的作用：
- en: The **Prometheus server** is the core component of Prometheus. Its primary responsibility
    is to periodically scrape the configured set of targets and persist any collected
    metrics into a time-series database. As a secondary task, the server evaluates
    an operator-defined list of alert rules and emits alert events each time any of
    those rules are satisfied.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus服务器**是Prometheus的核心组件。其主要职责是定期抓取配置的目标集，并将收集到的任何指标持久化到时间序列数据库中。作为次要任务，服务器评估操作员定义的警报规则列表，并在满足任何这些规则时发出警报事件。'
- en: The **Alertmanager** component ingests any alerts emitted by the Prometheus
    server and sends notifications through one or more communication channels (for
    example, email, Slack, or a third-party pager service).
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Alertmanager**组件接收Prometheus服务器发出的任何警报，并通过一个或多个通信渠道（例如，电子邮件、Slack或第三方呼叫服务）发送通知。'
- en: The service discovery layer enables Prometheus to dynamically update the list
    of endpoints to scrape by querying an external service (for example, Consul ^([2]))
    or an API such as the one provided by a container orchestration layer such as
    Kubernetes.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务发现层允许Prometheus通过查询外部服务（例如，Consul^([2]））或API（例如，由Kubernetes等容器编排层提供的API）来动态更新要抓取的端点列表。
- en: The **Pushgateway** component emulates a push-based system for collecting metrics
    from sources that cannot be scraped. This includes both services that are not
    directly reachable (for example, due to strict network policies) by Prometheus,
    as well as short-lived batch jobs. These services can push their metrics stream
    to a gateway, which acts as an intermediate buffer that Prometheus can then scrape
    like any other endpoint.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pushgateway** 组件模拟了一个基于推送的系统，用于从无法刮取的来源收集指标。这包括 Prometheus 无法直接访问的服务（例如，由于严格的网络策略），以及短暂的批量作业。这些服务可以将它们的指标流推送到一个网关，该网关充当
    Prometheus 可以像其他端点一样刮取的中间缓冲区。'
- en: Clients retrieve data from Prometheus by submitting queries written in a bespoke
    query language referred to as **PromQL**. An example of such a client is **Grafana** ^([4]),
    an open source solution for querying and visualizing metrics.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户端通过提交以称为 **PromQL** 的定制查询语言编写的查询从 Prometheus 获取数据。此类客户端的一个例子是 **Grafana** ^([4])，这是一个开源的查询和可视化指标的解决方案。
- en: We will explore these components in more detail in the following sections.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的章节中更详细地探讨这些组件。
- en: Supported metric types
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 支持的指标类型
- en: 'When it comes to a sophisticated metrics collection system such as Prometheus,
    you would normally expect support for a wide array of metric types. Unless you
    have prior experience using Prometheus, you will probably be surprised to find
    out that it only supports four types of metrics. In practice, however, when these
    metric types are combined with the expressiveness of the PromQL language, these
    are all we need to model any type of SLI we can think of! Here is the list of
    metrics supported by Prometheus:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到像 Prometheus 这样的复杂指标收集系统时，您通常会期望支持广泛的指标类型。除非您有使用 Prometheus 的先前经验，否则您可能会惊讶地发现它只支持四种类型的指标。然而，在实践中，当这些指标类型与
    PromQL 语言的表述性相结合时，这些就是我们需要来模拟任何我们可以想到的 SLI 的所有内容！以下是 Prometheus 支持的指标列表：
- en: '**Counters**: A counter is a cumulative metric whose value *increases monotonically* over
    time. Counters can be used to track the number of requests to a service, the number
    of downloads for an application, and so on.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计数器**：计数器是一个累积指标，其值随时间单调递增。计数器可以用来跟踪对服务的请求数量、应用程序的下载次数等。'
- en: '**Gauges**: A gauge tracks a single value that can go up or down. A common
    use case for gauges is to record usage (for example, CPU, memory, and load) stats
    about a server node and metrics such as the total number of users currently connected
    to a particular service.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**仪表**：仪表跟踪一个可以上升或下降的单个值。仪表的常见用例是记录服务器节点关于使用情况（例如，CPU、内存和负载）的统计数据，以及特定服务的当前连接用户总数等指标。'
- en: '**Histograms**: A histogram samples observations and assigns them to a preconfigured
    number of buckets. At the same time, it keeps track of the total number of items
    across all buckets, thus making it possible to calculate quantiles and/or aggregations
    for the histogram contents. Histograms can be used to answer queries such as,
    "what is the response time for serving 90% of requests in the last hour?"'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**直方图**：直方图对观测值进行采样，并将它们分配到预配置的桶中。同时，它跟踪所有桶中的项目总数，从而使得计算直方图内容的分位数和/或聚合成为可能。直方图可以用来回答诸如“在过去一小时中，为
    90% 的请求提供服务的时间是多少？”等问题。'
- en: '**Summaries**: Summaries are similar to histograms in that both metric types
    support bucketing and the calculation of quantiles. However, summaries perform
    quantile calculations directly on the client and can be used as an alternative
    for reducing the query load on the server.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**摘要**：摘要与直方图类似，因为这两种指标类型都支持分桶和计算分位数。然而，摘要直接在客户端执行分位数计算，可以用作减少服务器查询负载的替代方案。'
- en: Automating the detection of scrape targets
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动检测刮擦目标
- en: Prometheus's flexibility really shines when it comes to configuring the set
    of endpoints to be scraped. In this section, we will examine an indicative list
    of options for statically or dynamically configuring the set of endpoints that
    Prometheus pulls metrics from. For the full list of supported discovery options,
    you can refer to the Prometheus documentation ^([8]).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到配置要刮取的端点集时，Prometheus 的灵活性表现得尤为出色。在本节中，我们将检查用于静态或动态配置 Prometheus 从中提取指标的一组端点的指示性选项列表。有关支持的发现选项的完整列表，您可以参考
    Prometheus 文档 ^([8])。
- en: Static and file-based scrape target configuration
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 静态和基于文件的刮擦目标配置
- en: 'A static scrape configuration is considered the canonical way of providing
    scrape targets to Prometheus. The operator includes one or more static configuration
    blocks in the Prometheus configuration file that define the list of target hosts
    to be scraped and the set of labels to apply to the scraped metrics. You can see
    an example of such a block in the following code:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 静态抓取配置被认为是向Prometheus提供抓取目标的标准方式。操作员在Prometheus配置文件中包含一个或多个静态配置块，定义要抓取的目标主机列表以及应用于抓取指标的标签集。您可以在以下代码中看到一个这样的示例块：
- en: '[PRE1]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: An issue with the static config approach is that after updating the Prometheus
    configuration files, we need to restart Prometheus so it can pick up the changes.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 静态配置方法的一个问题是，在更新Prometheus配置文件后，我们需要重新启动Prometheus，以便它可以获取更改。
- en: 'A better alternative is to extract the static configuration blocks to an external
    file and then reference that file from within the Prometheus configuration via
    the `file_sd_config` option:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更好的选择是将静态配置块提取到外部文件中，然后通过`file_sd_config`选项从Prometheus配置中引用该文件：
- en: '[PRE2]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: When file-based discovery is enabled, Prometheus will watch the specified set
    of files for changes and automatically reload their contents once a change has
    been detected.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 当启用基于文件的发现时，Prometheus将监视指定的文件集以查找更改，并在检测到更改后自动重新加载其内容。
- en: Querying the underlying cloud provider
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查询底层云提供商
- en: Out of the box, Prometheus can be configured to leverage the native APIs offered
    by cloud providers such as AWS, GCE, Azure, and OpenStack to detect provisioned
    compute node instances and make them available as targets for scraping.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Prometheus可以被配置为利用云提供商（如AWS、GCE、Azure和OpenStack）提供的本地API，以检测已配置的计算节点实例，并将它们作为抓取目标提供。
- en: Each node discovered by Prometheus is automatically annotated with a series
    of *provider-specific* meta labels. These labels can then be referenced by operator-defined
    match rules to filter out any nodes that the operator is not interested in scraping.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus发现的每个节点都会自动注解一系列*特定提供者*的元标签。然后，这些标签可以通过操作员定义的匹配规则引用，以过滤掉操作员不感兴趣的任何节点。
- en: 'As an example, let''s say that we only want to scrape the EC2 instances that
    contain a tag with the name `scrape` and the value `true`. We can use a configuration
    block such as the following one to achieve this:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们只想抓取带有名为`scrape`且值为`true`的标签的EC2实例。我们可以使用如下配置块来实现这一点：
- en: '[PRE3]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: When Prometheus discovers a new EC2 instance, it will automatically iterate
    its set of tags and generate labels whose names follow the pattern `__meta_ec2_tag_<tagkey>` and
    set their value to the observed tag value. The filtering rule in the preceding
    snippet will discard any nodes where the value of the `__meta_ec2_tag_scrape` label
    does not match the provided regular expression.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 当Prometheus发现新的EC2实例时，它将自动迭代其标签集，并生成名称遵循模式`__meta_ec2_tag_<tagkey>`的标签，并将它们的值设置为观察到的标签值。前面的片段中的过滤规则将丢弃任何`__meta_ec2_tag_scrape`标签的值不匹配提供的正则表达式的节点。
- en: Leveraging the API exposed by Kubernetes
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用Kubernetes公开的API
- en: The last scrape target discovery method that we will be discussing in this chapter
    is highly recommended for workloads running on top of Kubernetes, such as the
    Links 'R' Us project. Once enabled, Prometheus will invoke the API endpoints exposed
    by Kubernetes to obtain information about the resource types that the operator
    is interested in scraping.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论的最后一种抓取目标发现方法，强烈推荐用于在Kubernetes之上运行的工作负载，例如“链接‘R’我们”项目。一旦启用，Prometheus将调用Kubernetes公开的API端点，以获取操作员感兴趣抓取的资源类型信息。
- en: 'Prometheus can be configured to create scrape targets for the following types
    of Kubernetes resources:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus可以被配置为为以下类型的Kubernetes资源创建抓取目标：
- en: '| **Resource Type** | **Description** |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| **资源类型** | **描述** |'
- en: '| **node** | Creates a scrape target for each node in the Kubernetes cluster
    and allows us to collect machine-level metrics that can be exported by running
    a tool such as node-exporter ^([9]). |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| **节点** | 为Kubernetes集群中的每个节点创建一个抓取目标，并允许我们收集可以通过运行工具（如node-exporter ^([9]）导出的机器级指标。
    |'
- en: '| **service** | Scans the Kubernetes `Service` resources and creates a scrape
    target for each exposed port. Prometheus will then attempt to pull any metrics
    exposed by the pods behind the service by performing periodic HTTP GET requests
    to each exposed port at the service''s IP address. This approach relies on the
    fact that `Service` resources act as load balancers by delegating each incoming
    request to a different pod and might be a better-performing alternative compared
    to pulling metrics from all the pods at the same time. |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| **服务** | 扫描 Kubernetes 的 `Service` 资源并为每个暴露的端口创建一个抓取目标。Prometheus 将随后尝试通过在服务
    IP 地址上对每个暴露的端口执行定期的 HTTP GET 请求来拉取由服务背后的 pod 暴露的任何指标。这种方法依赖于 `Service` 资源通过将每个传入请求委派给不同的
    pod 来充当负载均衡器的事实，并且可能比同时从所有 pod 拉取指标有更好的性能。|'
- en: '| **pod** | Discovers all Kubernetes `Pod` resources and creates a scrape target
    for each one of their containers. Prometheus will then perform periodic HTTP GET
    requests to pull the metrics out of each individual container in parallel. |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| **Pod** | 发现所有 Kubernetes 的 `Pod` 资源并为它们的每个容器创建一个抓取目标。然后 Prometheus 将并行执行定期的
    HTTP GET 请求以从每个单独的容器中拉取指标。|'
- en: '| **ingress** | Creates a target for each path on an `Ingress` resource. |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| **入口** | 为 `Ingress` 资源上的每个路径创建一个目标。|'
- en: In a similar fashion to the cloud-aware discovery implementation, Prometheus
    will annotate the discovered set of targets with a resource-specific set of meta
    labels. Based on the previous examples, can you guess what the following configuration
    block does?
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 与云感知发现实现类似，Prometheus 将使用特定于资源的元标签集注释已发现的集合目标。基于前面的示例，你能猜出以下配置块做了什么？
- en: '[PRE4]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Since we specified a `role` equal to `endpoints`, Prometheus will obtain the
    list of pods associated with that service. Prometheus will then create a scrape
    target for *each pod* if – and only if – their parent **service** contains an
    annotation with the name `prometheus_scrape` and the value `true`. This trick
    makes it really easy to enable automatic scraping for any service in our cluster
    simply by editing Kubernetes manifests.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们指定了 `role` 等于 `endpoints`，Prometheus 将获取与该服务关联的 pod 列表。如果 – 仅当 – 它们的父 **服务**
    包含名为 `prometheus_scrape` 且值为 `true` 的注释时，Prometheus 将为每个 pod 创建一个抓取目标。这个技巧使得通过编辑
    Kubernetes 清单来启用我们集群中任何服务的自动抓取变得非常简单。
- en: Instrumenting Go code
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 量化 Go 代码
- en: 'In order for Prometheus to be able to scrape metrics from our deployed services,
    we need to perform the following sequence of steps:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使 Prometheus 能够从我们的部署服务中抓取指标，我们需要执行以下步骤序列：
- en: Define the metrics that we are interested in tracking.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义我们感兴趣跟踪的指标。
- en: Instrument our code base so that it updates the values of the aforementioned
    metrics at the appropriate locations.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 量化我们的代码库，以便在适当的位置更新上述指标值。
- en: Collect the metric data and make it available for scraping over HTTP.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集指标数据并使其可通过 HTTP 进行抓取。
- en: One of the key benefits of microservice-based architectures is that software
    engineers are no longer constrained by the use of a single programming language
    for building their services. It is quite common to see microservices written in
    Go communicating with other services written in Rust or Java. Nevertheless, the
    need to monitor services across the board still remains ubiquitous.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 基于微服务架构的关键好处之一是软件工程师在构建他们的服务时不再受限于使用单一编程语言。看到用 Go 编写的微服务与其他用 Rust 或 Java 编写的服务进行通信是非常常见的。尽管如此，全面监控服务的需求仍然普遍存在。
- en: 'To make it as easy as possible for software engineers to integrate with Prometheus,
    its authors provide client libraries for different programming languages. All
    these clients have one thing in common: they handle all the low-level details
    involved in registering and exporting Prometheus metrics.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让软件工程师尽可能容易地与 Prometheus 集成，其作者为不同的编程语言提供了客户端库。所有这些客户端都有一个共同点：它们处理在注册和导出 Prometheus
    指标中涉及的所有底层细节。
- en: 'The examples in the following sections have a dependency on the official Go
    client package for Prometheus. You can install it by executing the following command:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 下文示例依赖于官方 Prometheus Go 客户端包。您可以通过执行以下命令进行安装：
- en: '[PRE5]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Registering metrics with Prometheus
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Prometheus 中注册指标
- en: '`promauto` is a subpackage of the Prometheus client that defines a set of convenience
    helpers for creating and registering metrics with the minimum possible amount
    of code. Each of the constructor functions from the `promauto` package returns
    a Prometheus metric instance that we can immediately use in our code.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '`promauto`是Prometheus客户端的一个子包，它定义了一组方便的辅助函数，用于以尽可能少的代码创建和注册度量。`promauto`包中的每个构造函数都返回一个Prometheus度量实例，我们可以在代码中立即使用。'
- en: 'Let''s take a quick look at how easy it is to register and populate some of
    the most common metrics types supported by Prometheus. The first metric type that
    we will be instantiating is a simple counter:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速看一下注册和填充Prometheus支持的一些最常见度量类型是多么容易。我们将实例化的第一个度量类型是一个简单的计数器：
- en: '[PRE6]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Each Prometheus metric must be assigned a unique name. If we attempt to register
    a metric with the same name twice, we will get an error. What's more, when registering
    a new metric, we can optionally specify a help message that provides additional
    information about the metric's purpose.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 每个Prometheus度量都必须分配一个唯一的名称。如果我们尝试注册具有相同名称的度量两次，我们将得到一个错误。更重要的是，在注册新度量时，我们可以可选地指定一个帮助信息，该信息提供了有关度量目的的附加信息。
- en: As shown in the preceding code snippet, once we obtain a counter instance, we
    can use the `Inc` method to increment its value and the `Add` method to add an
    arbitrary positive value to the counter.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 如前述代码片段所示，一旦我们获得一个计数器实例，我们可以使用`Inc`方法来增加其值，使用`Add`方法向计数器添加任意正数值。
- en: 'The next type of metric that we will be instantiating is a gauge. Gauges are
    quite similar to counters with the exception that their value can go either up
    or down. In addition to the `Inc` and `Add` methods, gauge instances also provide
    the `Dec` and `Sub` methods. The following block of code defines a gauge metric
    for tracking the number of pending items in a queue:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要实例化的下一类度量是一个仪表。仪表与计数器非常相似，除了它们的值可以上升或下降。除了`Inc`和`Add`方法外，仪表实例还提供了`Dec`和`Sub`方法。以下代码块定义了一个仪表度量，用于跟踪队列中挂起的项的数量：
- en: '[PRE7]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: To conclude our experimentation with the different types of Prometheus metrics,
    we will create a histogram metric. The `NewHistorgram` constructor expects the
    caller to specify a strictly ascending list of `float64` values that describe
    the width of each bucket that's used by the histogram.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 为了总结我们对不同类型Prometheus度量的实验，我们将创建一个直方图度量。`NewHistogram`构造函数期望调用者指定一个严格递增的`float64`值列表，这些值描述了直方图中每个桶的宽度。
- en: 'The following example uses the `LinearBuckets` helper from the `prometheus` package
    to generate `20` distinct buckets with a width of `100` units. The lower bound
    of the *left-most* histogram bucket will be set to the value `0`:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例使用`prometheus`包中的`LinearBuckets`辅助函数生成`20`个具有`100`单位宽度的不同桶。最左侧直方图桶的下限将被设置为值`0`：
- en: '[PRE8]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Adding values to a histogram instance is quite trivial. All we need to do is
    simply invoke its `Observe` method and pass the value we wish to track as an argument.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 向直方图实例添加值非常简单。我们只需要简单地调用其`Observe`方法，并将我们希望跟踪的值作为参数传递。
- en: Vector-based metrics
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于向量的度量
- en: One of the more interesting Prometheus features is its support for partitioning
    collected samples across one or more dimensions (*labels*, in Prometheus terminology).
    If we opt to use this feature, instead of having a single metric instance, we
    can work with a **vector** of metric values.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus的一个更有趣的特性是它支持在维度（在Prometheus术语中称为*labels*）之间分区收集的样本。如果我们选择使用此功能，而不是有一个单个的度量实例，我们可以与一个**向量**的度量值一起工作。
- en: 'In the following example, we have just launched an A/B test for a new website
    layout and we are interested in tracking the number of user registrations for
    each of the page layouts that we are actively trialing:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们刚刚启动了一个针对新网站布局的A/B测试，并且我们感兴趣的是跟踪我们正在积极试验的每个页面布局的用户注册数量：
- en: '[PRE9]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This time, instead of a single counter, we will be creating a vector of counters
    where every sampled value will be automatically tagged with a label named `layout`.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，我们将不再使用单个计数器，而是创建一个计数器向量，其中每个采样值都将自动标记为一个名为`layout`的标签。
- en: To increment or add value to this metric, we need to obtain the correct counter
    by invoking the variadic `WithLabelValues` method on the `regCountVec` variable.
    This method expects a string value for each defined dimension and returns the
    counter instance that corresponds to the provided label values.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 要增加或添加到此指标的值，我们需要通过在 `regCountVec` 变量上调用变长 `WithLabelValues` 方法来获取正确的计数器。此方法期望为每个定义的维度提供一个字符串值，并返回与提供的标签值相对应的计数器实例。
- en: Exporting metrics for scraping
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导出用于抓取的指标
- en: After registering our metrics with Prometheus and instrumenting our code to
    update them where needed, the only additional thing that we need to do is expose
    the collected values over HTTP so that Prometheus can scrape them.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在将我们的指标注册到 Prometheus 并对代码进行配置以在需要时更新它们之后，我们唯一需要做的事情就是通过 HTTP 暴露收集到的值，以便 Prometheus
    可以抓取它们。
- en: The `promhttp` subpackage from the Prometheus client package provides a convenience
    helper function called `Handler` that returns an `http.Handler` instance that
    encapsulates all the required logic for exporting collected metrics in the format
    expected by Prometheus.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 客户端包中的 `promhttp` 子包提供了一个名为 `Handler` 的便利辅助函数，该函数返回一个 `http.Handler`
    实例，该实例封装了导出收集到的指标所需的所有逻辑，这些指标符合 Prometheus 期望的格式。
- en: 'The exported data will not only include the metrics that have been registered
    by the developer but it will also contain an extensive list of metrics that pertain
    to the Go runtime. Some examples of such metrics are as follows:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 导出的数据不仅包括开发人员注册的指标，还包括与 Go 运行时相关的广泛指标列表。以下是一些此类指标的示例：
- en: The number of active goroutines
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 活跃的 goroutine 数量
- en: Information about stack and heap allocation
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于栈和堆分配的信息
- en: Performance statistics for the Go garbage collector
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Go 垃圾收集器的性能统计
- en: 'The following example demonstrates a minimal, self-contained hello-world kind
    of application that defines a counter metric and exposes two HTTP routes: `/ping` and `/metrics`.
    The handler for the first route increments the counter, while the latter exports
    the collected Prometheus metrics:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例演示了一个最小、自包含的 hello-world 类型的应用程序，该应用程序定义了一个计数器指标并公开了两个 HTTP 路由：`/ping` 和
    `/metrics`。第一个路由的处理程序增加计数器，而后者导出收集到的 Prometheus 指标：
- en: '[PRE10]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Try to compile and run the preceding example. You can find its sources in the `Chapter13/prom_http` folder
    in this book's GitHub repository. While the example is running, switch to another
    Terminal and execute a few `curl localhost:8080/ping` commands to increment the
    `pingapp_pings_total` counter.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试编译并运行前面的示例。您可以在本书 GitHub 仓库的 `Chapter13/prom_http` 文件夹中找到其源代码。当示例运行时，切换到另一个终端并执行几个
    `curl localhost:8080/ping` 命令来增加 `pingapp_pings_total` 计数器。
- en: 'Then, execute a `curl localhost:8080/metrics` command and examine the list
    of exported metrics. The following screenshot displays the last few lines of output
    upon executing the preceding command:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，执行一个 `curl localhost:8080/metrics` 命令并检查导出的指标列表。以下截图显示了执行前面命令后的最后几行输出：
- en: '![](img/22c28d11-1d02-4142-894b-20fe34be89bc.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](img/22c28d11-1d02-4142-894b-20fe34be89bc.png)'
- en: Figure 2: A subset of the metrics that have been exported by our example Go
    application
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：我们的示例 Go 应用程序导出的一组指标
- en: As you can see, the output includes not only the current value of the `pingapp_pings_total`
    counter but also several other important metrics that the Prometheus client automatically
    captured from the Go runtime for us.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，输出不仅包括 `pingapp_pings_total` 计数器的当前值，还包括 Prometheus 客户端为我们自动捕获的几个其他重要指标。
- en: Visualizing collected metrics using Grafana
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Grafana 可视化收集到的指标
- en: By this point, you should have already selected a suitable metrics collection
    solution for your applications and instrumented your code base to emit the metrics
    that you are interested in tracking. To make sense of the collected data and reason
    about it, we need to visualize it.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您应该已经为您的应用程序选择了一个合适的指标收集解决方案，并配置了您的代码库以发出您感兴趣跟踪的指标。为了使收集到的数据有意义并对其进行分析，我们需要对其进行可视化。
- en: For this task, we will be using Grafana ^([4]) as our tool of choice. Grafana
    offers a convenient, end-to-end solution that can be used to retrieve metrics
    from a variety of different data sources and construct dashboards for visualizing
    them. The supported list of data sources includes Prometheus, InfluxDB, Graphite,
    Google Stackdriver, AWS CloudWatch, Azure Monitor, SQL databases (MySQL, Postgres,
    and SQL Server), and Elasticsearch.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个任务，我们将使用 Grafana ^([4]) 作为我们的首选工具。Grafana 提供了一个方便的端到端解决方案，可以用于从各种不同的数据源检索指标并为它们构建仪表板进行可视化。支持的数据源列表包括
    Prometheus、InfluxDB、Graphite、Google Stackdriver、AWS CloudWatch、Azure Monitor、SQL
    数据库（MySQL、Postgres 和 SQL Server）以及 Elasticsearch。
- en: 'If you have already set up one of the preceding data sources and want to evaluate
    Grafana, the easiest way to do so is to spin up a Docker container using the following
    command:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经设置了一个前面的数据源并且想要评估 Grafana，最简单的方法是使用以下命令启动一个 Docker 容器：
- en: '[PRE11]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: You can then point your browser at `http://localhost:3000`, log in with the
    preceding credentials, and follow one of the several comprehensive guides available
    at Grafana's website to configure your first dashboard.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以将你的浏览器指向 `http://localhost:3000`，使用前面的凭据登录，并遵循 Grafana 网站上提供的几个综合指南之一来配置你的第一个仪表板。
- en: 'In terms of supported visualization widgets, the standard Grafana installation
    supports the following widget types:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在支持的可视化小部件方面，标准的 Grafana 安装支持以下 widget 类型：
- en: '**Graph**: A flexible visualization component that can plot single- and multi-series
    line charts or bar charts. Furthermore, graph widgets can be configured to display
    multiple series in overlapping or stacked mode.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图形**：一个灵活的可视化组件，可以绘制单系列和多系列线图或条形图。此外，图形小部件可以配置为以重叠或堆叠模式显示多个系列。'
- en: '**Logs panel**: A list of log entries that are obtained by a compatible data
    source (for example, Elasticsearch) whose contents are correlated with the information
    displayed by another widget.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日志面板**：一个日志条目列表，这些条目是通过兼容的数据源（例如，Elasticsearch）获取的，其内容与另一个小部件显示的信息相关联。'
- en: '**Singlestat**: A component that condenses a series into a single value by
    applying an aggregation function (for example, min, max, avg, and so on). This
    component may optionally be configured to display a sparkline chart or to be rendered
    as a gauge.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**单值统计**：一个通过应用聚合函数（例如，min、max、avg 等）将系列压缩为单个值的组件。此组件可以配置为显示折线图或作为仪表渲染。'
- en: '**Heatmap**: A specialized component that renders the changes in a histogram''s
    set of values over time. As shown in the following screenshot, heatmaps comprise a
    set of vertical slices where each slice depicts the histogram values at a particular
    point in time. Contrary to a typical histogram plot, where bar heights represent
    the count of items in a particular bucket, heatmaps apply a color map to visualize
    the frequency of items within each vertical slice.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**热图**：一个专门组件，用于渲染直方图值随时间的变化。如图所示，热图由一系列垂直切片组成，其中每个切片描述特定时间点的直方图值。与典型的直方图图不同，直方图的高度表示特定桶中项目的数量，而热图则使用颜色图来可视化每个垂直切片中项目的频率。'
- en: '**Table**: A component that is best suited for rendering series in tabular
    format.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**表格**：一个最适合以表格格式渲染系列组件。'
- en: 'The following screenshot demonstrates the built-in Grafana widgets as they
    would appear in an example dashboard:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图展示了内置的 Grafana 小部件，它们将如何在示例仪表板中显示：
- en: '![](img/97b28620-80fc-4f2c-b42c-6016705b374a.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/97b28620-80fc-4f2c-b42c-6016705b374a.png)'
- en: Figure 3: An example dashboard built with Grafana
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：使用 Grafana 构建的示例仪表板
- en: Apart from the default, built-in widgets, the operator can install additional
    widget types by leveraging Grafana's plugin mechanism. Examples of such widgets
    include world map, radar, pie, and bubble charts.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 除了默认的内置小部件外，操作员可以通过利用 Grafana 的插件机制安装额外的 widget 类型。此类小部件的示例包括世界地图、雷达图、饼图和气泡图。
- en: Using Prometheus as an end-to-end solution for alerting
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Prometheus 作为端到端警报解决方案
- en: By instrumenting our applications and deploying the necessary infrastructure
    for scraping metrics, we now have the means for evaluating the SLIs for each of
    our services. Once we define a suitable set of SLOs for each of the SLIs, the
    next item on our checklist is to deploy an alert system so that we can be automatically
    notified every time that our SLOs stop being met.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对应用程序进行监控并部署必要的指标抓取基础设施，我们现在有了评估我们每个服务SLIs（Service Level Indicators）的手段。一旦我们为每个SLI定义了一套合适的SLOs（Service
    Level Objectives），我们清单上的下一项就是部署一个警报系统，这样我们就可以在SLOs不再满足时自动收到通知。
- en: 'A typical alert specification looks like this:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的警报规范看起来像这样：
- en: '*When the value of metric **X **exceeds threshold **Y** for **Z** time units,
    then execute actions **a1, a2, a[n]***'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '*当指标值**X**超过阈值**Y**，并且持续**Z**个时间单位时，执行操作**a1, a2, a[n]***'
- en: What is the first thought that springs to mind when you hear a fire alarm going
    off? Most people will probably answer something along the lines of, *there might
    be a fire nearby*. People are naturally conditioned to assume that alerts are
    always temporally correlated with an issue that must be addressed immediately.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 当你听到火灾警报响起时，你首先想到的是什么？大多数人可能会回答类似“附近可能发生了火灾”的话。人们天生就会假设警报总是与必须立即解决的问题在时间上相关联。
- en: When it comes to monitoring the health of production systems, having alerts
    in place that require the immediate intervention of a human operator once they
    trigger is pretty much a standard operating procedure. However, this is not the
    only type of alert that an SRE might encounter when working on such a system.
    Oftentimes, being able to proactively detect and address issues before they get
    out of hand and become a risk for the stability of production systems is the only
    thing that stands between a peaceful night's sleep and that dreaded 2 AM page
    call.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到监控生产系统的健康状态时，一旦触发就需要人工操作员立即干预的警报已经几乎成为标准操作程序。然而，这并不是SRE在处理此类系统时可能遇到的唯一类型的警报。很多时候，能够主动检测并解决在失控并成为生产系统稳定性风险之前的问题，是平静的夜晚和可怕的凌晨2点被叫醒之间的唯一区别。
- en: 'Here is an example of a proactive alert: an SRE sets up an alert that fires
    once the disk usage on a database node exceeds 80% of the available storage capacity.
    Note that when the alarm does fire, the database is still working without any
    issue. However, in this case, the SRE is provided with ample time to plan and
    execute the required set of steps (for example, schedule a maintenance window
    to resize the disk assigned to the DB) to rectify the issue with the minimum disruption
    possible to the database service.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个主动警报的例子：SRE设置了一个警报，一旦数据库节点的磁盘使用率超过可用存储容量的80%，就会触发。请注意，当警报确实触发时，数据库仍在正常工作，没有任何问题。然而，在这种情况下，SRE有足够的时间来计划和执行所需的一系列步骤（例如，安排维护窗口来调整分配给数据库的磁盘大小），以尽可能减少对数据库服务的干扰来解决问题。
- en: Contrast the preceding case with a different scenario where the SRE is paged
    because the database did run out of space and, as a result, several services with
    a downstream dependency on the database are now offline. This is a particularly
    stressful situation for an SRE to be in as the system is already experiencing
    downtime.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 将前一个案例与一个不同的情况进行对比，在这种情况下，SRE（Site Reliability Engineer）被呼叫是因为数据库确实已经没有空间了，因此，现在有多个依赖于数据库的服务已经离线。对于SRE来说，这是一个特别紧张的情况，因为系统已经处于停机状态。
- en: Using Prometheus as a source for alert events
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Prometheus作为警报事件的源
- en: 'In order to use Prometheus as an alert-generating source, operators must define
    a collection of alert rules that Prometheus should monitor. The alert rule definitions
    live in external YAML files that are imported by the main Prometheus configuration
    file using a `rule_files` block, as follows:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将Prometheus用作警报生成源，操作员必须定义一组Prometheus应该监控的警报规则。警报规则定义存储在外部YAML文件中，这些文件通过`rule_files`块被主Prometheus配置文件导入，如下所示：
- en: '[PRE12]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Prometheus organizes multiple alert rules into **groups**. Rules within a group
    are always evaluated *sequentially* while each group is evaluated in *parallel*.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus将多个警报规则组织成**组**。组内的规则总是**顺序**评估，而每个组是**并行**评估的。
- en: 'Let''s take a look at the structure of a simple alert definition. The following
    snippet defines an alert group with the name `example` that contains a single
    alert definition:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个简单的警报定义的结构。以下代码片段定义了一个名为`example`的警报组，其中包含一个警报定义：
- en: '[PRE13]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Each alert block must always be assigned a unique name, as well as a **PromQL**
    (short for **Prometheus query language**) expression that Prometheus will recalculate
    each time it evaluates the alert rule. In the preceding example, the rule expression
    is satisfied once the value of the `up` metric becomes equal to zero.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 每个警报块都必须始终分配一个唯一的名称，以及Prometheus将每次评估警报规则时重新计算的一个**PromQL**（即**Prometheus查询语言**）表达式。在前面的例子中，规则表达式在`up`指标的值变为零时得到满足。
- en: The optional `for` clause can be used to defer the triggering of the alert until
    a particular time period elapses, during which the alert expression must always
    be satisfied. In this example, the alert will only fire if the `up` metric remains
    zero for at least 5 minutes.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 可选的`for`子句可以用来延迟警报的触发，直到经过特定的时间段，在此期间警报表达式必须始终满足。在这个例子中，只有当`up`指标至少保持5分钟为零时，警报才会触发。
- en: 'The `labels` block allows us to attach one or more labels to the alert. In
    this case, we tag the alert with a `severity: page` annotation to advise the component
    that''s responsible for handling the alert that it should page the SRE that is
    currently on call.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '`labels`块允许我们给警报附加一个或多个标签。在这种情况下，我们给警报添加一个`severity: page`注释，以通知负责处理警报的组件，它应该呼叫当前值班的服务可靠性工程师（SRE）。'
- en: Finally, the `annotations` block allows the operator to store additional bits
    of information, such as detailed descriptions of the alert or a URL pointing to
    a playbook for dealing with this kind of alert.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`annotations`块允许操作员存储额外的信息，例如警报的详细描述或指向处理此类警报的playbook的URL。
- en: A playbook is a succinct document that distills the best practices for resolving
    a particular problem. These documents are authored in advance and are normally
    attached to all outgoing notifications that are triggered due to an alert.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: playbook是一个简明的文档，总结了解决特定问题的最佳实践。这些文档提前编写，通常附加到由于警报触发的所有发出的通知。
- en: When an SRE gets paged, being able to access the playbook associated with a
    particular alert is an invaluable asset for quickly diagnosing the root cause
    of the problem and reducing the **mean time to resolution** (**MTTR**).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 当服务可靠性工程师（SRE）被呼叫时，能够访问与特定警报关联的playbook是无价资产，可以快速诊断问题的根本原因并减少**平均修复时间**（**MTTR**）。
- en: Handling alert events
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理警报事件
- en: Prometheus will periodically evaluate the configured set of alert rules and
    emit alert events when the preconditions for a rule are met. By design, the Prometheus
    server is only responsible for emitting alert events; it does not include any
    logic whatsoever for processing alerts.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus将定期评估配置的警报规则集，并在满足规则的前提条件时发出警报事件。按照设计，Prometheus服务器只负责发出警报事件；它不包含任何处理警报的逻辑。
- en: The actual processing of emitted alert events is handled by the Alertmanager
    component. The Alertmanager ingests the alert events emitted by Prometheus and
    is responsible for grouping, deduplicating, and routing each alert to the appropriate
    notification integrations (referred to as **receivers** in Alertmanager terminology).
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 实际处理发出的警报事件由Alertmanager组件负责。Alertmanager消费由Prometheus发出的警报事件，并负责将每个警报分组、去重并将警报路由到适当的通知集成（在Alertmanager术语中称为**接收器**）。
- en: We will begin our brief tour of the Alertmanager component by elaborating on
    how operators can use its built-in grouping and filtering functionality to manage
    incoming alert events. Next, we will learn about the basics of defining alert
    receivers and configuring routing rules to ensure that alerts are always delivered
    to the correct receiver.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将简要介绍Alertmanager组件，详细说明操作员如何使用其内置的分组和过滤功能来管理传入的警报事件。接下来，我们将了解定义警报接收器和配置路由规则的基本知识，以确保警报始终被发送到正确的接收者。
- en: Grouping alerts together
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将警报分组
- en: Dealing with a large volume of alerts that fire concurrently certainly seems
    like a daunting task from an SRE's point of view. To cut through the noise, Alertmanager
    allows operators to specify a set of rules for grouping together alerts based
    on the content of the labels that have been assigned to each alert event by Prometheus.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 处理同时触发的大量警报，从服务可靠性工程师（SRE）的角度来看，确实是一项艰巨的任务。为了过滤掉噪音，Alertmanager允许操作员指定一组规则，根据Prometheus为每个警报事件分配的标签内容来分组警报。
- en: To understand how alert grouping works, let's picture a scenario where 100 microservices
    are all trying to connect to a Kafka queue that is currently unavailable. *Each*
    of the services fires a high-priority alert, which, in turn, causes a new page
    notification to be sent to the SRE that is currently on-call. As a result, the
    SRE will get swamped with hundreds of page notifications about exactly the same
    issue!
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解警报分组是如何工作的，让我们设想一个场景，其中100个微服务都在尝试连接当前不可用的 Kafka 队列。**每个**服务都会触发一个高优先级警报，这反过来又会导致向当前值班的服务可靠性工程师（SRE）发送新的页面通知。结果，SRE
    将收到数百条关于确切相同问题的页面通知！
- en: To avoid situations like this, a much better solution would be to edit the Prometheus
    alert rule definition and ensure that all alert events for the queue service are
    annotated with a particular label, for example, `component=kafka`. Then, we can
    instruct the Alertmanager to group alerts based on the value of the `component` label
    and consolidate all those related to Kafka into a *single page notification*.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这种情况，一个更好的解决方案是编辑 Prometheus 警报规则定义，并确保所有针对队列服务的警报事件都带有特定的标签，例如，`component=kafka`。然后，我们可以指示
    Alertmanager 根据标签`component`的值对警报进行分组，并将所有与 Kafka 相关的警报合并为一条`单一页面通知`。
- en: Selectively muting alerts
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择性静音警报
- en: Another handy Alertmanager feature that you should be aware of is **alert inhibition**.
    This feature allows the operator to *mute* notifications for a set of alerts when
    a specific alert is currently firing.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个你应该注意的 Alertmanager 功能是**警报抑制**。此功能允许操作员在特定警报正在触发时，对一组警报的提醒进行静音。
- en: 'When the Alertmanager loads its configuration file, it looks for the list of
    alert inhibition rules under the top-level `inhibit_rules` key. Each rule entry
    must adhere to the following schema:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 当 Alertmanager 加载其配置文件时，它会在顶级`inhibit_rules`键下查找警报抑制规则的列表。每个规则条目都必须遵循以下模式：
- en: '[PRE14]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The `source_match` and `source_match_re` blocks work as selectors for the alert
    that activates the inhibition rule. The difference between the two blocks is that `source_match` attempts
    an exact match, whereas `source_math_re` matches label values of incoming alerts
    against a regular expression.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '`source_match`和`source_match_re`块作为激活抑制规则的警报的选择器。这两个块之间的区别在于，`source_match`尝试进行精确匹配，而`source_math_re`将传入警报的标签值与正则表达式进行匹配。'
- en: The `target_match` and `target_match_re` blocks are used to select the set of
    alerts that will be suppressed while the inhibition rule is active.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '`target_match`和`target_match_re`块用于选择在抑制规则激活期间将被抑制的警报集合。'
- en: Finally, the `equal` block prevents the inhibition rule from activating unless
    the source and target rules have the same value for the specified labels.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`equal`块防止抑制规则在没有源和目标规则具有指定标签相同值的情况下激活。
- en: To prevent an alert from inhibiting itself, alerts that match both the source
    and the target side of a rule are not allowed to be inhibited.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止警报抑制自身，匹配规则源和目标侧的警报不允许被抑制。
- en: 'As a proof of concept, let''s try to define a rule that suppresses any alert
    that fires during the weekend. A prerequisite for setting up this rule is to create
    a Prometheus alert that **only** fires during the weekend. Then, we can add the
    following block to the Alertmanager''s configuration file:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个概念验证，让我们尝试定义一条规则，以抑制周末期间触发的任何警报。设置此规则的前提是创建一个仅在周末触发的 Prometheus 警报。然后，我们可以在
    Alertmanager 的配置文件中添加以下块：
- en: '[PRE15]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: When the `Weekend` alert is firing, any other alert (excluding itself) will
    be automatically muted!
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 当`周末`警报正在触发时，任何其他警报（不包括自身）将被自动静音！
- en: Configuring alert receivers
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置警报接收器
- en: 'A receiver is nothing more than a fancy way of referring to a collection of
    notification integrations that can send out alerts through various channels. Out
    of the box, the Alertmanager supports the following integrations:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 接收器不过是一个高级别的术语，指的是可以发送警报通过各种渠道的通知集成集合。开箱即用，Alertmanager 支持以下集成：
- en: '**Email**: Send out an email with alert details'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**电子邮件**：发送包含警报详情的电子邮件'
- en: '**Slack/Hipchat/WeChat**: Post alert details to a chat service'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Slack/Hipchat/WeChat**：将警报详情发布到聊天服务'
- en: '**PagerDuty/Opsgenie/VictorOps**: Send a page notification to the SRE currently
    on call'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PagerDuty/Opsgenie/VictorOps**：向当前值班的 SRE 发送页面通知'
- en: '**WebHooks**: An escape hatch for implementing custom integrations'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**WebHooks**：实现自定义集成的逃生舱'
- en: 'When the Alertmanager loads its configuration file, it looks for the list of
    receiver definitions under the top-level `receivers` key. Each receiver block
    must adhere to the following schema:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 当Alertmanager加载其配置文件时，它会在顶级`receivers`键下查找接收者定义列表。每个接收者块必须遵循以下架构：
- en: '[PRE16]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Each receiver must be assigned a unique name that, as we will see in the following
    section, can be referenced by one or more routing rules. The operator must then
    specify a configuration for each notification mechanism that should be activated
    when an alert reaches the receiver.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 每个接收者都必须分配一个唯一的名称，正如我们将在下一节中看到的，该名称可以被一个或多个路由规则引用。然后操作员必须为每个在警报达到接收者时应激活的通知机制指定配置。
- en: 'However, if the operator does not provide **any** configuration block, the
    receiver behaves like a black hole: any alert that reaches it simply gets dropped.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果操作员没有提供任何配置块，接收者表现得像一个黑洞：任何到达它的警报都会被简单地丢弃。
- en: Routing alerts to receivers
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将警报路由到接收者
- en: 'Now, let''s take a closer look at the tree-based mechanism used by the Alertmanager
    for routing incoming alerts to a particular receiver. The top-level section of
    the Alertmanager''s configuration file must **always** define a `route` block.
    The block represents the root node of the tree and can contain the following set
    of fields:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们更深入地看看Alertmanager用于将传入警报路由到特定接收者的基于树的机制。Alertmanager配置文件的最高级部分必须**始终**定义一个`route`块。该块代表树的根节点，可以包含以下一组字段：
- en: '`match`: Specifies a set of label values that must match the values from the
    incoming alert to consider the current route node as matched.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`match`：指定一组标签值，这些值必须与传入警报的值匹配，才能将当前路由节点视为匹配。'
- en: '`match_re`: Similar to `match`, with the exception that label values are matched
    against a regular expression.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`match_re`：与`match`类似，但标签值是匹配正则表达式。'
- en: '`receiver`: The name of the receiver to deliver the incoming alert to if the
    alert matches the current route.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`receiver`：如果警报匹配当前路由，将传入警报交付给接收者的接收者名称。'
- en: '`group_by`: A list of label names to group incoming alerts by.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`group_by`：一组用于按标签分组传入警报的标签名称。'
- en: '`routes`: A set of child `route` blocks. If an alert does not match any of
    the child routes, it will be handled based on the configuration parameters of
    the current route.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`routes`：一组子`route`块。如果警报不匹配任何子路由，它将根据当前路由的配置参数进行处理。'
- en: 'To understand how tree-based routing works in practice, let''s step through
    a simple example. For the purpose of this example, the Alertmanager configuration
    file contains the following routing configurations:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解基于树的路由在实际中是如何工作的，让我们通过一个简单的例子来逐步分析。为了这个例子，Alertmanager的配置文件包含以下路由配置：
- en: '[PRE17]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Let''s see how the Alertmanager figures out the appropriate receiver for various
    incoming alerts by inspecting their label annotations:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过检查它们的标签注释来看看Alertmanager是如何确定各种传入警报的适当接收者的：
- en: If an incoming alert includes a `service` label whose value matches either `cockroachdb` or `cassandra`,
    the Alertmanager will dispatch the alert to the `page-SRE-on-call` receiver.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果传入的警报包含一个值为`cockroachdb`或`cassandra`的`service`标签，Alertmanager将把警报发送到`page-SRE-on-call`接收者。
- en: On the other hand, if the alert includes a `team` label whose value is equal
    to `backend`, the Alertmanager will dispatch it to the `notify-ops-channel-on-slack` receiver.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一方面，如果警报包含一个值为`backend`的`team`标签，Alertmanager将把它发送到`notify-ops-channel-on-slack`接收者。
- en: Any other incoming alert that doesn't match any of the two child routes will
    be dispatched to the `default` receiver by default.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何其他不匹配两个子路由的传入警报将默认发送到`default`接收者。
- en: This completes our tour of the Alertmanager tool. Granted, configuring alert
    rules for your applications can, at first, seem like a daunting task. Hopefully,
    the knowledge you've obtained by reading this chapter will allow you to begin
    experimenting with Prometheus and set up a few rudimentary Alertmanager test rules.
    With a little bit of practice and once you get the hang of the rule syntax, you
    will find that writing more sophisticated rules for monitoring your production
    applications will become a breeze!
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 这就完成了我们对Alertmanager工具的浏览。诚然，为您的应用程序配置警报规则可能一开始看起来是一项艰巨的任务。希望您通过阅读本章获得的知识将使您能够开始尝试使用Prometheus并设置一些基本的Alertmanager测试规则。经过一点实践，一旦您掌握了规则语法，您会发现为监控生产应用程序编写更复杂的规则将变得轻而易举！
- en: Summary
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: At the start of this chapter, we talked about the pros and cons of using a metrics
    collection system such as Prometheus to scrape and aggregate metrics data from
    not only our deployed applications but also from our infrastructure (for example, Kubernetes
    master/worker nodes).
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的开头，我们讨论了使用Prometheus这样的指标收集系统从我们的部署应用以及基础设施（例如，Kubernetes主/工作节点）中抓取和聚合指标数据的优缺点。
- en: Then, we learned how to leverage the official Prometheus client package for
    Go to instrument our code and export the collected metrics over HTTP so that they
    can be scraped by Prometheus. Next, we extolled the benefits of using Grafana
    for building dashboards by pulling in metrics from heterogeneous sources. In the
    final part of this chapter, we learned how to define alert rules in Prometheus
    and gained a solid understanding of using the Alertmanager tool to group, deduplicate,
    and route alert events that are emitted by Prometheus.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们学习了如何利用官方的Prometheus客户端包为Go编写代码进行仪表化，并通过HTTP导出收集到的指标，以便Prometheus可以抓取它们。接下来，我们赞扬了使用Grafana通过从异构源拉取指标来构建仪表板的优点。在本章的最后部分，我们学习了如何在Prometheus中定义警报规则，并深入理解了使用Alertmanager工具对Prometheus发出的警报事件进行分组、去重和路由。
- en: By exploiting the knowledge gained from this chapter, you will be able to instrument
    your Go code-base and ensure that important metrics for your applications' state
    and performance can be collected, aggregated and visualized. Moreover, if your
    current role also includes SRE responsibilities, you can subsequently feed these
    metrics into an alerting system and receive real-time notifications when the SLAs
    and SLOs for your services are not met.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用本章获得的知识，你将能够对你的Go代码库进行仪表化，并确保可以收集、聚合和可视化应用程序状态和性能的重要指标。此外，如果你的当前角色还包括SRE职责，你可以随后将这些指标输入到警报系统中，并在你的服务SLA和SLO未满足时接收实时通知。
- en: Next up, we will cover a few interesting ideas for extending what we have built
    in this book so as to further your understanding of the material.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将介绍一些有趣的想法，以扩展本书中构建的内容，从而进一步加深对材料的理解。
- en: Questions
  id: totrans-223
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What is the difference between an SLI and an SLO?
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: SLI和SLO之间的区别是什么？
- en: Explain how SLAs work.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释SLA是如何工作的。
- en: What is the difference between a push- and pull-based metrics collection system?
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于推送和拉取的指标收集系统之间的区别是什么？
- en: Would you use a push- or pull-based system to scrape data from a tightly locked
    down (that is, no ingress) subnet?
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你会使用基于推送或拉取的系统从严格锁定（即无入站）的子网中抓取数据吗？
- en: What is the difference between a Prometheus counter and a gauge metric?
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Prometheus计数器和度量指标之间的区别是什么？
- en: Why is it important for page notifications to be accompanied by a link to a
    playbook?
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么页面上通知需要附带一个playbook的链接？
- en: Further reading
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: Campbell, Matthew: *Scaling to a Million Machines with Prometheus* (PromCon
    2016): [https://promcon.io/2016-berlin/talks/scaling-to-a-million-machines-with-prometheus](https://promcon.io/2016-berlin/talks/scaling-to-a-million-machines-with-prometheus)
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 坎贝尔，马修：*使用Prometheus扩展到百万台机器*（PromCon 2016）：[https://promcon.io/2016-berlin/talks/scaling-to-a-million-machines-with-prometheus](https://promcon.io/2016-berlin/talks/scaling-to-a-million-machines-with-prometheus)
- en: '**Consul**: Secure service networking: [https://consul.io](https://consul.io)'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Consul**: 安全服务网络：[https://consul.io](https://consul.io)'
- en: '**Docker**: Enterprise container platform: [https://www.docker.com](https://www.docker.com)'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Docker**: 企业级容器平台：[https://www.docker.com](https://www.docker.com)'
- en: '**Grafana**: The open observability platform: [https://grafana.com/](https://grafana.com/)'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Grafana**: 开源的可观察性平台：[https://grafana.com/](https://grafana.com/)'
- en: '**Graphite**: An enterprise-ready monitoring tool that runs equally well on
    cheap hardware or a cloud infrastructure: [https://graphiteapp.org/](https://graphiteapp.org/)'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Graphite**: 一款适用于企业的监控工具，在廉价硬件或云基础设施上运行同样出色：[https://graphiteapp.org/](https://graphiteapp.org/)'
- en: '**InfluxDB**: A time-series database designed to handle high write and query
    loads: [https://www.influxdata.com/products/influxdb-overview](https://www.influxdata.com/products/influxdb-overview)'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**InfluxDB**: 一种设计用于处理高写入和查询负载的时间序列数据库：[https://www.influxdata.com/products/influxdb-overview](https://www.influxdata.com/products/influxdb-overview)'
- en: '**Nagios**: The industry standard In IT infrastructure monitoring: [https://www.nagios.org](https://www.nagios.org)'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Nagios**: IT基础设施监控的行业标准：[https://www.nagios.org](https://www.nagios.org)'
- en: '**Prometheus**: Configuration options: [https://prometheus.io/docs/prometheus/latest/configuration/configuration](https://prometheus.io/docs/prometheus/latest/configuration/configuration)'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus**: 配置选项：[https://prometheus.io/docs/prometheus/latest/configuration/configuration](https://prometheus.io/docs/prometheus/latest/configuration/configuration)'
- en: '**Prometheus**: Exporter for machine metrics: [https://github.com/prometheus/node_exporter](https://github.com/prometheus/node_exporter)'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus**: 机器指标的导出器：[https://github.com/prometheus/node_exporter](https://github.com/prometheus/node_exporter)'
- en: '**Prometheus**: Monitoring system and time-series database: [https://prometheus.io](https://prometheus.io)'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus**: 监控系统和时序数据库：[https://prometheus.io](https://prometheus.io)'
- en: '**StatsD**: Daemon for easy but powerful stats aggregation: [https://github.com/statsd/statsd](https://github.com/statsd/statsd)'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**StatsD**: 用于轻松但强大的统计聚合的守护进程：[https://github.com/statsd/statsd](https://github.com/statsd/statsd)'
