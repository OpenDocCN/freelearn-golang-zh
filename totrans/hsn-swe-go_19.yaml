- en: Assessments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Chapter 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Software engineering is defined as the application of a systematic, disciplined,
    quantifiable approach to the development, operation, and maintenance of software.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Some of the key questions that a software engineer must be able to answer are
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the business use cases that the software needs to support?
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: What components comprise the system and how do they interact with each other?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: What technologies will be used to implement the various system components?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: How will the software be tested to ensure that its behavior matches the customer's
    expectations?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: How does load affect the system's performance and what is the plan for scaling
    the system?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: An SRE spends approximately half of their time on operations-related tasks such
    as dealing with support tickets, being on call, automating processes to eliminate
    human errors, and so on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The waterfall model does not provide a detailed view of the processes that comprise
    each model step. In addition, it does not seem to support cross-cutting processes
    such as project management or quality control that run in parallel with the waterfall
    steps. A significant caveat of the waterfall model is that it operates under the
    assumption that all customer requirements are known in advance. The iterative
    enhancement model attempts to rectify these issues by executing small incremental
    waterfall iterations that allow the development team to adapt to changes in requirements.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'According to the lean development model, the most common sources of waste are
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The introduction of non-essential changes when development is underway
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: Overly complicated decision-making processes for signing off new features
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Unneeded communication between the various project stakeholders and the development
    teams
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The team decides to focus on speedy delivery at the expense of code quality.
    As a result, the code base becomes more complex and defects start accumulating.
    Now, the team must dedicate a part of their development time to fixing bugs instead
    of working on the requested features. Consequently, the implementation stage becomes
    a bottleneck that reduces the efficiency of the entire development process.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The key responsibility of the Product Owner is to manage the backlog for the
    project. On the other hand, the Scrum Master is responsible for organizing and
    running the various Scrum events.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The retrospective serves as a feedback loop for incrementally improving the
    team's performance across sprints. The team members should be discussing both
    the things that went well during the last sprint as well as the things that didn't.
    The outcome of the retrospective should be a list of corrective actions to address
    the problems that were encountered during the sprint.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Automation is important as it reduces the potential for human error. In addition,
    it reduces the time that's needed to test and deploy changes to production. Measuring
    is equally important as it allows DevOps engineers to monitor production services
    and receive alerts when their behavior diverges from the expected norm.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The company is expected to operate in a high-risk environment. For one, the
    new gaming console depends on a piece of technology that is not available yet
    and is being developed by a third party. What''s more, the market is already saturated:
    other, much larger competitors could also be working on their own next-gen console
    systems. The expected competitive advantage for ACME Gaming Systems may be rendered
    obsolete by the time their new system is released. This is yet another source
    of risk. Given the high risk that''s involved, the spiral model with its risk
    assessment and prototyping processes would be the most sensible choice for developing
    the software that will power the new console.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following is what the SOLID acronym initials stand for:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Single responsibility
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Open/Closed
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Liskov substitution
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Interface segregation
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Dependency inversion
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code conflates two responsibilities: retrieving/mutating the state of a
    document and creating a signature for the document''s content. Furthermore, the
    proposed implementation is inflexible as it forces the use of a specific signing
    algorithm. To address this problem, we can remove the `Sign` method from the `Document` type
    and provide an external helper that can sign not only instances of `Document` but
    also any type that can export its content as a string:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The idea behind the interface segregation principle is to provide clients with
    the smallest possible interface that satisfies their needs and thus avoid depending
    on interfaces that will not actually be used. In the provided example, the write
    method receives an `*os.File` instance as an argument. However, as the function
    implementation probably only needs to be able to *write* data to the file, we
    could achieve the same result by passing an `io.Writer` in the place of the `*os.File` instance.
    Apart from breaking the dependency to the `*os.File` concrete type, this change
    will also allow us to reuse the implementation for any type that implements `io.Writer` (for
    example, sockets, loggers, or others).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The use of `util` as a package name is not a recommended practice due to the
    following reasons:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It provides little context as to the package's purpose and contents.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: It can end up as the home for miscellaneous, possibly unrelated types and/or
    methods that would undoubtedly violate the single responsibility principle.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Import cycles cause the Go compiler to emit compile-time errors when you attempt
    to compile and/or run your code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Some of the advantages of using zero values when defining new Go types are
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: An explicit constructor is not required as Go will automatically assign the
    zero value to the fields of an object when it is allocated.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The types can be embedded into other types and used out-of-the-box without any
    further initialization (for example, embedding a `sync.Mutex` into a struct).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Chapter 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The purpose of software versioning is twofold. First, it allows software engineers
    to validate whether an external dependency can be safely upgraded without the
    risk of introducing issues to production systems. Secondly, being able to explicitly
    reference required software dependencies via their versions is a prerequisite
    for implementing the concept of repeatable builds.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A semantic version is a string that satisfies the following format: `MAJOR.MINOR.PATCH`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The major component is incremented when a breaking change is introduced to the
    software
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The minor component is incremented when new functionality is introduced to the
    software in a backward-compatible way
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The patch version is incremented when a backward-compatible fix is applied to
    the code
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: In the first case, we would increment the **minor** version as the new API does
    not break backward compatibility. In the second case, we would increment the **major** version
    as the new required parameter breaks compatibility with older versions of the
    API. Finally, in the third case, we would increment the **patch** version.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: One approach would be to tag each build with a unique, monotonically increasing
    number. Alternatively, we could annotate build artifacts with a timestamp that
    indicates when they were created.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The pros of vendoring are as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The capability to run reproducible builds for current or older versions of a
    piece of software
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Being able to access the required dependencies locally, even if they disappear
    from the place where they were originally hosted
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The cons of vendoring are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Engineers should monitor the change logs for their dependencies and manually
    upgrade them when security fixes become available.
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: If the authors of the vendored dependencies do not follow semantic versioning
    for their packages, upgrading a dependency can introduce breaking changes that
    must be addressed before it's able to compile our code.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Some differences between the dep tool and Go modules are as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Go modules fully integrate with the various commands, such as `go get`, `go
    build`, and `go test`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: While the dep tool selects the **highest** common version for a package, Go
    modules select the **minimum** viable version.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Go modules support multi-versioned dependencies.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Go modules do away with the *vendor* folder that's used by the dep tool.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Chapter 4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A stub satisfies a particular interface and returns **canned** answers for
    every invocation to the methods it implements. Mocks allow us to specify the following
    in a declarative way:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The order and parameters of the expected set of method invocations
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The set of values to be returned for each combination of inputs
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A fake object provides a fully working implementation whose behavior matches
    the objects that they are meant to substitute. For example, instead of having
    our tests communicate with a real **key-value** (**KV**) store, we might inject
    a fake object that provides a compatible, in-memory implementation of the KV store's
    API.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A table-driven test consists of three main components:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A type that encapsulates the parameters for running the test and its expected
    outcome. In Go programs, this is typically facilitated using an anonymous struct.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A slice of test cases to evaluate.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The test runner. Here, a for loop that iterates the list of test cases invokes
    the code under test with the correct set of parameters and verifies that the obtained
    results match the expectations for each test case.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The purpose of unit testing is to ensure that a particular unit of code (a function,
    method, or package), when exercised in **isolation**, behaves according to a set
    of specifications. To this end, a unit test will typically use a mechanism such
    as stubs, mocks, or fake objects to replace any external dependencies of the code
    under test. On the other hand, integration tests are designed to exercise multiple
    units together so as to verify that they interoperate correctly.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Integration tests are designed to exercise multiple units together so as to
    verify that they interoperate correctly. In a similar fashion to unit tests, integration
    tests will oftentimes use a mechanism such as stubs, mocks, or fake objects as
    a substitute for external components (for example, databases, web servers, and
    so on). On the other hand, functional tests do not use any sort of mocking mechanism
    as their primary purpose is to test the behavior of the **complete** system.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The ambassador pattern injects a proxy between an application and a service
    it depends on. The proxy is typically run as a sidecar process alongside the application
    and exposes APIs to do the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Divert outgoing service calls to a different version of the service
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Mock responses to outgoing service calls
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Inject faults to requests or responses for testing purposes
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Chapter 5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Functional requirements outline the list of core functionalities that a system
    will implement, as well as the set of interactions between the system and any
    external actors. On the other hand, non-functional requirements list the mechanisms
    and metrics that we can use to ascertain whether a proposed design is a good fit
    for solving a particular problem.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A user story is comprised of the following two key components:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A requirement specification must always be expressed from the viewpoint of the
    actor interacting with the system
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A set of acceptance criteria (also known as the *definition of done*) for evaluating
    whether the story goals have been successfully met
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: An attacker could submit a carefully crafted link with a link-local address
    that would trick the crawler into making a call to the metadata API offered by
    the cloud provider hosting our project and subsequently caching the response to
    the search index. Moreover, the attacker could submit a URL `file` as its protocol
    type and cause the crawler to read a local file from the machine and leak its
    contents to the search index.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A **service-level objective** (**SLO**) consists of the following parts:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A description of the thing being measured
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The expected service level, specified as a percentage
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The time period where the measurement takes place
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A UML component diagram provides a high-level view of the core components that
    comprise a system and visualizes their dependencies in terms of implemented and
    required interfaces.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Relational databases are a better fit for transactional workloads and for performing
    complex queries. They can scale horizontally using mechanisms such as data sharding
    but at the cost of requiring additional coordination for executing queries. On
    the other hand, NoSQL databases are best suited for crunching massive volumes
    of **denormalized** data. By design, NoSQL databases can efficiently scale horizontally
    (even across data centers), with many NoSQL offerings promising a linear increase
    in query performance as more nodes are added to the cluster. The main caveat of
    NoSQL databases is that they can only satisfy two facets of the **CAP** (**consistency**,
    **availability**, and **partition tolerance**) theorem.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A relational database would be a great fit for systems that perform a large
    volume of concurrent transactions, such as the ones you would expect to find in
    a bank. On the other hand, a system that needs to process a large number of events
    for analytics purposes would probably benefit more from a NoSQL solution.
  prefs: []
  type: TYPE_NORMAL
- en: To scale a DBMS for a read-heavy workload, we would deploy multiple read replicas
    and update our applications to send read-only queries to the replicas and write
    queries to the master node. For a write-heavy workload, we would deploy multiple
    master nodes and enable data sharding so that writes can be efficiently distributed
    across the master nodes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'According to the CAP theorem, distributed systems can only satisfy two of the
    following properties: consistency, availability, and partition tolerance. When
    deciding on which NoSQL solution to use, we must identify which two of the CAP
    terms are the most important for our particular application (CP, AP, or CA) and
    then limit our search to those NoSQL offerings that satisfy our selected CAP requirements.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Having an abstraction layer allows us to decouple the business logic from the
    underlying database system. This makes it much easier to switch to a different
    DBMS in the future, without having to update our business logic. Furthermore,
    testing our business logic code also becomes easier and faster as we can use a
    mechanism such as stubs, mocks, or fake objects to avoid running our tests against
    an actual database instance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: First, you would need to add the new method to the `Indexer` interface. Then,
    following a test-driven approach, you would need to add a test for the expected
    behavior of the new method to the `SuiteBase` type in the `indextest` package.
    Finally, you would need to visit all the types that adhere to the `Indexer` interface
    (in this case, the bleve and Elasticsearch indexers) and add an implementation
    for the new method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Go `interface{}` type conveys no useful information about the underlying
    type. If we use it for representing an argument to a function or a method, we
    effectively bypass the compiler's ability to statically check the function/method
    arguments at compile-time and instead have to manually check whether the input
    can be safely cast into a supported known type.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Instead of running the compute-intensive stages locally, we can migrate them
    to a remote machine with enough computing resources. The respective local stages
    can then be replaced with a proxy that transmits the local payload data to the
    remote machine via a **remote procedure call** (**RPC**), waits for the results,
    and pushes them to the next local stage. The following diagram outlines the proposed
    solution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/87496116-364e-46b7-b79d-45119ae937cc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Each processor function must satisfy the `Processor` interface, whose definition
    is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In addition, we also defined the `ProcessorFunc` type, which acts as an adaptor
    for converting a function with a compatible signature into a type that implements
    the `Processor` interface.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this particular use case, we can define a function that receives a `Processor` and
    a logger (for example, from the `logrus` package) instance and returns a new `Processor` that
    decorates the call to the `Process` method with additional logic that emits a
    log entry if an error occurs. The `makeErrorLoggingProcessor` function shows one
    of the possible ways of implementing this pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: A synchronous pipeline processes one payload at a time in **first-in, first-out**
    (**FIFO**) order and waits for it to exit the pipeline before processing the next
    available payload. As a result, if a single payload takes a long time to be processed,
    it effectively delays processing the payloads that are queued behind it. In an
    asynchronous pipeline, each stage operates asynchronously and can immediately
    begin processing the next payload as soon as the current payload has been sent
    to the next stage.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A dead-letter queue is a mechanism for deferring error handling for pipeline
    payloads to a later time. When the pipeline encounters an error while processing
    a payload, it appends the payload to the dead-letter queue, along with the error
    that occurred. The application can then introspect the contents of the dead-letter
    queue and decide how it wants to handle each error according to its business logic
    (for example, retry the failed payload, log or ignore the error, and so on).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A fixed-size worker pool contains a predetermined number of workers that are
    created at the same time as the pool and remain active (even when they are idle)
    until the pool is destroyed. A dynamic pool is configured with lower and upper
    worker limits and can automatically grow or shrink on demand to accommodate changes
    in the rate of incoming payloads.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To measure the total time that each payload spent in the pipeline, we will modify
    the `pipeline.Payload` struct and add a new *private* field of the `time.Time` type called `processStartedAt`.
    This new field will be used to record the timestamp when the payload entered the
    pipeline. Next, we will modify the `linkSource` implementation to populate `processStartedAt` when
    it emits a new `Payload`. Finally, we will update the (currently empty) `Consume` method
    of `nopSink` to calculate the elapsed time via a call to `time.Since`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The BSP computer is an abstract computer model made up of a collection of potentially
    heterogeneous processors that are interconnected via a computer network. Processors
    can not only access their own local memory, but they can also use the network
    link to exchange data with other processors. In other words, the BSP computer
    is effectively a **distributed memory** computer that can perform computations
    in parallel.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The **Single Program Multiple Data** (**SPMD**) technique models distributed
    data processing tasks as a self-contained piece of software that runs on a single-core
    machine. The program receives a set of data as input, applies a processing function
    to it, and emits some output. Parallelism is then achieved by splitting the dataset
    into batches, launching multiple instances of the **same** program to process
    each batch in parallel, and combining the results.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A super-step is broken down into two phases, or sub-steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A compute step, where each processor executes (in parallel) a single iteration
    of the user's program using the data that was assigned to the processor as input.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A communication step that runs after **all** the processors complete the compute
    step. During this step, processors communicate through the network and compare,
    exchange, or aggregate the results of their individual computations.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following block of code demonstrates how we can create an aggregator to
    keep track of the minimum `int64` value we''ve seen so far. The use of an `int64` pointer
    allows us to detect whether *any* value has been seen so far (otherwise, the pointer
    will be `nil`) and if so, the minimum value that''s been seen by the `Aggregate` method.
    Atomic access to the `int64` value is enforced via the use of `sync.Mutex`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Under the random surfer model, a user performs an initial search and lands
    on a page from the link graph. From that point on, users randomly select one of
    the following two options:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: They can click any outgoing link from the current page and navigate to a new
    page
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Alternatively, they can decide to run a new search query
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The preceding steps continue in perpetuity.
  prefs: []
  type: TYPE_NORMAL
- en: A PageRank score reflects the probability that a random surfer lands on a particular
    web page. In other words, the score expresses the importance (ranking) of each
    web page relative to every other web page on the internet.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At each step of the PageRank algorithm, each link distributes its accumulated
    PageRank score to its outgoing links. Dead-ends receive the PageRank scores from
    pages that are linked to them but never redistribute them as they have no outgoing
    links. If we don't take steps to handle these problematic cases, the graph dead-ends
    will end up with a significantly higher (and incorrect) PageRank score compared
    to regular pages in the graph.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following table summarizes the CRUD endpoints for a user entity:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '| **HTTP Verb** | **Path** | **Expects (JSON)** | **Returns (JSON)** | **HTTP
    Status** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| POST | `/users` | A user entry | The new user entry and its ID | 200 (success)
    or 201 (created) | Create a new user |'
  prefs: []
  type: TYPE_TB
- en: '| GET | `/users` | Nothing | An array with user entries | 200 (success) | Get
    a list of users |'
  prefs: []
  type: TYPE_TB
- en: '| GET | `/users/:id` | Nothing | The user with the specified ID | 200 (success)
    or 404 (not found) | Get user by ID |'
  prefs: []
  type: TYPE_TB
- en: '| PUT | `/users/:id` | A user entry | The updated user entry | 200 (success)
    or 404 (not found) | Update user by ID |'
  prefs: []
  type: TYPE_TB
- en: '| PATCH | `/users/:id` | A *partial* user entry | The updated user entry |
    200 (success) or 404 (not found) | Update individual fields for a user by ID |'
  prefs: []
  type: TYPE_TB
- en: '| DELETE | `/users/:id` | Nothing | Nothing | 200 (success) or 404 (not found)
    | Delete user by ID |'
  prefs: []
  type: TYPE_TB
- en: Basic authentication headers are transmitted as plaintext. By ensuring this
    information is transmitted over a TLS-encrypted channel, we prevent malicious
    actors from intercepting user credentials.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If a malicious adversary manages to install their own **certificate authority**
    (**CA**) on their targets' trusted certificate stores, they can mount a **man-in-the-middle**
    (**MitM**) attack and snoop on the TLS traffic between the target and any third
    party.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In a three-legged OAuth2 flow, the following occurs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A user visits service A and attempts to log in via service B.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The backend server for A generates an authorization URL for service B and redirects
    the user's browser to it. The generated URL includes the set of permissions that
    were requested by A and a URL that B should redirect the user to once they consent
    to granting access.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The user is redirected to service B and consents to the permissions that were
    requested by service A.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The user's browser is redirected to service A with an access code embedded in
    the URL.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The backend server for service A contacts service B and exchanges the access
    code with an access token.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Service A uses the token to access some resource (for example, user details)
    on service B on behalf of the user.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Protocol buffers are superior to JSON for request/response payloads for the
    following reasons:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: They utilize a much more compact binary format to serialize payloads
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Protocol buffer messages are strictly typed and support versioning
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The protoc compiler can be used to generate the required code for working with
    protocol buffer messages in a variety of programming languages
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'gRPC supports the following RPC modes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Unary RPC**: The client performs a request and receives a response.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Server-streaming RPC**: The client initiates an RPC connection to the server
    and receives a stream of responses from the server.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Client-streaming RPC**: The client initiates an RPC connection to the server
    and sends a stream of requests via the open connection. The server processes the
    requests and sends a single response.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bidirectional streaming RPC**: The client and the server share a bidirectional
    channel where each side can asynchronously send and receive messages.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Chapter 10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Some of the benefits of containerization are as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The same container image can run on a local development machine or a cloud instance
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: It is trivial to deploy a new version of a piece of software and perform a rollback
    if something goes wrong
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: It introduces an extra layer of security as applications are isolated from both
    the host and other applications
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Master nodes implement the *control plane* of a Kubernetes cluster. Worker nodes
    pool their resources (CPUs, memory, disks, GPUs, and so on) and execute the workloads
    that have been assigned to them by the master nodes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A regular Kubernetes service acts as a load balancer for distributing incoming
    traffic to a collection of pods. Regular services are reachable via the cluster
    IP address that's assigned to them by Kubernetes. A headless service provides
    the means for implementing a custom service discovery mechanism. It is not assigned
    a cluster IP address and DNS queries for it are returned the full list of pods
    behind the service.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Since both the OAuth2 client ID and secret are sensitive pieces of information,
    the recommended Kubernetes approach for sharing them with the frontend would be
    to create a secret resource.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A Kubernetes deployment creates a pod with non-predictable IDs, whereas a stateful
    set assigns predictable names that are constructed by concatenating the stateful
    set name and the pod ordinal (for example, web-0, web-1, and so on). Another difference
    is that while Kubernetes deployments spin up the required number of pods in parallel,
    a stateful set spins up pods sequentially.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A microservice-based architecture brings a lot of benefits to the table. However,
    at the same time, it adds a lot of complexity to a system and requires additional
    effort to make it resilient against network issues, to monitor its internal state,
    and to debug issues when something goes wrong. Consequently, selecting this pattern
    for an MVP or PoC is often considered to be a form of premature optimization that
    likely introduces more issues than it solves.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When the number of errors from a particular downstream service exceeds a particular
    threshold, the circuit breaker is tripped and all future requests automatically
    fail with an error. Periodically, the circuit breaker lets some requests go through
    and after a number of successful responses, the circuit breaker switches back
    to the open position, thereby allowing all the requests to go through.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Being able to trace requests as they travel through a system allows us to do
    the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure out how much time the request spends in each service and identify potential
    bottlenecks
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Understand and map the dependencies between services
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Pinpoint the root cause of issues that affect production systems
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Log entries may contain sensitive information such as credit card numbers, security
    credentials, customer names, addresses, or social security numbers. Unless we
    actively sanitize these entries, this information will end up in the logs and
    could be potentially visible to entities (employees or third parties) that are
    not authorized to access this kind of information.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To collect logs from the pods running in a Kubernetes cluster, we can use one
    of the following strategies:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use a daemon set to run a log collector on each Kubernetes node. The log collector
    digests the log files from each pod running on the node and ships them to a centralized
    log storage location.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploy a sidecar container in the same pod as the application whose logs we
    want to collect. The sidecar digests the application logs (which could be a single
    file or multiple files) and ships them to a centralized log storage location.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Ship logs directly from within the application.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Chapter 12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a leader-follower configuration, the nodes hold an election and elect a leader
    for the cluster. All reads and writes go through the cluster leader, while the
    other nodes monitor the leader and automatically hold a new election if the leader
    becomes unavailable. As the name implies, in a multi-master configuration, the
    cluster has several master nodes and each of the master nodes can serve both read
    and write requests. The master nodes implement some form of distributed consensus
    algorithm (Raft, Paxos, and so on) to ensure that they always share the same view
    of the cluster's state.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When implementing the checkpoint strategy, workers are periodically asked by
    the master to persist their current state to durable storage. If this operation
    succeeds, a new checkpoint is created. If a worker crashes or becomes unavailable,
    the master will request for the remaining healthy workers to load their state
    from the last known checkpoint and resume executing the computation job from that
    point on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The distributed barrier is a synchronization primitive that notifies the master
    node when all the workers have reached the same exact point of execution. This
    primitive is a prerequisite for executing compute jobs under the BSP model (see
    [Chapter 8](c505ec2d-0bd8-4edd-97e1-d06de2b326a5.xhtml), *Graph-Based Data Processing*),
    which requires that all the processors execute each super-step in the lockstep.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: While the algorithm itself has completed without any errors, something might
    go wrong if one or more workers attempt to persist their results to durable storage.
    Consequently, a computation job can't really be considered as completed until **all** the workers
    have persisted the results of the computation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A **service-level indicator** (**SLI**) is a type of metric that allows us to
    quantify the perceived quality of the service from the perspective of the end
    user (for example, metrics such as availability, throughput, and latency). A **service-level
    objective** (**SLO**) is the range of values for some SLIs that allow us to deliver
    a particular level of service to an end user or customer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A **service-level agreement** (**SLA**) is an implicit or explicit contract
    between a service provider and one or more service consumers. The SLA outlines
    a set of SLOs that have to be met and the consequences (financial or not) for
    meeting and failing to meet them.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In a push-based metrics collection system, the metric-producing clients connect
    to the metrics collection and aggregation service over a TCP or UDP connection
    and publish their metrics. In a pull-based system, the metrics collection system,
    at its own leisure, connects to each client and collects (scrapes) any new metrics.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Due to the network security policies in place, the metrics collection service
    would not be able to establish a connection to any of the metrics producers in
    the locked-down subnet. However, the applications running on that subnet should
    still be able to access other subnets, including the one that the metrics collection
    service runs on. Consequently, the logical choice in such a situation is to use
    a push-based system.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The value of a Prometheus counter can only increase, while the value of a Prometheus
    gauge can both increase and decrease.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A playbook is a short document that distills the best practices for resolving
    a particular type of problem. Having access to the playbook associated with a
    particular alert reduces the **mean time to resolution** (**MTTR**) as SREs can
    follow the playbook instructions to quickly diagnose the root cause of the problem
    and apply the recommended set of steps to fix it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
