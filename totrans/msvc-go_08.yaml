- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deployment with Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you have reached this chapter, you already know how to bootstrap microservices,
    set up the logic for accessing the database, implement service APIs, use serialization,
    and enable asynchronous communication between your microservices. Now, we are
    ready to cover a topic that is very important in practice—microservice deployment.
  prefs: []
  type: TYPE_NORMAL
- en: '`localhost` for **Kafka**. At some point, you will need to run your services
    remotely—for example, on a remote server or in a cloud, such as **Amazon Web Services**
    (**AWS**) or Microsoft Azure.'
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will help you to learn how to build and set up your applications
    for deployments to such remote infrastructure. Additionally, we are going to illustrate
    how to use one of the most popular deployment and orchestration systems, Kubernetes.
    You will learn about the benefits it provides, as well as how to set it up for
    the microservices that we created in the previous chapters.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Preparing application code for deployments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying via Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment best practices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let’s proceed to the first part of the chapter, which is going to help
    you to better understand the core ideas behind the deployment process, and prepare
    your microservices for deployments.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To complete this chapter, you need Go `1.11+` or above, similar to the previous
    chapters. Additionally, you will need Docker, which you can download at [https://www.docker.com](https://www.docker.com).
    You will need to register on the Docker website in order to test service deployments
    in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to Docker, to complete this chapter, you will need Kubernetes, which
    you can download at [https://kubernetes.io](https://kubernetes.io) (you will need
    the `kubectl` and `minikube` tools from it).
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find the GitHub code for this chapter here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/microservices-with-go/tree/main/Chapter08](https://github.com/PacktPublishing/microservices-with-go/tree/main/Chapter08)'
  prefs: []
  type: TYPE_NORMAL
- en: Preparing application code for deployments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to provide a high-level overview of a service
    deployment process and describe the actions required to prepare your microservices
    for deployments. You will learn how to configure Go microservices for running
    in different environments, how to build them for different operating systems,
    and some other tips for preparing your microservices for remote execution.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s proceed to the basics of the deployment process.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment basics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we mentioned in the introduction to this chapter, deployments allow you to
    run and update your applications on one or multiple servers. Such servers are
    usually located remotely (clouds or dedicated web hosting) and are running all
    the time to allow your applications to serve the request or process data 24/7.
  prefs: []
  type: TYPE_NORMAL
- en: 'The deployment process for each environment usually consists of multiple steps.
    The steps include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Build**: Build a service by compiling it (for compiled languages, such as
    Go) and including additional required files.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Rollout**: Copy the newly created build to servers of the target environment
    and replace the existing running code, if any, with the newly built one.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The rollout process is usually sequential: instead of replacing the build on
    all hosts parallelly, it performs one replacement at a time. For example, if you
    have ten service instances, the rollout process would first update one instance,
    then verify that the instance is healthy and move to the second one, and continue
    until it updates the last service instance. This is done to increase service reliability
    because if a new version consists of a bug or entirely fails to start on some
    server, the rollout would not affect all servers at once.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to enable the testing of microservices, servers can be classified
    into multiple categories, called environments:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Local/development**: Servers that are used for running and testing code while
    working on the code. This environment should never handle any requests from users,
    and it often consists just of a developer’s computer. It can be also configured
    to use simplified versions of a database and other components, such as single-server
    and in-memory implementations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Production**: Servers that are intended to handle user requests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Staging**: A mirror of a production environment, but is used for testing.
    Staging differs from the local/production environment due to configuration and
    separate data storages, which help to avoid any interference with production data
    during testing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Production deployments can be done in **canary** mode—a deployment mode that
    performs the changes only on a small fraction (such as 1%) of production hosts.
    Canary deployments are useful for the final testing of new code before updating
    all production instances of a service.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now see how developers can configure their microservices for deployments
    to multiple environments.
  prefs: []
  type: TYPE_NORMAL
- en: Application configuration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous section, we described the differences between various environments,
    such as local/development and production. Each environment is usually configured
    differently—if your services have access to databases, each environment will generally
    have a separate database with different credentials. To enable your services to
    run in such environments, you would need to have multiple configurations of your
    services, one per environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two ways of configuring your services:'
  prefs: []
  type: TYPE_NORMAL
- en: '**In-place/hardcode**: All required settings are stored in the service code
    (Go code, in our case).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Separate code and configuration**: Configuration is stored in separate files
    so that it can be modified independently.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Separating service code and configuration often results in better readability,
    which makes configuration changes easier. Each environment can have a separate
    configuration file or a set of files, allowing you to read, review, and update
    environment-specific configurations easily. Additionally, various data formats,
    such as YAML, can help to keep configuration files compact. Here’s a YAML configuration
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In this book, we are going to use an approach that separates application code
    and configuration files and stores the configuration in YAML format. This approach
    is common to many Go applications and can be seen in many popular open source
    Go projects.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that invalid configuration changes are among the top causes of service
    outages in most production systems. I suggest you explore various ways of automatically
    validating configuration files as a part of the code commit flow. An example of
    Git-based YAML configuration validation is provided in the following article:
    [https://ruleoftech.com/2017/git-pre-commit-and-pre-receive-hooks-validating-yaml](https://ruleoftech.com/2017/git-pre-commit-and-pre-receive-hooks-validating-yaml).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s review our microservice code and see which settings can be extracted
    from the application configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our `metadata service` does not have any settings other than its gRPC handler
    address, `localhost:8081`, which you can find in its `main.go` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can extract this setting to the service configuration. A YAML configuration
    file with this setting would look like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s make the changes for reading the configuration from a file. Inside the
    `metadata/cmd` directory, create a `config.go` file and add the following code
    to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In addition to this, create a `configs` directory inside the `metadata` service
    directory and add a `base.yaml` file to it with the following contents:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The file we just created contains the YAML configuration for our service. Now,
    let’s add code to our `main.go` file to read the configuration. Replace the first
    line of the `main` function that prints a log message with this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Additionally, replace the line with the `net.Listen` call with this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The code we have just added is using a `gopkg.in/yaml.v3` package to read a
    YAML file. Import it into our module by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Make the same changes that we just made for the other two services we created
    earlier. Use port number `8082` for the `rating` service and `8083` for the `movie`
    service in your YAML files.
  prefs: []
  type: TYPE_NORMAL
- en: The changes we just made helped us introduce the application configuration that
    is separate from the service logic. This can help us when we want to introduce
    additional configurable options—to make any configuration changes, we would just
    need to update the YAML files without touching our service Go code.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have finished configuring our microservices for deployment, we are
    ready to move to the next section, which is going to cover the deployment process
    of our microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying via Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to illustrate how to set up deployments for our
    microservices using a popular open source deployment and orchestration platform,
    Kubernetes. You will learn the basics of Kubernetes, how to set up our microservices
    for using it, and how to test our microservice deployments in Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Kubernetes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Kubernetes** is an open source deployment and orchestration platform that
    was initially created at Google and later maintained by a large developer community
    backed by the Linux Foundation. Kubernetes provides a powerful, scalable, and
    flexible solution for running and deploying applications of any size, from small
    single-instance applications to ones having tens of thousands of instances. Kubernetes
    helps to orchestrate multiple operations, such as deployments, rollbacks, up-
    and down-scaling of applications (changing the application instance count upward
    and downward), and many more.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In Kubernetes, each application consists of one or multiple **pods**—the smallest
    deployable units. Each pod contains one or multiple **containers**—lightweight
    software blocks containing the application code. The deployment of a single container
    to multiple pods is illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1 – Kubernetes deployment model'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.1_B188651.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.1 – Kubernetes deployment model
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes pods can be run on one or multiple hosts, called **nodes**. A group
    of nodes is called a **cluster**, and the relationship between the cluster, nodes,
    and its pods is illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2 – Kubernetes cluster model'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.2_B188651.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.2 – Kubernetes cluster model
  prefs: []
  type: TYPE_NORMAL
- en: 'For deploying a service in Kubernetes, developers generally need to perform
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Prepare a container image**: A **container image** contains either the application
    code or its compiled binary (both options can be used, as long as the container
    image contains the instructions and any tools to run the code), as well as any
    additional files required for running it. A container image is essentially a program
    ready for deployment.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Create a deployment configuration**: A Kubernetes deployment configuration
    tells it how to run the application. It includes settings such as the number of
    replicas (number of pods to run), names of containers, and many more.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Run a deployment command**: Kubernetes will apply the provided configuration
    by running the desired number of pods with the target application(s).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'One of the benefits of Kubernetes is abstracting away all the low-level details
    of deployments, such as selecting target servers to deploy (if you have many,
    you need to balance their load otherwise), copying and extracting your files,
    and running health checks. In addition to this, there are some other useful benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Service discovery**: Kubernetes offers a built-in service discovery API for
    use in applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rollbacks**: In case there are any issues with the deployment, Kubernetes
    allows you to roll back the changes to the previous state.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Automated restarts**: If any pod experiences any issue, such as an application
    crash, Kubernetes will perform a restart of that pod.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let’s describe how we can set up deployments of our microservices using
    Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up our microservices for Kubernetes deployments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'All the necessary steps for setting up deployments in Kubernetes for our three
    microservices are set out here:'
  prefs: []
  type: TYPE_NORMAL
- en: The first step is to create a container image for each service. Kubernetes supports
    multiple types of containers, and Docker is currently the most popular container
    type. We already used Docker in [*Chapter 3*](B18865_03.xhtml#_idTextAnchor051)
    and will illustrate now how to use it for creating containers for our services.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Inside the `metadata` service directory, create a file called `Dockerfile`
    and add the following code to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: In the file that we just added, we specified that to prepare the image for our
    container for the `metadata` service, Docker should use the `alpine:latest` base
    image. `main` to a container, copy the `configs` directory of the service, and
    expose an `8081` port so that we can accept incoming requests on it.
  prefs: []
  type: TYPE_NORMAL
- en: As the next step, add a file with the same contents inside the `rating` and
    the `movie` service directories. Make sure you use the right ports in the files
    (`8082` and `8083`, correspondingly).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once you have created the Docker configuration files, run the `build` command
    inside each service directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The results of the previous command should be the executable file called `main`,
    stored in each service directory. Note that we used a `GOOS=linux` variable—this
    tells the `go` tool to build our code for the Linux operating system.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next step is to build service images. Run this command from the `metadata`
    service directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, run this command from the `rating` service directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, run this command from the `movie` service directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'If each command is executed successfully, we are ready to run out containers
    using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The result of each execution should be a successful execution of each service.
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to create Docker Hub repositories in your account so that you
    can publish your service images to them. Log in to [https://hub.docker.com](https://hub.docker.com),
    go to the `metadata`, `rating`, and `movie`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Execute the following commands to publish the images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: These commands should upload the images we just created to your Docker Hub repositories
    so that Kubernetes can download them during the deployment.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we are ready to create a Kubernetes deployment configuration
    that is going to tell Kubernetes how to deploy our services.
  prefs: []
  type: TYPE_NORMAL
- en: 'Inside the `metadata` service directory, create a file called `kubernetes-deployment.yml`
    with the following contents:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The file that we just created provides instructions to Kubernetes on how to
    deploy our service. Here are some important settings:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Replicas**: The number of pods to run'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image**: The name of the container image to deploy'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ports**: Container port to expose'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that the container port is different from the application port (the one
    that we configured in our `APIConfig` structure). The mapping between these settings
    is done by Docker as a part of the `docker run` settings.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, create a file with the same name in the `rating` service directory with
    the following contents:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Remember to replace the `image` property with the Docker image name that you
    created in *step 4*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, create a `kubernetes-deployment.yml` file in the `movie` service directory
    with the following contents:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE91]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The next step is to start the local Kubernetes cluster using the `minikube`
    tool, which you should have installed as a part of Kubernetes. Run the following
    command to start the cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, apply our `metadata` deployment configuration by running the following
    command from the `metadata` service directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'If the previous command is executed successfully, you should see the new deployment
    by running this command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the command should be this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, check the state of the service pods by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should show the `Running` status for our `metadata` service pods,
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: As you may notice, Kubernetes created two pods for our service, the same number
    as we specified in the deployment configuration. Each pod has a `metadata` service.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can check the logs of each pod by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: Now, perform the same changes that we did for the `metadata` service for the
    other two services, and verify that the pods are running.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to make some manual API requests to the services, you need to set
    up port forwarding by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: This command would work for the `metadata`, `rating`, and `movie` services;
    however, you would need to replace the `8081` port value with `8082` and `8083`,
    correspondingly.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you did everything well, congratulations! We have finished setting up basic
    Kubernetes deployments of our microservices. Let’s summarize what we did in this
    section:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we created container images for each of our services so that we could
    deploy them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we published our container images to Docker Hub so that Kubernetes could
    pull the images during the deployment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We created a Kubernetes deployment configuration to tell it how to deploy our
    microservices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we tested our Kubernetes deployments using a combination of `minikube`
    and `kubectl` commands.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At this point, you should have some understanding of Kubernetes deployments
    and know how to deploy your microservices using them. This knowledge will help
    you to run your services on many platforms, including all popular cloud platforms,
    such as AWS, Azure, and **Google Cloud Platform** (**GCP**).
  prefs: []
  type: TYPE_NORMAL
- en: Deployment best practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we are going to describe some best practices related to the
    deployment process. These practices, listed here, will help you to set up a reliable
    deployment process for your microservices:'
  prefs: []
  type: TYPE_NORMAL
- en: Automated rollbacks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Canary deployments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuous deployment (CD)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automated rollbacks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Automated rollbacks** are the mechanism of automatically reverting a deployment
    in case there was a failure during it. Imagine you are making deployment of a
    new version of your service and that version has some application bug that is
    preventing it from starting successfully. In that case, the deployment process
    will replace your active instances of a service (if the service is already running)
    with the failing ones, making your services unavailable. Automated rollbacks are
    a way to detect and revert such bad deployments, helping you to avoid an outage
    in situations when your services become unavailable due to such issues.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Automated rollbacks are not offered by default in Kubernetes, at the time of
    writing this book, similar to many popular deployment platforms. However, this
    should not stop you from using this technique, especially if you aim to achieve
    high reliability of your services. The high-level idea of implementing automated
    rollbacks with Kubernetes is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Perform continuous health checks of your service (we are going to cover such
    logic in [*Chapter 12*](B18865_12.xhtml#_idTextAnchor171) of this book).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When you detect a health issue with your service, check whether there was a
    recent deployment of your service. For example, you can do so by running the `kubectl
    describe deployment` command.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In case there was a recent deployment and the time of it closely matches the
    time when the health check issues were detected, you can roll it back by executing
    this rollback command: `kubectl rollout undo deployment <DEPLOYMENT_NAME>`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Canary deployments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we mentioned at the beginning of the chapter, canary is a special type of
    deployment, where you update only a small fraction (1 to 3%) of instances. The
    idea of canary deployments is to test a new version of your code on a subset of
    production instances and validate its correctness before doing a regular production
    deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 'We won’t cover the details of setting up canary deployments in Kubernetes,
    but can cover the basic ideas that would help you to do this once you want to
    enable canary deployments for your microservices, as set out here:'
  prefs: []
  type: TYPE_NORMAL
- en: Create two separate Kubernetes deployment configurations, one for canary and
    one for production.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Specify the desired number of replicas in each configuration—if you want to
    run a service on 50 pods and let canary handle 2% of traffic, set 1 replica for
    canary and 49 replicas for production.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You may also add environment-specific suffixes to deployment names. For example,
    you can call a canary deployment of a rating service, `rating-canary,` and `rating-production`
    for the production environment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When you perform a deployment of your service, deploy it using a canary configuration
    first.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once you verify that the deployment was successful, make a deployment using
    a production configuration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Canary deployments are strongly recommended for increasing the reliability of
    your deployments. Testing new changes on a small fraction of traffic helps to
    reduce the impact of various application bugs and other types of issues that your
    services can encounter.
  prefs: []
  type: TYPE_NORMAL
- en: Replace with Continuous Deployment (CD)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Continuous Deployment** (**CD**) is a technique of making frequent recurring
    deployments. With CD, services get deployed automatically—for example, on each
    code change. The main benefit of CD is early deployment failure detection—if any
    change (such as a Git commit of a new service code) is causing a deployment failure,
    the failure would often get detected much sooner than in the case of manual deployments.'
  prefs: []
  type: TYPE_NORMAL
- en: You can automate deployments by programmatically monitoring a change log (such
    as Git commit history), or by using `kubectl apply` command.
  prefs: []
  type: TYPE_NORMAL
- en: Due to the high cadence of version updates, CD requires some tooling for automated
    checks of service health. We are going to cover such tooling later in [*Chapter
    11*](B18865_11.xhtml#_idTextAnchor152) and [*Chapter 12*](B18865_12.xhtml#_idTextAnchor171)
    of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have covered a very important topic—service deployments.
    You have learned about the basics of the service deployment process, as well as
    the necessary steps for preparing our microservices for deployment. Then, we introduced
    Kubernetes, a popular deployment and orchestration platform that is now provided
    by many companies and cloud providers. We have illustrated how to set up a local
    Kubernetes cluster and deploy our microservices to it, running multiple instances
    of each service to illustrate how easy is to run any arbitrary number of instances
    within the Kubernetes platform.
  prefs: []
  type: TYPE_NORMAL
- en: The knowledge you gained should help you to set up more complex deployment processes,
    as well as to work with the services that are already deployed via Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter summarizes our material on service deployments. In the next chapter,
    we are going to describe another important topic: unit and integration.'
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you’d like to learn more, refer to the following links:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes documentation: [https://kubernetes.io/docs/home/](https://kubernetes.io/docs/home/
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Service deployment best practices: [https://codefresh.io/learn/software-deployment/](https://codefresh.io/learn/software-deployment/
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Setting up Kubernetes services: [https://kubernetes.io/docs/concepts/services-networking/service/](https://kubernetes.io/docs/concepts/services-networking/service/
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Blue-green deployments: [https://www.redhat.com/en/topics/devops/what-is-blue-green-deployment](https://www.redhat.com/en/topics/devops/what-is-blue-green-deployment)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
