- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: Collecting Service Telemetry Data
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 收集服务遥测数据
- en: In the previous chapter, we explored the topic of service reliability and described
    various techniques for making your services more resilient to different types
    of errors. You learned that reliability-related work consists of making constant
    improvements in incident detection, mitigation, and prevention techniques.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们探讨了服务可靠性的主题，并描述了各种使您的服务更能抵御不同类型错误的技术。您了解到与可靠性相关的工作包括在事件检测、缓解和预防技术方面进行持续改进。
- en: In this chapter, we are going to take a closer look at various types of service
    performance data, which is essential for setting up service health monitoring
    and debugging and automating service incident detection. You will learn how to
    collect service logs, metrics, and traces, and how to visualize and debug communication
    between your microservices using the distributed tracing technique.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将更深入地探讨各种类型的服务性能数据，这对于设置服务健康监控、调试和自动化服务事件检测至关重要。您将学习如何收集服务日志、指标和跟踪信息，以及如何使用分布式跟踪技术可视化并调试微服务之间的通信。
- en: 'We will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下主题：
- en: Telemetry overview
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遥测概述
- en: Collecting service logs
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集服务日志
- en: Collecting service metrics
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集服务指标
- en: Collecting service traces
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集服务跟踪
- en: Now, let’s proceed to the overview of all the techniques that we are going to
    describe in this chapter.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续概述本章将要描述的所有技术。
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To complete this chapter, you will need Go 1.11+ or above. You will also need
    the following tools:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 要完成本章，您需要Go 1.11或更高版本。您还需要以下工具：
- en: '**grpcurl**: [https://github.com/fullstorydev/grpcurl](https://github.com/fullstorydev/grpcurl)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**grpcurl**：[https://github.com/fullstorydev/grpcurl](https://github.com/fullstorydev/grpcurl)'
- en: '**Jaeger**: [https://www.jaegertracing.io/](https://www.jaegertracing.io/)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Jaeger**：[https://www.jaegertracing.io/](https://www.jaegertracing.io/)'
- en: 'You can find the GitHub code for this chapter here: [https://github.com/PacktPublishing/microservices-with-go/tree/main/Chapter11](https://github.com/PacktPublishing/microservices-with-go/tree/main/Chapter11).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在此处找到本章的GitHub代码：[https://github.com/PacktPublishing/microservices-with-go/tree/main/Chapter11](https://github.com/PacktPublishing/microservices-with-go/tree/main/Chapter11)。
- en: Telemetry overview
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 遥测概述
- en: 'In the introduction to this chapter, we mentioned that there are different
    types of service performance data, all of which are essential for service health
    monitoring and troubleshooting. These types of data are called **telemetry data**
    and include the following:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的介绍中，我们提到了存在不同类型的服务性能数据，所有这些对于服务健康监控和故障排除都是必不可少的。这些类型的数据被称为**遥测数据**，包括以下内容：
- en: '**Logs**: Messages recorded by your services that provide insights into the
    operations they perform or errors they encounter'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日志**：由您的服务记录的消息，提供了对它们执行的操作或遇到的错误的洞察'
- en: '**Metrics**: Performance data produced by your services, such as the number
    of registered users, API request error rate, or percentage of free disk space'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指标**：由您的服务产生的性能数据，例如注册用户数量、API请求错误率或可用磁盘空间的百分比'
- en: '**Traces**: Data that shows how your services perform various operations, such
    as API requests, which other services they call, which internal operations they
    perform, and how long these operations take'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**跟踪**：显示您的服务执行各种操作的数据，例如API请求，它们调用了哪些其他服务，它们执行了哪些内部操作，以及这些操作花费了多长时间'
- en: 'Telemetry data is *immutable*: it captures events that have already happened
    to the service and provides the results of various measurements, such as service
    API response latency. When different types of telemetry data are combined, they
    become a powerful source of information about service behavior.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 遥测数据是**不可变的**：它捕获了服务已经发生的事件，并提供了各种测量结果，例如服务API响应延迟。当不同类型的遥测数据结合在一起时，它们成为了解服务行为的有力信息来源。
- en: 'In this chapter, we are going to describe how to collect service telemetry
    data to monitor the health of services. There are two types of service health
    and performance monitoring:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将描述如何收集服务遥测数据以监控服务的健康状态。有两种类型的服务健康和性能监控：
- en: '**White-box monitoring**: Monitoring services while having access to different
    types of internally produced data. For example, you can monitor a server’s CPU
    utilization by viewing it in the system monitoring application.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**白盒监控**：在可以访问不同类型内部生成数据的情况下监控服务。例如，您可以通过系统监控应用程序查看服务器的CPU利用率来监控它。'
- en: '**Black-box monitoring**: Monitoring services using only externally available
    data and indicators. In this case, you don’t know or have access to data related
    to their structure or internal behavior. For example, if a service has a publicly
    available health check API, an external system can monitor its health by calling
    that API without having access to internal service data.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**黑盒监控**：仅使用外部可用的数据和指标进行服务监控。在这种情况下，您不知道或无法访问与它们的结构或内部行为相关的数据。例如，如果一个服务有一个公开可用的健康检查API，外部系统可以通过调用该API来监控其健康状态，而不需要访问内部服务数据。'
- en: 'Both types of monitoring are powered by collecting and continuously analyzing
    service performance data. In general, the more types of data you collect from
    your application, the more opportunities you get for extracting various types
    of information about its health and behavior. Let’s list some of the ways you
    can use the information about your service performance:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种类型的监控都是通过收集和持续分析服务性能数据来实现的。一般来说，您从应用程序中收集的数据类型越多，您获得有关其健康和行为的信息类型就越多。让我们列出一些您可以使用有关服务性能信息的方法：
- en: '**Trend analysis**: Detect any trends in your service performance data:'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**趋势分析**：检测您的服务性能数据中的任何趋势：'
- en: Is your service health getting better or worse over time?
  id: totrans-26
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的服务健康状况随着时间的推移是变好还是变差？
- en: How does your API success rate change?
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的API成功率是如何变化的？
- en: How many new users are you getting compared to the previous day/month/year?
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与前一天/月/年相比，您获得了多少新用户？
- en: '**Semantic graph capturing**: Capture data on how your services communicate
    with each other and with any other components, such as databases, external APIs,
    and message brokers.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语义图捕获**：捕获有关您的服务如何相互通信以及与任何其他组件（如数据库、外部API和消息代理）通信的数据。'
- en: '**Anomaly detection**: Automatically detect anomalies in your service behavior,
    such as sudden drops in API requests.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异常检测**：自动检测服务行为中的异常，例如API请求的突然下降。'
- en: '**Event correlation**: Detect relationships between various types of events,
    such as unsuccessful deployments and service panics.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件关联**：检测各种类型事件之间的关系，例如失败的部署和服务崩溃。'
- en: 'While observability opens lots of opportunities, it comes with the following
    challenges:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然可观察性提供了很多机会，但也伴随着以下挑战：
- en: '**Collecting large datasets**: Real-time performance data often takes lots
    of space to store, especially if you have lots of services or if your services
    produce lots of data.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**收集大量数据集**：实时性能数据通常需要大量的存储空间，尤其是如果您有很多服务或您的服务产生了大量数据。'
- en: '**Need for specific tooling**: To collect, process, and visualize different
    types of data, such as logs, metrics, and traces, you need some extra tools. These
    tools often come at a price.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**需要特定工具**：要收集、处理和可视化不同类型的数据，例如日志、指标和跟踪，您需要一些额外的工具。这些工具通常需要付费。'
- en: '**Complex setup**: Observability tooling and infrastructure are often difficult
    to configure. To access all data coming from multiple services, you need to set
    up the proper data collection, aggregation, data retention policies, and many
    more strategies.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**复杂配置**：可观察性工具和基础设施通常很难配置。要访问来自多个服务的所有数据，您需要设置适当的数据收集、聚合、数据保留策略以及许多其他策略。'
- en: We are going to describe how to work with each type of telemetry data that you
    can collect in your microservices. For each type of data, we will provide some
    usage examples and describe the common ways of setting up the tooling for working
    with it. First, let’s proceed to look at service log collection.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将描述如何处理您在微服务中可以收集的每种类型的遥测数据。对于每种类型的数据，我们将提供一些使用示例，并描述设置工具以处理它的常见方式。首先，让我们继续查看服务日志收集。
- en: Collecting service logs
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 收集服务日志
- en: '**Logging** is a technique that involves collecting real-time application performance
    data in the form of a time-ordered set of messages called a **log**. Here is an
    example of a service log:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**日志记录**是一种涉及收集以时间顺序排列的消息集合的形式的实时应用程序性能数据的技术，称为**日志**。以下是一个服务日志的示例：'
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Logs can help us understand what was happening in the application at a particular
    moment in time. As you can see in the preceding example, the service started at
    11 P.M. and began connecting to the database a second later, finally logging a
    timeout error 10 seconds later.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 日志可以帮助我们了解在特定时间点应用程序中发生了什么。正如您在前面的示例中看到的那样，该服务在晚上11点开始启动，并在一秒后开始连接到数据库，最终在10秒后记录了一个超时错误。
- en: 'Logs can provide lots of valuable insights about the component that emitted
    them, such as the following:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 日志可以提供关于发出它们的组件的大量有价值的信息，例如以下内容：
- en: '**Order of operations**: Logs can help us understand the logical sequence of
    operations performed by a service by showing when each operation took place.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**操作顺序**：日志可以帮助我们通过显示每个操作发生的时间来理解服务执行的操作的逻辑顺序。'
- en: '**Failed operations**: One of the most useful applications of logs is the ability
    to see the list of errors recorded by a service.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**失败的操作**：日志最有用的应用之一是能够看到服务记录的错误列表。'
- en: '**Panics**: If a service experiences an unexpected shutdown due to panic, a
    log can provide the relevant information, helping troubleshoot the issue.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**恐慌**：如果一个服务由于恐慌而意外关闭，日志可以提供相关信息，帮助排查问题。'
- en: '**Debugging information**: Developers can log various types of additional information,
    such as request parameters or headers, that can help when debugging various issues.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**调试信息**：开发人员可以记录各种类型的附加信息，例如请求参数或头信息，这有助于调试各种问题。'
- en: '**Warnings**: Logs can indicate various system-level warnings, such as low
    disk space, that can be used as notification mechanisms for preventing various
    types of errors.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**警告**：日志可以指示各种系统级警告，例如磁盘空间不足，可以用作防止各种类型错误的警报机制。'
- en: 'We used logs in the services that we created in [*Chapter 2*](B18865_02.xhtml#_idTextAnchor027)
    – our services have been logging some important status messages via the built-in
    log library. Here’s an example:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在我们创建的服务中使用了日志[*第2章*](B18865_02.xhtml#_idTextAnchor027) – 我们的服务已经通过内置日志库记录了一些重要的状态消息。以下是一个示例：
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The built-in log library provides functionality for logging arbitrary text
    messages and panics. The output of the preceding operation would be as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 内置日志库提供了记录任意文本消息和恐慌的功能。前述操作的输出如下：
- en: '[PRE2]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: By default, the log library records all logs to the `stdout` stream associated
    with the current process. But it is possible to set the output destination by
    calling the `SetOutput` function. This way, you can write your logs to files or
    send them over the network.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，日志库将所有日志记录到与当前进程关联的`stdout`流。但可以通过调用`SetOutput`函数来设置输出目的地。这样，你可以将日志写入文件或将它们通过网络发送。
- en: 'Two types of functions are provided by the log library that can be used if
    a service experiences an unexpected or non-recoverable error:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 日志库提供了两种类型的函数，如果服务遇到意外或不可恢复的错误，可以使用：
- en: '`fatal`: Functions with this prefix immediately stop the execution of the process
    after logging the message.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`致命`：带有此前缀的函数在记录消息后立即停止进程的执行。'
- en: '`panic`: After logging the message, they call the Go `panic` function, writing
    the output of the associated error. The following is an example output of calling
    a `panic` function:'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`panic`：在记录消息后，它们会调用Go的`panic`函数，写入相关错误的输出。以下是一个调用`panic`函数的示例输出：'
- en: '[PRE3]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: While the built-in log library provides a simple way of logging arbitrary text
    messages, it lacks some useful functionality that makes it easier to collect and
    process the service logs. Among the missing features is the ability to log events
    in popular serialization formats, such as JSON, which would simplify how message
    data is parsed. Another issue is that it lacks `Error` and `Errorf` functions,
    which could be used for explicitly logging errors. Since the built-in logging
    library only provides a `Print` function, it’s unclear by default whether the
    logged message indicates an error, a warning, or neither.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然内置日志库提供了记录任意文本消息的简单方法，但它缺少一些有用的功能，使得收集和处理服务日志更容易。其中缺失的功能包括记录流行序列化格式（如JSON）中的事件的能力，这将简化消息数据的解析。另一个问题是它缺少`Error`和`Errorf`函数，这些函数可以用于显式记录错误。由于内置日志库只提供`Print`函数，默认情况下无法确定记录的消息表示错误、警告还是两者都不是。
- en: Yet, the biggest missing piece in the built-in log library is the ability to
    perform structured logging. **Structured logging** is a technique that involves
    collecting log messages in the form of serialized structures, such as JSON records.
    A distinct feature of such structures, compared to arbitrary text strings, is
    that they can contain additional metadata in the form of fields – key-value records.
    This allows the service to represent the message metadata as any supported type,
    such as a number, string, or serialized record.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，内置日志库中最大的缺失部分是执行结构化日志记录的能力。**结构化日志记录**是一种涉及以序列化结构的形式收集日志消息的技术，例如 JSON 记录。与任意文本字符串相比，此类结构的独特之处在于它们可以包含以字段形式存在的附加元数据
    – 键值记录。这使得服务能够以任何支持的类型表示消息元数据，例如数字、字符串或序列化记录。
- en: 'The following snippet includes an example of a JSON-encoded log structure:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码片段包括一个 JSON 编码的日志结构示例：
- en: '[PRE5]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As you may have noticed, in addition to using JSON as the output format, there
    are two additional features of the preceding log format:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如您可能已注意到的，除了使用 JSON 作为输出格式外，先前的日志格式还有两个附加功能：
- en: '`level` that specifies the type of a log message.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`level` 指定日志消息的类型。'
- en: '`service`, which is used to indicate the service that emitted the message.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`service`，用于指示发出消息的服务。'
- en: 'The output format described earlier allows us to decode the log messages much
    easier. It also helps us interpret their contents based on the log level and the
    additional message fields. Additional metadata can also be used for searching:
    for example, we can search for messages that have a particular `service` field
    value.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 之前描述的输出格式使我们能够更容易地解码日志消息。它还帮助我们根据日志级别和额外的消息字段来解释其内容。还可以使用附加元数据进行搜索：例如，我们可以搜索具有特定
    `service` 字段值的消息。
- en: 'Now, let’s focus on log-level metadata from the previous example. First, let’s
    review some of the common log levels:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们专注于上一个示例中的日志级别元数据。首先，让我们回顾一些常见的日志级别：
- en: '**Info**: Informational messages that do not indicate any error. An example
    of such a message is a log record indicating that the service successfully connected
    to the database.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信息**：不指示任何错误的 informational 消息。此类消息的例子是日志记录表明服务成功连接到数据库。'
- en: '**Error**: Messages indicating errors, such as network timeouts.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**错误**：指示错误的消息，例如网络超时。'
- en: '**Warning**: Messages indicating some potential issues, such as too many open
    files.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**警告**：指示一些潜在问题的消息，例如打开的文件太多。'
- en: '**Fatal**: Messages indicating critical or non-recoverable errors, such as
    insufficient memory, that make executing the service further impossible.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**致命**：指示关键或不可恢复的错误，例如内存不足，使得进一步执行服务变得不可能。'
- en: '`Debug` messages is usually disabled by default, as they often generate a large
    amount of data.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Debug` 消息通常默认禁用，因为它们通常会生成大量数据。'
- en: 'Log levels also help us interpret log messages. Consider the following unstructured
    message produced by the built-in log library, which does not include any level
    information:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 日志级别也帮助我们解释日志消息。考虑以下由内置日志库生成的无结构消息，它不包含任何级别信息：
- en: '[PRE6]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Can you tell whether it’s a regular informational message indicating the regular
    behavior (for example, the service intentionally terminated a connection after
    performing some work), a warning, or an error? If this is an error, is it critical
    or not? Without the log level providing additional context, it is difficult to
    interpret this message.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 您能否判断这是一条表示常规行为（例如，服务在执行一些工作后有意终止了连接）的常规信息性消息，还是警告或错误？如果是错误，它是关键的还是非关键的？如果没有日志级别提供额外的上下文，很难解释这条消息。
- en: Another advantage of explicitly using log levels is the ability to enable or
    disable that ability to log specific types of levels. For example, logging `Debug`
    messages can be disabled under normal service conditions and enabled during troubleshooting.
    `Debug` messages often include much more information than regular ones, requiring
    more disk space and making it harder to navigate the other types of logs. Different
    logging libraries let us enable or disable specific levels, such as `Debug` or
    even `Info`, leaving only logs indicating warnings, errors, fatal errors, and
    panics.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 显式使用日志级别的另一个优点是能够启用或禁用记录特定类型级别的功能。例如，在正常服务条件下可以禁用 `Debug` 消息的记录，并在故障排除期间启用。`Debug`
    消息通常包含比常规消息更多的信息，需要更多的磁盘空间，并使其他类型的日志导航更困难。不同的日志库允许我们启用或禁用特定级别，例如 `Debug` 或甚至 `Info`，只留下表示警告、错误、致命错误和恐慌的日志。
- en: Let’s review some popular Go logging libraries and focus on choosing the one
    that we would use in our microservices.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**log15** ([https://github.com/inconshreveable/log15](https://github.com/inconshreveable/log15)):'
- en: Choosing the logging library
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择日志库
- en: In this section, we will describe some of the existing Go logging libraries
    and review their features. This section should help you choose the logging library
    that you will use in your microservices.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 流行 Go 日志库的列表包括以下内容：
- en: 'First, let’s list the features that we would like to get from the logging library:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将描述一些现有的 Go 日志库并回顾它们的功能。本节应有助于您选择将在您的微服务中使用的日志库。
- en: '**Structured logging**: Supports logging structured messages that may include
    additional fields in a key-value format.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**结构化日志**：支持记录结构化消息，可能包括键值格式中的额外字段。'
- en: '**Fast performance**: Writing log messages should not have a noticeable impact
    on service performance.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，让我们列出我们希望从日志库中获得的功能：
- en: '**Log level support**: Enforce inclusion of a log level in message metadata.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由 Go 开发团队官方支持，包含在 Go SDK 中
- en: 'The following is an additional feature that would be nice to have:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些额外且令人愉悦的功能：
- en: '`Printf`-like format (for example, support an `Errorf` function to log a formatted
    error).'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日志级别支持**：强制在消息元数据中包含日志级别。'
- en: 'Now, let’s review some of the most popular Go logging libraries. When evaluating
    library performance, we will be using the logging library benchmark data: https://github.com/uber-go/zap#performance.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们回顾一些最受欢迎的 Go 日志库。在评估库性能时，我们将使用日志库基准数据：[https://github.com/uber-go/zap#performance](https://github.com/uber-go/zap#performance)。
- en: 'The list of popular Go logging libraries includes the following:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 功能丰富，支持快速的最小化日志记录器，以及带有额外功能的稍慢版本
- en: '**Built-in Go log** **package** (https://pkg.go.dev/log):'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内置 Go 日志包** ([https://pkg.go.dev/log](https://pkg.go.dev/log)):'
- en: Officially supported by the Go development team, included in the Go SDK
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简洁优雅的 API
- en: Does not support structured logging and does not have built-in support for log
    levels
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不支持结构化日志，也没有内置对日志级别的支持
- en: '**zap** (https://github.com/uber-go/zap):'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**zap** ([https://github.com/uber-go/zap](https://github.com/uber-go/zap)):'
- en: Fastest performance among all logging libraries reviewed
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在所有已审查的日志库中性能最快
- en: Feature-rich and supports a fast minimalistic logger, as well as a slightly
    slower one with additional features
  id: totrans-91
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类似于 `Printf` 的格式（例如，支持 `Errorf` 函数来记录格式化的错误）。
- en: '**zerolog** (https://github.com/rs/zerolog):'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**zerolog** ([https://github.com/rs/zerolog](https://github.com/rs/zerolog)):'
- en: Fast performance
  id: totrans-93
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**快速性能**：写入日志消息不应对服务性能产生明显影响。'
- en: Simple and elegant API
  id: totrans-94
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 让我们回顾一些流行的 Go 日志库，并专注于选择我们将在微服务中使用的库。
- en: '`go-kit` toolkit for microservice development'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`go-kit` 微服务开发工具包'
- en: Slightly slower than `zerolog` and `zap`, but faster than the other logging
    libraries
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比`zerolog`和`zap`略慢，但比其他日志库快
- en: '**apex/log** (https://github.com/apex/log):'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**apex/log** ([https://github.com/apex/log](https://github.com/apex/log)):'
- en: 'Has built-in support for various log storages, such as Elasticsearch, Graylog,
    and AWS Kinesis*   **log15** (https://github.com/inconshreveable/log15):'
  id: totrans-98
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内置支持各种日志存储，如 Elasticsearch、Graylog 和 AWS Kinesis
- en: Feature-rich logging toolkit
  id: totrans-99
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 功能丰富的日志工具包
- en: Much slower than the other log libraries reviewed
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比其他已审查的日志库慢得多
- en: The preceding list provides some high-level details about some of the popular
    Go logging libraries to help you choose the right one for your services. All libraries,
    except the built-in `log` package, provide the features that we need, including
    structured logging and log levels. Now, the question is, how do we select the
    best one among them?
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 上述列表提供了一些关于一些流行 Go 日志库的高级细节，以帮助您为您的服务选择正确的库。所有库（除了内置的 `log` 包）都提供了我们需要的功能，包括结构化日志和日志级别。现在，问题是如何从它们中选出最佳的一个？
- en: My personal opinion is that the `zap` library provides the most flexible and
    yet most performant solution to service logging problems. It allows us to use
    two separate loggers, called `Logger` and `SugaredLogger`. `Logger` can be used
    in high-performance applications, while `SugaredLogger` can be used when you need
    some extra features; we will review these features in the next section.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我个人的观点是，`zap` 库提供了最灵活且性能最出色的服务日志解决方案。它允许我们使用两个独立的日志记录器，分别称为 `Logger` 和 `SugaredLogger`。`Logger`
    可用于高性能应用，而 `SugaredLogger` 可用于需要额外功能时；我们将在下一节中回顾这些功能。
- en: Using logging features
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用日志功能
- en: 'Let’s start practicing and demonstrate how to use some features of the `zap`
    logging library that we picked in the previous section. First, let’s start with
    the basics and illustrate how to log a simple message that has the `Info` level
    and an additional metadata field called `serviceName`. The complete Go code for
    this example is as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始练习并展示如何使用我们在上一节中选择的 `zap` 日志库的一些功能。首先，让我们从基础知识开始，说明如何记录一个具有 `Info` 级别和一个名为
    `serviceName` 的附加元数据字段的简单消息。本例的完整 Go 代码如下：
- en: '[PRE7]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We initialize the `logger` variable by calling the `zap.NewProduction` function,
    which returns a production-configured logger. This logger omits debug messages,
    uses JSON as the output format, and includes stack traces in the logs. Then, we
    create a structured log message by including a `serviceName` field by using the
    `zap.String` function, which can be used to log string data.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过调用 `zap.NewProduction` 函数初始化 `logger` 变量，该函数返回一个生产配置的日志记录器。这个日志记录器省略了调试消息，使用
    JSON 作为输出格式，并在日志中包含堆栈跟踪。然后，我们通过使用 `zap.String` 函数包含一个 `serviceName` 字段来创建一个结构化日志消息，该函数可以用于记录字符串数据。
- en: 'The output of the preceding example is as follows:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 上一例子的输出如下：
- en: '[PRE8]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The `zap` library offers support for other types of Go primitives, such as
    `int`, `long`, `bool`, and many more. Corresponding functions for creating log
    field names follow the same naming format, such as `Int`, `Long`, and `Bool`.
    Additionally, `zap` includes a set of functions for the other built-in Go types,
    such as `time.Duration`. The following code shows an example of a `time.Duration`
    field:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '`zap` 库为其他类型的 Go 原始数据提供支持，例如 `int`、`long`、`bool` 以及更多。创建日志字段名的相应函数遵循相同的命名格式，例如
    `Int`、`Long` 和 `Bool`。此外，`zap` 包含了一组用于其他内置 Go 类型的函数，例如 `time.Duration`。以下代码展示了
    `time.Duration` 字段的示例：'
- en: '[PRE9]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Let’s illustrate how to log arbitrary objects, such as structures. In [*Chapter
    2*](B18865_02.xhtml#_idTextAnchor027), we defined the `Metadata` structure:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们说明如何记录任意对象，例如结构。在 [*第2章*](B18865_02.xhtml#_idTextAnchor027) 中，我们定义了 `Metadata`
    结构：
- en: '[PRE10]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let’s assume that we want to log the entire structure for debugging purposes.
    One way of doing so is to use the `zap.Stringer` field. This field allows us to
    log any structure or interface with the `String()` function. We can define a `String`
    function for our `Metadata` structure as follows:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要为了调试目的记录整个结构。这样做的一种方法是通过使用 `zap.Stringer` 字段。该字段允许我们使用 `String()` 函数记录任何结构或接口。我们可以为我们的
    `Metadata` 结构定义一个 `String` 函数，如下所示：
- en: '[PRE11]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now, we can log the `Metadata` structure as a log field:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以将 `Metadata` 结构作为日志字段进行记录：
- en: '[PRE12]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The output would look as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '[PRE13]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Now, let’s illustrate one more useful technique of using the `zap` library.
    If you want to include the same fields in multiple messages, you can re-initialize
    the logger by using the `With` function, as illustrated in the following example:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们再展示一个使用 `zap` 库的有用技巧。如果你想在多个消息中包含相同的字段，你可以通过使用 `With` 函数重新初始化日志记录器，如下面的例子所示：
- en: '[PRE14]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The results of both calls to the `Debug` function will now include both the
    `endpoint` and `ratingId` fields.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 现在两次调用 `Debug` 函数的结果将包括 `endpoint` 和 `ratingId` 字段。
- en: 'You can also use this technique when you create new service components in your
    code. In the following example, we are creating a sub-logger inside the `New`
    function:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在创建代码中的新服务组件时使用这种技巧。在下面的例子中，我们在 `New` 函数内部创建了一个子日志记录器：
- en: '[PRE15]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This way, the newly created instance of a `Handler` structure will be initialized
    with a logger that includes the `component` field with the `ratingController`
    value in each message.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，新创建的 `Handler` 结构实例将使用包含每个消息中 `component` 字段具有 `ratingController` 值的日志记录器进行初始化。
- en: Now that we have covered some of the primary service logging use cases, let’s
    discuss how to store logs in a microservice environment.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经覆盖了一些主要的服务日志用例，让我们讨论如何在微服务环境中存储日志。
- en: Storing microservice logs
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 存储微服务日志
- en: By default, logs of each service instance are written to the output stream of
    the process running it. This mechanism of log collection allows us to monitor
    service operations by continuously reading the data from the associated stream
    (`stdout` in most cases) on a host running a service instance. However, without
    any additional software, the log data would not be persisted, so you would not
    be able to read your previously recorded logs after a service restart or a sudden
    crash.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，每个服务实例的日志会被写入运行该实例的进程的输出流。这种日志收集机制允许我们通过持续读取运行服务实例的主机上相关流（大多数情况下是`stdout`）中的数据来监控服务操作。然而，如果没有额外的软件，日志数据将不会被持久化，因此在服务重启或突然崩溃后，您将无法读取之前记录的日志。
- en: 'Various software solutions allow us to store and query the log data in a multi-service
    environment. They help solve multiple other problems:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 各种软件解决方案允许我们在多服务环境中存储和查询日志数据。它们帮助解决多个其他问题：
- en: '**Distributed log collection**: If you have multiple services running on different
    hosts, you must collect the service logs on each host independently and send them
    for further aggregation.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分布式日志收集**：如果您有多个服务在不同的主机上运行，您必须独立收集每个主机上的服务日志并将它们发送进行进一步聚合。'
- en: '**Centralized log storage**: To be able to query the data that’s emitted by
    different services, you need to store it in a centralized way – all logs across
    all services should be accessible during the query execution.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集中式日志存储**：为了能够查询不同服务发出的数据，您需要以集中化的方式存储它 – 在查询执行期间，所有服务的所有日志都应该是可访问的。'
- en: '**Data retention**: Logging data usually takes a lot of disk space, and it
    often becomes too expensive to store it indefinitely for all your services. To
    solve this problem, you need to establish the right data retention policies for
    your services that will allow you to configure how long you can store the data
    for each one.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据保留**：日志数据通常占用大量磁盘空间，并且通常存储所有服务的日志变得过于昂贵。为了解决这个问题，您需要为您的服务建立合适的数据保留策略，这将允许您配置每个服务可以存储数据的时间长度。'
- en: '**Efficient indexing**: To be able to quickly query your logging data, the
    logs need to be indexed and stored efficiently. Modern indexing software can help
    you query terabytes of log data in under 10 milliseconds.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高效索引**：为了能够快速查询您的日志数据，日志需要被高效地索引和存储。现代索引软件可以帮助您在不到10毫秒的时间内查询TB级的日志数据。'
- en: Different tools help facilitate such log operations, such as Elasticsearch and
    Graylog. Let’s briefly review Elasticsearch to provide an example of an end-to-end
    log management solution.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的工具有助于简化此类日志操作，例如Elasticsearch和Graylog。让我们简要回顾Elasticsearch，以提供一个端到端的日志管理解决方案的示例。
- en: '**Elasticsearch** is a popular open source search engine that was created in
    2010 and quickly gained popularity as a scalable system for indexing and querying
    different types of structured data. While the primary use case of Elasticsearch
    is a full-text search, it can be efficiently used for storing and querying various
    types of structured data, such as service logs. Elasticsearch is also a part of
    the toolkit called the **Elastic Stack**, also called **ELK**, which includes
    some other systems:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '**Elasticsearch**是一个流行的开源搜索引擎，它于2010年创建，并迅速成为索引和查询不同类型结构化数据的可扩展系统的热门选择。虽然Elasticsearch的主要用例是全文搜索，但它可以有效地用于存储和查询各种类型的结构化数据，例如服务日志。Elasticsearch也是名为**Elastic
    Stack**（也称为**ELK**）的工具包的一部分，它包括一些其他系统：'
- en: '**Logstash**: A data processing pipeline that can collect, aggregate, and transform
    various types of data, such as service logs'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Logstash**：一个数据处理管道，可以收集、聚合和转换各种类型的数据，例如服务日志'
- en: '**Kibana**: A user interface for accessing the data in Elasticsearch, providing
    convenient visualization and querying features'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kibana**：一个用于访问Elasticsearch中数据的用户界面，提供便捷的可视化和查询功能'
- en: 'The log collection pipeline in the Elastic Stack looks like this:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Elastic Stack中的日志收集管道看起来是这样的：
- en: '![Figure 11.1 – Logging pipeline in the Elastic Stack'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '![图11.1 – Elastic Stack中的日志管道'
- en: '](img/Figure_11.1_B18865.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_11.1_B18865.jpg)'
- en: Figure 11.1 – Logging pipeline in the Elastic Stack
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1 – Elastic Stack中的日志管道
- en: In this flow chart, service logs are collected by Logstash and sent to Elasticsearch
    for indexing and storing. Then, users can access the logs and other data indexed
    in Elasticsearch using the Kibana interface.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个流程图中，服务日志由Logstash收集并发送到Elasticsearch进行索引和存储。然后，用户可以使用Kibana界面访问日志和其他在Elasticsearch中索引的数据。
- en: One of the key advantages of the Elastic Stack is that most of its tools are
    available for free and are open source. It is well-maintained and extremely popular
    in the developer community, making it easier to search for relevant documentation,
    get additional support, or find some additional tooling. It also has a set of
    libraries for all popular languages, allowing us to perform various types of queries
    and API calls to all components of the pipeline.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Elastic Stack 的一个关键优势是，其大多数工具都是免费且开源的。它维护良好，在开发者社区中极为流行，这使得搜索相关文档、获取额外支持或找到一些额外工具变得更加容易。它还提供了一套适用于所有流行语言的库，使我们能够对管道的所有组件执行各种类型的查询和
    API 调用。
- en: The Go library for using the Elasticsearch API is called `go-elasticsearch`
    and can be found on GitHub at [https://github.com/elastic/go-elasticsearch](https://github.com/elastic/go-elasticsearch).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 用于使用 Elasticsearch API 的 Go 库称为 `go-elasticsearch`，可以在 GitHub 上找到：[https://github.com/elastic/go-elasticsearch](https://github.com/elastic/go-elasticsearch)。
- en: We are not going to cover the Elastic Stack in detail as it’s outside of the
    scope of this chapter, but you can get more familiar with the Elastic Stack by
    reading its official documentation (https://www.elastic.co/guide/index.html).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会详细讨论 Elastic Stack，因为它超出了本章的范围，但您可以通过阅读其官方文档（https://www.elastic.co/guide/index.html）来了解更多关于
    Elastic Stack 的信息。
- en: 'Having covered some high-level details regarding some popular logging software,
    let’s move on to the next topic: describing the best practices of logging.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在介绍了一些流行的日志软件的高级细节之后，让我们继续下一个主题：描述日志的最佳实践。
- en: Logging best practices
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 日志最佳实践
- en: 'So far, we have covered the most important aspects of logging and described
    how to choose a logging library, as well as how to establish the logging infrastructure
    for collecting and analyzing data. Let’s describe some of the best practices for
    logging service data:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经涵盖了日志最重要的方面，并描述了如何选择日志库，以及如何建立用于收集和分析数据的日志基础设施。让我们描述一些日志服务数据的最佳实践：
- en: Avoid using interpolated strings.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免使用插值字符串。
- en: Standardize your log messages.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准化您的日志消息。
- en: Periodically review your log data.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定期审查您的日志数据。
- en: Set up appropriate log retention.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置适当的日志保留。
- en: Identify the message source in logs.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在日志中识别消息来源。
- en: Let’s now cover each practice in detail.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们详细说明每个实践。
- en: Avoid using interpolated strings
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 避免使用插值字符串
- en: 'One of the top logging anti-patterns is the usage of **interpolated strings**
    – messages that embed metadata inside text fields. Let’s take the following snippet
    of code as an example:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的日志反模式之一是使用 **插值字符串** – 在文本字段中嵌入元数据的消息。以下代码片段可以作为例子：
- en: '[PRE16]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The problem with this code is that it merges two types of data into a single
    text message: an operation name (user registration) and a user identifier. Such
    messages make it harder to search and process log metadata: each time you need
    to extract `userID` from a log message, you would need to parse a string that
    contains it.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的问题在于它将两种类型的数据合并到一个单独的文本消息中：一个操作名称（用户注册）和一个用户标识符。这样的消息使得搜索和处理日志元数据变得更加困难：每次您需要从日志消息中提取
    `userID` 时，您都需要解析包含它的字符串。
- en: 'Let’s update our example by following the structured logging approach, where
    we log additional metadata as message fields:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过遵循结构化日志记录方法来更新我们的示例，其中我们将额外的元数据作为消息字段进行记录：
- en: '[PRE17]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The updated version makes a big difference when you want to query your data.
    Now, you can query all log events that have `User successfully registered` text
    messages and easily access all user identifiers associated with them. Avoiding
    interpolated messages helps keep your log data easy to query and parse, simplifying
    all operations with it.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 当您想要查询数据时，更新后的版本会带来很大的差异。现在，您可以查询所有包含 `User successfully registered` 文本消息的日志事件，并轻松访问与之相关的所有用户标识符。避免使用插值消息有助于保持您的日志数据易于查询和解析，简化所有与之相关的操作。
- en: Standardize your log messages
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 标准化您的日志消息
- en: 'In this section, we covered the benefits of log centralization and the advantages
    of querying the data across multiple services. But I would like to emphasize how
    it is important to standardize the format of log messages in a microservice environment.
    Sometimes, it is useful to execute log queries that span multiple services, API
    endpoint handlers, or other components. For example, you may need to perform the
    following types of queries on your log data:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了日志集中化的好处以及跨多个服务查询数据的优势。但我想强调，在微服务环境中标准化日志消息的格式是多么重要。有时，执行跨越多个服务、API端点处理程序或其他组件的日志查询是有用的。例如，您可能需要在您的日志数据上执行以下类型的查询：
- en: Get the distribution of timeout errors across all services.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取所有服务中超时错误的分布情况。
- en: Get the daily count of errors for each API endpoint.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取每个API端点的错误每日计数。
- en: Get distinct error messages across all database repositories.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取所有数据库存储库中独特的错误消息。
- en: If your services log the data using different field names, you will not be able
    to easily gather such data using a common query function. On the opposite side,
    establishing the common field names helps ensure the log messages follow the same
    naming convention, simplifying any queries you write.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的服务使用不同的字段名记录数据，您将无法轻松地使用通用查询函数收集此类数据。相反，建立通用字段名有助于确保日志消息遵循相同的命名约定，简化您编写的任何查询。
- en: 'To make sure the logs are emitted in the same way across all services and all
    components, you may follow these tips:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保所有服务和所有组件以相同的方式发出日志，您可以遵循以下提示：
- en: 'Create a shared package that includes log field names as constants; take the
    following example:'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个包含日志字段名作为常量的共享包；以下是一个示例：
- en: '[PRE18]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'To avoid forgetting to include some important field inside a certain structure,
    function, or set of functions, re-initialize the logger by setting the field as
    early as possible; take the following example:'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了避免忘记在某个结构、函数或函数集中包含某些重要字段，请尽早通过设置字段来重新初始化记录器；以下是一个示例：
- en: '[PRE24]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Additionally, ensure that the root logger of your service is setting the service
    name so that all your service components will automatically collect this field
    by default:'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此外，确保您的服务根记录器设置了服务名称，以便所有服务组件将默认自动收集此字段：
- en: '[PRE29]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The tips that we just provided should help you standardize the usage of common
    fields across all your service components, making it easier to query the logged
    data and aggregate it in different ways.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚提供的提示应该有助于您在所有服务组件中标准化常用字段的用法，使查询记录的数据和以不同方式聚合数据变得更加容易。
- en: Periodically review your log data
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定期审查您的日志数据
- en: 'Once you start collecting your service logs, it is important to periodically
    review them. Look out for the following cases:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦开始收集您的服务日志，定期审查它们就很重要。注意以下情况：
- en: '**Make sure there is no PII data in logs**: **Personally identifiable information**
    (**PII**), such as full names and SSNs, falls under many regulations and generally
    must not be stored in logs. Make sure that no component, such as an API handler
    or a repository component, emits any such data, even for debugging.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**确保日志中没有PII数据**：**个人身份信息**（PII），例如全名和SSN，受到许多法规的约束，通常不应存储在日志中。请确保没有任何组件，例如API处理程序或存储库组件，发出任何此类数据，即使是出于调试目的。'
- en: '**Check that your service doesn’t emit extra debug data**: Sometimes, developers
    log some additional data, such as request fields, to debug various issues. Check
    that no service is continuously emitting too many debug messages during a prolonged
    period, polluting the logs and using too much disk space.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**检查您的服务是否未发出额外的调试数据**：有时，开发者为了调试各种问题，会在日志中记录一些额外的数据，例如请求字段。请确保没有服务在长时间内持续发出过多的调试消息，污染日志并占用过多磁盘空间。'
- en: Set up appropriate log retention
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置适当的日志保留策略
- en: Log data often takes a lot of space to store. If it keeps growing in size without
    any additional actions being taken, you may end up using all your disk space and
    having to urgently clean up the old records. To prevent this, various log storage
    solutions allow you to configure **retention policies** for your data. For example,
    you can configure your log storage to keep the logs for some services for up to
    a few years, while limiting some other services to just a few days, depending
    on the requirements. Additionally, you can set some size constraints so that the
    logs of your services don’t exceed a predefined size threshold.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 日志数据通常需要占用大量的存储空间。如果它不断增长而没有采取任何额外措施，你可能会用完所有磁盘空间，并不得不紧急清理旧记录。为了防止这种情况，各种日志存储解决方案允许你为你的数据配置**保留策略**。例如，你可以配置你的日志存储，将某些服务的日志保留几年，同时将其他一些服务的保留时间限制为几天，具体取决于需求。此外，你还可以设置一些大小限制，以确保你的服务日志不超过预定义的大小阈值。
- en: Ensure you set retention policies for all types of your logs, avoiding situations
    when you need to clean up unneeded log records manually.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 确保为所有类型的日志设置保留策略，避免需要手动清理不需要的日志记录的情况。
- en: Identify the message source in logs
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 识别日志中的消息来源
- en: 'Imagine that you are viewing your system logs and notice the following error
    event:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你正在查看系统日志，并注意到以下错误事件：
- en: '[PRE33]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Can you understand the problem described in this event? The log record includes
    the `Request timed out` error message and has the `error` level, but it does not
    provide any meaningful context to us. Without any additional context, we can’t
    easily understand the problem that caused the log event.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 你能理解这个事件中描述的问题吗？日志记录包括`请求超时`错误消息，并且具有`error`级别，但它没有为我们提供任何有意义的上下文。没有额外的上下文，我们无法轻易理解导致日志事件的根本问题。
- en: 'Providing the context of any log message is crucial for making it easy to work
    with the logs. This is especially important in a microservice environment, where
    similar operations can be performed by multiple services or components. It should
    always be easy to understand each message and have some reference to the component
    it is coming from. In this section, we already mentioned the practice of including
    some additional information, such as the name of the component, in a log event.
    Such metadata would generally include the following:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 提供任何日志消息的上下文对于轻松处理日志至关重要。这在微服务环境中尤为重要，因为类似操作可以由多个服务或组件执行。始终应该能够理解每条消息，并有一些关于其来源组件的参考。在本节中，我们已经提到了在日志事件中包含一些额外信息的做法，例如组件名称。此类元数据通常包括以下内容：
- en: Name of the service
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务的名称
- en: Name of the component emitting the event (for example, endpoint name)
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发出事件的组件名称（例如，端点名称）
- en: Name of the file (optional)
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件名称（可选）
- en: 'A more detailed version of the preceding log message looks like this:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 上一条日志消息的更详细版本如下所示：
- en: '[PRE34]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: At this point, we have discussed the main topics related to logging and can
    move on to the next section, which describes another type of telemetry data –
    metrics.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经讨论了与日志记录相关的主要主题，可以继续到下一节，该节描述另一种类型的遥测数据——指标。
- en: Collecting service metrics
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 收集服务指标
- en: 'In this section, we are going to describe another type of service telemetry
    data: **metrics**. To understand what metrics are and how they are different from
    log data, let’s start with an example. Imagine that you have a set of services
    providing APIs to their users, and you want to know how many times per second
    each API endpoint is called. How would you do this?'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将描述另一种类型的服务遥测数据：**指标**。为了理解指标是什么以及它们与日志数据的区别，让我们从一个例子开始。假设你有一组为用户提供API的服务，你想要知道每个API端点每秒被调用多少次。你将如何做？
- en: One possible way of solving this problem is using logs. We could create a log
    event for each request, and then we would be able to count the number of events
    for each endpoint, aggregating them by second, minute, or in any other possible
    way. Such a solution would work until we get too many requests per endpoint and
    can’t log each one independently anymore. Let’s assume there is a service that
    processes more than a million requests per second. If we used logs to measure
    its performance, we would need to produce more than a million log events every
    second, generating lots of data.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的可能方法之一是使用日志。我们可以为每个请求创建一个日志事件，然后我们就能按端点计数事件的数量，按秒、分钟或任何其他可能的方式聚合它们。这种解决方案会一直有效，直到每个端点的请求太多，无法再独立记录每个请求。让我们假设有一个每秒处理超过一百万个请求的服务。如果我们使用日志来衡量其性能，我们每秒就需要生成超过一百万个日志事件，这将产生大量数据。
- en: A more optimal solution to this problem would be to use some sort of value-based
    aggregation. Instead of storing the data representing each request separately,
    we could summarize the count of requests per second, minute, or hour, making the
    data more optimal for storing.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的更优解决方案是使用某种基于值的聚合。而不是单独存储表示每个请求的数据，我们可以总结每秒、每分钟或每小时的请求计数，使数据更适合存储。
- en: The problem that we just described is a perfect use case for using metrics –
    real-time quantitative measurements of system performance, such as request rate,
    latency, or cumulative counts. Like logs, metrics are time-based – each record
    includes a timestamp representing a unique instant of time in the past. However,
    unlike log events, metrics are primarily used for storing individual values. In
    our example, the value of an endpoint request rate metric would be the count of
    requests per second.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚才描述的问题非常适合使用指标——对系统性能进行实时定量测量，如请求速率、延迟或累积计数。像日志一样，指标是基于时间的——每条记录都包含一个时间戳，代表过去某个独特的时间点。然而，与日志事件不同，指标主要用于存储单个值。在我们的例子中，端点请求速率指标的价值将是每秒请求的数量。
- en: 'Metrics are generally represented as **time series** – sets of objects, called
    **data points**, containing the following data:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 指标通常表示为**时间序列**——包含以下数据的对象集合，称为**数据点**：
- en: Timestamp
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间戳
- en: Value (most commonly, the value is numerical)
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 值（最常见的是数值）
- en: An optional set of **tags**, defined as key-value pairs, that contain any additional
    metadata
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可选的**标签**集合，定义为键值对，包含任何附加元数据
- en: 'To help you better understand the use cases of using metrics, let’s define
    some common metric types:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助您更好地理解使用指标的使用案例，让我们定义一些常见的指标类型：
- en: '**Counters**: These are time series representing the value of a cumulative
    counter over time. An example would be the counter of service requests – each
    data point would include a timestamp and the count of requests at that particular
    moment.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计数器**：这些是表示随时间累积计数器值的时序。一个例子是服务请求计数器——每个数据点将包括一个时间戳和在该特定时刻的请求计数。'
- en: '**Gauges**: These are time series representing the changes of a single scalar
    value over time. An example of a gauge is a dataset that contains the amount of
    free disk space on a server at different moments: each data point contains a single
    numerical value.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**仪表**：这些是表示单个标量值随时间变化的时序。仪表的一个例子是包含服务器在不同时刻的空闲磁盘空间量的数据集：每个数据点包含一个单一的数值。'
- en: '**Histograms**: These are time series representing the distribution of some
    value against a predefined set of value ranges, called **buckets**. An example
    of a histogram metric is a dataset, containing the number of users for different
    age groups.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**直方图**：这些是表示某些值相对于预定义的值范围分布的时序，称为**桶**。直方图指标的一个例子是包含不同年龄段用户数量的数据集。'
- en: Let’s focus on each metric type to help you understand their differences and
    the common use cases for each one.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们专注于每种指标类型，以帮助您了解它们之间的差异以及每种类型的常见用例。
- en: 'Counter metrics are generally used for measuring two types of data:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 计数器指标通常用于衡量两种类型的数据：
- en: Cumulative value over time (for example, the total number of errors)
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随时间累积的值（例如，错误总数）
- en: Change of the cumulative value over time (for example, the number of newly registered
    users per hour)
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随时间累积值的改变（例如，每小时新注册用户数）
- en: The second use case is technically a different representation of the first one
    – if you know how many users you had at each moment in time, you can see how this
    value changes. Because of this, counters are often used to measure the rates of
    various events, such as API requests, over time.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个用例在技术上是对第一个用例的不同表示——如果您知道在每一个时间点有多少用户，您可以看到这个值是如何变化的。正因为如此，计数器通常用于测量各种事件（如API请求）随时间的变化率。
- en: 'The following code snippet provides an example of a `Counter` interface in
    a `tally` metrics library (we’ll review this library later in this chapter):'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段提供了一个`Counter`接口在`tally`指标库中的示例（我们将在本章后面回顾这个库）：
- en: '[PRE35]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Unlike counters, gauges are used for storing unique values of measurements,
    such as the service’s available memory over time. Here is a gauge example from
    a `tally` library:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 与计数器不同，仪表用于存储测量的唯一值，例如服务随时间可用的内存。以下是从`tally`库中的一个仪表示例：
- en: '[PRE36]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Some of the other gauge use cases include the following:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 一些其他的仪表用例包括以下内容：
- en: Number of goroutines running by a service instance
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由服务实例运行的goroutine数量
- en: Number of active connections
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 活跃连接数
- en: Number of open files
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 打开文件数
- en: 'Histograms are slightly different from counters and gauges. They require us
    to define a set of ranges that will be used to store the subsets of recorded data.
    The following are some examples of using histogram metrics:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图与计数器和仪表略有不同。它们要求我们定义一组范围，这些范围将用于存储记录数据的子集。以下是一些使用直方图指标的示例：
- en: '**Latency tracking**: You can track how long it takes to perform a certain
    service operation by creating a set of buckets representing various duration ranges.
    For example, your buckets could be 0–100 ms, 100–200 ms, 200–300 ms, and so on.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**延迟跟踪**：您可以通过创建代表各种持续时间范围的桶来跟踪执行特定服务操作所需的时间。例如，您的桶可以是0-100毫秒、100-200毫秒、200-300毫秒，依此类推。'
- en: '**Cohort tracking**: You can track statistical data, such as the number of
    records in each group of values. For example, you can track how many users of
    each age subscribed to your service.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**群体跟踪**：您可以跟踪统计数据，例如每个值组的记录数。例如，您可以跟踪每个年龄段有多少用户订阅了您的服务。'
- en: Now that we have covered some high-level basics of metrics, let’s provide an
    overview of storing metrics.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经介绍了一些指标的高级基础知识，让我们概述一下存储指标的方法。
- en: Storing metrics
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 存储指标
- en: 'Similar to logs, storing metrics in a microservice environment brings some
    common challenges:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 与日志类似，在微服务环境中存储指标会带来一些常见的挑战：
- en: '**Collection and aggregation**: Metrics need to be collected from all service
    instances and sent for further aggregation and storage.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**收集和聚合**：需要从所有服务实例收集指标，并进一步聚合和存储。'
- en: '**Aggregation**: Collected data needs to be aggregated, so various types of
    metrics, such as counters, would contain the data coming from all service instances.
    For example, the counter measuring the total number of requests should summarize
    the data across all service instances.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚合**：收集的数据需要被聚合，因此各种类型的指标，如计数器，将包含来自所有服务实例的数据。例如，测量总请求数的计数器应该汇总所有服务实例的数据。'
- en: Let’s review some of the popular tools that provide such features.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一些提供此类功能的流行工具。
- en: Prometheus
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Prometheus
- en: Prometheus is a popular open source monitoring solution that provides mechanisms
    for collecting and querying service metrics, as well as setting up automated alerts
    for detecting various types of incidents. Prometheus gained popularity in the
    developer community due to its simple data model and being a very flexible model
    for data ingestion, which we are going to cover in this section.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus是一个流行的开源监控解决方案，它提供了收集和查询服务指标以及设置自动警报以检测各种类型事件的机制。由于其简单的数据模型和非常灵活的数据摄取模型，Prometheus在开发社区中获得了流行，我们将在本节中介绍这些内容。
- en: Note
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'Did you know that Prometheus is written in Go? You can check its source code
    on its GitHub page: [https://github.com/prometheus/prometheus](https://github.com/prometheus/prometheus).'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 您知道Prometheus是用Go编写的吗？您可以在其GitHub页面上查看其源代码：[https://github.com/prometheus/prometheus](https://github.com/prometheus/prometheus)。
- en: Prometheus supports three types of metrics – counters, gauges, and histograms.
    It stores each metric as a time series, similarly to the model that we described
    at the beginning of the *Collecting service metrics* section. Each metric contains
    the value, additional tags, called **labels**, and a name that can be used for
    identifying it.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus支持三种类型的指标——计数器、仪表和直方图。它将每个指标存储为时间序列，类似于我们在“收集服务指标”部分开头描述的模型。每个指标包含值、额外的标签，称为**标签**，以及一个用于识别它的名称。
- en: 'Once the data gets into the Prometheus time series storage, it is available
    for querying via its query language, called **PromQL**. PromQL allows us to fetch
    time series data using various functions that allow us to easily filter or exclude
    certain name and label combinations. The following is an example of a PromQL query:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据进入Prometheus时间序列存储后，它可以通过其查询语言**PromQL**进行查询。PromQL允许我们使用各种函数来检索时间序列数据，这些函数使我们能够轻松地过滤或排除某些名称和标签组合。以下是一个PromQL查询的示例：
- en: '[PRE37]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: In this example, the query fetches time series with the `http_requests_total`
    name, a label that contains the environment key and production value, and any
    value of a method label that is not equal to `GET`.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，查询检索了名为`http_requests_total`的时间序列，包含环境键和产品值的标签，以及任何不等于`GET`的方法标签的值。
- en: 'There is an official Prometheus Go client on GitHub that provides various mechanisms
    to get the metrics data into Prometheus, as well as to execute the PromQL queries.
    You can access it here: [https://github.com/prometheus/client_golang](https://github.com/prometheus/client_golang).'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub上有一个官方的Prometheus Go客户端，它提供了将指标数据导入Prometheus以及执行PromQL查询的各种机制。您可以通过以下链接访问它：[https://github.com/prometheus/client_golang](https://github.com/prometheus/client_golang)。
- en: 'The documentation for instrumenting Go applications for using Prometheus can
    be found at the following link: [https://prometheus.io/docs/guides/go-application](https://prometheus.io/docs/guides/go-application).'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 关于为使用Prometheus对Go应用程序进行度量的文档，可以在以下链接找到：[https://prometheus.io/docs/guides/go-application](https://prometheus.io/docs/guides/go-application)。
- en: Graphite
  id: totrans-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Graphite
- en: Graphite is another popular monitoring tool that offers metric collection, aggregation,
    and querying functionality that is similar to Prometheus. Although it has been
    among the oldest service monitoring tools in the industry, it remains an extremely
    powerful instrument for working with service metric data.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: Graphite是另一个流行的监控工具，它提供了与Prometheus类似的指标收集、聚合和查询功能。尽管它是行业中最古老的服务监控工具之一，但它仍然是处理服务指标数据的一个极其强大的工具。
- en: 'A typical Graphite installation consists of three main components:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的Graphite安装包括三个主要组件：
- en: '**Carbon**: A service that listens for time series data'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Carbon**：一个监听时间序列数据的服务'
- en: '**Whisper**: A time series database'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Whisper**：一个时间序列数据库'
- en: '**Graphite-web**: A web interface and an API for accessing the metrics data'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Graphite-web**：一个用于访问指标数据的Web界面和API'
- en: 'Graphite offers a quick integration with a data visualization tool called **Grafana**,
    which we are going to cover in [*Chapter 13*](B18865_13.xhtml#_idTextAnchor181)
    of this book. You can read more details about Graphite on its website: [https://graphiteapp.org](https://graphiteapp.org).'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: Graphite提供了一个快速的数据可视化工具**Grafana**的集成，我们将在本书的[*第13章*](B18865_13.xhtml#_idTextAnchor181)中介绍。您可以在Graphite的网站上了解更多关于Graphite的详细信息：[https://graphiteapp.org](https://graphiteapp.org)。
- en: Now, let’s move on to the next section, where we will describe the popular libraries
    for emitting service metrics.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续下一节，我们将描述发布服务指标的一些流行库。
- en: Popular Go metrics libraries
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 流行的Go指标库
- en: 'There are some popular Go libraries for working with metrics that could help
    you ingest and query your time series metrics data. Let’s provide a brief overview
    of some of them:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些流行的Go库可以帮助您处理指标，从而导入和查询您的时序指标数据。以下是一些简要概述：
- en: '**Tally** (https://github.com/uber-go/tally):'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Tally** (https://github.com/uber-go/tally):'
- en: A performant and minimalistic library for emitting service metrics
  id: totrans-261
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个高效且简约的库，用于发布服务指标
- en: Built-in support for data ingestion in Prometheus, StatsD, and M3
  id: totrans-262
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Prometheus、StatsD和M3内置的数据导入支持
- en: '**rcrowley/go-metrics** (https://github.com/rcrowley/go-metrics):'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**rcrowley/go-metrics** (https://github.com/rcrowley/go-metrics):'
- en: The Go port of a popular Java metric library (https://github.com/dropwizard/metrics)
  id: totrans-264
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是一个流行的Java指标库的Go版本（https://github.com/dropwizard/metrics）
- en: Supports data ingestion into StatsD and Graphite
  id: totrans-265
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持将数据导入StatsD和Graphite
- en: Has lots of integrations for exporting data to various observability systems,
    such as Datadog and Prometheus
  id: totrans-266
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持将数据导出到各种可观察性系统，例如Datadog和Prometheus
- en: '`go-kit` toolkit'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`go-kit`工具包'
- en: Supports multiple metric storages, such as StatsD and Graphite
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持多个指标存储，例如StatsD和Graphite
- en: We will leave the decision of picking the metrics library for your services
    to you, as each library provides some useful features that you can leverage when
    developing your microservices. I am going to use the tally library in the examples
    throughout this chapter as it provides a simple and minimalistic API that can
    help illustrate the common metrics use cases. In the next section, we will review
    some of the use cases of using the metrics in the Go microservice code.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把选择服务指标库的决定留给你，因为每个库都提供了一些有用的功能，你可以在开发微服务时利用这些功能。我将在本章的示例中使用tally库，因为它提供了一个简单且最小化的API，可以帮助说明常见的指标用例。在下一节中，我们将回顾一些在Go微服务代码中使用指标用例。
- en: Emitting service metrics
  id: totrans-270
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 发射服务指标
- en: In this section, we will provide some examples of emitting and collecting service
    metrics while covering some common scenarios, such as measuring API request rates,
    operation latencies, and emitting gauge values. We will use the tally library
    in our examples, but you can implement this logic using all other popular metric
    libraries.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将提供一些发射和收集服务指标的示例，同时涵盖一些常见场景，例如测量API请求速率、操作延迟以及发射仪表值。我们将使用tally库作为示例，但你也可以使用所有其他流行的指标库来实现此逻辑。
- en: 'First, let’s provide an example of how to initialize the tally library so that
    you can start using it in your service code. In the following example, we are
    initializing it using the StatsD client (you can use any other tool to collect
    the metrics):'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们提供一个示例，说明如何初始化tally库，以便你可以在服务代码中使用它。在以下示例中，我们使用StatsD客户端来初始化它（你可以使用任何其他工具来收集指标）：
- en: '[PRE38]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: In this example, we are creating a tally reporter that will submit the metrics
    to the data collector (StatsD in our use case) and create a **scope** – an interface
    for reporting the metrics data – that would automatically submit them for collection.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们创建了一个tally报告器，它将提交指标到数据收集器（在我们的用例中是StatsD），并创建一个**作用域**——一个用于报告指标数据的接口，它会自动提交它们以供收集。
- en: 'Tally scopes are hierarchical: when we initialize the library, we create a
    **root scope**, which includes initial metadata in the form of key-value tags.
    All scopes that are created from it would include the parent metadata, preventing
    cases of missing tags during the metric’s emission.'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: Tally作用域是分层的：当我们初始化库时，我们创建一个**根作用域**，它包含以键值标签形式存在的初始元数据。所有从它创建的作用域都会包含父级元数据，从而防止在指标发射过程中出现缺少标签的情况。
- en: 'Once you get the scope, you can start reporting the metrics. The following
    example illustrates how to increment a counter metric by measuring the API request
    count, which would be automatically reported by tally:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦确定了范围，你就可以开始报告指标。以下示例说明了如何通过测量API请求次数来增加计数器指标，这些请求将由tally自动报告：
- en: '[PRE39]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The `Inc` operation increments the value of the counter by `1`, and the updated
    value of the metric gets collected by tally automatically in the background. This
    does not affect the performance of the function that performs the provided operations.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '`Inc`操作通过`1`增加计数器的值，并且更新的指标值将由tally在后台自动收集。这不会影响执行提供的操作的功能的性能。'
- en: 'If you want to add some additional tags to the metric, you can use the `Tagged`
    function:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要向指标添加一些额外的标签，你可以使用`Tagged`函数：
- en: '[PRE40]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The following example illustrates how to update the gauge value. Let’s say
    we have a function that calculates the number of active users in the system and
    we want to report this value to the metrics storage. We can achieve this by using
    a gauge metric in the following way:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例说明了如何更新仪表值。假设我们有一个计算系统中活跃用户数量的函数，并且我们希望将此值报告到指标存储。我们可以通过以下方式使用仪表指标来实现：
- en: '[PRE41]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Now, let’s provide an example of reporting a time duration. A common use case
    of this is reporting the latency of various operations. In the following example,
    we are reporting how long it takes to execute our function:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们提供一个报告时间段的示例。这种用法的一个常见场景是报告各种操作的延迟。在以下示例中，我们报告执行我们的函数所需的时间：
- en: '[PRE42]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: In our example, we are initializing the `operation_latency` timer and calling
    the `Start` function of it to start measuring operation latency. The `Start` function
    returns the instance of a `Stopwatch` interface, which includes the `Stop` function.
    This reports the time it takes since the stopwatch’s start time.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，我们初始化了`operation_latency`计时器，并调用其`Start`函数以开始测量操作延迟。`Start`函数返回一个`Stopwatch`接口的实例，该实例包括`Stop`函数。这报告了自计时器开始时间以来的时间。
- en: 'When reporting the latency metrics, the tally library uses the default buckets,
    unless you provide their exact values. For example, when reporting the metrics
    to Prometheus, tally is using the following bucket configuration:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在报告延迟度量时，tally库使用默认的桶，除非您提供它们的精确值。例如，当将度量报告给Prometheus时，tally正在使用以下桶配置：
- en: '[PRE43]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Let’s provide an example of using a histogram with a set of predefined numerical
    buckets:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们提供一个使用一组预定义数值桶的直方图的例子：
- en: '[PRE44]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: In our example, we are initializing the histogram metric using a set of predefined
    buckets from 0 to 130 and recording the value that matches the user age in years
    using it. Each bucket of the histogram will then contain the sum of the values.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，我们使用从0到130的一系列预定义的桶来初始化直方图度量，并使用它记录与用户年龄匹配的值。然后，直方图的每个桶将包含值的总和。
- en: Now that we have provided some basic examples of emitting service metrics, let’s
    look at the best practices for working with metrics data.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经提供了一些发出服务度量的基本示例，让我们看看处理度量数据的最佳实践。
- en: Metrics best practices
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 度量最佳实践
- en: In this section, we will describe some of the best practices related to metric
    data collection. The list is not exhaustive, but should still be useful for setting
    up metric collection logic in your services.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将描述一些与度量数据收集相关的最佳实践。这个列表不是详尽的，但仍然对在您的服务中设置度量收集逻辑很有用。
- en: Keep tag cardinality in mind
  id: totrans-294
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意标签基数
- en: 'When you emit your metrics and add additional tags to time series data, keep
    in mind that most time series databases are not designed to store **high-cardinality**
    data, which can contain lots of possible tag values. For example, the following
    types of data should not be generally included in service metrics:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 当您发出度量并添加额外的标签到时间序列数据时，请记住，大多数时间序列数据库都不是为存储**高基数**数据而设计的，这些数据可能包含许多可能的标签值。例如，以下类型的数据通常不应包含在服务度量中：
- en: Object identifiers, such as movie or rating IDs
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对象标识符，例如电影或评分ID
- en: Randomly generated data, such as UUIDs (for example, request UUIDs)
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机生成数据，例如UUID（例如，请求UUID）
- en: The reason for this is indexing is that each tag key-value combination must
    be indexed to make the time series searchable, and it becomes expensive to perform
    this when there are lots of distinct tag values.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况的原因是索引，因为每个标签键值组合都必须被索引以使时间序列可搜索，当存在大量不同的标签值时，执行此操作变得昂贵。
- en: 'You can still use some low-cardinality data in metric tags. The following are
    some possible examples:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 您仍然可以在度量标签中使用一些低基数数据。以下是一些可能的例子：
- en: City ID
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 城市ID
- en: Service name
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务名称
- en: Endpoint name
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 端点名称
- en: Remember this tip to avoid reducing the throughput of your metrics pipeline
    and to ensure your services don’t emit user identifiers and other types of high-cardinality
    metadata.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 记住这个技巧以避免降低度量管道的吞吐量，并确保您的服务不发出用户标识和其他类型的高基数元数据。
- en: Standardize metric and tag names
  id: totrans-304
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 标准化度量标签名称
- en: Imagine that you have hundreds of services, and each service follows different
    metric naming conventions. For example, one service could be using `api_errors`
    as the name of the API error counter metric, while the other could be using the
    `api_request_errors` name. If you wanted to compare the metrics for such services,
    you would need to remember which naming convention each service was using. Such
    metric discovery will always take time, reducing your ability to analyze your
    data.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你有数百个服务，每个服务遵循不同的度量命名约定。例如，一个服务可能使用`api_errors`作为API错误计数器度量的名称，而另一个可能使用`api_request_errors`名称。如果您想比较此类服务的度量，您需要记住每个服务使用的是哪种命名约定。这种度量发现总是需要时间，这会降低您分析数据的能力。
- en: A much better solution is to standardize the names of common metrics and tags
    across all your services. This way, you can easily search and compare various
    performance indicators, such as service client and server error rates, API throughput,
    and request latency. In [*Chapter 12*](B18865_12.xhtml#_idTextAnchor171), we will
    review some common performance indicators that you can use to monitor the health
    of your services.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更好的解决方案是在所有服务中标准化常见指标和标签的名称。这样，你可以轻松搜索和比较各种性能指标，例如服务客户端和服务器错误率、API吞吐量和请求延迟。在[*第12章*](B18865_12.xhtml#_idTextAnchor171)中，我们将回顾一些你可以用来监控服务健康状况的常见性能指标。
- en: Set the appropriate retention
  id: totrans-307
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置适当的保留时间
- en: Most time series databases are capable of storing large datasets of metrics
    due to efficient aggregation. Unlike logs that require you to store each record
    independently, metrics can be aggregated into a smaller dataset. For example,
    if you store the counter data, you can store the sums of the values instead of
    storing each value separately. Even with these optimizations, time series data
    can take a lot of disk space to store. Large companies can store terabytes of
    metrics data, so it becomes important to manage its size and set up data retention
    policies, similar to logs and other types of telemetry data.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 由于高效的聚合，大多数时间序列数据库能够存储大量指标数据集。与需要独立存储每条记录的日志不同，指标可以聚合到更小的数据集中。例如，如果你存储计数器数据，你可以存储值的总和而不是单独存储每个值。即使有这些优化，时间序列数据仍然需要大量的磁盘空间来存储。大型公司可以存储数以TB计的指标数据，因此管理其大小并设置数据保留策略变得很重要，类似于日志和其他类型的遥测数据。
- en: 'Metric storages, such as Prometheus, have a default retention time of 15 days,
    allowing you to change it in the settings. For example, to set the data retention
    time in Prometheus to 60 days, you can use the following flag:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 指标存储，如Prometheus，默认保留时间为15天，允许你在设置中更改它。例如，要将Prometheus中的数据保留时间设置为60天，你可以使用以下标志：
- en: '[PRE45]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Limiting the storage retention time helps keep the size of the time series datasets
    under control, making it easier to manage the storage capacity and plan the infrastructure
    spending on data storage.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 限制存储保留时间有助于控制时间序列数据集的大小，从而更容易管理存储容量并规划数据存储的基础设施支出。
- en: 'Now that we’ve discussed the metrics data, let’s move on to the next section,
    which covers a powerful technique: tracing.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经讨论了指标数据，让我们继续到下一节，该节涵盖了一个强大的技术：跟踪。
- en: Tracing
  id: totrans-313
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跟踪
- en: So far, we have covered two common types of observability data – logs and metrics.
    Having logs and metrics data in place is often sufficient for service debugging
    and troubleshooting. However, there is another type of data that is useful for
    getting insights into microservice communication and data flows.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经涵盖了两种常见的可观察性数据类型——日志和指标。拥有日志和指标数据通常足以进行服务调试和故障排除。然而，还有一种类型的数据对于深入了解微服务通信和数据流非常有用。
- en: 'In this section, we are going to discuss **distributed tracing** – a technique
    that involves recording and analyzing interactions between different services
    and service components. The main idea behind distributed tracing is to automatically
    record all such interactions and provide a convenient way to visualize them. Let’s
    look at the following example, which illustrates a distributed tracing use case
    known as call analysis:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论**分布式跟踪**——一种涉及记录和分析不同服务和服务组件之间交互的技术。分布式跟踪背后的主要思想是自动记录所有此类交互并提供一种方便的方式来可视化它们。让我们看看以下示例，它说明了称为调用分析的分布式跟踪用例：
- en: '![Figure 11.2 – Tracing visualization example'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 11.2 – Tracing visualization example]'
- en: '](img/Figure_11.2_B18865.jpg)'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/Figure_11.2_B18865.jpg]'
- en: Figure 11.2 – Tracing visualization example
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.2 – 跟踪可视化示例
- en: 'Here, you can see the execution of a single `GetMovieDetails` request for our
    movie service. The data provides some insights into the operation’s execution:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你可以看到对我们电影服务的单个`GetMovieDetails`请求的执行。这些数据提供了一些关于操作执行的见解：
- en: Soon after the request starts, two parallel calls come from the movie service;
    one to the metadata service and the other to the rating service.
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请求开始不久后，电影服务会发起两个并行调用；一个调用元数据服务，另一个调用评分服务。
- en: The call to the metadata service takes 100 milliseconds to complete.
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调用元数据服务的完成时间为100毫秒。
- en: The call to the rating service takes 1,100 milliseconds to complete, spanning
    almost the entire request processing time.
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调用评分服务的完成时间为1,100毫秒，几乎涵盖了整个请求处理时间。
- en: The data that we just extracted provided us with lots of valuable information
    for analyzing the movie service’s performance. First, it helped us understand
    how an individual request was handled by the movie service, as well as which sub-operations
    it performed. We can also see the duration of each operation and find out which
    one was slowing down the entire request. By using this data, we could troubleshoot
    endpoint performance issues, finding which components make a significant impact
    on request processing.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚提取的数据为我们提供了分析电影服务性能的大量有价值信息。首先，它帮助我们了解单个请求是如何被电影服务处理的，以及它执行了哪些子操作。我们还可以看到每个操作的持续时间，并找出哪个操作减慢了整个请求。通过使用这些数据，我们可以排查端点性能问题，找出对请求处理有重大影响的组件。
- en: 'In our example, we showed the interaction between just three services, but
    tracing tools allow us to analyze the behavior of systems that use tens and even
    hundreds of services simultaneously. The following are some other use cases that
    make tracing a powerful tool for production debugging:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，我们展示了仅三个服务之间的交互，但跟踪工具使我们能够分析同时使用数十甚至数百个服务的系统的行为。以下是一些其他用例，这些用例使跟踪成为生产调试的有力工具：
- en: '**Error analysis**: Tracing allows us to visualize the errors on complex call
    paths, such as chains of calls spanning lots of different services.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**错误分析**：跟踪使我们能够可视化复杂调用路径上的错误，例如跨越许多不同服务的调用链。'
- en: '**Call path analysis**: Sometimes, you may investigate issues in systems you
    are not very familiar with. Tracing data helps you visualize the call path of
    various operations, helping you understand the logic of the services without requiring
    you to analyze their code.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**调用路径分析**：有时，您可能需要调查您不太熟悉的系统中的问题。跟踪数据有助于您可视化各种操作的调用路径，帮助您理解服务的逻辑，而无需分析它们的代码。'
- en: '**Operation performance breakdown**: Tracing allows us to see the duration
    of individual steps of a long-running operation.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**操作性能分解**：跟踪使我们能够看到长时间运行的操作的各个步骤的持续时间。'
- en: 'Let’s describe the tracing data model so that you can get familiar with its
    common terminology. The core element of tracing is a **span** – a record representing
    some logical operation, such as a service endpoint call. Each span has the following
    properties:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们描述跟踪数据模型，以便您熟悉其常用术语。跟踪的核心元素是一个**span**——表示某些逻辑操作的记录，例如服务端点调用。每个span都具有以下属性：
- en: Operation name
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作名称
- en: Start time
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始时间
- en: End time
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结束时间
- en: An optional set of tags providing some additional metadata related to the execution
    of the associated operation
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个可选的标签集，提供与相关操作执行相关的某些附加元数据
- en: An optional set of associated logs
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个可选的关联日志集
- en: Spans can be grouped into hierarchies to model relationships between different
    operations. For example, in *Figure 11**.2*, our `GetMovieDetails` span included
    two child spans, representing `GetMetadata` and `GetAggregatedRating` operations.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 可以将span分组到层次结构中，以表示不同操作之间的关系。例如，在*图11.2*中，我们的`GetMovieDetails` span包含两个子span，分别代表`GetMetadata`和`GetAggregatedRating`操作。
- en: Let’s explore how we can collect and use tracing data in our Go applications.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索如何在我们的Go应用程序中收集和使用跟踪数据。
- en: Tracing tools
  id: totrans-336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 跟踪工具
- en: There are various tools for distributed tracing in a microservice environment.
    Among the most popular ones is Jaeger, which we will review in this section.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 在微服务环境中，有各种分布式跟踪工具。其中最受欢迎的是Jaeger，我们将在本节中对其进行回顾。
- en: Note
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'There are multiple observability libraries and tools available for developers,
    including libraries for trace collection. To standardize the data model and make
    data interchangeable, there is an OpenTelemetry project that contains the specification
    of the tracing data model. You can get familiar with the project on its website:
    [https://opentelemetry.io](https://opentelemetry.io).'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 开发者可以使用多种可观察性库和工具，包括跟踪收集库。为了标准化数据模型并使数据可交换，有一个包含跟踪数据模型规范的OpenTelemetry项目。您可以在其网站上了解该项目：[https://opentelemetry.io](https://opentelemetry.io)。
- en: Jaeger is an open source distributed tracing tool that provides mechanisms for
    collecting, aggregating, and visualizing the tracing data. It offers a simple
    but highly flexible setup and a great user interface for accessing trace data.
    This is the reason why it quickly became one of the most popular observability
    tools across the industry.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: Jaeger 是一款开源的分布式跟踪工具，它提供了收集、聚合和可视化跟踪数据的机制。它提供了一个简单但高度灵活的设置，以及一个优秀的用户界面来访问跟踪数据。这也是它迅速成为行业内最受欢迎的可观察性工具之一的原因。
- en: Jaeger is compatible with the OpenTelemetry specification, so it can be used
    in combination with any clients implementing the tracing specification, such as
    the Go SDK (https://opentelemetry.io/docs/instrumentation/go/). The OpenTelemetry
    SDK is currently the recommended way of emitting trace data from applications,
    so we are going to use it in our examples throughout this section.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: Jaeger 与 OpenTelemetry 规范兼容，因此它可以与任何实现跟踪规范的客户端一起使用，例如 Go SDK（https://opentelemetry.io/docs/instrumentation/go/）。目前，OpenTelemetry
    SDK 是从应用程序中发出跟踪数据的首选方式，因此在本节的示例中我们将使用它。
- en: 'The general data flow for services using Jaeger looks like this:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Jaeger 的服务的一般数据流看起来像这样：
- en: '![Figure 11.3 – Jaeger data flow'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.3 – Jaeger 数据流]'
- en: '](img/Figure_11.3_B18865.jpg)'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/Figure_11.3_B18865.jpg]'
- en: Figure 11.3 – Jaeger data flow
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.3 – Jaeger 数据流
- en: In the preceding diagram, a service using a Jaeger-compatible library is emitting
    traces to the Jaeger backend, which is storing them in the span storage. The data
    is accessible for querying and visualization via the Jaeger UI.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图中，使用与 Jaeger 兼容库的服务正在向 Jaeger 后端发出跟踪，后端将它们存储在跨度存储中。数据可以通过 Jaeger UI 进行查询和可视化。
- en: Note
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'Jaeger is another example of an observability tool written in Go. You can check
    out the Jaeger source code on its official GitHub page: [https://github.com/jaegertracing/jaeger](https://github.com/jaegertracing/jaeger).'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: Jaeger 是用 Go 编写的可观察性工具的另一个例子。您可以在其官方 GitHub 页面上查看 Jaeger 的源代码：[https://github.com/jaegertracing/jaeger](https://github.com/jaegertracing/jaeger)。
- en: 'You can find more information about the Jaeger project on its website: [https://www.jaegertracing.io](https://www.jaegertracing.io).'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在其网站上找到有关 Jaeger 项目的更多信息：[https://www.jaegertracing.io](https://www.jaegertracing.io)。
- en: Let’s see some examples of instrumenting Go services to emit the tracing data.
    We will use the OpenTelemetry SDK in our examples to make our code compatible
    with different tracing software.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一些为 Go 服务添加跟踪数据的功能示例。在我们的示例中，我们将使用 OpenTelemetry SDK 来使我们的代码与不同的跟踪软件兼容。
- en: Collecting tracing data with the OpenTelemetry SDK
  id: totrans-351
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 OpenTelemetry SDK 收集跟踪数据
- en: In this section, we will show you how to emit tracing data in your service code.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将向您展示如何在服务代码中发出跟踪数据。
- en: 'As we mentioned at the beginning of the *Tracing* section, the core benefit
    of distributed tracing is the ability to automatically capture data that shows
    how services and other network components communicate with each other. Unlike
    metrics, which measure the performance of individual operations, traces help to
    collect information on how each request or operation is handled across the entire
    network of nodes that report this data. To report the traces, service instances
    need to be **instrumented** so that they perform two distinct roles:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在“跟踪”部分的开始所述，分布式跟踪的核心优势是能够自动捕获显示服务和其他网络组件之间如何相互通信的数据。与衡量单个操作性能的指标不同，跟踪有助于收集关于每个请求或操作在整个报告此数据的节点网络中如何处理的详细信息。为了报告跟踪，服务实例需要**被仪器化**，以便它们执行两个不同的角色：
- en: '**Report the data on distributed operations**: For each **traceable operation**
    – an operation spanning multiple components, such as network requests or database
    queries – an instrumented service should report spans. The report should contain
    the operation name, start time, and end time.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**报告分布式操作的数据**：对于每个**可跟踪操作**——跨越多个组件的操作，例如网络请求或数据库查询——被仪器化的服务应报告跨度。报告应包含操作名称、开始时间和结束时间。'
- en: '**Facilitate context propagation**: The service should explicitly propagate
    context throughout the execution (if you are confused by this, please read the
    following paragraphs – this is the main trick behind distributed tracing!).'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**促进上下文传播**：服务应明确在整个执行过程中传播上下文（如果您对此感到困惑，请阅读以下段落——这是分布式跟踪背后的主要技巧！）。'
- en: We already defined a span earlier in this chapter, so let’s move to the second
    requirement for service instrumentation. What is context propagation and how do
    we perform it in the Go microservice code?
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章中已经定义了一个 span，现在让我们转向服务仪表化的第二个要求。上下文传播是什么，以及我们如何在 Go 微服务代码中执行它？
- en: Context propagation is a technique that involves explicitly passing an object,
    called a **context**, into other functions in the form of an argument. The context
    may contain arbitrary metadata, so passing it to another function helps propagate
    it further. That is, each function down the stream can either add new metadata
    to the context or access the metadata that already exists in it.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文传播是一种技术，它涉及将一个称为 **上下文** 的对象显式地以参数的形式传递给其他函数。上下文可能包含任意元数据，因此将其传递给另一个函数有助于进一步传播。也就是说，流中的每个函数都可以向上下文中添加新的元数据或访问其中已存在的元数据。
- en: 'Let’s illustrate context propagation via a diagram:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个图表来阐述上下文传播：
- en: '![Figure 11.4 – Context propagation example'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 11.4 – Context propagation example](img/Figure_11.4_B18865.jpg)'
- en: '](img/Figure_11.4_B18865.jpg)'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/Figure_11.4_B18865.jpg](img/Figure_11.4_B18865.jpg)'
- en: Figure 11.4 – Context propagation example
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.4 – 上下文传播示例
- en: In the previous flow chart, there is an HTTP request coming from `ctx.reqId`
    for the request to pass the request identifier. `ctx.reqId` header further to
    **Service C** so that all services can record the identifier of the request, for
    which they perform the operations.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的流程图中，有一个来自 `ctx.reqId` 的 HTTP 请求，用于传递请求标识符。`ctx.reqId` 标头进一步传递到 **服务 C**，以便所有服务都能记录请求的标识符，并针对该标识符执行操作。
- en: The example that we just provided illustrates context propagation between three
    services. This is achieved by including specific HTTP headers in requests, which
    provide additional metadata for request processing. There are multiple ways of
    propagating the data when executing various operations. We will start by looking
    at the regular Go function calls.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚才提供的例子说明了三个服务之间的上下文传播。这是通过在请求中包含特定的 HTTP 标头来实现的，这些标头为请求处理提供了额外的元数据。在执行各种操作时，有多种传播数据的方式。我们将首先查看常规的
    Go 函数调用。
- en: 'We covered Go context propagation in [*Chapter 2*](B18865_02.xhtml#_idTextAnchor027)
    and mentioned the `context` package, which provides a type called `context.Context`.
    Passing the context between two Go functions of a single service is as easy as
    calling another function with an additional argument, as shown here:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 [*第 2 章*](B18865_02.xhtml#_idTextAnchor027) 中介绍了 Go 上下文传播，并提到了 `context`
    包，它提供了一个名为 `context.Context` 的类型。在单个服务中的两个 Go 函数之间传递上下文就像调用另一个函数并添加一个额外的参数一样简单，如下所示：
- en: '[PRE46]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'In our example, we pass the context that we receive in our function into another
    one, propagating it throughout the execution chain. We can attach additional metadata
    to the context by using the `WithValue` function, as shown in the following code
    block:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，我们将我们在函数中接收到的上下文传递给另一个函数，在整个执行链中传播它。我们可以通过使用 `WithValue` 函数将额外的元数据附加到上下文中，如下面的代码块所示：
- en: '[PRE47]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: In this updated example, we are passing the modified context to the other function,
    which will include some additional tracing metadata.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个更新的例子中，我们将修改后的上下文传递给另一个函数，该函数将包括一些额外的跟踪元数据。
- en: 'Now, let’s connect this knowledge with the core concept of tracing – a span.
    A span represents an individual operation, such as a network request, that can
    be related to some other operations, such as the other network calls that are
    made during the request’s execution. In our `getMovieDetails` example, the original
    request would be represented as a `getMovieDetails` request handling. To establish
    the relationship between the child and parent spans, we need to pass the identifier
    of the parent span to its children. We can do this by propagating it through the
    context of each function call, as we illustrated earlier. To make this easier
    to understand, let’s summarize the steps for collecting the trace data for a Go
    function:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将这个知识与跟踪的核心概念——span——联系起来。span 代表一个单独的操作，例如网络请求，它可以与其他操作相关联，例如在请求执行期间做出的其他网络调用。在我们的
    `getMovieDetails` 示例中，原始请求将表示为 `getMovieDetails` 请求处理。为了建立子 span 和父 span 之间的关系，我们需要将父
    span 的标识符传递给其子 span。我们可以通过在每次函数调用中传播它来实现这一点，就像我们之前所展示的那样。为了使这一点更容易理解，让我们总结一下收集
    Go 函数跟踪数据的步骤：
- en: For the original function being traced, we generate a new parent span object.
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为原始的跟踪函数生成一个新的父 span 对象。
- en: When the function makes calls to any other functions that need to be included
    in the trace (for example, network calls or database requests), we pass the parent
    span data to them as a part of the Go `context` argument.
  id: totrans-371
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当函数调用任何需要包含在跟踪中的其他函数（例如，网络调用或数据库请求）时，我们将父跨度数据作为Go `context`参数的一部分传递给它们。
- en: When a function receives a context with some parent span metadata, we include
    the parent span ID in the span data associated with the function.
  id: totrans-372
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当一个函数接收一个包含一些父跨度元数据的上下文时，我们将父跨度ID包含在函数关联的跨度数据中。
- en: All the functions in the chain should follow the same steps and, at the end
    of each execution, report the captured span data.
  id: totrans-373
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 链中的所有函数都应该遵循相同的步骤，并在每次执行的末尾报告捕获的跨度数据。
- en: 'Now, let’s demonstrate how to use this technique in Go applications. We are
    going to use the OpenTelemetry Go SDK in our examples, and use Jaeger as the data
    source of the tracing data:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们演示如何在Go应用程序中使用这项技术。在我们的示例中，我们将使用OpenTelemetry Go SDK，并使用Jaeger作为跟踪数据的数据源：
- en: 'Let’s start with the configuration changes. Inside each service directory,
    update the `cmd/config.go` file to the following:'
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从配置更改开始。在每个服务目录内部，更新`cmd/config.go`文件到以下内容：
- en: '[PRE48]'
  id: totrans-376
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-378
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-380
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '[PRE54]'
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-383
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[PRE56]'
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-385
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: The configuration that we just added will help us set the Jaeger URL for submitting
    the trace data.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚添加的配置将帮助我们设置提交跟踪数据的Jaeger URL。
- en: 'The next step is to update the `configs/base.yaml` file for each service so
    that it includes the Jaeger API URL property. We can do this by adding the following
    code at the end:'
  id: totrans-388
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是更新每个服务的`configs/base.yaml`文件，以便它包含Jaeger API URL属性。我们可以通过在末尾添加以下代码来完成：
- en: '[PRE59]'
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Let’s create a shared function that can be used in each service to initialize
    the tracing data provider. This is going to submit our traces to Jaeger. In our
    root `pkg` directory, create a directory called `tracing` and add a `tracing.go`
    file with the following contents:'
  id: totrans-391
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个可以在每个服务中使用的共享函数，用于初始化跟踪数据提供者。这将提交我们的跟踪到Jaeger。在我们的根`pkg`目录中，创建一个名为`tracing`的目录，并添加一个`tracing.go`文件，内容如下：
- en: '[PRE61]'
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-393
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-394
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '[PRE64]'
  id: totrans-395
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '[PRE65]'
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '[PRE66]'
  id: totrans-397
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '[PRE67]'
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '[PRE68]'
  id: totrans-399
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-400
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '[PRE70]'
  id: totrans-401
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '[PRE71]'
  id: totrans-402
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '[PRE72]'
  id: totrans-403
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '[PRE73]'
  id: totrans-404
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '[PRE74]'
  id: totrans-405
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '[PRE75]'
  id: totrans-406
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '[PRE76]'
  id: totrans-407
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '[PRE77]'
  id: totrans-408
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '[PRE78]'
  id: totrans-409
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: '[PRE79]'
  id: totrans-410
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '[PRE80]'
  id: totrans-411
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '[PRE81]'
  id: totrans-412
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '[PRE82]'
  id: totrans-413
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: Here, we are initializing the Jaeger client and using it to create the OpenTelemetry
    trace data provider. The provider will automatically submit the trace data that
    we will collect throughout the service execution.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们初始化了Jaeger客户端，并使用它来创建OpenTelemetry跟踪数据提供者。该提供者将自动提交我们在服务执行过程中收集的跟踪数据。
- en: 'The next step is to update the `main.go` file of each service. Add the `go.opentelemetry.io/otel`
    import to the `imports` block of the `main.go` file for each service, and add
    the following code block after the first `log.Printf` call:'
  id: totrans-415
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是更新每个服务的`main.go`文件。将`go.opentelemetry.io/otel`导入添加到每个服务的`main.go`文件的`导入`块中，并在第一个`log.Printf`调用之后添加以下代码块：
- en: '[PRE83]'
  id: totrans-416
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '[PRE84]'
  id: totrans-417
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '[PRE85]'
  id: totrans-418
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE85]'
- en: '[PRE86]'
  id: totrans-419
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '[PRE87]'
  id: totrans-420
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE87]'
- en: '[PRE88]'
  id: totrans-421
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '[PRE89]'
  id: totrans-422
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '[PRE90]'
  id: totrans-423
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '[PRE91]'
  id: totrans-424
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE91]'
- en: '[PRE92]'
  id: totrans-425
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE92]'
- en: '[PRE93]'
  id: totrans-426
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE93]'
- en: The last two lines of the code set the global OpenTelemetry trace provider to
    our Jaeger-based version. These lines also enable context propagation, which will
    allow us to transfer the tracing data between the services.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的最后两行将全局OpenTelemetry跟踪提供者设置为基于Jaeger的版本。这些行还启用了上下文传播，这将允许我们在服务之间传输跟踪数据。
- en: 'To enable client-side context propagation, update the `internal/grpcutil/grpcutil.go`
    file to the following:'
  id: totrans-428
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要启用客户端上下文传播，更新`internal/grpcutil/grpcutil.go`文件到以下内容：
- en: '[PRE94]'
  id: totrans-429
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE94]'
- en: '[PRE95]'
  id: totrans-430
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE95]'
- en: '[PRE96]'
  id: totrans-431
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE96]'
- en: '[PRE97]'
  id: totrans-432
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE97]'
- en: '[PRE98]'
  id: totrans-433
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE98]'
- en: '[PRE99]'
  id: totrans-434
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE99]'
- en: '[PRE100]'
  id: totrans-435
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE100]'
- en: '[PRE101]'
  id: totrans-436
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE101]'
- en: '[PRE102]'
  id: totrans-437
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE102]'
- en: '[PRE103]'
  id: totrans-438
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE103]'
- en: '[PRE104]'
  id: totrans-439
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE104]'
- en: '[PRE105]'
  id: totrans-440
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE105]'
- en: '[PRE106]'
  id: totrans-441
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE106]'
- en: '[PRE107]'
  id: totrans-442
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE107]'
- en: '[PRE108]'
  id: totrans-443
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE108]'
- en: '[PRE109]'
  id: totrans-444
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE109]'
- en: '[PRE110]'
  id: totrans-445
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE110]'
- en: '[PRE111]'
  id: totrans-446
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE111]'
- en: '[PRE112]'
  id: totrans-447
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE112]'
- en: '[PRE113]'
  id: totrans-448
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE113]'
- en: '[PRE114]'
  id: totrans-449
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE114]'
- en: Here, we added an OpenTelemetry-based interceptor that injects the tracing data
    into each request.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们添加了一个基于OpenTelemetry的拦截器，它将跟踪数据注入到每个请求中。
- en: 'Inside the `main.go` file of each service, change the line containing the `grpc.NewServer()`
    call to the following one, to enable server-side context propagation:'
  id: totrans-451
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在每个服务的`main.go`文件中，更改包含`grpc.NewServer()`调用的行，如下所示，以启用服务器端上下文传播：
- en: '[PRE115]'
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE115]'
- en: The change that we just made is similar to the previous step, just for server-side
    handling.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚做出的更改与上一步类似，只是针对服务器端处理。
- en: 'The last step is to make sure all the new libraries are included in our project
    by running the following command:'
  id: totrans-454
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一步是确保所有新库都包含在我们的项目中，通过运行以下命令来完成：
- en: '[PRE116]'
  id: totrans-455
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE116]'
- en: With that, our services have been instrumented with tracing code and emit span
    data on each API request.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们的服务已经通过跟踪代码进行了配置，并在每个API请求上发出跨度数据。
- en: 'Let’s test our newly added code by running our services and making some requests
    to them:'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过运行我们的服务和向它们发出一些请求来测试我们新添加的代码：
- en: 'To be able to collect the tracing data, you will need to run Jaeger locally.
    You can do this by running the following command:'
  id: totrans-458
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要能够收集跟踪数据，您需要在本地运行Jaeger。您可以通过运行以下命令来完成：
- en: '[PRE117]'
  id: totrans-459
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE117]'
- en: '[PRE118]'
  id: totrans-460
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE118]'
- en: '[PRE119]'
  id: totrans-461
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE119]'
- en: '[PRE120]'
  id: totrans-462
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE120]'
- en: '[PRE121]'
  id: totrans-463
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE121]'
- en: '[PRE122]'
  id: totrans-464
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE122]'
- en: '[PRE123]'
  id: totrans-465
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE123]'
- en: '[PRE124]'
  id: totrans-466
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE124]'
- en: '[PRE125]'
  id: totrans-467
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE125]'
- en: '[PRE126]'
  id: totrans-468
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE126]'
- en: '[PRE127]'
  id: totrans-469
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE127]'
- en: '[PRE128]'
  id: totrans-470
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE128]'
- en: '[PRE129]'
  id: totrans-471
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE129]'
- en: Now, we can start all our services locally by executing the `go run *.go` command
    inside each `cmd` directory.
  id: totrans-472
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以通过在每个 `cmd` 目录中执行 `go run *.go` 命令来本地启动所有服务。
- en: 'Let’s make some requests to our movie service. In [*Chapter 5*](B18865_05.xhtml#_idTextAnchor076),
    we mentioned the `grpcurl` tool. Let’s use it again to make a manual gRPC query:'
  id: totrans-473
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们对我们的电影服务进行一些请求。在 [*第5章*](B18865_05.xhtml#_idTextAnchor076) 中，我们提到了 `grpcurl`
    工具。让我们再次使用它来手动进行 gRPC 查询：
- en: '[PRE130]'
  id: totrans-474
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE130]'
- en: 'If everything was correct, we should get our trace in Jaeger. Let’s check it
    in the Jaeger UI by going to `http://localhost:16686/`. You should see a similar
    page as follows:'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切正常，我们应该在 Jaeger 中看到我们的跟踪。让我们通过转到 `http://localhost:16686/` 来在 Jaeger UI
    中检查它。你应该会看到一个类似的页面，如下所示：
- en: '![Figure 11.5 – Jaeger UI'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 11.5 – Jaeger UI'
- en: '](img/Figure_11.5_B18865.jpg)'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/Figure_11.5_B18865.jpg)'
- en: Figure 11.5 – Jaeger UI
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: Figure 11.5 – Jaeger UI
- en: 'Select the **movie** service in the **Service** field and click **Find Traces**.
    You should see some trace results, as shown here:'
  id: totrans-479
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **服务** 字段中选择 **movie** 服务，然后点击 **查找跟踪**。你应该会看到一些跟踪结果，如下所示：
- en: '![Figure 11.6 – Jaeger traces for the movie service'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 11.6 – 电影服务的 Jaeger 跟踪'
- en: '](img/Figure_11.6_B18865.jpg)'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/Figure_11.6_B18865.jpg)'
- en: Figure 11.6 – Jaeger traces for the movie service
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: Figure 11.6 – 电影服务的 Jaeger 跟踪
- en: 'If you click on the trace, you will see its visualized view, as shown here:'
  id: totrans-483
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你点击跟踪，你会看到其可视化的视图，如下所示：
- en: '![Figure 11.7 – Jaeger trace view for the GetMovieDetails endpoint call'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 11.7 – GetMovieDetails 端点调用的 Jaeger 跟踪视图'
- en: '](img/Figure_11.7_B18865.jpg)'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/Figure_11.7_B18865.jpg)'
- en: Figure 11.7 – Jaeger trace view for the GetMovieDetails endpoint call
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: Figure 11.7 – GetMovieDetails 端点调用的 Jaeger 跟踪视图
- en: On the left panel, you can see the request as a tree of spans, where the root
    span represents the `MovieService/GetMovieDetails` operation, which includes the
    calls to the `MetadataService/GetMetadata` and `RatingService/GetAggregatedRating`
    endpoints. Congratulations, you have set up distributed tracing for your microservices
    using the OpenTracing SDK! All our gRPC calls are now traced automatically, without
    any need to add any extra service logic. This provides us with a convenient mechanism
    for collecting valuable data on service communication.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 在左侧面板中，你可以看到请求作为一个跨度的树，其中根跨度代表 `MovieService/GetMovieDetails` 操作，它包括对 `MetadataService/GetMetadata`
    和 `RatingService/GetAggregatedRating` 端点的调用。恭喜你，你已经使用 OpenTracing SDK 为你的微服务设置了分布式跟踪！我们所有的
    gRPC 调用现在都自动跟踪，无需添加任何额外的服务逻辑。这为我们提供了一个方便的机制来收集有关服务通信的有价值数据。
- en: 'As an extra step, let’s illustrate how to add tracing for our database operations.
    As you can see from the trace view in the preceding screenshot, we currently don’t
    have any database-related spans on our graph. This is because our database logic
    has not been instrumented yet. Let’s demonstrate how to do this manually:'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 作为额外的一步，让我们说明如何为我们的数据库操作添加跟踪。如前一个屏幕截图中的跟踪视图所示，我们目前在我们的图表上没有任何数据库相关的跨度。这是因为我们的数据库逻辑还没有被度量。让我们演示如何手动进行此操作：
- en: Open the `metadata/internal/repository/memory/memory.go` file and add `go.opentelemetry.io/otel`
    to its imports.
  id: totrans-489
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 `metadata/internal/repository/memory/memory.go` 文件，并将 `go.opentelemetry.io/otel`
    添加到其导入中。
- en: 'In the same file, add the following constant:'
  id: totrans-490
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在同一文件中添加以下常量：
- en: '[PRE131]'
  id: totrans-491
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE131]'
- en: 'At the beginning of the `Get` function, add the following code:'
  id: totrans-492
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Get` 函数的开始处添加以下代码：
- en: '[PRE132]'
  id: totrans-493
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE132]'
- en: '[PRE133]'
  id: totrans-494
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE133]'
- en: 'Add a similar code block at the beginning of the `Put` function:'
  id: totrans-495
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Put` 函数的开始处添加一个类似的代码块：
- en: '[PRE134]'
  id: totrans-496
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE134]'
- en: '[PRE135]'
  id: totrans-497
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE135]'
- en: We just manually instrumented our in-memory metadata repository for emitting
    the trace data on its primary operations, `Get` and `Put`. Now, each call to these
    functions should create a span in the captured trace, allowing us to see when
    and how long each operation is being executed.
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚手动度量了我们的内存元数据存储库，以便在其主要操作 `Get` 和 `Put` 上发出跟踪数据。现在，对这些函数的每次调用都应该在捕获的跟踪中创建一个跨度，使我们能够看到每个操作何时以及执行了多长时间。
- en: 'Let’s test our newly added code. Restart the metadata service and make a new
    `grpcurl` request to the movie service provided previously. If you check for new
    traces in Jaeger, you should see the new one, with an additional span:'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们测试我们新添加的代码。重新启动元数据服务，并使用之前提供的电影服务进行新的 `grpcurl` 请求。如果你在 Jaeger 中检查新的跟踪，你应该会看到新的一个，并增加一个跨度：
- en: '![Figure 11.8 – Jaeger trace view with an additional repository span'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 11.8 – Jaeger 跟踪视图，包含额外的存储库跨度'
- en: '](img/Figure_11.8_B18865.jpg)'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/Figure_11.8_B18865.jpg)'
- en: Figure 11.8 – Jaeger trace view with an additional repository span
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: Figure 11.8 – 包含额外存储库跨度的 Jaeger 跟踪视图
- en: Notice the last span in the trace view, representing the `Repository/Get` operation.
    It is the result of our change. Now, we can see the database operations on our
    traces. You can go ahead and update the rating service repository by including
    similar logic – follow the preceding instructions, and you should be able to make
    it work in the same way that we just did for the metadata service.
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 注意追踪视图中最后一个跨度，代表`Repository/Get`操作。这是我们更改的结果。现在，我们可以在我们的追踪中看到数据库操作。你可以继续更新评分服务仓库，包括类似的逻辑——遵循前面的说明，你应该能够以我们刚刚为元数据服务所做的方式使其工作。
- en: When should you manually add span data to your functions? I would suggest doing
    this for each operation involving network calls, I/O operations (such as writing
    and reading from files), database writes and reads, and any other calls that can
    take a substantial amount of time. I would personally say that any function that
    takes more than 50 ms to complete is a good candidate for tracing.
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该在何时手动将跨度数据添加到你的函数中？我建议对于涉及网络调用、I/O操作（如读写文件）、数据库读写以及其他可能花费大量时间的调用，都进行这样的操作。我个人认为，任何执行时间超过50毫秒的函数都是进行追踪的好候选。
- en: At this point, we have provided a high-level overview of Go tracing techniques,
    and this marks an end to our journey into telemetry data. In the next few chapters,
    we will continue our explorations into other fields, such as dashboarding, system-level
    performance analysis, and some advanced observability techniques.
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经提供了Go追踪技术的概述，这也标志着我们探索遥测数据的旅程的结束。在接下来的几章中，我们将继续探索其他领域，例如仪表盘、系统级性能分析和一些高级可观察性技术。
- en: Summary
  id: totrans-506
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we covered observability by describing various techniques for
    analyzing the real-time performance of Go microservices and covering the main
    types of service telemetry data, such as logs, metrics, and traces. You learned
    about some of the best practices for performing logging, metric collection, and
    distributed tracing. We demonstrated how you can instrument your Go services to
    collect the telemetry data, as well as how to set up the tooling for distributed
    tracing. We also provided some examples of tracing the requests spanning three
    of the services that we implemented earlier in this book.
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们通过描述分析Go微服务实时性能的各种技术，并涵盖服务遥测数据的主要类型，如日志、指标和追踪，来介绍可观察性。你学习了执行日志记录、指标收集和分布式追踪的一些最佳实践。我们展示了如何对你的Go服务进行配置以收集遥测数据，以及如何设置分布式追踪的工具。我们还提供了追踪本书早期实现的服务中跨越三个服务的请求的示例。
- en: The knowledge that you gained in this chapter should help you debug various
    performance issues of your microservices, as well as enable monitoring of various
    types of telemetry data. In [*Chapter 12*](B18865_12.xhtml#_idTextAnchor171),
    we will demonstrate how to use the collected telemetry data to set up service
    alerting for detecting service-related incidents as quickly as possible.
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中获得的知识应该有助于你调试微服务的各种性能问题，并使各种类型的遥测数据监控成为可能。在[*第12章*](B18865_12.xhtml#_idTextAnchor171)中，我们将展示如何使用收集到的遥测数据来设置服务警报，以便尽可能快地检测与服务相关的事件。
- en: Further reading
  id: totrans-509
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'To learn more about the topics that were covered in this chapter, take a look
    at the following resources:'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于本章所涉及的主题，请查看以下资源：
- en: '*Monitoring Distributed* *Systems*: [https://sre.google/sre-book/monitoring-distributed-systems/](https://sre.google/sre-book/monitoring-distributed-systems/)'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*监控分布式系统*：[https://sre.google/sre-book/monitoring-distributed-systems/](https://sre.google/sre-book/monitoring-distributed-systems/)'
- en: '*Effective* *Troubleshooting*: [https://sre.google/sre-book/effective-troubleshooting/](https://sre.google/sre-book/effective-troubleshooting/)'
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*有效的故障排除*：[https://sre.google/sre-book/effective-troubleshooting/](https://sre.google/sre-book/effective-troubleshooting/)'
- en: '*Mastering Distributed* *Tracing*: [https://www.packtpub.com/product/mastering-distributed-tracing/9781788628464](https://www.packtpub.com/product/mastering-distributed-tracing/9781788628464)'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*掌握分布式追踪*：[https://www.packtpub.com/product/mastering-distributed-tracing/9781788628464](https://www.packtpub.com/product/mastering-distributed-tracing/9781788628464)'
- en: 'Logging best practices: [https://devcenter.heroku.com/articles/writing-best-practices-for-application-logs](https://devcenter.heroku.com/articles/writing-best-practices-for-application-logs)'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志最佳实践：[https://devcenter.heroku.com/articles/writing-best-practices-for-application-logs](https://devcenter.heroku.com/articles/writing-best-practices-for-application-logs)
- en: '*Ten commandments of* *logging*: [https://www.dataset.com/blog/the-10-commandments-of-logging/](https://www.dataset.com/blog/the-10-commandments-of-logging/)'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*日志记录的十诫*: [https://www.dataset.com/blog/the-10-commandments-of-logging/](https://www.dataset.com/blog/the-10-commandments-of-logging/)'
- en: 'Microservice logging tips: [https://www.techtarget.com/searchapparchitecture/tip/5-essential-tips-for-logging-microservices](https://www.techtarget.com/searchapparchitecture/tip/5-essential-tips-for-logging-microservices)'
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微服务日志记录技巧：[https://www.techtarget.com/searchapparchitecture/tip/5-essential-tips-for-logging-microservices](https://www.techtarget.com/searchapparchitecture/tip/5-essential-tips-for-logging-microservices)
- en: 'OpenTelemetry documentation: [https://opentelemetry.io/docs/](https://opentelemetry.io/docs/)'
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenTelemetry 文档：[https://opentelemetry.io/docs/](https://opentelemetry.io/docs/)
- en: 'Beginner’s Guide to OpenTelemetry: [https://logz.io/learn/opentelemetry-guide/](https://logz.io/learn/opentelemetry-guide/)'
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenTelemetry 初学者指南：[https://logz.io/learn/opentelemetry-guide/](https://logz.io/learn/opentelemetry-guide/)
- en: '*The 3 Pillars of System* *Observability*: [https://iamondemand.com/blog/the-3-pillars-of-system-observability-logs-metrics-and-tracing/](https://iamondemand.com/blog/the-3-pillars-of-system-observability-logs-metrics-and-tracing/)'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*系统可观察性的三个支柱*: [https://iamondemand.com/blog/the-3-pillars-of-system-observability-logs-metrics-and-tracing/](https://iamondemand.com/blog/the-3-pillars-of-system-observability-logs-metrics-and-tracing/)'
- en: '*What is* *observability?*: [https://www.dynatrace.com/news/blog/what-is-observability-2/](https://www.dynatrace.com/news/blog/what-is-observability-2/)'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*什么是* *可观察性？*: [https://www.dynatrace.com/news/blog/what-is-observability-2/](https://www.dynatrace.com/news/blog/what-is-observability-2/)'
- en: '*What is* *Telemetry?*: [https://www.sumologic.com/insight/what-is-telemetry/](https://www.sumologic.com/insight/what-is-telemetry/)'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*什么是* *遥测？*: [https://www.sumologic.com/insight/what-is-telemetry/](https://www.sumologic.com/insight/what-is-telemetry/)'
