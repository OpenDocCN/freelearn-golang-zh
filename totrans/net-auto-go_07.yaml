- en: '7'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Automation Frameworks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most engineers start their automation journey by writing small ad hoc scripts.
    Over time, as these scripts grow in size and number, we need to think about the
    operating model for the solutions we create and how strong the foundations we
    are building upon are. Ultimately, we have to coordinate automation practices
    across different teams to generate business outcomes at scale.
  prefs: []
  type: TYPE_NORMAL
- en: To reduce the time and effort spent automating their use cases, some organizations
    try to standardize their tools and reuse generic components in their solutions,
    which often leads them to automation frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: Automation frameworks allow different teams to come together under the same
    umbrella, break silos that may lead to inefficiencies, embrace common practices
    and code reusability, and enforce policies across domains to make the developed
    solutions more secure.
  prefs: []
  type: TYPE_NORMAL
- en: 'When choosing what best fits your environment and use cases, make sure you
    evaluate different automation frameworks. In this chapter, we will review some
    of them and focus specifically on how they can integrate with Go. In particular,
    we will look at the following:'
  prefs: []
  type: TYPE_NORMAL
- en: How Go programs can become Ansible modules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The development of a custom Terraform provider
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An overview of the rest of the well-known Go-based frameworks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We close this chapter by looking at the current trends in the industry and how
    the new generation of automation frameworks may develop in the future.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can find the code examples for this chapter in the book’s GitHub repository
    (see the *Further reading* section), in the `ch07` folder.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: We recommend you execute the Go programs in this chapter in a virtual lab environment.
    Refer to the appendix for the prerequisites and instructions on how to build it.
  prefs: []
  type: TYPE_NORMAL
- en: Ansible
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ansible is an open source project, framework, and automation platform. Its descriptive
    automation language has captured the attention of many network engineers who see
    it as an introduction with minimal friction into the world of network automation
    and something that can help them become productive relatively quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Ansible has an agentless push-based architecture. It connects to the hosts it
    manages via SSH and runs a series of tasks. These tasks are small programs that
    we call Ansible modules, which are the units of code that Ansible abstracts away
    from the user. A user only has to give the input arguments and can rely on Ansible
    modules to do all the heavy work for them. Although the level of abstraction may
    vary, Ansible modules allow users to focus more on the desired state of their
    infrastructure and less on the individual commands required to achieve that state.
  prefs: []
  type: TYPE_NORMAL
- en: Overview of Ansible components
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Playbooks are at the core of Ansible. These text-based declarative YAML files
    define a set of automation tasks that you can group in different plays. Each task
    runs a module that comes from either the Ansible code base or a third-party content
    collection:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.1 – Ansible high-level diagram](img/B16971_07_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.1 – Ansible high-level diagram
  prefs: []
  type: TYPE_NORMAL
- en: We use an Ansible inventory to describe the hosts or network devices we want
    to manage with Ansible. *Figure 7**.1* provides a high-level overview of these
    elements.
  prefs: []
  type: TYPE_NORMAL
- en: Inventory
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'An inventory is a list of managed hosts you can define statically in a text
    file or pull dynamically from an external system. You can manage hosts individually
    or collectively using groups. The following code snippet shows an Ansible inventory
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: You can also use inventory to define group- and host-level variables that become
    available to Ansible playbooks.
  prefs: []
  type: TYPE_NORMAL
- en: Playbooks, plays, and tasks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Ansible playbooks are files that you write using a YAML-based **Domain-Specific
    Language** (**DSL**). A playbook can have one or more plays on it. Each Ansible
    play targets a host or a group of hosts from an inventory to perform a series
    of tasks in a specific order. The following code output shows an example of a
    playbook with a single play and two tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The last example is a snippet from a larger playbook (see *Further reading*)
    included in the `ch07/ansible` folder of this book’s GitHub repository. That playbook
    has four tasks spread across two different plays. We use that playbook to review
    different concepts throughout this section.
  prefs: []
  type: TYPE_NORMAL
- en: Modules
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Each task executes an Ansible module. Although implementations may vary, the
    goal of an Ansible module is to be idempotent, so no matter how many times you
    run it against the same set of hosts, you always get the same outcome.
  prefs: []
  type: TYPE_NORMAL
- en: Ansible ships with several modules written mostly in Python, but it doesn’t
    stop you from using another programming language, which is what we explore in
    this section.
  prefs: []
  type: TYPE_NORMAL
- en: Working with Ansible modules
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The code of an Ansible module can execute either on a remote node, for hosts
    such as Linux servers, or locally, on the node running the playbook. The latter
    is what we typically do when the managed node is an API service or a network device
    because they both lack an execution environment with dependencies such as Linux
    shell and Python. Luckily, modern network operating systems meet those requirements,
    which give us both options of running the code locally or remotely.
  prefs: []
  type: TYPE_NORMAL
- en: If you look at the preceding playbook snippet, you can see how we implemented
    these two options. The first task invokes the `go_srl` module that gets delegated
    to the localhost. This means it runs from the machine running Ansible and targets
    a remote host provided in the host argument. The second task executes the `go_cvx`
    module, which is not delegated and thus runs on a remote node, targeting its API
    calls at the localhost.
  prefs: []
  type: TYPE_NORMAL
- en: 'The rest of the playbook uses a combination of local and remote execution environments,
    as denoted by the gear symbols in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.2 – Playbook example](img/B16971_07_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.2 – Playbook example
  prefs: []
  type: TYPE_NORMAL
- en: 'The Ansible playbook first runs an Ansible play to configure each node of the
    topology with these high-level objectives:'
  prefs: []
  type: TYPE_NORMAL
- en: Configure the SR Linux node (`srl`) using a compiled Go code we execute locally
    on the machine running Ansible
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configure the NVIDIA Cumulus node (`cvx`) using a compiled Go code we execute
    on the remote node
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configure the Arista EOS node (`ceos`) using a compiled Go code we execute locally
    on the machine running Ansible
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The choice of local or remote execution environments in the preceding playbook
    is random and only serves to show the two different approaches. Since all our
    lab devices are Linux-based, we can change this behavior without reworking the
    Ansible modules we use.
  prefs: []
  type: TYPE_NORMAL
- en: The second play has a single task that verifies the configured state on all
    three devices using a non-compiled code we execute using the `go run` command.
    We use this last task to show an alternative approach to concurrency that uses
    Go native primitives instead of Ansible forks to execute tasks on several nodes
    at the same time. We discuss this later in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Developing an Ansible module
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While Ansible developers write most Ansible modules in Python, there are different
    reasons to write a module in another programming language:'
  prefs: []
  type: TYPE_NORMAL
- en: Your company might use another programming language already.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maybe you know or feel more comfortable writing in a different language.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code is already available and there is no business justification to rewrite
    it in another programming language.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You want to take advantage of a feature that is not available in Python.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ansible’s role is not to rip and replace everything that you have, especially
    if it’s working for you already. To illustrate this, we will take a set of Go
    programs from other chapters and turn them into Ansible modules we can execute
    in a playbook to configure our lab topology.
  prefs: []
  type: TYPE_NORMAL
- en: Ansible module interface
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can extend Ansible by adding custom modules. Their implementation code
    should go into the `library` folder. When Ansible runs into a task with a module
    that is not installed in the system, it looks for a file with the module’s name
    in the `library` folder and tries to run it as a module, going through the following
    sequence of steps:'
  prefs: []
  type: TYPE_NORMAL
- en: It saves all module arguments in a temporary file, for example, `/tmp/foo`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It executes that module as a child process, passing it the filename as the first
    and only argument, for example, `./``library/my_module /tmp/foo`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It waits for the process to complete and expects to receive a structured response
    in its standard output.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: While Ansible always expects a response in a JSON format, the input file format
    Ansible passes to the module depends on whether the module is a script or a binary.
    All binary modules get their input arguments as a JSON file, while script modules
    receive their input arguments as Bash files or just a list of key-value pairs.
  prefs: []
  type: TYPE_NORMAL
- en: From Go’s code perspective, to make this input behavior uniform, we normalize
    the input format to JSON before running any non-compiled Go programs. We do this
    using a wrapper Bash script that transforms the Bash input into JSON before calling
    the `go run` command, as you can see in the `ch07/ansible/library/go_state` file
    of this book’s GitHub repository (see *Further reading*).
  prefs: []
  type: TYPE_NORMAL
- en: Adapting your Go code to interact with Ansible
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ultimately, a custom Ansible module can do anything as long as it understands
    how to parse the input arguments and knows how to return the expected output.
    We would need to change the Go programs from other chapters to make them an Ansible
    module. But the amount of changes necessary is minimal. Let’s examine this.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, for this example, we need to create a struct to parse the module arguments
    we receive in the input JSON file. These arguments include login credentials and
    the input data model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The input data model we use for Ansible remains the same as the one that we
    used in other chapters. This data is in the `ch07/ansible/host_vars` directory
    for this example. With Ansible, this data model becomes just a subset of all variables
    defined for each host. We pass it, along with the rest of the host variables,
    as a base64-encoded string. Inside our module, we decode the input string and
    decode it into the same `Model` struct we used before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: At this point, we’ve parsed enough information for our Go program to configure
    a network device. This part of the Go code does not require any modifications.
    The only thing you need to be mindful of is that instead of logging to the console,
    you now need to send any log messages as a response to Ansible.
  prefs: []
  type: TYPE_NORMAL
- en: 'When all the work is complete, we need to prepare and print the response object
    for Ansible. The following code snippet shows the *happy path* when all changes
    have gone through:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Using a similar pattern to what we just described, we have created a custom
    module for each one of the three lab devices and one module to verify the state
    of the lab topology as we did in [*Chapter 6*](B16971_06.xhtml#_idTextAnchor144),
    *Configuration Management*. You can find these modules in the `ch07/ansible/`{`srl`|`cvx`|`ceos`|`state`}
    directories of this book’s GitHub repository (see *Further reading*).
  prefs: []
  type: TYPE_NORMAL
- en: Before we move on to the execution, we want to show one way we can make use
    of Go’s built-in features to speed up and optimize concurrent task execution in
    Ansible.
  prefs: []
  type: TYPE_NORMAL
- en: Taking advantage of Go’s concurrency
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ansible’s default behavior is to run each task on all hosts before moving on
    to the next one (linear strategy). Of course, it doesn’t just run one task on
    one host at a time; instead, it uses several independent processes attempting
    to run simultaneously on as many hosts as the number of forks you define in the
    Ansible configuration. Whether these processes run in parallel depends on the
    hardware resources available to them.
  prefs: []
  type: TYPE_NORMAL
- en: A less expensive approach from a resource utilization perspective is to leverage
    Go concurrency. This is what we do in the `go_state` Ansible module, where we
    target a single node from the inventory, the implicit localhost, and leave the
    concurrent communication with the remote nodes to Go.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the following module, we reuse the code example from the *State validation*
    section of [*Chapter 6*](B16971_06.xhtml#_idTextAnchor144), *Configuration Management*
    that has the access details embedded in the code already, but you could also pass
    these access details as arguments to the module to achieve the same result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The trade - off of this approach is that we gain speed and get more efficient
    use of resources, but we lose the inventory management side of Ansible. Be mindful
    of this when trying to decide whether this is the right fit for your use case.
  prefs: []
  type: TYPE_NORMAL
- en: Running the playbook
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can find the complete example involving four Go Ansible modules in the
    `ch07/ansible` directory. To run it, first make sure the lab topology is running
    from the root folder of the repository with `make lab-up`, then run the playbook
    with the `ansible-playbook` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we’ve covered how Go programs can integrate with Ansible, we will
    move on to another popular automation framework: Terraform.'
  prefs: []
  type: TYPE_NORMAL
- en: Terraform
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Terraform is an open source software solution for declarative infrastructure
    management. It allows you to express and manage the desired state of your infrastructure
    with code. It has gained initial popularity as a framework to automate public
    cloud infrastructure but now supports a variety of on-premises and public cloud
    resources, platforms, services—almost anything that has an API.
  prefs: []
  type: TYPE_NORMAL
- en: One of the key distinctions of Terraform is the way it manages state. Once it
    creates a remote resource initially, it saves the resulting state in a file and
    relies on that state to be there for its next runs. As you update and develop
    your infrastructure code, the state file enables Terraform to manage the entire
    life cycle of a remote resource, calculating the precise sequence of API calls
    to transition between states. This ability to manage state and the declarative
    configuration language and the agentless, API-first architecture allowed Terraform
    to become deeply entrenched in the cloud infrastructure space and become a critical
    part of DevOps and Infrastructure-as-Code toolchains.
  prefs: []
  type: TYPE_NORMAL
- en: If we look at the Terraform registry (see *Further reading*), we can see over
    a hundred providers in the networking category ranging from SDN appliances and
    firewalls to various cloud services. This number is on a rising trend, as more
    people adopt a declarative approach to manage their infrastructure as code. This
    is why we believe it’s important for network automation engineers to know Terraform
    and be able to extend its capabilities using Go.
  prefs: []
  type: TYPE_NORMAL
- en: Overview of Terraform components
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The entire Terraform ecosystem is a collection of Go packages. They distribute
    the main CLI tool, often referred to as *Terraform Core*, as a statically compiled
    binary. This binary implements the command-line interface and can parse and evaluate
    instructions written in **Hashicorp Configuration Language** (**HCL**). On every
    invocation, it builds a resource graph and generates an execution plan to reach
    the desired state described in the configuration file. The main binary only includes
    a few plugins but can discover and download the required dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: 'Terraform plugins are also distributed as standalone binaries. Terraform Core
    starts and terminates the required plugins as child processes and interacts with
    them using an internal gRPC-based protocol. Terraform defines two types of plugins:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Providers**: Interact with a remote infrastructure provider and implement
    the required changes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Provisioners**: Implement a set of imperative actions, declared as a set
    of terminal commands, to bootstrap a resource that a provider created before'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram demonstrates what we have described and shows how different
    Terraform components communicate internally and externally:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.3 – Terraform high-level diagram](img/B16971_07_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.3 – Terraform high-level diagram
  prefs: []
  type: TYPE_NORMAL
- en: 'The vast majority of Terraform plugins are providers as they implement the
    declarative resource actuation and communicate with an upstream API. A provider
    defines two types of objects that you can use to interact with a remote API:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Resources**: Represent the actual managed infrastructure objects, such as
    virtual machines, firewall policies, and DNS records'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data Sources**: Offer a way to query information that is not managed by Terraform,
    such as a list of supported cloud regions, VM images, or **Identity and Access
    Management** (**IAM**) roles'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s up to the Terraform provider maintainers to decide what resources and data
    sources to implement, so the coverage may vary, especially between official and
    community-supported providers.
  prefs: []
  type: TYPE_NORMAL
- en: Working with Terraform
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A typical Terraform workflow involves several stages that need to happen in
    sequence. We first need to define a provider that determines what infrastructure
    we would manage, and then describe the state of our infrastructure using a combination
    of resources and data sources. We will walk through these stages by following
    a configuration file, `ch07/terraform/main.tf`, we’ve created in this book’s GitHub
    repository (see *Further reading*).
  prefs: []
  type: TYPE_NORMAL
- en: Defining a provider
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Providers define connection details for the upstream API. They can point at
    the public AWS API URL or an address of a private vCenter instance. In the next
    example, we show how to manage the demo instance of Nautobot running at [https://demo.nautobot.com/](https://demo.nautobot.com/).
  prefs: []
  type: TYPE_NORMAL
- en: 'Terraform expects to find a list of required providers, along with their definition,
    in one file in the current working directory. For the sake of simplicity, we include
    those details at the top of the `main.tf` file and define credentials in the same
    file. In production environments, these details may live in a separate file, and
    you should source credentials externally, for example, from environment variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'With this information defined, we can initialize Terraform. The following command
    instructs Terraform to perform plugin discovery and download any dependencies
    into a local `./``terraform` directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: At the end of this step, Terraform creates a lock file, `.terraform.lock.hcl`,
    to record the provider selections it just made. Include this file in your version
    control repository so that Terraform can guarantee to make the same selections
    by default when you run `terraform init` on a different machine.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a resource
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To create a resource, we define it in a configuration block with zero or more
    arguments that assign values to resource fields. The following resource creates
    a new `Manufacturer` object in Nautobot with the specified name and description:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can run `terraform plan` to check whether the current configuration
    matches the existing state. If they don’t match, Terraform creates an execution
    plan with the proposed changes to make the remote objects match the current configuration.
    We could skip the `terraform plan` command and move straight to `terraform apply`,
    which generates the plan and also executes it in a single step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see the result of running this plan in Nautobot’s web UI at [https://demo.nautobot.com/dcim/manufacturers/new-vendor/](https://demo.nautobot.com/dcim/manufacturers/new-vendor/),
    or you can check the resulting state using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: At the time of writing, there was no Terraform provider available for Nautobot,
    so the last example used a custom provider we created specifically for this book.
    Creating a new provider can enable many new use cases and it involves writing
    Go code, so this is what we cover next.
  prefs: []
  type: TYPE_NORMAL
- en: Developing a Terraform provider
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Eventually, you may come across a provider with limited or missing capabilities,
    or a provider may not even exist for a platform that is part of your infrastructure.
    This is when knowing how to build a provider can make a difference, to either
    extend or fix a provider or build a brand new one. The only prerequisite to get
    started is the availability of a Go SDK for the target platform. For example,
    Nautobot has a Go client package that gets automatically generated from its OpenAPI
    model, which we used already in the *Getting config inputs from other systems
    via HTTP* section of [*Chapter 6*](B16971_06.xhtml#_idTextAnchor144), *Configuration
    Management*, so we have all we need to develop its Terraform provider.
  prefs: []
  type: TYPE_NORMAL
- en: The recommended way to create a new Terraform provider is to start with the
    terraform-provider-scaffolding project (see *Further reading*). This repository
    provides enough boilerplate to allow you to focus on the internal logic while
    it provides function stubs and implements **Remote Procedure Call** (**RPC**)
    integration. We used this template to create the Nautobot provider, so you can
    compare our final result with the template to see what changes we made.
  prefs: []
  type: TYPE_NORMAL
- en: As a by-product of developing a Terraform provider using the scaffolding project,
    you can register your Git repository in the Terraform registry and get the benefit
    of automatically rendered provider documentation (see *Further reading*).
  prefs: []
  type: TYPE_NORMAL
- en: Defining a provider
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The provider’s internal code (`internal/provider/provider.go` (see *Further
    reading*)) starts with a schema definition for the provider itself as well as
    its managed resources and data sources. Inside the provider’s schema, we define
    two input arguments—`url` and `token`. You can extend each schema struct with
    more constraints, default values, and validation functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'With login information defined, the provider can initialize an API client for
    the target platform. This happens inside a local function where `url` and `token`
    get passed to the Nautobot’s Go SDK, which creates a fully authenticated HTTP
    client. We save this client in a special `apiClient` struct, which gets passed
    as an argument to all provider resources, as we show later on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have prepared a remote API client, we can start writing code for
    our managed resources.
  prefs: []
  type: TYPE_NORMAL
- en: Defining resources
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Just like how we defined a schema for our provider, we now need to define a
    schema for each managed resource and data source. For educational purposes, we
    only implement a single resource type, `Manufacturer`, and a corresponding data
    source you can use to retrieve the list of all existing manufacturers in Nautobot.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we define a schema, our goal is to match the upstream API as closely as
    possible. This should reduce the number of required data transformations and make
    the implementation work much easier. Let’s look at Nautobot’s Go SDK code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The schema that we define for the `Manufacturer` resource in `resource_manufacturer.go`
    closely follows the fields and types defined in the preceding output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Once we have defined all schemas with their constraints, types, and descriptions,
    we can start implementing resource operations. The scaffolding project provides
    stubs for each one of the CRUD functions, so we only need to fill them out with
    code.
  prefs: []
  type: TYPE_NORMAL
- en: The create operation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We first look at the `resourceManufacturerCreate` function, which gets invoked
    when Terraform determines that it must create a new object. This function has
    two very important arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '`meta`: Stores the API client we created earlier'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`d`: Stores all resource arguments defined in the HCL configuration file'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We extract the user-defined configuration from `d` and use it to build a new
    `nb.Manufacturer` object from the Nautobot’s SDK. We can then use the API client
    to send that object to Nautobot and save the returned object ID:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Typically, we don’t define all optional fields when we create a new object.
    A remote provider assigns the unique ID and initializes default values as it creates
    a new object. Some platforms return the newly created object back, but there is
    no guarantee of that. Hence, it’s a common pattern in Terraform provider implementations
    to call a read function at the end of the create function to synchronize and update
    a local state.
  prefs: []
  type: TYPE_NORMAL
- en: The read operation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The read function updates the local state to reflect the latest state of an
    upstream resource. We’ve seen in the preceding example how the create function
    calls the read at the end of its execution to update the state of a newly created
    object.
  prefs: []
  type: TYPE_NORMAL
- en: But the most important use of read is to detect configuration drift. When you
    do `terraform plan` or `terraform apply`, read is the first thing that Terraform
    executes and its goal is to retrieve the current upstream state and compare it
    with the state file. This allows Terraform to understand whether users have manually
    changed a remote object, so it needs to reconcile its state, or whether it’s up
    to date and no updates are necessary.
  prefs: []
  type: TYPE_NORMAL
- en: 'Read has the same signature as the rest of the CRUD functions, which means
    it gets the latest version of a managed resource as `*schema.ResourceData` and
    an API client stored in `meta`. The first thing we need to do in this function
    is fetch the upstream object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We use the data we get back to update the local Terraform state:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: At this stage, our local state should be in sync with the upstream and Terraform
    can decide whether any changes are necessary as a result.
  prefs: []
  type: TYPE_NORMAL
- en: Remaining implementations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this chapter, we only cover a subset of the Nautobot provider code. The
    remaining sections we need to implement include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The resource **update** and **delete** functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data** **source** implementation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the sake of brevity, we don’t include this code in the book, but the full
    implementation for the `Manufacturer` resource and data source is available in
    our demo Nautobot provider repository (see *Further reading*).
  prefs: []
  type: TYPE_NORMAL
- en: Networking providers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Writing a provider and keeping it up to date is a major undertaking. At the
    beginning of this section, we mentioned that Terraform has several providers in
    the networking category of the Terraform registry (see *Further reading*). We
    invite you to explore them and always check whether there’s an existing provider
    before implementing your own.
  prefs: []
  type: TYPE_NORMAL
- en: 'Terraform’s guarantees of declarative configuration and state management are
    very appealing to network engineers trying to adopt DevOps and GitOps practices.
    As the interest grows, so does the number of new network-related providers, with
    the following notable recent additions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**JUNOS Terraform Automation Framework** (see *Further reading*): Allows you
    to create a custom JunOS Terraform provider from YANG files'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Terraform Provider for Cisco IOS XE** (see *Further reading*): Manages the
    configuration of Cisco Catalyst IOS XE devices including switches, routers, and
    wireless LAN controllers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**terraform-provider-junos** (see *Further reading*): An unofficial Terraform
    provider for Junos OS devices with the NETCONF protocol'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**terraform-provider-ciscoasa** (see *Further reading*): DevNet provider to
    configure Cisco ASA firewall rules'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This completes the overview of Terraform and its network-related use cases.
    We hope that its adoption continues to increase and the number of networking providers
    grows. In the next section, we wrap up with a brief overview of a few other automation
    frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: Other automation frameworks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our industry has many more automation frameworks and solutions that we would
    have liked to cover in this chapter. The best we can do is just scratch the surface,
    leaving much of the exploration up to you. At the same time, we don’t want to
    leave you thinking there’s nothing out there besides Ansible and Terraform. This
    section gives you an overview of other automation frameworks and solutions that
    you can use or adapt to use within a networking context.
  prefs: []
  type: TYPE_NORMAL
- en: Gornir
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Nornir (see *Further reading*) is a popular network automation framework for
    Python that offers a pure programming experience by ditching DSL in favor of the
    Python API. It has a pluggable architecture where you can replace or extend almost
    any element of the framework, from inventory to device connections. It also has
    a flexible way to parallelize groups of tasks without having to deal with Python’s
    concurrency primitives directly.
  prefs: []
  type: TYPE_NORMAL
- en: Gornir (see *Further reading*) is a Nornir implementation in Go. Keeping with
    the same principles, it offers things such as inventory management, concurrent
    execution of tasks, and pluggable connection drivers. Gornir ships with a minimal
    set of drivers, but its core provides Go interfaces to improve upon and extend
    this feature. If you’re coming to Go from Python and are familiar with Nornir,
    Gornir may offer a very smooth transition through a familiar API and workflows.
  prefs: []
  type: TYPE_NORMAL
- en: Consul-Terraform-Sync
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the preceding section, we examined how you can use Terraform to manage resources
    declaratively on a remote target, using Nautobot as an example. Hashicorp, the
    same company behind Terraform, has developed another automation solution that
    builds on top of it. It’s called Consul-Terraform-Sync (see *Further reading*)
    and it enables automatic infrastructure management by combining Terraform with
    Consul and linking them together with a synchronization agent.
  prefs: []
  type: TYPE_NORMAL
- en: Consul is a distributed key/value store used for service discovery, load balancing,
    and access control. It works by setting up a cluster of nodes that use the Raft
    consensus protocol to have a consistent view of their internal state. Server nodes
    communicate with their clients and broadcast relevant updates to make sure clients
    have an up-to-date version of the relevant part of the internal state. All this
    happens behind the scenes, with minimal configuration, which makes Consul a very
    popular choice for service discovery and data storage.
  prefs: []
  type: TYPE_NORMAL
- en: The main idea of the Consul-Terraform-Sync solution is to use Consul as a backend
    for Terraform configuration and state. The synchronization agent connects to Consul,
    waits for updates, and automatically triggers Terraform reconciliation as it detects
    any changes.
  prefs: []
  type: TYPE_NORMAL
- en: Consul-Terraform-Sync allows you to automate Terraform deployments for any of
    these providers and ensures that your state always matches your intent thanks
    to the automated reconciliation process.
  prefs: []
  type: TYPE_NORMAL
- en: mgmt
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`mgmt` (see *Further reading*) is another infrastructure automation and management
    framework written completely in Go. It has its own DSL and synchronizes its state
    using a baked-in etcd cluster. It uses a few interesting ideas, such as a declarative
    and functional DSL, resource graphs, and dynamic state transitions triggered by
    closed-loop feedback. Just like Gornir, `mgmt` ships with a set of plugins that
    users can extend, but none of these plugins is specifically for network devices
    since the main use case for mgmt is Linux server management.'
  prefs: []
  type: TYPE_NORMAL
- en: Looking into the future
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we have covered popular network automation frameworks in use
    today. All these frameworks are at a different stage of development—some have
    already reached their peak while others are still crossing the chasm (see *Further
    reading*). But it’s important to remember that automation frameworks are not a
    solved problem with well-established projects and well-understood workflows. This
    field is constantly developing, and new automation approaches are emerging on
    the horizon.
  prefs: []
  type: TYPE_NORMAL
- en: 'These alternative approaches do not resemble what we had seen before. One big
    trend that we’re seeing lately is the departure from an imperative automation
    paradigm, where a human operator manually triggers actions and tasks. We briefly
    discussed this trend in [*Chapter 5*](B16971_05.xhtml#_idTextAnchor128), *Network
    Automation*, and we want to revisit it here to show how the *closed-loop* automation
    approach changes the landscape of infrastructure management systems. Most modern
    automation frameworks develop into systems that exhibit some or all the following
    characteristics:'
  prefs: []
  type: TYPE_NORMAL
- en: Focus on the complete life cycle management of a system as opposed to individual
    stages, such as bootstrapping, provisioning, or decommissioning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exclusive use of declarative state definition and automatic reconciliation,
    or self-healing implemented internally.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Separation of state definitions from the platform managing this state through
    practices such as GitOps.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Offer a cloud-native self-service experience via APIs, reducing the friction
    in consuming of these services both manually and programmatically.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’re currently at a point when these systems and their building blocks are
    becoming a reality, with some notable examples including Crossplane, Nokia Edge
    Network Controller, and Anthos Config Sync. They build these systems as Kubernetes
    controllers, leveraging the Operator model, allowing them to expose their APIs
    in a standard way, so other systems can talk to them with the same set of tools.
    We still don’t know whether these systems could become mainstream and displace
    the incumbent frameworks, since they increase the level of complexity and they
    introduce a steep learning curve. Regardless of that, it’s an area to explore,
    like other potential new trends that might develop, since infrastructure management
    is far from being a solved problem.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Whether to choose Ansible, Terraform, or a programming language to solve a particular
    use case depends on many variables. But don’t fall into the trap of looking at
    this as a binary decision. Most times, different technologies complement each
    other to offer solutions, as we showed in this chapter. In the next chapter, we
    will explore newer and more advanced techniques to interact with networking devices
    and Go.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This book’s GitHub repository: https://github.com/PacktPublishing/Network-Automation-with-Go'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Playbook: https://github.com/PacktPublishing/Network-Automation-with-Go/blob/main/ch07/ansible/playbook.yml'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Terraform registry: [https://registry.terraform.io/browse/providers?category=networking](https://registry.terraform.io/browse/providers?category=networking
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'terraform-provider-scaffolding project: [https://github.com/hashicorp/terraform-provider-scaffolding](https://github.com/hashicorp/terraform-provider-scaffolding
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Provider documentation: [https://registry.terraform.io/providers/nleiva/nautobot/latest/docs?pollNotifications=true](https://registry.terraform.io/providers/nleiva/nautobot/latest/docs?pollNotifications=true
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Provider’s internal code: [https://github.com/nleiva/terraform-provider-nautobot/blob/main/internal/provider/provider.go](https://github.com/nleiva/terraform-provider-nautobot/blob/main/internal/provider/provider.go
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`resource_manufacturer.go`: [https://github.com/nleiva/terraform-provider-nautobot/blob/main/internal/provider/resource_manufacturer.go](https://github.com/nleiva/terraform-provider-nautobot/blob/main/internal/provider/resource_manufacturer.go
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nautobot provider repository: [https://github.com/nleiva/terraform-provider-nautobot](https://github.com/nleiva/terraform-provider-nautobot
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'JUNOS Terraform Automation Framework: [https://github.com/Juniper/junos-terraform](https://github.com/Juniper/junos-terraform
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Terraform Provider for Cisco IOS XE: [https://github.com/CiscoDevNet/terraform-provider-iosxe](https://github.com/CiscoDevNet/terraform-provider-iosxe
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'terraform-provider-junos: [https://github.com/jeremmfr/terraform-provider-junos](https://github.com/jeremmfr/terraform-provider-junos
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'terraform-provider-ciscoasa: https://github.com/CiscoDevNet/terraform-provider-ciscoasa'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nornir: [https://github.com/nornir-automation/nornir/](https://github.com/nornir-automation/nornir/
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gornir: [https://github.com/nornir-automation/gornir](https://github.com/nornir-automation/gornir
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Consul-Terraform-Sync: [https://learn.hashicorp.com/tutorials/consul/consul-terraform-sync-intro?in=consul/network-infrastructure-automation](https://learn.hashicorp.com/tutorials/consul/consul-terraform-sync-intro?in=consul/network-infrastructure-automation
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mgmt`: [https://github.com/purpleidea/mgmt](https://github.com/purpleidea/mgmt)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://en.wikipedia.org/wiki/Diffusion_of_innovations](https://en.wikipedia.org/wiki/Diffusion_of_innovations)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Part 3: Interacting with APIs'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As the way that networks are built, deployed, and operated has evolved, new
    protocols and interfaces have emerged to facilitate machine-to-machine communication
    as an enabler of network automation. In these chapters, we will navigate through
    some of these new capabilities and how to take advantage of them with Go.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part of the book comprises the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B16971_08.xhtml#_idTextAnchor182), *Network APIs*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B16971_09.xhtml#_idTextAnchor209), *OpenConfig*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 10*](B16971_10.xhtml#_idTextAnchor225), *Network Monitoring*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 11*](B16971_11.xhtml#_idTextAnchor247), *Expert Insights*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 12*](B16971_12.xhtml#_idTextAnchor279), *Appendix: Building a Testing
    Environment*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
