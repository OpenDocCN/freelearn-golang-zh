- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Telemetry
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explore the practical world of **telemetry**, where the
    elegance of Go’s programming model meets the crucial need for application observability.
    We are equipping you with the tools of logging, tracing, and metrics to shed light
    on the inner workings of your Go applications, empowering you to ensure they run
    efficiently and reliably.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter is your guide to enhancing the art and science of application telemetry.
    From the comprehensive practice of structured logging, which brings order and
    clarity to application logs, to the detailed insights offered by tracing and the
    thorough analysis enabled by metrics, this chapter covers it all.
  prefs: []
  type: TYPE_NORMAL
- en: 'The chapter will cover the following key topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Traces
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **OpenTelemetry** (**OTel**) project
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will have acquired the skills to observe, understand,
    and actively improve the performance and reliability of your apps, fostering a
    sense of engagement and motivation in your work.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Make sure you have Docker installed on your machine. You can download it from
    the official Docker website ([https://www.docker.com/get-started](https://www.docker.com/get-started)).
  prefs: []
  type: TYPE_NORMAL
- en: All the code shown in this chapter can be found in the `ch11` directory of our
    Git repository.
  prefs: []
  type: TYPE_NORMAL
- en: Logs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Logging, the unsung hero of system programming, is often as overlooked as the
    “terms and conditions” checkbox on software updates. Most developers treat logging
    the same way teenagers treat a clean room: a nice idea in theory but somehow never
    a priority until things start to smell funny. The common misconception here? That
    logging is just an afterthought, a mere diary for your code to occasionally scribble
    in. Spoiler alert: it’s not!'
  prefs: []
  type: TYPE_NORMAL
- en: Imagine, if you will, a software development version of an archeological dig.
    Each log entry is a carefully unearthed artifact, offering clues to the civilization
    (code base) that once thrived. Now, picture some developers at this dig, using
    a bulldozer (poor logging practices) to uncover these delicate treasures. The
    result? A lot of broken pottery and bewildered faces. This, my friends, is what
    happens when logging into Go is not given the respect and precision it demands.
  prefs: []
  type: TYPE_NORMAL
- en: Logging in Go, especially in the context of system programming, is an essential
    tool for understanding the behavior of applications. It provides visibility into
    the system, enabling developers to track down bugs, monitor performance, and understand
    traffic patterns. Go, being the pragmatic language it is, offers built-in support
    for logging via the standard library’s log package, but the plot thickens when
    system-level programming comes into play.
  prefs: []
  type: TYPE_NORMAL
- en: For system programming, where performance and resource optimization are paramount,
    the standard `log` package might not always cut it. This is where structured logging
    comes into the spotlight. Structured logging, as opposed to plain text logging,
    organizes log entries into a structured format, typically JSON. This format makes
    logs easier to query, analyze, and understand, especially when you’re sifting
    through mountains of data trying to find the proverbial needle in a haystack.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s not just talk the talk; let’s walk the walk with a code snippet illustrating
    structured logging in Go:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This code utilizes the experimental `slog` package introduced in Go 1.21\. It
    resides within the `log` sub-package (`log/slog`). It offers the convenience of
    no external dependencies being required, simplifying project management.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s explore the snippet’s key points:'
  prefs: []
  type: TYPE_NORMAL
- en: '`handler := slog.NewJSONHandler(os.Stdout)`: This line creates a `slog.Handler`
    responsible for formatting and potentially routing log entries. Here, `slog.NewJSONHandler`
    generates a JSON formatter and `os.Stdout` specifies the standard output as the
    destination.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logger := slog.New(handler)`: This line creates a `slog.Logger` instance.
    The newly created JSON handler is used to configure the logger’s output format
    and destination.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logger.Info("A group of walrus emerges from the ocean", slog.Attr("animal",
    "walrus"), slog.Attr("size", 10))`: This logs an informational message using the
    `Info` method'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`slog.Attr("animal", "walrus"), slog.Attr("size", 10)`: These leverage `slog.Attr`
    to create key-value pairs (attributes) that enhance the log message with structured
    data. This makes logs easier to parse and analyze by tools or downstream applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logging in Go is not just about keeping a record; it’s about making sense of
    your application’s story, one log entry at a time. Remember – like any good story,
    the devil is in the details (or in this case, the data).
  prefs: []
  type: TYPE_NORMAL
- en: Logging, in the realm of software development, serves as the cornerstone for
    understanding, diagnosing, and tracking the behavior of applications. It is akin
    to the breadcrumb trail left by Hansel and Gretel in the famous fairy tale, offering
    guidance back through the complex woods of your code base to understand what happened,
    when, and why.
  prefs: []
  type: TYPE_NORMAL
- en: At its core, logging involves recording events and data during the execution
    of a program. These events could range from general information about the application’s
    operation to errors and system-specific messages that provide insight into its
    health and performance. The significance of logging can be likened to the role
    of a flight recorder or “black box” in aviation; it captures crucial information
    that can be analyzed post-factum to understand events leading up to an incident
    or to optimize future performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Effective logging practices empower developers through the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Debugging and troubleshooting**: Logs are one of the main places to look
    when something goes wrong. They can help pinpoint where an error occurred and
    under what circumstances, reducing the time it takes to resolve issues.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security auditing**: Logging access and transaction data can help detect
    unauthorized access attempts, data breaches, and other security threats, facilitating
    swift action.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Compliance and record keeping**: In many industries, keeping detailed logs
    is a regulatory requirement for compliance purposes, serving as proof of proper
    data handling and other practices.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Understanding user behavior**: Logging can provide insights into how users
    interact with your application, which features are most popular, and where users
    may encounter difficulties.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Despite its critical role, logging is not without challenges. It requires a
    careful balance to ensure that the right amount of information is captured – too
    little and you may miss important clues; too much, and you’re sifting through
    a haystack looking for needles. The art and science of logging lie in determining
    what to log, how to log it, and how to make sense of the data collected, all while
    minimizing performance impacts on the application.
  prefs: []
  type: TYPE_NORMAL
- en: When we look for performance today, uber/zap is one of the fastest logging libraries
    out there. Let’s explore the main differences between using slog versus zap.
  prefs: []
  type: TYPE_NORMAL
- en: Zap versus slog
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When deciding between slog and zap, consider your application’s specific needs.
  prefs: []
  type: TYPE_NORMAL
- en: For applications where performance is paramount, and you need fine-grained control
    over logging, zap offers proven speed and configurability.
  prefs: []
  type: TYPE_NORMAL
- en: If you’re looking for a modern, efficient logging solution that integrates well
    with Go’s context package and emphasizes simplicity and flexibility, slog may
    be the right choice.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the zap version of the same example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This example is intentionally more exaggerated to depict how configurable the
    zap library is. Let me explain what is going on here, step by step:'
  prefs: []
  type: TYPE_NORMAL
- en: '`go.uber.org/zap` for core zap functionality and `go.uber.org/zap/zapcore`
    for low-level configuration.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`encoderConfig` configuration for JSON output with human-readable keys.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`consoleEncoder`) and an output destination (`consoleSink`) that writes to
    the standard output.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`zapcore.NewCore` function constructs the core of our logger, which combines
    the encoder, the sink, and the configured log level (`zap.InfoLevel`).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`zap.New`, we build a zap logger based on `core`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Infow` for logging. It makes it easier to add structured data to log messages
    (and runs slower than the non-sugared version).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: However, both slog and zap enhance Go’s logging capabilities, extending beyond
    the standard library to offer structured, efficient, and flexible logging solutions.
    The choice between them depends on your application’s specific requirements, including
    performance considerations, the need for structured logging, and the level of
    customization required.
  prefs: []
  type: TYPE_NORMAL
- en: Logging for debugging or monitoring?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Debugging logs are primarily used during the development phase or when diagnosing
    issues in a system. Their main aim is to provide developers with detailed, contextual
    information about the application’s behavior at a specific moment in time, particularly
    when errors or unexpected behaviors occur.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the characteristics of debugging logs:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Granularity**: Debugging logs are often highly detailed, including verbose
    information about the state of the application, variable values, execution paths,
    and error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Temporary**: These logs may be generated in a development environment or
    temporarily enabled in production to track down specific issues. They are not
    typically kept running permanently in a living environment due to their verbose
    nature.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Developer focused**: The audience for debugging logs is usually the developers
    who are familiar with the application’s code base. The information is technical
    and requires a deep understanding of the application’s internals.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The most common examples of these logs are stack traces and key variables at
    certain checkpoints.
  prefs: []
  type: TYPE_NORMAL
- en: When we’re logging for monitoring, logs are designed for the ongoing observation
    of an application in production. They help in understanding the application’s
    health and usage patterns over time, facilitating proactive maintenance and optimization.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the characteristics of monitoring logs:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Aggregation friendly**: Monitoring logs are structured to be easily aggregated
    and analyzed by monitoring tools. They often follow a consistent format, making
    it simpler to extract metrics and trends.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Persistent**: These logs are continuously generated and collected as part
    of the application’s normal operation in production environments. They are less
    detailed than debugging logs to balance informativeness with performance overhead.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Operational insight**: The focus is on information relevant to the operation
    of the application, user activity, and error rates. The audience includes not
    only developers but also system administrators and operations teams.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For instance, we can see this kind of logging strategy on HTTP request logs
    including method, URL, and status code.
  prefs: []
  type: TYPE_NORMAL
- en: The main difference between these two methods is the objective, detail level,
    audience, and life span.
  prefs: []
  type: TYPE_NORMAL
- en: In essence, logging for debugging and monitoring serve complementary but distinct
    roles in the life cycle of an application. Effective logging strategies recognize
    these differences, implementing tailored approaches to meet the unique needs of
    debugging and monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to logging, the format you choose can significantly impact the
    readability, processing speed, and overall usefulness of your log data. Two popular
    formats are JSON logs and structured text logs. Choosing between them requires
    understanding their differences, advantages, and the specific needs of your application
    or environment. Let’s outline a framework to help us to make an informed decision.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we should consider the log consumption tools:'
  prefs: []
  type: TYPE_NORMAL
- en: '**JSON logs**: If you’re using modern log management systems or tools designed
    to ingest and query JSON data (such as **Elasticsearch, Logstash, Kibana** (**ELK**),
    or Splunk), JSON logs can be highly advantageous. These tools can natively parse
    JSON, allowing for more efficient querying, filtering, and analysis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Structured text logs**: If your log consumption mainly involves reading logs
    directly for debugging purposes or using tools that don’t natively parse JSON,
    structured text logs might be preferable. Structured text logs can be easier to
    read for humans, especially when tailing logs in a console.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Also, we evaluate log data complexity:'
  prefs: []
  type: TYPE_NORMAL
- en: '**JSON logs**: JSON is well suited for logging complex and nested data structures.
    If your application logs contain a wide variety of data types or structured data
    that benefits from hierarchical organization, JSON logs can encapsulate this complexity
    more effectively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Structured text logs**: For simpler logging requirements where logs are primarily
    flat messages with a few key-value pairs, structured text logs can be sufficient
    and more straightforward to work with.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After this evaluation, we can assess performance and overhead:'
  prefs: []
  type: TYPE_NORMAL
- en: '**JSON logs**: Writing logs in JSON format can introduce additional computational
    overhead due to serialization costs. For high-throughput applications where performance
    is critical, assess whether your system can handle this overhead without significant
    impact.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Structured text logs**: Generally, generating structured text logs is less
    CPU-intensive than JSON serialization. If performance is a paramount concern and
    your log data is relatively simple, structured text logging may be the more efficient
    choice.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we can create a plan for log analysis and troubleshooting.
  prefs: []
  type: TYPE_NORMAL
- en: '**JSON logs**: For scenarios where logs are extensively analyzed to gain insights
    into application behavior, and user actions, or for troubleshooting complex issues,
    JSON logs provide a more structured and “queryable” format. They facilitate deeper
    analysis and can be automatically processed by many tools.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Structured text logs**: If your log analysis needs are straightforward or
    you primarily use logs for real-time troubleshooting without complex querying,
    structured text logs might suffice.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lastly, we can assess the development and maintenance context:'
  prefs: []
  type: TYPE_NORMAL
- en: '**JSON logs**: Consider whether your development team is comfortable with JSON
    format and parsing, as well as whether your logging framework and infrastructure
    support JSON logging effectively'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Structured text logs**: Structured text logs might be preferred for teams
    looking for simplicity and ease of use, especially if they are not using advanced
    log processing tools'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The general guideline is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Log consumption tools**: Choose JSON for advanced processing tools; choose
    structured text for simplicity or direct consumption.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data complexity**: Use JSON for complex, nested data; structured text for
    simpler data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance considerations**: Opt for structured text when performance is
    critical; use JSON with performance impact in mind.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Analysis and troubleshooting**: Select JSON for in-depth analysis needs;
    structured text for basic troubleshooting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Team and infrastructure**: Consider team familiarity and infrastructure capabilities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ultimately, the choice between JSON and structured text logs depends on balancing
    the specific needs of your application, the capabilities of your log processing
    infrastructure, and your team’s preferences and skills. It’s not uncommon for
    systems to employ both types in different contexts or layers of the application
    to optimize for both human readability and machine processing.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding what to log and what not to log is crucial for maintaining efficient,
    secure, and useful logging practices.
  prefs: []
  type: TYPE_NORMAL
- en: What to log?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Proper logging can help you debug issues, monitor system performance, and understand
    user behavior. However, excessive, or inappropriate, logging can lead to performance
    degradation, storage issues, and security vulnerabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a guide to help navigate these decisions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Errors**: Capture any errors that occur. Include stack traces to facilitate
    debugging.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**System state changes**: Log significant state changes within your application,
    such as system startup or shutdown, configuration changes, and status changes
    of critical components.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User actions**: Log key user actions, especially those that modify data or
    trigger significant processes in your application. This helps in understanding
    user behavior and diagnosing issues.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**When you don’t have a metrics server** **in place**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance metrics**: Log performance-related metrics such as response times,
    throughput, and resource utilization. This information is crucial for monitoring
    the health and performance of your system.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security events**: Log security-related events, such as login attempts, access
    control violations, and other suspicious activities. These logs are vital for
    security monitoring and incident response.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**API calls**: When your application interacts with external services through
    APIs, logging these calls can be helpful for tracking dependencies and troubleshooting
    issues.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**When you don’t have an audit system to send the** **system events**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Critical business transactions**: Log important business transactions to
    provide an audit trail that can be used for compliance, reporting, and business
    intelligence purposes.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: What not to log?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There is a series of information that’s not suitable for logging, such as the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sensitive information**: Avoid logging sensitive information such as passwords,
    **personal identification information** (**PII**), credit card numbers, and security
    tokens. Exposure to such information can lead to security breaches and compliance
    violations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Verbose or debug information in production**: While verbose or debug-level
    logs can be incredibly useful during development, they can overwhelm production
    systems. Use appropriate log levels and consider dynamic log level adjustment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Redundant or irrelevant information**: Logging the same information multiple
    times or capturing irrelevant details can clutter your logs and consume unnecessary
    storage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Large binary data**: Avoid logging large binary objects, such as files or
    images. These can significantly increase the size of your log files and degrade
    performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User input without sanitization**: Logging raw user input can introduce security
    risks, such as injection attacks. Always sanitize input before logging it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The best practices can be summarized here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Use structured logging**: Structured logs make it easier to search and analyze
    data. Use a consistent format such as JSON across your logs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Implement log rotation and retention policies**: Automatically rotate logs
    and define retention policies to manage disk space and comply with data retention
    requirements'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Secure log data**: Ensure that logs are stored securely, access is controlled,
    and transmission of log data is encrypted'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitor log files for anomalies**: Regularly review log files for unusual
    activity or errors that could indicate operational or security issues'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By following these guidelines, you can ensure that your logging practices contribute
    positively to the maintenance, performance, and security of your applications.
  prefs: []
  type: TYPE_NORMAL
- en: Remember, the goal is to capture enough information to be useful without compromising
    system performance or security.
  prefs: []
  type: TYPE_NORMAL
- en: Often, we need more information regarding the program execution and our series
    of records (logs) are not enough. This is where we rely on traces.
  prefs: []
  type: TYPE_NORMAL
- en: Traces
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So, you’ve heard that tracing in Golang is as straightforward as pie, have you?
    Let’s not kid ourselves; in the realm of system programming, tracing is more like
    baking a soufflé in a microwave – sure, you might end up with something edible,
    but it’s hardly going to win you any Michelin stars.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an analogy that might tickle your fancy: Imagine you’re a detective
    in a software development murder mystery. The victim? System performance. The
    suspects? A motley crew of goroutines, each more suspicious than the last. Your
    only hope of cracking the case lies in the intricate art of trace analysis. But
    beware, this is no child’s play. You’ll need all your wit, wisdom, and a hefty
    dose of sarcasm to navigate through the quagmire of stack traces and execution
    threads.'
  prefs: []
  type: TYPE_NORMAL
- en: Tracing in Golang, for those unacquainted with the finer points of system programming,
    is the Sherlock Holmes debugging tool. It allows developers to observe the behavior
    of their programs during execution, offering invaluable insights into performance
    bottlenecks and sneaky bugs that would otherwise remain as elusive as a well-behaved
    cat in a room full of rocking chairs.
  prefs: []
  type: TYPE_NORMAL
- en: At its core, Golang’s tracing framework leverages the `runtime/trace` package
    to let you peer into the running soul of your application. By collecting a wide
    range of events related to goroutines, heap allocation, garbage collection, and
    more, it sets the stage for a deep dive into the inner workings of your code.
  prefs: []
  type: TYPE_NORMAL
- en: The power of trace analysis comes alive with tools such as `go tool trace`,
    which parses trace files generated by your Go application and serves them up in
    a web interface that’s as revealing as it is mesmerizing. Here, you can visualize
    the execution of goroutines, track down latency issues, and get to the bottom
    of those performance mysteries that keep you up at night.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a practical look with a simple code example. Imagine you’ve wrapped
    your critical section with trace calls like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: When you run this program, it outputs a kind of ugly output, right?
  prefs: []
  type: TYPE_NORMAL
- en: This snippet kick-starts the tracing process, directing the output to stderr,
    where you can later analyze it to your heart’s content. Remember, this is just
    the tip of the iceberg.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s step back and learn how to add the trace in our programs and check the
    output properly.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, to start tracing, you need to import the `runtime/trace` package.
    This package provides the functionality to start and stop tracing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We need to call `trace.Start` at the point in your code where you want to begin
    tracing. Similarly, you should call `trace.Stop` when you want to end the tracing,
    usually after a specific operation you’re interested in measuring:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Run your Go program as usual. The program will execute and generate a trace
    file named `trace.out` (or whatever you named your file) in the current directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'After your program has run, you can analyze the trace file using `go tool trace`.
    This command will start a web server that hosts a web-based user interface for
    analyzing the trace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: When you run this command, it will print a URL to your console. Open this URL
    in your web browser to view the trace viewer. The viewer provides various views
    to analyze different aspects of your program’s execution, such as the goroutine
    analysis, heap analysis, and other aspects we explored in [*Chapter 9*](B21662_09.xhtml#_idTextAnchor193),
    *Analyzing Performance*.
  prefs: []
  type: TYPE_NORMAL
- en: 'For programs with HTTP servers, the approach is slightly different. Let’s add
    tracing capabilities to this simple program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: To trace the HTTP endpoint, we’ll need to wrap your handler with a function
    that starts and stops tracing around the handler’s execution. You can use the
    `runtime/trace` package for tracing and `net/http/httptrace` for more detailed
    HTTP tracing.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s modify our main package to include the `runtime/trace` package,
    as shown in the previous snippet. Then, create a trace wrapper for your HTTP handler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, wrap your HTTP handlers with `TraceHandler`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Follow the same steps as in the previous program to start and stop tracing,
    and then run your application. Make some requests to your server to ensure there’s
    activity to trace.
  prefs: []
  type: TYPE_NORMAL
- en: After stopping the trace and generating the trace file, use the `go tool trace`
    command to analyze the trace data. Pay special attention to the sections related
    to network I/O and HTTP requests to understand the performance of your endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: Effective tracing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Instead of tracing your entire program, focus on the parts where performance
    is critical. This approach reduces the size of the trace file and makes analysis
    easier.
  prefs: []
  type: TYPE_NORMAL
- en: Spend some time exploring the different views available in the trace viewer.
    Each view provides insights into specific aspects of your program’s execution.
    Also, when analyzing the trace, look for unusual patterns or anomalies, such as
    goroutines that are blocked for a long time or excessive garbage collection pauses.
  prefs: []
  type: TYPE_NORMAL
- en: Ensure that the context containing the trace is passed to any downstream calls
    made during the request handling. This allows for a more comprehensive trace that
    includes the entire request life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: When possible, use middleware for tracing. For more complex applications, consider
    implementing tracing as middleware in your HTTP server. This approach allows for
    more flexibility and reusability across different parts of your application.
  prefs: []
  type: TYPE_NORMAL
- en: Reflecting on my own trials and tribulations with Golang’s tracing, I recall
    a project that was as bogged down as a luxury sedan in a mud wrestling pit. After
    hours of poring over trace outputs, I stumbled upon a revelation that was as profound
    as discovering your car keys in the refrigerator. It dawned on me that tracing,
    much like a skilled sommelier, could discern the subtle nuances between a fine
    performance and a disastrous bottleneck. In the end, the solution was as simple
    as rearranging some database calls, yet it underscored the nuanced sophistication
    of Golang’s tracing capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Tracing is primarily used for performance analysis and debugging. It’s particularly
    useful for identifying concurrency issues, understanding system behavior under
    load, and pinpointing sources of latency in distributed systems. It offers a more
    granular view of program execution compared to logging. While logging records
    discrete events or states, tracing in Go can provide a continuous, detailed account
    of program execution, including system-level events.
  prefs: []
  type: TYPE_NORMAL
- en: Logging versus tracing
  prefs: []
  type: TYPE_NORMAL
- en: Also, there are performance considerations in both cases. Logging and tracing
    can impact the performance of a Go application, but the impact is generally more
    significant with tracing, especially when using execution tracing in a production
    environment. Developers need to balance the level of detail captured against the
    performance overhead.
  prefs: []
  type: TYPE_NORMAL
- en: To wrap it up, think of tracing in Golang like dissecting a complex piece of
    machinery. Without the right tools and knowledge, you’re just a monkey with a
    wrench. But arm yourself with Golang’s tracing package, and you transform into
    a master mechanic, tuning your application to purr like a kitten on a warm lap.
    Remember, the devil is in the details, and sometimes, those details are hidden
    deep within the traces of your code.
  prefs: []
  type: TYPE_NORMAL
- en: Distributed tracing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Distributed tracing involves monitoring the complete journey of a request as
    it travels across various interconnected services in a distributed system. Imagine
    a complex e-commerce application with separate services for product search, shopping
    cart, payment processing, and order fulfillment. A single user request might trigger
    interactions with all these services.
  prefs: []
  type: TYPE_NORMAL
- en: 'How does it work? You might ask yourself. There are four key concepts: unique
    identifier, propagation, spans, and collection and analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: A unique identifier (trace ID) is assigned to the initial request. This ID becomes
    the thread that ties together all subsequent logs and events related to that specific
    request.
  prefs: []
  type: TYPE_NORMAL
- en: The trace ID is then propagated across all services involved in handling the
    request. This can be done through headers in HTTP requests, messages in queues,
    or any mechanism suitable for the communication protocol between services.
  prefs: []
  type: TYPE_NORMAL
- en: Each service creates a “span” that captures information about its role in handling
    the request. This span might include details such as timestamps, service names,
    function calls, and any errors encountered.
  prefs: []
  type: TYPE_NORMAL
- en: The spans are collected by a central tracing system, which then stitches them
    together based on the trace ID. This provides a holistic view of the entire request
    flow, encompassing all the services involved.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main benefits of distributed tracing are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Enhanced observability**: Distributed tracing sheds light on how requests
    move through your system, revealing potential bottlenecks and inefficiencies'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Root cause analysis**: When errors occur, tracing helps pinpoint the exact
    service or component responsible, even if the error manifests itself much later
    in the request flow'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance optimization**: By analyzing trace data, you can identify slow
    services or communication issues between services, enabling performance optimization
    efforts'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Debugging microservices**: Debugging complex interactions between microservices
    becomes significantly easier with the context provided by distributed tracing'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Several open-source and commercial tools are available for implementing distributed
    tracing. Some popular options include Zipkin, Jaeger, Honeycomb, and Datadog.
  prefs: []
  type: TYPE_NORMAL
- en: But what about the freedom to switch between observability tools and backend
    providers without requiring large changes to your application’s code? Later in
    this chapter, we’ll see there is a gap the OTel project is trying to fill.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s continue to expand our knowledge with the next pillar of telemetry: metrics.'
  prefs: []
  type: TYPE_NORMAL
- en: Metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Nothing screams “I’ve made it as a programmer” quite like obsessing over performance
    data in a language that was designed to be as exciting as watching paint dry on
    a rainy day. But here we are, poised to dive into the thrilling world of Go metrics,
    armed with the enthusiasm of a sloth on tranquilizers. It’s a delightful journey
    through a labyrinth of numbers and charts, where the Minotaur you’re facing is
    your own code, mysteriously gobbling up resources in ways that make quantum physics
    seem straightforward by comparison.
  prefs: []
  type: TYPE_NORMAL
- en: Now, for those brave souls still with me and not deterred by the ominous shadows
    of impending doom, let’s get serious for a moment. Metrics in the context of Go
    are essential tools for understanding the behavior and performance of your applications.
    They provide insights into various aspects of your system, such as memory usage,
    CPU load, and goroutine counts. Go, with its minimalist charm and concurrency
    model, offers a plethora of opportunities for system programmers to shoot themselves
    in the foot, performance wise. Thankfully, it also provides band-aids in the form
    of built-in and third-party libraries designed to collect, report, and analyze
    these metrics. The Go runtime, for example, exposes a wealth of performance data
    through the `runtime` and `net/http/pprof` packages, allowing programmers to monitor
    their applications in real time.
  prefs: []
  type: TYPE_NORMAL
- en: One of the more popular third-party libraries is Prometheus, with its Go client
    library offering a rich set of tools to define and collect metrics. It integrates
    seamlessly into Go applications, providing a robust solution for monitoring not
    just system-level metrics but also application-specific metrics that can help
    in diagnosing performance bottlenecks and understanding user behavior.
  prefs: []
  type: TYPE_NORMAL
- en: 'To give you a taste, let’s consider a simple example using Prometheus to collect
    HTTP request count in a Go web service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This snippet uses the `prometheus/client_golang` library to interact with Prometheus.
    A counter metric `http_requests_processed` is used to track the number of HTTP
    requests, labeled by status code. The `/metrics` endpoint exposes metrics for
    Prometheus to scrape. Inside the HTTP handler, the counter metric is incremented
    with appropriate status code labels.
  prefs: []
  type: TYPE_NORMAL
- en: Simplicity
  prefs: []
  type: TYPE_NORMAL
- en: This is a basic example. Real-world applications would involve richer metrics
    and instrumentation.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s run our Prometheus server by following these steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a Prometheus configuration file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new file and name it `prometheus.yml`
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Paste the following basic configuration into the file:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: 'Pull the Prometheus Docker image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open your terminal and run the following command to download the latest Prometheus
    Docker image:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the Prometheus container:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use the following command to run Prometheus, mapping `prometheus.yml` to the
    container:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: Replace `<path_to_your_prometheus.yml>` with the actual path to your configuration
    file.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Access the Prometheus web interface:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open your web browser and go to `http://localhost:9090`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: You should now see the Prometheus user interface.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Explore Prometheus:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the expression browser (the `up` and click **Execute**. This should show
    you whether Prometheus itself is running.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Explore other built-in metrics, experiment with the query language, and get
    a feel for Prometheus.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, we can execute our code and see the metrics. First, we need to save the
    code and build it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Explore the metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '`http://localhost:8080/metrics`. You should see the raw Prometheus metrics
    output.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`http://localhost:9090`), try queries such as the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`http_requests_processed`: See the total number of requests, broken down by
    status codes'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`rate(http_requests_processed[1m])`: View the request rate over the last minute'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: We now can see our metrics, but what metrics can we use, and what metric should
    we use? Let’s explore this!
  prefs: []
  type: TYPE_NORMAL
- en: What metric should we use?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Choosing the right type of metric to monitor in your application is akin to
    selecting the appropriate tool for a job—use a hammer for nails, not for screws.
    In the world of monitoring and observability, the primary metric types—**Counter**,
    **Gauge**, **Histogram**, and **Summary**—each serve distinct purposes. Understanding
    these purposes is crucial to effectively measure and analyze your application’s
    behavior and performance.
  prefs: []
  type: TYPE_NORMAL
- en: Counters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A Counter is a simple metric that only goes up (increments) over time and resets
    to zero on restarts. It’s perfect for tracking occurrences of events. Use a Counter
    when you want to count things, such as requests served, tasks completed, or errors
    that occurred. For example, counting the number of times a user performs a specific
    action on your site.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some use cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Event counting**: Perfect for counting occurrences of specific events. For
    instance, you could use a counter to track the number of user signups, tasks completed,
    or errors encountered.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rate measurement**: Although the counter itself only goes up, you can measure
    the rate of increase over time, making it suitable for understanding how frequently
    an event is happening, such as requests per second.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gauges
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A Gauge is a metric that represents a single numerical value that can arbitrarily
    go up and down. It’s like a thermometer that measures the current temperature.
  prefs: []
  type: TYPE_NORMAL
- en: Use a Gauge for values that fluctuate over time, such as current memory usage,
    number of concurrent sessions, or the temperature of a machine. Gauges are great
    for monitoring resources where the current state at a specific point in time is
    more relevant than the rate of change.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some use cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Resource levels**: Gauges are well suited for measuring quantities that can
    increase and decrease, such as the current memory usage, disk space remaining,
    or the number of active users'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sensor readings**: Any real-time measurement that fluctuates over time, such
    as temperature sensors, CPU load, or queue lengths'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Histograms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A Histogram samples observations (typically things such as request durations
    or response sizes) and counts them in configurable buckets. It also provides a
    sum of all observed values.
  prefs: []
  type: TYPE_NORMAL
- en: Use a Histogram when you need to understand the distribution of a metric, not
    just its average. Histograms are ideal for tracking the latency of requests or
    the size of responses in your application because they allow you to see not just
    the average but also how the values are spread out, such as the 95th percentile
    latency.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some use cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Distribution measurement**: Histograms excel when you need to capture the
    distribution of metric values over time. This is crucial for understanding not
    just averages but the variability and outliers in your data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance analysis**: Ideal for measuring request latencies or response
    sizes. Histograms help identify long-tail delays that might not affect the average
    much but significantly impact user experience.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summaries
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Like Histograms, Summaries also sample observations. However, they calculate
    sliding window quantiles (e.g., the 50th, 90th, and 99th percentiles) instead
    of providing buckets. Summaries can be more computation intensive than Histograms
    because they compute these quantiles on the fly.
  prefs: []
  type: TYPE_NORMAL
- en: Use a Summary when you need precise quantiles over a sliding time window, especially
    for metrics where long-term accuracy is less critical than recent trends. They’re
    particularly useful for tracking request durations and response sizes when you
    need to know the exact distribution dynamically.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some use cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dynamic quantiles**: When you need accurate quantiles in a sliding time window,
    summaries are the best choice. They provide a more detailed view of metric distributions,
    adjusting as new data comes in.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recent trends analysis**: Suitable for scenarios where recent performance
    is more relevant than long-term averages, allowing you to respond to changes in
    patterns quickly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing the right metric
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The decision boils down to the nature of what you’re measuring and how you
    intend to use the data:'
  prefs: []
  type: TYPE_NORMAL
- en: Counting occurrences? Go with a Counter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Measuring values that increase and decrease? A Gauge is your friend
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Need to understand distributions? Histograms shine here
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Require dynamic quantiles over recent data? Summaries are the answer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remember, the goal is not just to collect metrics but to derive actionable insights
    from them. Therefore, choosing the right type of metric is crucial for effective
    monitoring and analysis. It ensures you’re not just collecting data for the sake
    of it but are gathering information that can genuinely inform decisions about
    your application’s performance and design.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more about metrics and how to query them, please look at the Prometheus
    documentation ([https://prometheus.io/docs/concepts/metric_types/](https://prometheus.io/docs/concepts/metric_types/)).
  prefs: []
  type: TYPE_NORMAL
- en: In conclusion, metrics in Golang is like embarking on a grand adventure in a
    submarine. You’re under the surface, in the deep dark sea of code, navigating
    through the murky waters of performance. Your metrics are your sonar, pinging
    against potential issues and guiding you through the abyss to the promised land
    of efficient, scalable software. Remember, in the vast ocean of system programming,
    it’s not the size of the ship that matters, but the power of your metrics that
    charts the course to success.
  prefs: []
  type: TYPE_NORMAL
- en: The OTel project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OTel is an open-source, vendor-neutral project under the **Cloud Native Computing
    Foundation** (**CNCF**). It provides a set of standards, APIs, and SDKs for instrumenting,
    generating, collecting, and exporting telemetry data.
  prefs: []
  type: TYPE_NORMAL
- en: This data includes traces (the flow of requests through systems), metrics (measurements
    about system behavior), and logs (structured event records). Also, it aims to
    standardize how applications are instrumented, making it easier to adopt observability
    tools without vendor lock-in.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we look from the maturity perspective, Golang is one of the primary supported
    languages within OTel. Basically, it provides a comprehensive SDK with libraries
    for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`go.opentelemetry.io/otel/trace`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`go.opentelemetry.io/otel/metric`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`go.opentelemetry.io/otel/propagation`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OTel’s Go SDK integrates seamlessly with popular libraries and frameworks, making
    adding instrumentation to your existing Golang applications easy.
  prefs: []
  type: TYPE_NORMAL
- en: Also, the SDK supports various exporters, enabling you to send your telemetry
    data to different analysis backends. An exhaustive list of vendors can be found
    on the OTel website ([https://opentelemetry.io/ecosystem/vendors/](https://opentelemetry.io/ecosystem/vendors/)).
  prefs: []
  type: TYPE_NORMAL
- en: 'The major benefits of adopting OTel for Go projects are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Vendor neutrality**: You have the freedom to switch between observability
    tools and backend providers without requiring large changes to your application’s
    code'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Streamlined instrumentation**: OTel makes instrumenting your Golang services
    easier and less tedious'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Unified data format**: It provides standardized data formats, ensuring your
    trace and metric data can be understood by multiple platforms and tools'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Strong community**: The Golang SDK is backed by an active community, offering
    support, and contributing to continuous improvement'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As OTel gains even wider adoption, it’s likely to become the de facto standard
    for observability in Golang applications. This standardization benefits the entire
    ecosystem by promoting vendor neutrality, portability, and easier adoption of
    best practices.
  prefs: []
  type: TYPE_NORMAL
- en: OTel
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So, you think adding OTel to your program is like snapping some fancy Lego bricks
    together, huh? A bit of configuration magic, a sprinkle of auto-instrumentation,
    and voila – instant observability! Well, let’s just say you’re in for a surprise,
    my friend.
  prefs: []
  type: TYPE_NORMAL
- en: Now, before you toss your keyboard in frustration, let’s break down what OTel
    is. Think of it as a universal toolbox for collecting telemetry data from your
    application. OTel, in turn, is like your application’s internal monologue – traces
    of its execution, performance metrics, logs, and other whispers of its inner workings.
    OTel lets you shine that light into the darkest corners of your code base, revealing
    where things slow down, where errors sprout, and how your users interact with
    your creation.
  prefs: []
  type: TYPE_NORMAL
- en: Logs are not ready yet
  prefs: []
  type: TYPE_NORMAL
- en: 'The Logs SDK for Go is in development and we can follow the status on the official
    status page for the SDK: [https://opentelemetry.io/status/](https://opentelemetry.io/status/).
    Therefore, the following examples will use the uber/zap library for logging.'
  prefs: []
  type: TYPE_NORMAL
- en: OTel itself is a set of specifications, APIs, and SDKs. It doesn’t magically
    make your app observable. You’ll need to strategically place sensors (think of
    them as fancy probes) throughout your code. This is where the “fun” of manual
    instrumentation comes in, along with deciding what data to collect in the first
    place.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create a program that uses Otel from scratch. The following are the steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Create your Go project**: Create a new directory for your project and initialize
    a Go module:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Install dependencies**: Install the necessary packages for OTel and zap logging:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`main.go` file in your project directory. First, let’s set up zap for advanced
    logging:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This code snippet initializes a production-grade logger with zap, which provides
    structured logging capabilities.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Configure OTel tracing**: Next, add OTel tracing to your application, sending
    data to the OTel Collector:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This section adds tracing, configured to export trace data via the **OTel**
    **Protocol** (**OTLP**).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Add a sample HTTP handler**: For demonstration, add a simple HTTP handler
    that emits traces and logs for each request:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`docker-compose` with the file located in the `ch11/otel/` directory in your
    terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The collector should be set up to receive traces on the default OTLP port and
    route them to your tracing backend.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run your application:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`http://localhost:8080/`) from your browser or using `curl`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '*Voilà*! We made an application leveraging OTel’s lock-in-free characteristics!'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Back in my day, we used to debug systems with print statements and the occasional
    panicked curse. OTel is a far more civilized approach. Think of it like building
    your own intricate network of informants within your code. They’ll report back
    every detail, letting you pinpoint problems not just faster, but sometimes even
    before they wreak havoc.
  prefs: []
  type: TYPE_NORMAL
- en: Isn’t that better than a good ol’ debugging brawl? Now, it’s time to wrap up.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we conclude this chapter on telemetry in Go, we’ve journeyed through the
    essential practices and tools that illuminate the inner mechanics of Go applications,
    enhancing their observability. This exploration began with an in-depth look at
    logging, where we learned to transcend essential log messages, adopting structured
    logging for its clarity and ease of analysis. We then navigated the complex yet
    crucial world of tracing, uncovering the intricate execution paths of our applications
    to identify and resolve performance bottlenecks. Also, we ventured into metrics,
    where quantitative data measurement enabled us to monitor and tune our applications
    for optimal performance. Lastly, we combined all the knowledge in a vendor-free
    solution backed by OTel.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll start to look at how to distribute our apps.
  prefs: []
  type: TYPE_NORMAL
