- en: '5'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Performing Integration Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, we discussed the broader topic of writing and testing
    code with **test-driven development** (**TDD**), but have kept our implementation
    focus on unit tests. As we’ve discussed at length so far, unit tests are at the
    bottom of the test pyramid, being the most numerous, as they are testing all the
    different independent parts or units of the application.
  prefs: []
  type: TYPE_NORMAL
- en: The concepts we have discussed so far have allowed us to write unit tests that
    test these units in isolation, across a variety of scenarios. In [*Chapter 3*](B18371_03.xhtml#_idTextAnchor061),
    *Mocking and Assertion Frameworks*, we learned how to make use of frameworks to
    easily create mocks, which allow us to instantiate units whose dependencies we
    have full control over. As discussed in [*Chapter 4*](B18371_04.xhtml#_idTextAnchor085),
    *Building Efficient Test Suites*, we learned how to make use of the popular technique
    of table-driven testing to easily write tests across a variety of cases, including
    edge and corner cases.
  prefs: []
  type: TYPE_NORMAL
- en: No matter how well we write our unit tests, they have the limitation that they
    only verify their limited scope. In other words, unit tests verify that each unit
    is working correctly, but not that they integrate and function correctly together.
    The integrations between units, which may be developed by different teams, can
    often be the cause of errors and outages, so it is important to verify that they
    behave as expected, independently and together.
  prefs: []
  type: TYPE_NORMAL
- en: We will now turn our attention to implementing integration testing suites, which
    will give us the confidence that the functionality that matters will work as intended
    when multiple units work together. We will explore how to containerize our applications,
    ensuring that our tests mimic our production environments and perform as expected.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The limitations of unit testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The implementation of integration tests in Go
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to behavior-driven test writing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The importance of database testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Containerization with Docker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will need to have **Go version 1.19** or later installed to run the code
    samples in this chapter. The installation process is described in the official
    Go documentation at [https://go.dev/doc/install](https://go.dev/doc/install).
  prefs: []
  type: TYPE_NORMAL
- en: The code examples included in this book are publicly available at [https://github.com/PacktPublishing/Test-Driven-Development-in-Go/chapter05](https://github.com/PacktPublishing/Test-Driven-Development-in-Go/chapter05).
  prefs: []
  type: TYPE_NORMAL
- en: Supplementing unit tests with integration tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unit tests are small, fast tests that verify the behavior of a single component.
    In Go, the UUT is typically the package, which exposes an API that these fast
    tests can verify against. These independent units combine to make up **components**,
    which are identifiable parts of a system. Usually, components have well-defined
    responsibilities and provide a group of related functions. A component’s units
    work together to deliver the component’s functionality.
  prefs: []
  type: TYPE_NORMAL
- en: Engineers rely heavily on unit tests in the development phase, and they are
    an important pillar of TDD, where the testing practice requires the testing code
    to be written together with the implementation code. However, they have some limitations
    that make the remaining tests of the testing pyramid essential. Therefore, as
    TDD practitioners, we cannot simply focus on unit tests.
  prefs: []
  type: TYPE_NORMAL
- en: Limitations of unit testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The practice of verifying functionality with unit tests has been the subject
    of debate in the engineering community because of its limitations. *Figure 5**.1*
    presents a summary of their advantages and disadvantages:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.1 – Advantages and disadvantages of unit testing ](img/Figure_5.01_B18371.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.1 – Advantages and disadvantages of unit testing
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the advantages of unit tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Support refactoring**: Unit tests make it easier to refactor code because
    they provide fast verification of existing functionality. They decrease the risk
    associated with changing code, which can lead to breaking existing functionality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Early bug detection**: Unit tests verify the implementation at the development
    phase before it has been integrated with the existing product and can be tested
    end-to-end. This also ensures that bugs don’t propagate to other teams or are
    accidentally released. Early bug detection can also lead to shorter development
    times and reduced project costs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Easier debugging**: Detecting and fixing errors is easier when the tests
    have a limited scope. As the **UUT** is tested in isolation from its dependencies,
    we know that any failing tests are caused either by the test setup or the implementation
    of the UUT.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Better code design**: Poorly designed code is hard to test code and can highlight
    to developers where their code must be rewritten or refactored. In practice, unit
    tests promote better code design because they bring the testing concerns to the
    development phase.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Documentation alongside implementation**: Unit tests serve as detailed documentation
    for the functionality and behavior of a component. As tests live alongside the
    code in Go, they give developers access to it without the use of another documentation
    system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'And these are the disadvantages:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Increase the amount of code**: Unit tests increase the code that developers
    must write early on. This is problematic for tasks that require prototyping or
    don’t have well-established requirements. Developers don’t want to write large
    amounts of code that then need to be changed alongside the implementation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Increased refactor effort**: While unit tests ensure that refactoring has
    not broken any existing functionality, causing regressions, the tests themselves
    must be refactored in the case of changes in requirements. This can increase the
    cost of refactoring efforts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Difficult to identify realistic scenarios**: As the codebase grows and functionality
    becomes more complex, it will be difficult, if not impossible, to test all the
    execution paths of a component. However, as unit tests are written based on code
    and not user requirements, it can be difficult for developers to identify which
    scenarios are realistic and should be covered.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Difficulties testing user interfaces (UIs)**: It is difficult to test UIs
    with unit tests. Usually, they verify business logic, as they traditionally do
    not have libraries available for UI verification.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integration tests are a good way to supplement unit tests, as they address some
    of the disadvantages and limitations of unit tests highlighted previously. Next,
    we will learn how to implement and run them for our Go packages.
  prefs: []
  type: TYPE_NORMAL
- en: Unit tests are considered good practice
  prefs: []
  type: TYPE_NORMAL
- en: While they do pose some disadvantages, the consensus in the community is that
    they should be used as part of development practice. Understanding their limitations
    highlights what other testing needs we need to cover for the full verification
    of our system.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing integration tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Integration tests and end-to-end tests are often used interchangeably, but
    they each have a scope and purpose in the testing pyramid. *Figure 5**.2* depicts
    the testing pyramid and highlights the difference in scope and speed between integration
    and end-to-end tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.2 – The distinction between integration and end-to-end tests ](img/Figure_5.02_B18371.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.2 – The distinction between integration and end-to-end tests
  prefs: []
  type: TYPE_NORMAL
- en: 'The difference in speed between integration and end-to-end tests is due to
    the functionality that they cover:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Integration tests** cover one or multiple components, ensuring that the individual
    components work well as a combined entity. While the logic of the particular component
    is verified by its unit tests, the purpose of the integration test is to exercise
    the conditions at the seams between the components.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**End-to-end tests** replicate the usage of the system by the user. They require
    starting up all services and dependencies of the system under test. Then, tests
    that mimic user behavior are written using helper frameworks. These tests verify
    that the system is performing correctly under real-world conditions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So, if end-to-end tests cover more functionality than integration tests and
    can be automated, why should we bother to implement integration tests? *Figure
    5**.3* depicts some of the drawbacks of end-to-end tests and how integration tests
    address them:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.3 – Challenges of end-to-end tests ](img/Figure_5.03_B18371.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.3 – Challenges of end-to-end tests
  prefs: []
  type: TYPE_NORMAL
- en: 'All of the tests in the testing pyramid work together to address each other’s
    shortcomings. In particular, integration tests and end-to-end tests work together
    in unison:'
  prefs: []
  type: TYPE_NORMAL
- en: Typically, end-to-end tests are performed at **the end of the development process**,
    once the system is relatively stable and can be called end to end. On the other
    hand, integration tests can be performed as soon as the individual components
    are ready, earlier in the development cycle, thereby **shortening the feedback
    loop** and allowing developers to detect bugs earlier on in the project.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As they require more setup and resources, end-to-end tests are **slow and possibly
    expensive** to run. Therefore, engineers might run them as releases and not individual
    code commits. On the other hand, integration tests require much less setup, so
    they are **faster and cheaper to run**. They are often included in the code commit
    checks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As previously mentioned, the focus of end-to-end tests is to verify the **test
    user flow and experience** in real-world scenarios. On the other hand, integration
    tests focus on **integration with external and internal modules** in a variety
    of scenarios, such as negative testing and partial outages. These can be difficult
    to set up in end-to-end tests, which require the entire system to be configured.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integration tests are implemented just as unit tests
  prefs: []
  type: TYPE_NORMAL
- en: We use the same mechanisms for integration tests. We make use of setup functions
    and mocks and table tests to write tests that simply have a larger scope. Furthermore,
    integration tests have the same test signature as unit tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'The setup for integration tests is slightly more complex than unit tests, as
    multiple components, some of which are external, must be configured and started.
    *Figure 5**.4* shows a typical example of the technologies and configurations
    we might use:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.4 – Example configuration of integration tests ](img/Figure_5.04_B18371.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.4 – Example configuration of integration tests
  prefs: []
  type: TYPE_NORMAL
- en: 'The various parts of the integration tests that need to be configured are as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The **Component under test** part is initialized. The component under test is
    larger than the UUT, but it is still self-contained and defined within a single
    module. The scope of the integration test is to ensure multiple units work as
    expected, but they are always contained within the single module under test.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If required, we initialize the **Database** component with a given seed/start
    position of test data contained inside it. As they are complex, databases are
    rarely mocked and will most often be started and populated before the component
    under test is started. Database start positions are often specified as **SQL files**
    or **JSON files**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker makes it easier to configure **Real components** together and is often
    used for system configuration. We will look at how to leverage the power of Docker
    later in this chapter in the *Spinning up and tearing down environments with Docker*
    section.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most often, the component under test will require dependencies for it to start
    and function correctly. These dependencies could be internal to the project or
    external dependencies to the organization, such as a third-party service. These
    external dependencies will be mocked, allowing us to test our component with a
    variety of inputs and conditions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s have a look at an example integration test for our `BookSwap` application,
    which we introduced in [*Chapter 4*](B18371_04.xhtml#_idTextAnchor085), *Building
    Efficient Test Suites*. We will write an integration test for the `GET /` endpoint
    that will return a welcome message and a list of available books. It will also
    allow us to explore testing web applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'The HTTP handler that’s registered to respond to this request is relatively
    simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The implementation of `Handler` highlights the following implementation details:'
  prefs: []
  type: TYPE_NORMAL
- en: We create a custom `Handler` type with all its required dependencies. In the
    case of the `BookSwap` application, we save an instance of `BookService` and an
    instance of `UserService`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The handler has a method for each endpoint that it serves. We create a handler
    method that takes in a `ResponseWriter` and a `Request`. This signature is typical
    of `http.HandlerFunc`, which is an adapter to allow the use of Go functions as
    HTTP handlers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We invoke the `List` function of `BookService` to fetch the list of books and
    construct a response. This custom response is then written to `ResponseWriter`,
    which allows us to easily unmarshal Go structs to HTTP responses.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The setup of our handler code is pretty straightforward and will be similar
    to any code you will write for HTTP responses. But how would we test it? We could
    unit test `BookService` and ensure that it functions correctly, but we also need
    to test that the responses the handlers construct are as expected. It’s time to
    write our very first integration test.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Go standard library has the `httptest` package ([https://pkg.go.dev/net/http/httptest](https://pkg.go.dev/net/http/httptest)),
    which allows us to easily test HTTP handlers and clients. This package contains
    the functionality for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Starting servers with a specific `http.HandlerFunc` with the `httptest.Server`
    type.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating incoming requests to pass to handlers with the `httptest.NewRequest`
    function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recording responses with the `httptest.ResponseRecorder` type for assertions
    in testing code. The recorder conforms to the `http.ResponseWriter` type and can
    be used in its place in handler code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A simple integration test for our `GET /` HTTP handler is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The `TestIndexIntegration` test is relatively straightforward since it does
    not require any complex request construction or response verification:'
  prefs: []
  type: TYPE_NORMAL
- en: The signature of the test is just like any other unit test. It starts with the
    `Test` prefix and takes in a single parameter of the `*``testing.T` type.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, we create an instance of `BookService` with a single book as the starting
    position. The purpose of the test is to ensure that `BookService` integrates with
    its handler and returns responses as expected.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We create a new handler with the instantiated `BookService`. Then, we pass the
    handler to the `httptest.NewServer` function, which creates and starts a server
    instance to serve our handler. We defer the call to the `Close` function, as this
    server should be shut down at the end of the test execution. This concludes the
    `Arrange` section of our test.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `Act` section of our test is very simple. We invoke the server at its URL
    using the `http.Get` method. This is the same method that our clients will be
    using, and the test is not aware that it is calling a special, mocked server.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we can run assertions on our response and possible error in the `Assert`
    section of our test. We verify that no error is returned and that the response
    has the `200 OK` HTTP status code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, we read the body of the response and unmarshal it into our custom response
    type. This makes it easier for us to verify the response, but we could have also
    verified the contents of the response body as a string.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The last assertion verifies that the book instance created in the `Arrange`
    section is contained in the custom response. The test then concludes and the deferred
    call to the server `Close` function is run, cleaning up the server resources set
    up by the test.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `httptest` package allows us to seamlessly verify the behavior of HTTP handlers
    and integration tests using the same libraries and functions that clients will
    use. This allows us to write powerful integration tests.
  prefs: []
  type: TYPE_NORMAL
- en: Running integration tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Integration tests can be run just like any other unit test that we have been
    running so far – by using the `go test` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The test runs successfully since it has the typical signature of a unit test.
    However, notice that this integration test takes nearly 2 seconds to run on my
    machine. This is the measurement for a particular test run, but I have registered
    runtimes as high as 4 seconds for just this simple `GET` request. As the number
    of integration tests for a particular application grows, they have the potential
    to severely slow down our test suites, even if we run them using `t.Parallel()`,
    as we learned in [*Chapter 4*](B18371_04.xhtml#_idTextAnchor085), *Building Efficient
    Test Suites*.
  prefs: []
  type: TYPE_NORMAL
- en: It would be great to separate our unit tests and much slower integration tests.
    We could then run unit tests for all commits and integration tests for code releases.
    There is no perfect, built-in way to signal to the test runner which tests are
    integration tests, but we can explore a few options.
  prefs: []
  type: TYPE_NORMAL
- en: Short mode
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `go test` command has a built-in flag called `-short` that we can access
    using the `testing.Short()` function. This flag allows us to mark long-running
    tests for skipping by adding a short snippet to their test code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The `t.Skip` method will ensure that this long-running test will be skipped.
    We can then run the tests in short mode by adding the `–short` flag to our test
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: As expected, the long-running test is skipped.
  prefs: []
  type: TYPE_NORMAL
- en: The major downside of this approach is that it requires the user to have special
    knowledge to achieve a fast-running test suite, which should be the default behavior.
    There is no built-in `–long` flag that we can use to execute all (including long-running)
    tests.
  prefs: []
  type: TYPE_NORMAL
- en: Naming conventions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another option is to use naming conventions, which would not require any special
    code functions to be added to any tests. For example, you could agree with in
    your team that unit tests will end with the `Unit` suffix and integration tests
    with the `Integration` suffix. Depending on the length and contents of the file,
    we could create separate integration and unit test files. Both unit and integration
    tests can use the dedicated test package, named with the `_test` suffix, keeping
    the source and test code dependencies separated.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we can make use of the `–run` flag, which we explored in [*Chapter 2*](B18371_02.xhtml#_idTextAnchor035),
    *Unit Testing Essentials*, to instruct the test runner to run a subset of tests
    based on their name. We run all unit tests using the `go test -run Unit ./...`
    command, which will recursively traverse folders to search for any test that contains
    the word `Unit`. Analogously, integration tests will be run using the `go test
    -v -run Integration ./...` command.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, this method suffers from the same major downside as short mode,
    as running the default `go test` command without the `–run` flag will cause all
    tests to run, including the slower integration tests.
  prefs: []
  type: TYPE_NORMAL
- en: Environment variables
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The last option is to create an environment variable to make up for the lack
    of a corresponding flag. Again, we will have to add a short code snippet to our
    test to verify this environment variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We make use of the `os.Getenv` method to read environment variables, which will
    return empty if the variable has not been defined. If this variable is empty,
    we skip the integration test, allowing the default behavior of our test suite
    to only run fast tests, skipping integration tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'Running integration tests is easy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Note that this version of the command will only run on `CMD` terminals. Alternatively,
    you can set the `LONG` environment variable to '`true`' in your terminal and then
    run the preceding `go test` command on its own after setting this.
  prefs: []
  type: TYPE_NORMAL
- en: We will make use of the environment variables solution going forward. The expected
    default behavior of the test suite is to run fast-running unit tests. This solution
    allows us to keep specialized knowledge out of the expected default behavior and
    makes it easy to run integration tests when required. It also integrates well
    with containerization technologies such as Docker, which we will explore later
    in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Behavior-driven testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have now learned how to supplement unit tests with integration tests, increasing
    the scope of our component under test. End-to-end tests have the most scope as
    they test the entirety of our system. They are often discussed together with **behavior-driven
    design** (**BDD**), which is a branch of TDD that focuses on writing human-readable
    tests based on user requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Fundamentals of BDD
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first step of BDD practitioners is to establish a shared vocabulary between
    the different interested parties: business stakeholders, domain experts, and various
    other engineering functions.'
  prefs: []
  type: TYPE_NORMAL
- en: Based on this shared and well-understood vocabulary, the user requirements are
    then converted into **user acceptance tests** (**UATs**). These tests are end-to-end
    tests that ensure that system requirements are covered by all new releases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Tests are usually written in the `GET /` endpoint we have previously implemented
    looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Story: View the list** **of books**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Given** a user'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`GET /` root endpoint'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Then** the list of available books is returned to the user'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The test specification reads like plain English and establishes the main aspects
    of the test case:'
  prefs: []
  type: TYPE_NORMAL
- en: Who the main actor of the test case is
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What their expected behavior is
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What the user will get from the performed action
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that the test case does not specify any implementation details of the application
    and instead focuses on *the behavior* of the application. Test cases treat the
    application as a **black box**. This simplicity is the power of BDD, where test
    specifications are not something that only engineers and testing professionals
    can write.
  prefs: []
  type: TYPE_NORMAL
- en: BDD is about bridging gaps
  prefs: []
  type: TYPE_NORMAL
- en: The emphasis on shared language and easily readable tests ensures that the gaps
    between technical and non-technical stakeholders are bridged. This avoids misunderstandings
    and delays in the implementation of the system’s intended behavior.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 5**.5* highlights some of the advantages and disadvantages of writing
    tests using BDD:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.5 – Advantages and disadvantages of writing BDD tests ](img/Figure_5.05_B18371.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.5 – Advantages and disadvantages of writing BDD tests
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the advantages of BDD:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Single source of truth**: The biggest advantage of BDD is that it allows
    teams to have a single source of truth for the intended behavior of the application.
    Furthermore, we have a unified vocabulary to express this behavior across the
    business.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tests as documentation**: While unit tests can also serve as documentation
    for the application, BDD tests are easier to read and understand, since they focus
    on readability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Specific behaviors**: With their Given-When-Then structure, BDD tests encourage
    writing test cases for specific behavior. This often helps narrow down larger
    and potentially vague user requirements that have been established at the beginning
    of the project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Wider involvement**: Anyone in the team or the business can contribute to
    the specification of these tests, making it easier to detect any bugs or functional
    oversights early on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'And here are the disadvantages:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Time-consuming**: It can be time-consuming to get multiple stakeholders together
    to establish test cases at the beginning of the project. Furthermore, it can also
    be time-consuming to maintain these tests during the lifetime of the project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Requires commitment**: The different stakeholders need to commit to taking
    on the work of specifying and discussing these test cases upfront.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dependent on good BDD practices**: Unless correctly specified together with
    the correct stakeholders, BDD tests can become ambiguous and difficult to implement.
    The successful specification of tests is therefore dependent on good BDD practices
    in the business.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we understand some of the advantages of BDD tests and how to write
    them, we can turn our attention to implementing them in Go.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing BDD tests with Ginkgo
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In [*Chapter 3*](B18371_03.xhtml#_idTextAnchor061), *Mocking and Assertion Frameworks*,
    we learned how to create mocks and write assertions with the `testify` open source
    testing library. This allows us to create streamlined unit tests and easily create
    mocks. However, a more expressive testing library was required to easily produce
    BDD-style tests.
  prefs: []
  type: TYPE_NORMAL
- en: The `ginkgo` ([https://github.com/onsi/ginkgo](https://github.com/onsi/ginkgo))
    project was started in 2013 to fill this need. It is a testing framework built
    on top of Go’s `testing` package and it is designed to help us write expressive
    BDD tests. It is used together with the `gomega` ([https://github.com/onsi/gomega](https://github.com/onsi/gomega))
    matcher library, which exposes assertion matchers that we can use in our tests.
    This framework received mixed support from the community, as it brought the Ruby
    way of writing tests to Go. However, it is currently the default way to write
    BDD-style tests and it is an important part of our TDD journey.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Ginkgo` library supports Go modules and can easily be installed with the
    `go install` command, just like `testify`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Ginkgo installation location
  prefs: []
  type: TYPE_NORMAL
- en: The `install` command will install the `ginkgo` CLI in your `$GOBIN` path, so
    ensure that it is set accordingly before you install it. By default, the `$GOBIN`
    path is `$GOPATH/bin`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `go get` command then fetches the `gomega` assertion library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Ginkgo tests live in `_test.go` files, just like regular unit tests, but they
    are organized in test suites. Suites can be compared to the table tests that we
    previously implemented, where we grouped tests by similar functionality and scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suites are generated in the current directory using the `ginkgo` `bootstrap`
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The file is named according to the package declared in the current directory.
    The generated file contains the package declaration and some essential code for
    the suite’s declaration. Note that this command will fail if a suite already exists.
  prefs: []
  type: TYPE_NORMAL
- en: The `bootstrap` command is a convenient way to generate this boilerplate for
    us and ensure that all test files have the same basic structure, across our all
    projects. It also ensures that our suites’ naming is consistent, so it is a powerful
    standardization tool.
  prefs: []
  type: TYPE_NORMAL
- en: Testing terminology
  prefs: []
  type: TYPE_NORMAL
- en: '`ginkgo` uses the same terminology as the `ginkgo` tests going forward.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The generated `chapter05/handlers/handlers_suite_test.go`, contains the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This file contains the necessary information for interacting with the `ginkgo`
    runner:'
  prefs: []
  type: TYPE_NORMAL
- en: The suite test file is declared inside the `handlers_test` package corresponding
    to this directory. The separate `_test` package ensures that we only test the
    exported functionality of the source package. This is essential to writing integration
    tests that only assert the external behavior of the API.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `ginkgo` and `gomega` libraries are imported using the dot (`.`) operator.
    This allows us to have access to test and assertion functionality without having
    to qualify each function with the package name. This can be disabled, but it is
    discouraged by the BDD community, as tests should read as naturally as possible.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The signature of the test is as expected. The test signature takes in a single
    parameter of the `*testing.T` type. This is the entry point of our generated suite.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The test contains two calls to the `Ginkgo` test runner. We will not spend too
    much time discussing the internals of these functions, but, as all the testing
    library is open source, you can look up what they do yourself. The call to `RunSpecs`
    instructs the test runner to begin running the suite and execute all existing
    specs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The suite only serves as an entry point for the specs to begin executing, which
    are usually defined in separate test files.
  prefs: []
  type: TYPE_NORMAL
- en: 'We define `ginkgo` equivalent to the `Index` endpoint integration test that
    we previously saw in the *Implementing integration tests* section in the `chapter05/handlers/handlers_index_test.go`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The Ginkgo equivalent of our `Index` integration test seems quite different
    from the code we are used to seeing. Its focus is on setting up the various aspects
    of the test in an easy-to-read **spec tree**:'
  prefs: []
  type: TYPE_NORMAL
- en: We make use of closures to set up our spec hierarchy. The `Describe` function
    allows us to create `Describe` node.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `BeforeEach` function creates **setup nodes** that run before tests. They
    are used for extracting common setups, allowing us to streamline our tests.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `AfterEach` function creates setup nodes that run after tests. They allow
    us to clean up after our specs have run, ensuring that critical resources are
    cleaned up correctly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can further define container nodes inside the top-level nodes as required
    to organize our specs and their scenarios.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Context` function is an alias for `Describe` that allows us to add extra
    information to our specs to help people understand them. It also creates container
    nodes but can be used to organize information.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `It` function allows us to define **subject nodes**. These nodes contain
    the assertions of the subject under test and cannot contain any other nested nodes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The assertions inside the subject nodes are written with the `gomega` assertion
    library. These can be nested just like the assertions of `testify` but take a
    human-readable form. All assertions must begin with the `Expect` function, which
    wraps an actual value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Figure 5**.6* shows a visual representation of the structure of the spec tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.6 – The structure of the spec tree ](img/Figure_5.06_B18371.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.6 – The structure of the spec tree
  prefs: []
  type: TYPE_NORMAL
- en: All tests begin with a `Describe` container node. This top-level node can then
    contain multiple `BeforeEach` setup nodes, multiple `AfterEach` nodes, other `Context`
    container nodes, and multiple `It` subject nodes. As we saw in the handlers integration
    test, these nodes are arranged to build a hierarchy that reflects our test scenario.
  prefs: []
  type: TYPE_NORMAL
- en: Nesting rules
  prefs: []
  type: TYPE_NORMAL
- en: The spec tree consists of nested container nodes. Setup nodes can be nested
    inside them. Like the behavior of deferred functions, the innermost function will
    run first. Then, the others will continue in the same fashion going outward.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have generated our suite and populated it with specs, we can run it
    by using the `ginkgo` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Just like the `go test` command we have used so far, `ginkgo` also supports
    the `./...` operator, which will traverse subdirectories and look for suites to
    run.
  prefs: []
  type: TYPE_NORMAL
- en: As we can see from the output, the container nodes and subject nodes are used
    to construct meaningful names for the spec suite. Ginkgo allows us to construct
    test collections with meaningful test outputs. We will continue to explore it
    in future chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding database testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the world of testing, databases are often overlooked in literature. Most
    applications often assume in-memory data storage, just as we have done with the
    `BookSwap` application so far. However, it is important to understand the difficulties
    and techniques that we have available when it comes to verifying our databases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Databases are often seen as external systems or black boxes in our system.
    They provide specialized behavior and are often complex systems, which most often
    cannot fail. *Figure 5**.6* depicts the typical data translation between different
    formats:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.7 – The data formats of a typical system ](img/Figure_5.07_B18371.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.7 – The data formats of a typical system
  prefs: []
  type: TYPE_NORMAL
- en: Data changes formats multiple times in a typical application. User requests
    usually enter our system in **JSON** format. The **API layer** area then translates
    these requests to the internal application models and sends them further down
    the stack to the **Service layer** area. Finally, the **Service layer** area persists
    these in the database using **SQL** or whatever the expected format of the database
    is. Often, **NoSQL databases** will save their data back in **JSON** format and
    persist it.
  prefs: []
  type: TYPE_NORMAL
- en: 'We should write tests that cover the following aspects of our database systems:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Startup and availability**: The application should wait for the database
    to become available and should do so in an efficient manner.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Persistence and querying**: Once data is stored in the database, it should
    be correctly stored and fetched. This is done by the business logic and should
    be verified to be implemented correctly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance testing**: This type of non-functional testing is important for
    the database, which typically powers all the requests in the application. Typical
    verifications include load testing using large files or results counts, running
    tests using multiple remote users, and any edge cases regarding the values of
    the column/field values of the database payloads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These crucial aspects of our systems should be covered by testing, especially
    around the points where data formats vary and translations occur. These format
    translations can be the cause of bugs and outages. For example, one field might
    be a mandatory non-nullable value at the database level, but be missing further
    up the stack.
  prefs: []
  type: TYPE_NORMAL
- en: Mocks as databases
  prefs: []
  type: TYPE_NORMAL
- en: It might be tempting to assume that a mock would be fitting to wrap around complex
    external behavior, but the community generally discourages this as an engineering
    anti-pattern. End-to-end and integration tests should verify and run against the
    databases that they use in production to avoid differences in functionality and
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: Useful libraries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Fortunately, the Go ecosystem provides some great libraries to allow us to
    easily integrate databases into our applications. Here are some Go libraries that
    you will find useful when integrating databases into your Go applications:'
  prefs: []
  type: TYPE_NORMAL
- en: '`go-testfixtures` ([https://github.com/go-testfixtures/testfixtures](https://github.com/go-testfixtures/testfixtures)):
    An open source library that makes it easy to write functional database tests.
    It uses the **Ruby on Rails** way of setting up data samples using fixtures files.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`golang-migrate` ([https://github.com/golang-migrate/migrate](https://github.com/golang-migrate/migrate)):
    An open source library that makes setting up database startup positions easy,
    without us having to write our own data formats and files. It supports a variety
    of SQL and NoSQL databases.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`go-txdb` ([https://github.com/DATA-DOG/go-txdb](https://github.com/DATA-DOG/go-txdb)):
    An open source library that runs database queries in transactions. Once the tests
    are complete, transactions are rolled back and data is not persisted. This allows
    us to run our tests in isolation on top of a real database.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gorm` ([https://github.com/go-gorm/gorm](https://github.com/go-gorm/gorm)):
    A popular open source library that provides **object-relational mapping** (**ORM**).
    This developer-friendly library makes it easier to convert database types into
    useful custom structs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bun` ([https://github.com/uptrace/bun](https://github.com/uptrace/bun)): This
    is the new, rewritten version of the `go-pg` ([https://github.com/go-pg/pg](https://github.com/go-pg/pg))
    project. This project provides ORM functionality for multiple SQL databases.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The literature on whether to use SQL or NoSQL databases is vast and involves
    a wide set of recommendations. We will not start this discussion here, but SQL
    databases remain the most popular database solutions. We will focus on how to
    implement and test SQL databases in our discussions going forward. We will also
    see some of the libraries we mentioned in this section in action going forward.
  prefs: []
  type: TYPE_NORMAL
- en: Spinning up and tearing down environments with Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The final topic we will cover in our exploration of integration and end-to-end
    testing is **containerization** using the popular technology known as Docker.
    It provides us with the ability to start up applications in our local and remote
    environments in the same way.
  prefs: []
  type: TYPE_NORMAL
- en: Docker gives developers the confidence that their applications will behave in
    the same way across environments, which is particularly useful for managing and
    deploying test environments.
  prefs: []
  type: TYPE_NORMAL
- en: Fundamentals of Docker
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A **container** is a unit of software that bundles up code and all its dependencies,
    enabling us to run it in multiple environments. The specification of the container
    is known as a **container image**. Docker Engine interprets the specification
    of container images and turns them into containers.
  prefs: []
  type: TYPE_NORMAL
- en: Containerization versus virtualization
  prefs: []
  type: TYPE_NORMAL
- en: '**Virtualization** refers to running multiple operating systems on a single
    machine. Containerization refers to running multiple applications developed in
    the environment of one operating system on a single machine.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 5**.7* depicts containers running on the host environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.8 – Running containers with Docker ](img/Figure_5.08_B18371.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.8 – Running containers with Docker
  prefs: []
  type: TYPE_NORMAL
- en: Containers are lightweight, allowing multiple containers to run on the same
    physical hardware. **Docker Engine** oversees managing them and enforcing isolation
    levels, ensuring that malicious code cannot escape outside of its current namespace,
    but also importantly ensuring that tests have a realistic level of isolation.
    In practice, this means that we can download and run a set of images for complex
    systems to run on shared hardware.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, we could run multiple containers on shared infrastructure: a Go
    web application, a database, event buses and queues, monitoring, and so on. All
    these different technologies and images can be managed by a single **standardized
    technology** with Docker Engine.'
  prefs: []
  type: TYPE_NORMAL
- en: Using Docker
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The concept of containerization does not belong to Docker exclusively, but we
    will refer only to the usage of Docker going forward. Docker Engine can easily
    be installed by following the official documentation available at [https://www.docker.com/get-started/](https://www.docker.com/get-started/).
  prefs: []
  type: TYPE_NORMAL
- en: 'Docker Engine ships with a powerful CLI that contains two main commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '`docker` deploys and manages a single application or container. The Docker
    CLI offers an extensive list of commands and options, some of the most common
    being these:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker pull` downloads an image from the image repository, named `docker run`
    creates a container from an image. If the image is not available locally, it will
    be downloaded from the image repository, prolonging the container startup time.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker ps` lists all the locally running containers. This command is commonly
    used to get the unique container ID for each container. These unique IDs can then
    be used to reference specific containers in other commands.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker stop` instructs the container to shut down, giving it time to gracefully
    shut down and clean up its resources. Docker Engine makes use of operating system
    signals to communicate shutdown to containers. Containers can then be restarted
    using the `docker start` command.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker kill` instructs the container to stop its execution immediately, without
    allowing time for graceful shutdown.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker exec` allows us to access a running container. Since containers are
    isolated from the rest of the operating system, the only way to have access to
    its resources and setup is to request access from Docker Engine.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker compose` deploys and manages multiple containers within the same single
    host. This allows us to configure and start multiple containers with a single
    command, as opposed to starting them each individually with the `docker` command.
    Another key advantage is that the containers will be running and networking as
    a single group, making it easy to deploy complex systems across environments.
    Some of the most common `docker compose` commands are as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker compose up` starts the specified containers of a given `.yml` file.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker compose ps` lists the containers of a Compose project, including their
    statuses and registered ports. These containers will also be visible when running
    the `docker ps` command, but this command will output more container information.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker compose stop` instructs running containers to stop, without removing
    them. They can then be restarted again using the `docker compose` `start` command.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker compose kill` forces containers to immediately stop using the `SIGKILL`
    system signal.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: That’s all the basics we need to know to install Docker Engine and perform some
    basic tasks with Docker. In [*Chapter 6*](B18371_06.xhtml#_idTextAnchor142), *End-To-End
    Testing the BookSwap Web Application*, we will look at the configuration of the
    custom Dockerfile for our application, the changes we need to make to our existing
    implementation to make use of a database, and how to run end-to-end tests based
    on these easy to spin up and tear down containers.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we moved on from focusing on unit tests, which verify the functionality
    of code in small isolated units. We began with an introduction to the importance
    of integration testing and learned how to write and run integration tests for
    HTTP handlers using the `httptest` library. Then, we learned what the practice
    of writing BDD-style tests entails and how to implement them using the `ginkgo`
    testing library. Then, we discussed the importance of testing databases and what
    useful libraries there are available to us to be able to write these. Finally,
    we covered the advantages of containerization and learned how to use Docker and
    configure services with `docker compose`.
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 6*](B18371_06.xhtml#_idTextAnchor142), *End-To-End Testing the
    BookSwap Web Application*, we will expand on all the fundamentals of the technologies
    we have learned so far and apply them to test the `BookSwap` web application.
    This will give us good hands-on practice to configure a typical web application
    that has a simple database dependency.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Answer the following questions to test your knowledge of this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: What is the difference between integration tests and end-to-end tests?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is **behavior-driven** **design** (**BDD**)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Should we mock databases? Why/why not?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a container?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To learn more about the topics that were covered in this chapter, take a look
    at the following resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '*BDD in Action: Behavior-driven development for the whole software lifecycle*,
    by John Ferguson Smart, published by Manning Publications'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Docker: Up & Running: Shipping Reliable Containers in Production*, by Sean
    Kane and Karl Matthias, published by O’Reilly'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Designing Data-Intensive Applications: The Big Ideas Behind Reliable, Scalable,
    and Maintainable Systems*, by Martin Kleppmann, published by O’Reilly'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
