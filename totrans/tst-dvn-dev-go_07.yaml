- en: '7'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Refactoring in Go
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have explored concepts and techniques for tests across the entire testing
    pyramid. We have applied these concepts while building our main project of study,
    the `BookSwap` application. This web application is currently verified by the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: Unit tests implemented using the Go standard library
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integration tests implemented using `httptest`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: End-to-end tests implemented using `godog`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To demonstrate these techniques in a realistic example, we have extended the
    functionality of the `BookSwap` application with a variety of components. In [*Chapter
    6*](B18371_06.xhtml#_idTextAnchor142), *End-To-End Testing the BookSwap Web Application*,
    we extended the project by adding the ability to run it in Docker and use a PostgreSQL
    database to save its data.
  prefs: []
  type: TYPE_NORMAL
- en: 'All of these changes have added complexity to our `BookSwap` application, which
    now relies on the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Two libraries for database migration and operations – `golang-migrate` and `gorm`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Three different types of files – source files, implementation files, and Docker
    files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A complex code structure with multiple layers – `db`, `handlers`, and `cmd`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `BookSwap` application started as a simple REST API with a small scope of
    functionality. However, as we kept refining it and adding more code, it became
    more difficult to install and start up. This is part of the natural life cycle
    of software projects. As an engineer, you will more often have to modify and extend
    existing code, performing **brownfield development**, than start and implement
    brand-new projects with no existing dependencies, also known as **greenfield development**.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter is dedicated to `BookSwap` application, we will learn about good
    practices for code refactoring. Then, we will learn how to validate the behavior
    of the restructured code, which should perform and behave identically to its legacy
    equivalent. Finally, we will discuss best practices for splitting up monolithic
    applications into microservices.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What code refactoring is and why it is an essential part of the development
    process
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to effectively change implementation and test code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Error verification in Go
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to validate refactoring success criteria
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Good practices for splitting up monolithic applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will need to have **Go version 1.19** or later installed to run the code
    samples in this chapter. The installation process is described on the official
    Go documentation at [https://go.dev/doc/install](https://go.dev/doc/install).
  prefs: []
  type: TYPE_NORMAL
- en: The code examples included in this book are publicly available at [https://github.com/PacktPublishing/Test-Driven-Development-in-Go/chapter07](https://github.com/PacktPublishing/Test-Driven-Development-in-Go/chapter07).
  prefs: []
  type: TYPE_NORMAL
- en: Understanding changing dependencies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 1*](B18371_01.xhtml#_idTextAnchor015), *Getting to Grips with Test-Driven
    Development*, we discussed refactoring the code we are writing as part of the
    **Red-Green-Refactor** TDD technique. This involved limiting the cleaning up of
    code as we write it. However, as we continue our journey with TDD, it is essential
    that we consider how our code will evolve through time and consider larger-scale
    code refactoring or rewrites.
  prefs: []
  type: TYPE_NORMAL
- en: '**Code refactoring** is often used interchangeably with **code redesigning**,
    but they represent different levels of code modification. Code redesigning involves
    changing the functionality of a code base/service, while code refactoring involves
    changing the way the service delivers its existing functionality. In fact, if
    done correctly, code refactoring will be invisible to any internal and external
    users of the service functionality.'
  prefs: []
  type: TYPE_NORMAL
- en: The purpose of code refactoring
  prefs: []
  type: TYPE_NORMAL
- en: 'Developers refactor their code to make it more efficient, maintainable, and
    extendable. There are many benefits to code refactoring: better readability, improved
    performance, and enabling developers to change the code more efficiently. Together,
    these are known as **non-functional requirements**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A project’s testing strategy is an essential aid for verifying and supporting
    efficient code changes and will help developers avoid the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Functionality regressions**: The refactored code should not break any existing
    functionality, causing a regression. Integration tests will identify components
    that might no longer work together correctly, while end-to-end tests will pinpoint
    which breakages affect user-facing functionality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance degradation**: The refactored code should not perform any slower
    than the existing functionality. Integration tests will identify which components
    have slowed down for a particular scenario or operation, signaling to developers
    which components should be investigated further. End-to-end tests will identify
    which performance issues are affecting users but might make it more difficult
    to isolate the problem, as they don’t provide the granularity of system components.
    However, they will give an important indication of the severity of a particular
    performance issue, allowing developers to correctly prioritize issues. We will
    cover performance testing in more detail in [*Chapter 8*](B18371_08.xhtml#_idTextAnchor179),
    *Testing* *Microservice Architectures*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Changes outside the intended scope**: The refactored code should not affect
    components outside the intended scope of the changes. This indication is particularly
    important for legacy code bases, where developers might not have a clear picture
    of the dependency graph of the different components. Unit tests will pinpoint
    which packages within the current codebase/service might be affected by the refactor,
    while integration tests will highlight whether the APIs between different services
    might be broken.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The potential costs of these issues come in multiple forms:'
  prefs: []
  type: TYPE_NORMAL
- en: Losing business/transaction volume during a potential outage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Increased infrastructure/cloud costs in the case of slower performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Increased development costs if developers take a longer time to deliver a code
    change
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Therefore, it is essential that code refactoring is easy to take on and verify.
  prefs: []
  type: TYPE_NORMAL
- en: Code refactoring steps and techniques
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we understand the fundamental need for code refactoring, let us explore
    some code refactoring techniques. These are not limited to Go development itself,
    but it is important to understand the process by which we change the code so that
    we can then understand how to effectively validate its output. *Figure 7**.1*
    depicts the basic working process of code refactoring:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.1 – The working process of code refactoring ](img/Figure_7.01_B18371.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.1 – The working process of code refactoring
  prefs: []
  type: TYPE_NORMAL
- en: 'The code refactoring steps rely on tests for verification:'
  prefs: []
  type: TYPE_NORMAL
- en: The developer identifies the change that they want to make to the existing implementation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, they make the required change, ensuring that the code continues to compile.
    This might require making changes to both the implementation and testing code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once their first change is done, the developer runs the test suite to verify
    their implementation changes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the tests are passing, then this refactor is successful and the developer
    has successfully implemented this change. They can proceed to commit it and release
    it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the tests are failing, then this refactor is not successful and the developer
    must revise their refactored change. This might mean making further changes to
    either the implementation or test code or simply adjusting their new code changes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The working process is closely related to the red-green-refactor process that
    we have seen in earlier chapters. The developer should not share any changes that
    they make without the test suite successfully passing. This is most often enforced
    by commit checks and test run verifications as part of the build/release pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: 'As depicted in *Figure 7**.2*, code refactoring should consist of a series
    of minor code changes or modifications, ensuring that the refactored code retains
    the same major functionality:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.2 – Refactoring as a series of minor changes ](img/Figure_7.02_B18371.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.2 – Refactoring as a series of minor changes
  prefs: []
  type: TYPE_NORMAL
- en: As with many aspects of the code development process, releasing small, isolated
    changes is better than large code releases. This allows developers to verify each
    code change and release it in turn. Furthermore, in the case of issues, reverting
    a small code change will be easier than reverting larger code changes that have
    been committed over multiple days.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 7**.3* depicts an overview of five popular code refactoring techniques:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.3 – Five popular code refactoring techniques ](img/Figure_7.03_B18371.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.3 – Five popular code refactoring techniques
  prefs: []
  type: TYPE_NORMAL
- en: 'The five techniques can be used together to improve code complexity and duplication:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Red-green-refactor** is the technique we are already familiar with. The implementation
    is written alongside its corresponding tests, starting with a failing test, making
    it pass, and then refactoring the written code as required. This approach ensures
    that all functionality is covered by tests and that the refactoring is undertaken
    as part of the initial implementation. As tests are written alongside the code,
    this technique will most likely require test changes as part of the code refactoring
    process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Extract** is the technique that involves extracting an existing code fragment
    from a potentially large function into its own function. This function name should
    describe the functionality that the extracted fragment implements, improving the
    readability of the previous large function containing multiple pieces of functionality.
    As code is only extracted, not rewritten, test changes will not likely be required.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Simplify** is the technique that improves the complexity of large functions.
    This can be done by refactoring conditional expressions or adjusting method calls
    by refactoring function parameters or adjusting interface signatures. As this
    technique involves changing function signatures, test changes will most likely
    be required.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inline** is the opposite technique to **Extract**. It involves removing redundant
    functions by taking their contents and putting them in place of the existing function
    call. This reduces the indirection of the code, reducing the cognitive burden
    of the developer reading the code. Unless the method being tested is removed,
    this technique will not likely require test changes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Abstraction** is the technique most likely suited for larger-scope code refactoring.
    This technique involves introducing new levels of abstraction, such as interfaces,
    to remove repetition and allow the reuse of behaviors across multiple packages.
    Since new interfaces will require the use of mocks and larger scope refactoring,
    this technique will most likely require test changes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These popular techniques will help you refactor your code and ensure that it
    continues to adhere to the SOLID principles we have previously discussed in [*Chapter
    3*](B18371_03.xhtml#_idTextAnchor061), *Mocking and* *Assertion Frameworks*.
  prefs: []
  type: TYPE_NORMAL
- en: Technical debt
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Code refactoring is an extremely important and unavoidable part of the development
    life cycle. When code is not routinely refactored and maintained, it begins to
    accumulate **technical debt**. The subject of how to effectively manage technical
    debt has been discussed often in the engineering community, as it is easy for
    engineering managers to prioritize delivering new features, which have a tangible
    monetary value, as opposed to addressing technical debt, which does not have immediate
    consequences or cost associated with it.
  prefs: []
  type: TYPE_NORMAL
- en: Technical debt in Agile
  prefs: []
  type: TYPE_NORMAL
- en: In Agile, technical debt is the term used to refer to the consequences of prioritizing
    speed over quality. While the code is tested for correct functionality, its internal
    structure might be the result of poor architectural choices that have been made
    for speed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The consequences of technical debt can affect your project in a variety of
    ways:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bugs**: As code accumulates technical debt, duplicated code and high cohesion
    can lead to bugs that are difficult to fix and detect. These can have financial
    consequences in the case that they cause outages or affect user operations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Decreased productivity**: As technical debt does not follow SOLID principles
    and does not resemble the rest of the code base, it can be difficult for developers
    to change it with new features. Furthermore, technical debt is also typically
    not well documented, so it can be difficult to reason around expected behavior.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Limits new features**: As it accumulates, developers can spend their entire
    time fixing bugs and performance issues with technical debt, meaning that they
    do not have time to deliver new features. This “putting out fires” and chaotic
    way of working frustrates engineers and can even lead to higher staff attrition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical debt is often compared to financial debt. If we don’t take care of
    the issues in our code for a prolonged period of time and continue extending code
    that has been poorly designed, the debt becomes larger and more difficult to handle,
    similar to how financial debt accumulates interest. To avoid these consequences,
    technical debt should be handled alongside other work in the Agile way of working.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 7**.4* depicts how Agile teams typically structure their work to address
    technical debt with a prioritized work **backlog**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.4 – Sprint planning with technical debt ](img/Figure_7.04_B18371.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.4 – Sprint planning with technical debt
  prefs: []
  type: TYPE_NORMAL
- en: 'The **sprint backlog** is a combination of feature work and technical debt:'
  prefs: []
  type: TYPE_NORMAL
- en: The development team and product team each maintain their own backlogs. Typically,
    these are represented by Jira tickets or GitHub issues with details of the work
    to be done. The technical debt work will typically involve refactoring existing
    code, while the feature work will consist of adding new functionality. The sprint
    backlog attempts to find a balance between these two types of work.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: During sprint planning, representative stakeholders prioritize the work. It
    is considered good practice to involve the development team during planning to
    ensure that the entire team has a good understanding of the goals of the upcoming
    sprint. The engineering team consists of experts who can scope what refactoring
    work should be taken on. They often have an understanding of which parts of the
    system require attention.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The outcome of the sprint planning meeting is a prioritized list of work that
    makes up the sprint backlog. Based on their expertise, the technical team typically
    provides time estimates for the work to be done. These estimates are then used
    to determine what work can be undertaken to match the capacity of the team. Refactoring
    and feature work are treated as equal, with time being given to each piece of
    work based on provided estimates.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While technical debt seems like it does not have any immediate cost, it’s important
    that teams are allowed to take time to refactor and maintain their code.
  prefs: []
  type: TYPE_NORMAL
- en: Planning for technical debt
  prefs: []
  type: TYPE_NORMAL
- en: A “little and often” approach works best, where technical debt is planned alongside
    feature work, as opposed to a “Big Bang” approach, where a whole sprint is dedicated
    to fixing issues and doing extensive code refactors.
  prefs: []
  type: TYPE_NORMAL
- en: Changing dependencies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have a good understanding of how to plan and undertake code refactoring,
    it is time to turn our attention to a special case of code refactoring, which
    is changing dependencies. As discussed in [*Chapter 3*](B18371_03.xhtml#_idTextAnchor061),
    *Mocking and Assertion Frameworks*, dependencies are typically wrapped in our
    own interfaces. Go’s powerful interface also helps us refactor our code when dependencies
    change.
  prefs: []
  type: TYPE_NORMAL
- en: 'Interfaces make our code easier to refactor, as well as less coupled, by providing
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Clear expected behavior**: Interfaces are defined on the calling side, establishing
    what the expected behavior of the external dependency will be inside the package.
    Developers have a clear way to indicate what functionality and method signatures
    they expect the external dependency to provide.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Compiler-enforced method signatures**: Once the expected behavior is defined,
    the compiler will verify that any struct that is passed as the interface will
    satisfy these signatures. Therefore, the code can never get into a state where
    a certain method is not defined, and cause runtime errors once called.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Separation between packages**: As the interface lives inside the calling
    package, it provides a barrier between the package and the external dependency.
    The dependency can then be refactored or have new functionality implemented without
    the need to handle these changes in the calling packages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Implementation opacity**: The calling package does not have any knowledge
    of the external dependency. This makes it easy for us to replace one concrete
    implementation with another, which makes changing dependencies during refactoring
    easy. We have already seen an example of this in [*Chapter 3*](B18371_03.xhtml#_idTextAnchor061),
    *Mocking and Assertion Frameworks*, where we saw how to provide mocks for dependencies
    of the UUT, allowing us to test its behavior in isolation from all its other concrete
    dependencies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A good example to analyze this is `PostingService` of the `BookSwap` application.
    The purpose of the service is to take on the order and provide all the book shipping
    functionality:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: As expected, we have defined `PostingService` as an interface that we have defined
    inside the `BookSwap` application. This service has not been implemented, as we
    have considered the implementation of this service as fully external. Please note
    that this is a purely fictional service that we have used to demonstrate the process
    of providing and consuming external dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: '`BookService` takes `PostingService` using this defined interface as a dependency:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We can provide any implementation of this function as long as it provides the
    method defined by the interface. This makes it easy for us to provide any implementation
    of this service to the method, without making any further code changes inside
    this package, which means we can keep the scope of the refactoring small to the
    implementing package.
  prefs: []
  type: TYPE_NORMAL
- en: Nil values as dependencies
  prefs: []
  type: TYPE_NORMAL
- en: The zero value of an interface is nil, so it will satisfy the method signature
    when passed in as well. While a nil value dependency can cause errors if a function
    is called on it, using nil for dependencies we are not interested in is particularly
    useful when writing tests.
  prefs: []
  type: TYPE_NORMAL
- en: While implementation is easy to swap when the signature of the dependency stays
    as expected, changing the interface method signature is not so easy and will require
    us to make changes to the calling packages, which have defined their own wrapping
    interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: 'When changing the signature of an interface, you will typically need to make
    the following changes:'
  prefs: []
  type: TYPE_NORMAL
- en: Make the changes to the implementation of the interface, if it is part of your
    project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update the test code to ensure that the refactored changes are working correctly.
    This will ensure that you have not introduced any bugs or caused regressions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Based on the compiler errors, you can easily identify which packages use the
    implementation type as a dependency, as they will no longer satisfy these old
    method signatures. Then, you can make the corresponding changes to any interfaces
    that wrap around the implementation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you are using a mock generation tool, you can regenerate your mocks according
    to the newly updated interface definitions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As identified by compilation errors, you can make any changes to the test code.
    These changes might be required after regenerating the mocks or to test the new
    behavior of the refactoring.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The compiler is your guide
  prefs: []
  type: TYPE_NORMAL
- en: The enforcement of interface signatures will help you identify which packages
    must be modified and ensure that the code does not end up in an unstable state.
    The compiler will highlight any code that needs to be modified and guide you in
    your refactoring efforts.
  prefs: []
  type: TYPE_NORMAL
- en: As changing interfaces requires a lot of rework, developers will try to avoid
    making these changes. However, taking the time to design your code according to
    good architectural principles should help you avoid needing to make such sweeping
    code changes often.
  prefs: []
  type: TYPE_NORMAL
- en: Relying on your tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We now have a good understanding of how to refactor our code and have learned
    how to take advantage of some of Go’s best features: the compiler and interfaces.
    This should make your refactoring much easier and help you fit it into your sprint
    planning. In this section, we will have a look at a couple of examples of code
    refactors in the `BookSwap` application that will allow us to use all the techniques
    we have explored in this chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: Automated refactoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One of the biggest strengths of Go is its tooling, and IDE support is no exception
    to this:'
  prefs: []
  type: TYPE_NORMAL
- en: The Google Go team maintains an extension for Go development in Visual Studio
    Code ([https://code.visualstudio.com/docs/languages/go](https://code.visualstudio.com/docs/languages/go))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `vim-go` plugin ([https://github.com/fatih/vim-go](https://github.com/fatih/vim-go))
    is a popular open source plugin maintained by the Go community
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The team at JetBrains has created GoLand ([https://www.jetbrains.com/go/](https://www.jetbrains.com/go/)),
    which is a dedicated product for Go development
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of these IDEs provide us with support for looking up references and usages
    of a given type and for renaming symbols across the entire call stack. This can
    take a lot of the boring grunt work of simple refactoring, but you will still
    have to make quite a few changes yourself.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s consider the refactoring involved in renaming `BookService` to `BookRepository`.
    We might want to change this name, as we added functionality related to the database
    of the `BookSwap` application in [*Chapter 6*](B18371_06.xhtml#_idTextAnchor142),
    *End-to-End Testing the BookSwap* *Web Application*.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will rename the struct with our IDE’s rename symbol functionality:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This will update all the direct references to the old `BookService` in all implementation
    and test code across the entire application. This saves us from fixing a lot of
    compilation errors manually.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we need to ensure all methods relating to this struct are correctly named.
    The `NewBookService` initialization function will need to be renamed as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The renamed function makes it clear that it is responsible for creating `BookRepository`
    given its dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: We will need to review any test code for test signatures that relate to the
    old name as well. As we want to name tests after the functionality they verify
    and not the types they verify, we will not need to change any test names for this
    rename.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the filenames that contain and test these definitions will need to
    be changed to match:'
  prefs: []
  type: TYPE_NORMAL
- en: The `book_service.go` file becomes `book_repository.go`, making the naming of
    the file and the code it contains consistent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `book_service_test.go` file becomes `book_repository_test.go`, ensuring
    that the test code and implementation stay grouped together
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That’s all the work we need to do for renaming a service in our `BookSwap` application.
    This simple code refactor did not require any test changes, but it did demonstrate
    the process that you will have to undertake in refactoring Go code and how you
    can rely on your IDE to take care of some of the more laborious parts.
  prefs: []
  type: TYPE_NORMAL
- en: Validating refactored code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While renaming symbols is straightforward, a far more common change that you
    will find yourself having to make will be to change a method’s signature. Let
    us see refactoring for a method signature change of the `Get` method of `BookRepository`,
    which currently has this signature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This method takes in an ID, fetches `Book` from the database, or returns an
    error in the case that the book is not found. This is a common signature for this
    functionality.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will change this method to take in `*Book` and return only an error. This
    will mean that the book fetched from the database will be populated on the `book`
    parameter and return an error if is not found. The new signature of this method
    will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'With the new signature in place, it’s time to change our test code accordingly.
    The assertions in `TestGet` `Book` of the `book_repository_test.go` file get changed
    to make use of the new signature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We change the test code to make it compile and adjust to the new signature of
    the function. During refactoring, tests should be changed as little as possible
    to ensure that the refactored code has not caused any regressions.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, the test will be compiling, but we have not completely implemented
    the code for the new signature. It’s time to turn our attention to the implementation
    of this new method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The code is adjusted to read the ID of the `b *Book` parameter, and the database
    populates its results to the same passed-in parameter. Then, we return an error
    or `nil` according to whether the item is found or not.
  prefs: []
  type: TYPE_NORMAL
- en: 'Any other calling code will need to be adjusted in the same way as we have
    adjusted our test code. The compiler will let you know if you have missed any
    code that needs to be refactored. For example, if we add a second parameter to
    the `Get` method of `BookRepository` and forget to change it in its test, the
    compiler will let us know that the expected method signature is not defined when
    the test is run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Remember, your test code is the first external consumer of your package’s API,
    so any changes to the implementation code will affect your tests first. Note that
    this non-compiling state of the code has not been committed on our repository,
    so your test output will not match the preceding snippet.
  prefs: []
  type: TYPE_NORMAL
- en: Error verification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 4*](B18371_04.xhtml#_idTextAnchor085), *Building Efficient Test
    Suites*, we briefly discussed Go’s approach of explicit error handling. We learned
    that errors are typically returned last in a list of multiple return values. So
    far, we have been using Go’s inbuilt `error` type and representative error messages
    to indicate to the user when something has gone wrong. Let us now take a closer
    look at how error verification works in Go.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have created errors in two ways so far. The simplest way is using the `errors.New`
    function. It creates an error with a given message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This function takes in an error message as a parameter and returns the `error`
    interface type. In order to get our error message back, we invoke the `Error`
    method on the function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This method returns the message as a string type.
  prefs: []
  type: TYPE_NORMAL
- en: 'Writing a test to compare the incoming and outgoing error messages is trivial
    for this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'As we have full control of the entire error message, we can easily assert that
    the values are equal. However, what if the error message construction is part
    of the function? It is common practice in Go to construct representative error
    messages that include inputs and other call parameters. These kinds of errors
    are typically constructed using the `fmt.Errorf` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The `fmt.Errorf` function formats the error the same as the rest of the formatting
    functions in the `fmt` package, but returns an `error` type with a well-formatted
    message. Asserting on this error message is slightly more complicated.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first option is to reconstruct the error message in the test code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The test code makes use of the `fmt.Sprintf` function to format the expected
    error message using the same format from the call to the `fmt.Errorf` function
    in the `checkOdd` implementation function.
  prefs: []
  type: TYPE_NORMAL
- en: 'This first option has three disadvantages:'
  prefs: []
  type: TYPE_NORMAL
- en: The test code has to repeat the implementation code simply for the purposes
    of verification. This can get complex if the error message requires significant
    setup.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The test code is now tightly coupled to the implementation code. Changing the
    error formatting logic in the implementation code now requires the same change
    in the test code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is no way to ensure that the formatting is replicated in the exact same
    way across test scenarios. This is likely to be a problem in large code bases
    that are maintained by large engineering teams.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The second option is to relax our error verification so that we no longer need
    to completely recreate the error message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The `assert.Contains` function is used to verify that the error message contains
    some substrings, which we can be relatively sure will not change in the implementation
    code. This option has removed the need for full implementation of the error message
    formatting, simplifying our test code.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, this second option also has quite a few disadvantages:'
  prefs: []
  type: TYPE_NORMAL
- en: The error message assertion is not fully verified. For example, the implementation
    could be producing completely nonsense messages and our test will pass as long
    as the strings verified are contained within it. The test would no longer be able
    to assert on the full functionality of the implementation code. Other types of
    testing, such as integration or end-to-end tests, may verify this. However, we
    will explore how to include error assertions in unit tests.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even though it has been reduced, the test code still has some leaked implementation
    knowledge and a hardcoded part of the error message. Therefore, the test is still
    brittle and tightly coupled to its implementation counterpart.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is still no way to ensure that the assertions are performed in the same
    way across tests. In fact, because the expected string is no longer constructed
    during the Arrange part of the test, it can be even more difficult to find the
    hardcoded strings until the test suite points out the failures.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As discussed, both of our two immediate options have significant disadvantages.
    However, as we remember from [*Chapter 4*](B18371_04.xhtml#_idTextAnchor085),
    *Building Efficient Test Suites*, the `error` type is a simple interface with
    only a single method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: We can easily implement our own custom error types by implementing this simple
    function. As we have seen on multiple occasions, the power of interfaces shines
    in many aspects of the Go programming language, and error handling is one of them
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: Custom error types
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The third option for error handling is to create our own custom error types,
    which will allow us to add more information to the error type than simply formatting
    a string multiple times. This will give us flexibility in both implementation
    and test code.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will define a simple `evenNumberError` type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This type has a field for the input of our `checkOdd` function. This will allow
    the test to have access to the input value without having to check the returned
    error message, which was necessary for the first and second options presented
    previously.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we need to add a method to this new type to ensure that it satisfies
    the `error` interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This method has `evenNumberError` as a receiver and the same signature as the
    `error` interface. Inside the method, we use the same format and the `fmt.Sprintf`
    function, together with the `input` field of the receiver.
  prefs: []
  type: TYPE_NORMAL
- en: 'The implementation function can be changed to use this new `error` type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: With the error formatting wrapped inside the `evenNumberError` type, the `return`
    statement of this function simply consists of creating a new instance of this
    type and returning a pointer to it. We pass the parameter from the `checkOdd`
    function to its initialization.
  prefs: []
  type: TYPE_NORMAL
- en: Always return the error interface
  prefs: []
  type: TYPE_NORMAL
- en: One last thing to note is that the `checkOdd` function still returns the `error`
    interface. Therefore, the calling code does not need to have any knowledge of
    the custom error types created in this package. When working with custom error
    types, you should always follow this pattern as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'The test code is much simplified with this new custom `error` type in place:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The implementation of the error verification in this example demonstrates how
    to run verifications on custom `error` types:'
  prefs: []
  type: TYPE_NORMAL
- en: We create an instance of the `evenNumberError` type with the `input` field.
    This is much simpler than having to create an expected error message.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After calling the `checkOdd` function, we need to convert the built-in `error`
    value to the custom `error` type. This is done by using the `errors.As` function,
    which returns `true` if the conversion has been successful.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We use the `require.True` function to ensure that the test fails if the conversion
    fails.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we use the `assert.Equal` function to ensure that the actual error
    is as expected.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The implementation of the test is much simpler, and it is no longer tightly
    coupled to error formatting inside the function under test. This approach does
    have a slight disadvantage in that it creates a new custom type, but working with
    custom `error` types streamlines the implementation code by providing a single,
    unified, way to format errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'We run the test as usual to see our error verification in action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Each test case runs in its subtest, as can be seen from the organized output.
  prefs: []
  type: TYPE_NORMAL
- en: Another advantage of using custom `error` types is that they allow a function
    to return multiple types of errors, which can provide context to callers of a
    given package or service. For now, we should remember that they have the advantage
    of streamlining our test code while providing precise error verification possibilities.
  prefs: []
  type: TYPE_NORMAL
- en: Splitting up the monolith
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The final aspect of refactoring that we will discuss is moving from a monolith
    to a microservice architecture. While there are examples of large companies that
    successfully operate using a monolithic architecture, the consensus in the technical
    community is that a microservice architecture is easier to scale and maintain,
    particularly when working across multiple teams. It is therefore important to
    discuss some of the basics of how and when to split up a service during refactoring.
  prefs: []
  type: TYPE_NORMAL
- en: What is a monolithic application?
  prefs: []
  type: TYPE_NORMAL
- en: A **monolithic application** is a single application that is built and released
    in one unit. The term is typically used to refer to a large application, with
    many different responsibilities that serve many different user journeys.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 7**.5* depicts some of the advantages and disadvantages of monolithic
    applications:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.5 – Pros and cons of monolithic applications ](img/Figure_7.05_B18371.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.5 – Pros and cons of monolithic applications
  prefs: []
  type: TYPE_NORMAL
- en: 'The list of pros and cons of monolithic applications spans from deployment
    to resilience:'
  prefs: []
  type: TYPE_NORMAL
- en: As monoliths are built and deployed in one running application, developers will
    find them **easy to deploy**. However, as all the components are deployed together,
    they also cannot be scaled individually, making the application **harder to scale**.
    This can be a significant bottleneck to how many requests the application can
    handle, affecting a business’s revenue. Scaling the monolith as a whole can also
    be unduly expensive, as all resources are scaled together.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monolithic applications have a lower cognitive burden because all of their code
    lives in one single, searchable code base. At the beginning of the project, developers
    have an easier time developing in one single code base. However, as the project
    progresses and the team grows, the code base becomes constrained by its initial
    architecture, design, and technology choices. Often, this leads to **slower**
    **development speed**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As they only have to start up one application, engineers find monolithic applications
    **simple to test and debug**. However, as all modules are hosted together, **errors
    can cause full outages** of the application. This can again significantly affect
    a business’s revenue.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many organizations start out with a monolithic application when they have a
    small code base and engineering team. Then, as their team and application functionality
    grow, they struggle to scale and maintain their monoliths. A new approach to building
    applications was required to mitigate the disadvantages that come with developing
    code in a monolith.
  prefs: []
  type: TYPE_NORMAL
- en: What is a microservice architecture?
  prefs: []
  type: TYPE_NORMAL
- en: A **microservice architecture** is a system design method that relies on independently
    built and released services, known as **microservices**. These independent units
    have their own responsibilities and self-contained resources for accomplishing
    their goals.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 7**.6* depicts some of the advantages and disadvantages of microservice
    architectures:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.6 – Pros and cons of microservice architectures ](img/Figure_7.06_B18371.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.6 – Pros and cons of microservice architectures
  prefs: []
  type: TYPE_NORMAL
- en: 'The pros of microservice architectures have addressed many of the cons of monolithic
    applications:'
  prefs: []
  type: TYPE_NORMAL
- en: As each microservice is independently deployed, this type of architecture offers
    **flexible scaling**. This allows us to scale one part of the application, according
    to which user journeys are most popular. However, as each service has its own
    dedicated set of resources, microservice architectures can incur **higher** **infrastructure
    costs**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The smaller code bases of the microservices are **easier to maintain**, especially
    when it comes to refactoring. They can also make their own technical choices,
    offering engineers the opportunity to choose the best tool for the goals of each
    microservice. However, the separation between the different code bases does require
    **higher organizational overhead** in order to ensure that the individual units
    function together correctly and follow a unified set of engineering standards.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As each microservice has its own well-defined functionality and responsibilities,
    they require a **smaller scope of tests** to ensure that they are working correctly.
    However, the integration points become the focal point of tests, making integration
    tests more important than ever. When a systemic error happens, each service also
    has its own set of logs, making this type of architecture **more difficult** **to
    debug**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Figure 7**.7* depicts the two system types:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.7 – Monolithic application versus microservice architecture ](img/Figure_7.07_B18371.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.7 – Monolithic application versus microservice architecture
  prefs: []
  type: TYPE_NORMAL
- en: The monolithic application contains all of the components required in one single
    unit and relies on one database. The microservice architecture splits the monolithic
    application according to the functionality that they provide and these functionalities
    depend on each other to deliver the same user journeys as the monolithic application.
  prefs: []
  type: TYPE_NORMAL
- en: As we have seen, neither development approach is perfect. A monolithic application
    may work perfectly well when application traffic is predictable or the team has
    strict architecture design guidelines, but most organizations grow their teams
    and evolve their products. In these circumstances, organizations will usually
    opt for a microservice architecture. Therefore, it is absolutely essential for
    engineers to know how to develop and test microservice architectures.
  prefs: []
  type: TYPE_NORMAL
- en: Key refactoring considerations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many organizations have undertaken the work to split up their monolithic applications
    into microservice architectures. The engineering community has discussed how to
    undertake this journey as painlessly and successfully as possible. We can highlight
    some key considerations for this type of refactoring.
  prefs: []
  type: TYPE_NORMAL
- en: Define boundaries
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In order to be successful, microservices need to have their own domain and have
    well-defined application boundaries. Engineering teams can identify which parts
    of the monolith they should extract, either through analysis or generated dependency
    graphs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on these, they can scope the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The **functionality and models of the domain** that the microservice will be
    responsible for. For example, in an e-commerce application, we might identify
    a service that is responsible for placing and managing items in the shopping cart.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **upstream dependencies** that the microservice will require. For example,
    the previously identified shopping cart service will have a dependency on the
    inventory service, which will tell it how much items cost and whether they are
    in stock.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **downstream dependencies** and data storage solution that the microservice
    will require. For example, the shopping cart service will save its data to an
    in-memory data structure store, such as Redis, and have a downstream dependency
    to a checkout service once the user decides to purchase their cart.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The result of the boundary identification exercise could be a high-level design
    of the infrastructure requirements of the microservice, as well as an overview
    of the API that the microservice will expose to other parts of the system.
  prefs: []
  type: TYPE_NORMAL
- en: Loose coupling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One of the advantages of a microservice architecture is that it allows us to
    build services that are **loosely coupled**, from both a development and deployment
    perspective. However, this advantage can be easily lost if the teams don’t isolate
    inter-service dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: What is a loose coupling for microservices?
  prefs: []
  type: TYPE_NORMAL
- en: In microservice architectures, services are loosely coupled if changes to one
    service’s design or implementation will not cause changes in other services that
    it depends on or that depend on it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Loosely coupled microservices should follow the following rules of thumb:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Have separate data stores**: When microservices share a single database,
    they also share a **single point of failure**. An outage on the shared database
    will cause all of the services that depend on it to fail as well.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use asynchronous communication**: Use asynchronous communication patterns
    such as queues and event buses to pass data to other services. This allows us
    to scale services independently and even batch messages when appropriate.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Implement fault tolerance**: Design your service with the assumption that
    its internal and external dependencies will fail or be slow to respond. A common
    way this is implemented in REST APIs is with the circuit breaker pattern, which
    will time out external calls when patterns of failure are detected in order to
    ensure that your microservice can continue to function, using default values if
    one of its dependencies is no longer available.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Make backward-compatible changes**: Whenever possible, microservice APIs
    should make backward-compatible changes that will not force other services to
    implement changes to their payloads at the same time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Implement request tracing and service monitoring**: In the microservice world,
    it is important to understand how requests flow through your system. This is important
    for detecting errors in your system and identifying services with insufficient
    infrastructure resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Following these rules during microservice design and implementation will help
    you take advantage of the true power of microservices. In [*Chapter 8*](B18371_08.xhtml#_idTextAnchor179),
    *Testing Microservice Architectures*, we will discuss these principles further
    and discuss the challenges of testing microservices and how we need to adjust
    our testing strategy to fit the microservice world.
  prefs: []
  type: TYPE_NORMAL
- en: How will the microservice behave without its dependencies?
  prefs: []
  type: TYPE_NORMAL
- en: Once we have identified the dependencies of a microservice, we should remember
    to design and test for the behavior of the microservice in the case that its dependencies
    encounter an outage. This important part of microservice design, known as **graceful
    degradation**, should not be overlooked.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we tackled the important topic of code refactoring, which is
    a crucial and unavoidable part of extending and maintaining healthy code bases.
    We started by learning some common code refactoring techniques and discussed the
    true cost of technical debt. Then, we revisited the power of interfaces, which
    make it easy to change dependencies and allow us to use the compiler as a guide
    during refactoring.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we considered the test changes that we have to make to our tests to ensure
    that they continue to verify behaviors during two common refactorings: renaming
    structs and changing method signatures. Expanding upon our previous knowledge
    of error handling and verification, we learned how to create custom error types
    and more easily verify error messages.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we learned some of the reasons why organizations move from monolithic
    applications to microservice architectures, and explored some rules of thumb that
    allow us to create loosely coupled microservices.
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 8*](B18371_08.xhtml#_idTextAnchor179), *Testing Microservice Architectures*,
    we will expand on all the concepts we have learned so far and learn what considerations
    should be made when testing microservice architectures. We will apply and demonstrate
    these concepts on our demo application, the `BookSwap` application.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is the difference between code redesign and code refactoring?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Describe the working process of code refactoring.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is technical debt?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a monolithic application? What is a microservice architecture?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Clean Architecture: A Craftsman’s Guide to Software Structure and Design*,
    Robert C. Martin, published by Addison-Wesley'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Refactoring: Improving the Design of Existing Code*, Martin Fowler, published
    by Addison-Wesley Professional'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Building Microservices Second Edition: Designing Fine-Grained Systems*, Sam
    Newman, published by O’Reilly'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Monolith to Microservices: Evolutionary Patterns to Transform Your Monolith*,
    Sam Newman, published by O’Reilly'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
